<html><h3>Pattern ID :1668
</h3><img src='4329410.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        self._cached_h = None
        self._k = k

        <a id="change">if </a>weight<a id="change">:
            </a>self.weight<a id="change"> = </a>nn.Parameter(th.Tensor(in_feats, out_feats))
        else:
            self.register_parameter(&quotweight&quot, None)
</code></pre><h3>After Change</h3><pre><code class='java'>
                 bias=True):
        
        super().__init__()
        <a id="change">if norm not in (&quotnone&quot, &quotboth&quot, &quotright&quot, &quotleft&quot)</a><a id="change">:
            </a><a id="change">raise </a>DGLError(<a id="change">&quotInvalid norm value. Must be either "none", "both", "right" or "left".&quot
                           &quot But got "{}".&quot.format(norm</a><a id="change">)</a>)     
        self._in_feats = in_feats
        self._out_feats<a id="change"> = </a>out_feats            
        self._cached = cached
        self._cached_h = None
        self._k = k
        self._norm = norm
        self._add_self_loop<a id="change"> = </a>add_self_loop

        self.linear = Linear(in_feats, out_feats, weight=weight, bias=bias)
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/edisonleeeee/graphwar/commit/c43665fd30401c63acbd50175da1880509a52d21#diff-4e82f29fd5c78eabd4fe1d5867020e786dc0deb6b867e435c11f46885eaadad4L70' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4329410</div><div id='project'> Project Name: edisonleeeee/graphwar</div><div id='commit'> Commit Name: c43665fd30401c63acbd50175da1880509a52d21</div><div id='time'> Time: 2021-12-06</div><div id='author'> Author: cnljt@outlook.com</div><div id='file'> File Name: graphwar/nn/sgconv.py</div><div id='m_class'> M Class Name: SGConv</div><div id='n_method'> N Class Name: SGConv</div><div id='m_method'> M Method Name: __init__(9)</div><div id='n_method'> N Method Name: __init__(7)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: graphwar/nn/sgconv.py</div><div id='n_file'> N File Name: graphwar/nn/sgconv.py</div><div id='m_start'> M Start Line: 70</div><div id='m_end'> M End Line: 85</div><div id='n_start'> N Start Line: 90</div><div id='n_end'> N End Line: 108</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self._cached_h = None
        self._k = k

        <a id="change">if </a>weight<a id="change">:
            </a>self.weight<a id="change"> = </a>nn.Parameter(th.Tensor(in_feats, out_feats))
        else:
            self.register_parameter(&quotweight&quot, None)
</code></pre><h3>After Change</h3><pre><code class='java'>
                 bias=True):
        
        super().__init__()
        <a id="change">if norm not in (&quotnone&quot, &quotboth&quot, &quotright&quot, &quotleft&quot)</a><a id="change">:
            </a><a id="change">raise </a>DGLError(<a id="change">&quotInvalid norm value. Must be either "none", "both", "right" or "left".&quot
                           &quot But got "{}".&quot.format(</a>norm<a id="change">)</a>)     
        self._in_feats<a id="change"> = </a>in_feats
        self._out_feats = out_feats            
        self._cached = cached
        self._cached_h = None
        self._k = k
        self._norm = norm
        self._add_self_loop<a id="change"> = </a>add_self_loop

        self.linear = Linear(in_feats, out_feats, weight=weight, bias=bias)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/edisonleeeee/graphwar/commit/c43665fd30401c63acbd50175da1880509a52d21#diff-4e82f29fd5c78eabd4fe1d5867020e786dc0deb6b867e435c11f46885eaadad4L63' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4329411</div><div id='project'> Project Name: edisonleeeee/graphwar</div><div id='commit'> Commit Name: c43665fd30401c63acbd50175da1880509a52d21</div><div id='time'> Time: 2021-12-06</div><div id='author'> Author: cnljt@outlook.com</div><div id='file'> File Name: graphwar/nn/sgconv.py</div><div id='m_class'> M Class Name: SGConv</div><div id='n_method'> N Class Name: SGConv</div><div id='m_method'> M Method Name: __init__(9)</div><div id='n_method'> N Method Name: __init__(7)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: graphwar/nn/sgconv.py</div><div id='n_file'> N File Name: graphwar/nn/sgconv.py</div><div id='m_start'> M Start Line: 70</div><div id='m_end'> M End Line: 85</div><div id='n_start'> N Start Line: 90</div><div id='n_end'> N End Line: 108</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                 loss_mask=dict(
                     type=&quotCrossEntropyLoss&quot, use_mask=True, loss_weight=1.0)):
        super(FCNMaskHead, self).__init__()
        <a id="change">if </a>upsample_method not in [None, &quotdeconv&quot, &quotnearest&quot, &quotbilinear&quot]<a id="change">:
            </a>raise ValueError(
                &quotInvalid upsample method {}, accepted methods &quot
                &quotare "deconv", "nearest", "bilinear"&quot.format(upsample_method))
        self.num_convs = num_convs
        &#47&#47 WARN: roi_feat_size is reserved and not used
        self.roi_feat_size = _pair(roi_feat_size)
        self.in_channels = in_channels
        self.conv_kernel_size = conv_kernel_size
        self.conv_out_channels = conv_out_channels
        self.upsample_method = upsample_method
        self.upsample_ratio<a id="change"> = </a>upsample_ratio
        self.num_classes = num_classes
        self.class_agnostic = class_agnostic
        self.conv_cfg = conv_cfg</code></pre><h3>After Change</h3><pre><code class='java'>
                 loss_mask=dict(
                     type=&quotCrossEntropyLoss&quot, use_mask=True, loss_weight=1.0)):
        super(FCNMaskHead, self).__init__()
        <a id="change">self.upsample_cfg</a> = upsample_cfg.copy()
        <a id="change">if self.upsample_cfg[&quottype&quot] not in [
                None, &quotdeconv&quot, &quotnearest&quot, &quotbilinear&quot, &quotcarafe&quot
        ]</a><a id="change">:
            </a><a id="change">raise </a>ValueError(
                <a id="change">&quotInvalid upsample method {}, accepted methods &quot
                &quotare "deconv", "nearest", "bilinear", "carafe"&quot.format(
                    </a>self.upsample_cfg[&quottype&quot]<a id="change">)</a>)
        self.num_convs = num_convs
        &#47&#47 WARN: roi_feat_size is reserved and not used
        self.roi_feat_size = _pair(roi_feat_size)
        self.in_channels = in_channels
        self.conv_kernel_size = conv_kernel_size
        self.conv_out_channels = conv_out_channels
        self.upsample_method = self.upsample_cfg.get(&quottype&quot)
        self.scale_factor<a id="change"> = </a>self.upsample_cfg.pop(&quotscale_factor&quot)
        self.num_classes = num_classes
        self.class_agnostic = class_agnostic
        self.conv_cfg = conv_cfg
        self.norm_cfg = norm_cfg
        self.fp16_enabled = False
        self.loss_mask = build_loss(loss_mask)

        self.convs = nn.ModuleList()
        for i in range(self.num_convs):
            in_channels = (
                self.in_channels if i == 0 else self.conv_out_channels)
            padding = (self.conv_kernel_size - 1) // 2
            self.convs.append(
                ConvModule(
                    in_channels,
                    self.conv_out_channels,
                    self.conv_kernel_size,
                    padding=padding,
                    conv_cfg=conv_cfg,
                    norm_cfg=norm_cfg))
        upsample_in_channels = (
            self.conv_out_channels if self.num_convs &gt; 0 else in_channels)
        upsample_cfg_<a id="change"> = </a>self.upsample_cfg.copy()
        if self.upsample_method is None:
            self.upsample = None
        elif self.upsample_method == &quotdeconv&quot:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/saic-vul/iterdet/commit/b5431092505f7dcd7de616c8a79eba4d2532fbc8#diff-82a2ab843e4fc204629926964b43e16f568eee55dbebb2a9832e4f310aad05c6L17' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4329415</div><div id='project'> Project Name: saic-vul/iterdet</div><div id='commit'> Commit Name: b5431092505f7dcd7de616c8a79eba4d2532fbc8</div><div id='time'> Time: 2020-02-21</div><div id='author'> Author: 1155098160@link.cuhk.edu.hk</div><div id='file'> File Name: mmdet/models/mask_heads/fcn_mask_head.py</div><div id='m_class'> M Class Name: FCNMaskHead</div><div id='n_method'> N Class Name: FCNMaskHead</div><div id='m_method'> M Method Name: __init__(12)</div><div id='n_method'> N Method Name: __init__(13)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: mmdet/models/mask_heads/fcn_mask_head.py</div><div id='n_file'> N File Name: mmdet/models/mask_heads/fcn_mask_head.py</div><div id='m_start'> M Start Line: 23</div><div id='m_end'> M End Line: 76</div><div id='n_start'> N Start Line: 26</div><div id='n_end'> N End Line: 90</div><BR>