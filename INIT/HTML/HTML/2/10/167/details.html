<html><h3>Pattern ID :167
</h3><img src='670762.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                 loss_mask=dict(
                     type=&quotCrossEntropyLoss&quot, use_mask=True, loss_weight=1.0)):
        super(FCNMaskHead, self).__init__()
        <a id="change">if upsample_method not in [None, &quotdeconv&quot, &quotnearest&quot, &quotbilinear&quot]</a><a id="change">:
            </a>raise ValueError(
                &quotInvalid upsample method {}, accepted methods &quot
                &quotare "deconv", "nearest", "bilinear"&quot.format(upsample_method))
        self.num_convs = num_convs
        &#47&#47 WARN: roi_feat_size is reserved and not used
        self.roi_feat_size = _pair(roi_feat_size)
        self.in_channels = in_channels
        self.conv_kernel_size = conv_kernel_size
        self.conv_out_channels = conv_out_channels
        self.upsample_method = upsample_method
        self.upsample_ratio<a id="change"> = </a>upsample_ratio
        self.num_classes = num_classes
        self.class_agnostic = class_agnostic
        self.conv_cfg = conv_cfg</code></pre><h3>After Change</h3><pre><code class='java'>
                     type=&quotCrossEntropyLoss&quot, use_mask=True, loss_weight=1.0)):
        super(FCNMaskHead, self).__init__()
        self.upsample_cfg = upsample_cfg.copy()
        <a id="change">if self.upsample_cfg[&quottype&quot]</a><a id="change"> not in [
                None, &quotdeconv&quot, &quotnearest&quot, &quotbilinear&quot, &quotcarafe&quot
        ]:
            </a>raise ValueError(
                &quotInvalid upsample method {}, accepted methods &quot
                &quotare "deconv", "nearest", "bilinear", "carafe"&quot.format(
                    <a id="change">self.upsample_cfg[&quottype&quot]</a>))
        self.num_convs = num_convs
        &#47&#47 WARN: roi_feat_size is reserved and not used
        self.roi_feat_size = _pair(roi_feat_size)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/shinya7y/universenet/commit/b5431092505f7dcd7de616c8a79eba4d2532fbc8#diff-82a2ab843e4fc204629926964b43e16f568eee55dbebb2a9832e4f310aad05c6L23' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 670762</div><div id='project'> Project Name: shinya7y/universenet</div><div id='commit'> Commit Name: b5431092505f7dcd7de616c8a79eba4d2532fbc8</div><div id='time'> Time: 2020-02-21</div><div id='author'> Author: 1155098160@link.cuhk.edu.hk</div><div id='file'> File Name: mmdet/models/mask_heads/fcn_mask_head.py</div><div id='m_class'> M Class Name: FCNMaskHead</div><div id='n_method'> N Class Name: FCNMaskHead</div><div id='m_method'> M Method Name: __init__(12)</div><div id='n_method'> N Method Name: __init__(13)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: mmdet/models/mask_heads/fcn_mask_head.py</div><div id='n_file'> N File Name: mmdet/models/mask_heads/fcn_mask_head.py</div><div id='m_start'> M Start Line: 23</div><div id='m_end'> M End Line: 76</div><div id='n_start'> N Start Line: 26</div><div id='n_end'> N End Line: 90</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.gcb = gcb
        self.with_gcb = gcb is not None
        self.gen_attention = gen_attention
        self.with_gen_attention = <a id="change">gen_attention is not None</a>

        if self.style == &quotpytorch&quot:
            self.conv1_stride = 1
            self.conv2_stride = stride
        else:
            self.conv1_stride = stride
            self.conv2_stride = 1

        self.norm1_name, norm1 = build_norm_layer(norm_cfg, planes, postfix=1)
        self.norm2_name, norm2 = build_norm_layer(norm_cfg, planes, postfix=2)
        self.norm3_name, norm3 = build_norm_layer(
            norm_cfg, planes * self.expansion, postfix=3)

        self.conv1 = build_conv_layer(
            conv_cfg,
            inplanes,
            planes,
            kernel_size=1,
            stride=self.conv1_stride,
            bias=False)
        self.add_module(self.norm1_name, norm1)
        fallback_on_stride = False
        if self.with_dcn:
            fallback_on_stride = dcn.pop(&quotfallback_on_stride&quot, False)
        if not self.with_dcn or fallback_on_stride:
            self.conv2 = build_conv_layer(
                conv_cfg,
                planes,
                planes,
                kernel_size=3,
                stride=self.conv2_stride,
                padding=dilation,
                dilation=dilation,
                bias=False)
        else:
            assert self.conv_cfg is None, &quotconv_cfg must be None for DCN&quot
            self.conv2 = build_conv_layer(
                dcn,
                planes,
                planes,
                kernel_size=3,
                stride=self.conv2_stride,
                padding=dilation,
                dilation=dilation,
                bias=False)

        self.add_module(self.norm2_name, norm2)
        self.conv3 = build_conv_layer(
            conv_cfg,
            planes,
            planes * self.expansion,
            kernel_size=1,
            bias=False)
        self.add_module(self.norm3_name, norm3)

        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample

        if self.with_gcb:
            gcb_inplanes = planes * self.expansion
            self.context_block = ContextBlock(inplanes=gcb_inplanes, **gcb)

        &#47&#47 gen_attention
        <a id="change">if </a>self.with_gen_attention<a id="change">:
            </a>self.gen_attention_block<a id="change"> = </a>GeneralizedAttention(
                planes, **gen_attention)

    @property</code></pre><h3>After Change</h3><pre><code class='java'>
        if self.with_plugins:
            &#47&#47 collect plugins for conv1/conv2/conv3
            self.after_conv1_plugins = [
                <a id="change">plugin[&quotcfg&quot]</a> for <a id="change">plugin</a> in plugins
                if <a id="change">plugin[&quotposition&quot] == &quotafter_conv1&quot</a>
            ]
            self.after_conv2_plugins = [
                plugin[&quotcfg&quot] for plugin in plugins
                if plugin[&quotposition&quot] == &quotafter_conv2&quot</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/shinya7y/universenet/commit/1cccda2d0bf06094229075828030a8228d71fd28#diff-9e74a787bb65349ba8132ef6e75391c75732620feb72f0ec0283e9913e7afc80L88' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 670763</div><div id='project'> Project Name: shinya7y/universenet</div><div id='commit'> Commit Name: 1cccda2d0bf06094229075828030a8228d71fd28</div><div id='time'> Time: 2020-03-31</div><div id='author'> Author: xvjiarui0826@gmail.com</div><div id='file'> File Name: mmdet/models/backbones/resnet.py</div><div id='m_class'> M Class Name: Bottleneck</div><div id='n_method'> N Class Name: Bottleneck</div><div id='m_method'> M Method Name: __init__(12)</div><div id='n_method'> N Method Name: __init__(13)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: mmdet/models/backbones/resnet.py</div><div id='n_file'> N File Name: mmdet/models/backbones/resnet.py</div><div id='m_start'> M Start Line: 100</div><div id='m_end'> M End Line: 192</div><div id='n_start'> N Start Line: 105</div><div id='n_end'> N End Line: 200</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                 loss_mask=dict(
                     type=&quotCrossEntropyLoss&quot, use_mask=True, loss_weight=1.0)):
        super(FCNMaskHead, self).__init__()
        <a id="change">if upsample_method not in [None, &quotdeconv&quot, &quotnearest&quot, &quotbilinear&quot]</a><a id="change">:
            </a>raise ValueError(
                &quotInvalid upsample method {}, accepted methods &quot
                &quotare "deconv", "nearest", "bilinear"&quot.format(upsample_method))
        self.num_convs = num_convs
        &#47&#47 WARN: roi_feat_size is reserved and not used
        self.roi_feat_size = _pair(roi_feat_size)
        self.in_channels = in_channels
        self.conv_kernel_size = conv_kernel_size
        self.conv_out_channels = conv_out_channels
        self.upsample_method = upsample_method
        self.upsample_ratio = upsample_ratio
        self.num_classes = num_classes
        self.class_agnostic = class_agnostic
        self.conv_cfg = conv_cfg
        self.norm_cfg = norm_cfg
        self.fp16_enabled = False
        self.loss_mask = build_loss(loss_mask)

        self.convs = nn.ModuleList()
        for i in range(self.num_convs):
            in_channels = (
                self.in_channels if i == 0 else self.conv_out_channels)
            padding = (self.conv_kernel_size - 1) // 2
            self.convs.append(
                ConvModule(
                    in_channels,
                    self.conv_out_channels,
                    self.conv_kernel_size,
                    padding=padding,
                    conv_cfg=conv_cfg,
                    norm_cfg=norm_cfg))
        upsample_in_channels = (
            self.conv_out_channels if self.num_convs &gt; 0 else in_channels)
        if self.upsample_method is None:
            self.upsample = None
        elif self.upsample_method == &quotdeconv&quot:
            self.upsample<a id="change"> = </a>nn.ConvTranspose2d(
                upsample_in_channels,
                self.conv_out_channels,
                self.upsample_ratio,</code></pre><h3>After Change</h3><pre><code class='java'>
                 loss_mask=dict(
                     type=&quotCrossEntropyLoss&quot, use_mask=True, loss_weight=1.0)):
        super(FCNMaskHead, self).__init__()
        <a id="change">self.upsample_cfg</a> = upsample_cfg.copy()
        <a id="change">if </a><a id="change">self.upsample_cfg[&quottype&quot] not in [
                None, &quotdeconv&quot, &quotnearest&quot, &quotbilinear&quot, &quotcarafe&quot
        ]:
            </a>raise ValueError(
                &quotInvalid upsample method {}, accepted methods &quot
                &quotare "deconv", "nearest", "bilinear", "carafe"&quot.format(
                    <a id="change">self.upsample_cfg[&quottype&quot]</a>))
        self.num_convs = num_convs
        &#47&#47 WARN: roi_feat_size is reserved and not used
        self.roi_feat_size = _pair(roi_feat_size)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/saic-vul/iterdet/commit/b5431092505f7dcd7de616c8a79eba4d2532fbc8#diff-82a2ab843e4fc204629926964b43e16f568eee55dbebb2a9832e4f310aad05c6L17' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 670761</div><div id='project'> Project Name: saic-vul/iterdet</div><div id='commit'> Commit Name: b5431092505f7dcd7de616c8a79eba4d2532fbc8</div><div id='time'> Time: 2020-02-21</div><div id='author'> Author: 1155098160@link.cuhk.edu.hk</div><div id='file'> File Name: mmdet/models/mask_heads/fcn_mask_head.py</div><div id='m_class'> M Class Name: FCNMaskHead</div><div id='n_method'> N Class Name: FCNMaskHead</div><div id='m_method'> M Method Name: __init__(12)</div><div id='n_method'> N Method Name: __init__(13)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: mmdet/models/mask_heads/fcn_mask_head.py</div><div id='n_file'> N File Name: mmdet/models/mask_heads/fcn_mask_head.py</div><div id='m_start'> M Start Line: 23</div><div id='m_end'> M End Line: 76</div><div id='n_start'> N Start Line: 26</div><div id='n_end'> N End Line: 90</div><BR>