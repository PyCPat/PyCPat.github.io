<html><h3>Pattern ID :872
</h3><img src='2789194.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        super().__init__()

        inner_dim = int(dim * ff_mult)
        <a id="change">if </a>ffn_type == "GEGLU"<a id="change">:
            </a>self.net = nn.Sequential(
                GEGLU(dim, inner_dim),
                nn.Dropout(dropout),
                nn.Linear(inner_dim, dim)
            )
        elif ffn_type == "standard":
            self.net = nn.Sequential(
                nn.Linear(dim, inner_dim),
                nn.GELU(),
                <a id="change">nn.Dropout(</a>dropout<a id="change">)</a>,
                nn.Linear(inner_dim, dim)
            )
        elif ffn_type == "bilinear":</code></pre><h3>After Change</h3><pre><code class='java'>

        self.heads = heads

        rows = <a id="change">[]</a>
        for i in range(max_length):  &#47&#47 build the full Alibi relative position bias matrix
            rows.append(torch.LongTensor([x for x in range(0 - i, max_length - i)]).view(1, -1).abs())

        &#47&#47 This implementation alternates between upper triangular and lower triangular biases. Using the full matrix</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/antofuller/configaformers/commit/f2fa8c59ce1537b400a3288f9c556e84ca993807#diff-fcf59ce11a888c8312fa1547129217a783407a793109b95d67b265e47d08375bL17' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2789194</div><div id='project'> Project Name: antofuller/configaformers</div><div id='commit'> Commit Name: f2fa8c59ce1537b400a3288f9c556e84ca993807</div><div id='time'> Time: 2021-09-04</div><div id='author'> Author: afuller187187@gmail.com</div><div id='file'> File Name: building_blocks.py</div><div id='m_class'> M Class Name: FeedForward</div><div id='n_method'> N Class Name: Alibi</div><div id='m_method'> M Method Name: __init__(3)</div><div id='n_method'> N Method Name: __init__(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: building_blocks.py</div><div id='n_file'> N File Name: building_blocks.py</div><div id='m_start'> M Start Line: 58</div><div id='m_end'> M End Line: 103</div><div id='n_start'> N Start Line: 17</div><div id='n_end'> N End Line: 57</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.norm2 = nn.LayerNorm(d_model)

        &#47&#47 obj self attention
        <a id="change">if </a>obj_self_attn<a id="change">:
            </a>self.self_attn_obj = nn.MultiheadAttention(d_model, n_heads, dropout=dropout)
            self.dropout_obj = <a id="change">nn.Dropout(</a>dropout<a id="change">)</a>
            self.norm_obj = nn.LayerNorm(d_model)
            self.obj_attn_mask = self.generate_obj_attn_mask()

        &#47&#47 ffn</code></pre><h3>After Change</h3><pre><code class='java'>
        self.anchors = anchors

        self.shapes = {
            &quotP0&quot: <a id="change">[</a>160, 160, 256<a id="change"></a>],
            &quotP1&quot: [80, 80, 128],
            &quotP2&quot: [40, 40, 64],
            &quotP3&quot: [20, 20, 32],</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/bwittmann/transoar/commit/93490790c06b3fe20dfd1eae015b8d79f8fd627a#diff-46296950c0873e06db813f2eb25910c85d79a555ca8fbaddd81bde89454be936L147' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2789195</div><div id='project'> Project Name: bwittmann/transoar</div><div id='commit'> Commit Name: 93490790c06b3fe20dfd1eae015b8d79f8fd627a</div><div id='time'> Time: 2022-05-25</div><div id='author'> Author: bastian.wittmann@tum.de</div><div id='file'> File Name: transoar/models/necks/focused_decoder.py</div><div id='m_class'> M Class Name: FocusedDecoderLayer</div><div id='n_method'> N Class Name: FocusedDecoderLayer</div><div id='m_method'> M Method Name: __init__(10)</div><div id='n_method'> N Method Name: __init__(8)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: transoar/models/necks/focused_decoder.py</div><div id='n_file'> N File Name: transoar/models/necks/focused_decoder.py</div><div id='m_start'> M Start Line: 155</div><div id='m_end'> M End Line: 179</div><div id='n_start'> N Start Line: 99</div><div id='n_end'> N End Line: 117</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if normalize:
            layers.append(nn.InstanceNorm2d(out_size))
        layers.append(nn.LeakyReLU(0.2))
        <a id="change">if </a>dropout<a id="change">:
            </a>layers.append(<a id="change">nn.Dropout(</a>dropout<a id="change">)</a>)
        self.model = nn.Sequential(*layers)

    def forward(self, x):</code></pre><h3>After Change</h3><pre><code class='java'>
class UnetDown(nn.Module):
    def __init__(self, in_size, out_size):
        super(UnetDown, self).__init__()
        layers = <a id="change">[</a>Conv3(in_size, out_size), nn.MaxPool2d(2)<a id="change"></a>]
        self.model = nn.Sequential(*layers)

    def forward(self, x):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/cloneofsimo/mindiffusion/commit/c84221717042f2235d39ab9be621950aa55208f2#diff-ebddb7bc7cae3150fbd132ca1aa04e771b76ca1be6686541f7a01475a049fd70L10' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2789205</div><div id='project'> Project Name: cloneofsimo/mindiffusion</div><div id='commit'> Commit Name: c84221717042f2235d39ab9be621950aa55208f2</div><div id='time'> Time: 2022-04-15</div><div id='author'> Author: cloneofsimo@gmail.com</div><div id='file'> File Name: mindiffusion/unet.py</div><div id='m_class'> M Class Name: UnetDown</div><div id='n_method'> N Class Name: UnetDown</div><div id='m_method'> M Method Name: __init__(3)</div><div id='n_method'> N Method Name: __init__(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: mindiffusion/unet.py</div><div id='n_file'> N File Name: mindiffusion/unet.py</div><div id='m_start'> M Start Line: 10</div><div id='m_end'> M End Line: 18</div><div id='n_start'> N Start Line: 29</div><div id='n_end'> N End Line: 31</div><BR>