<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        super().__init__()

        inner_dim = int(dim * ff_mult)
        <a id="change">if </a>ffn_type == "GEGLU"<a id="change">:
            </a>self.net = nn.Sequential(
                GEGLU(dim, inner_dim),
                nn.Dropout(dropout),
                nn.Linear(inner_dim, dim)
            )
        elif ffn_type == "standard":
            self.net = nn.Sequential(
                nn.Linear(dim, inner_dim),
                nn.GELU(),
                <a id="change">nn.Dropout(</a>dropout<a id="change">)</a>,
                nn.Linear(inner_dim, dim)
            )
        elif ffn_type == "bilinear":</code></pre><h3>After Change</h3><pre><code class='java'>

        self.heads = heads

        rows = <a id="change">[]</a>
        for i in range(max_length):  &#47&#47 build the full Alibi relative position bias matrix
            rows.append(torch.LongTensor([x for x in range(0 - i, max_length - i)]).view(1, -1).abs())

        &#47&#47 This implementation alternates between upper triangular and lower triangular biases. Using the full matrix</code></pre>