<html><h3>Pattern ID :1609
</h3><img src='4196821.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            self.make_windows: bool = True
        &#47&#47 Init normalization layers
        self.normalization_1: nn.Module = norm_layer(normalized_shape=in_channels)
        self.normalization_2<a id="change">: nn.Module = </a><a id="change">norm_layer(normalized_shape=in_channels)</a>
        &#47&#47 Init window attention module
        self.window_attention: WindowMultiHeadAttention = WindowMultiHeadAttention(
            in_features=in_channels,
            window_size=self.window_size,</code></pre><h3>After Change</h3><pre><code class='java'>
        super(SwinTransformerBlock, self).__init__()
        self.dim: int = dim
        self.feat_size: Tuple[int, int] = feat_size
        self.target_shift_size: Tuple[int, int] = <a id="change">to_2tuple(</a>shift_size<a id="change">)</a>
        self.window_size, self.shift_size = self._calc_window_shift(to_2tuple(window_size))
        self.window_area = self.window_size[0] * self.window_size[1]

        &#47&#47 attn branch</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/feng-lab/pytorch-image-models/commit/c6e4b7895a7dbcd9b98396cbef383dd1c72b0ad3#diff-ed4e73b2f003b1bf594949d63e8066b203ff134a32665c27fe72e45e3a6607afL298' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4196821</div><div id='project'> Project Name: feng-lab/pytorch-image-models</div><div id='commit'> Commit Name: c6e4b7895a7dbcd9b98396cbef383dd1c72b0ad3</div><div id='time'> Time: 2022-02-23</div><div id='author'> Author: rwightman@gmail.com</div><div id='file'> File Name: timm/models/swin_transformer_v2_cr.py</div><div id='m_class'> M Class Name: SwinTransformerBlock</div><div id='n_method'> N Class Name: SwinTransformerBlock</div><div id='m_method'> M Method Name: __init__(13)</div><div id='n_method'> N Method Name: __init__(12)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: timm/models/swin_transformer_v2_cr.py</div><div id='n_file'> N File Name: timm/models/swin_transformer_v2_cr.py</div><div id='m_start'> M Start Line: 412</div><div id='m_end'> M End Line: 454</div><div id='n_start'> N Start Line: 298</div><div id='n_end'> N End Line: 342</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                               use_checkpoint=use_checkpoint)
            self.layers.append(layer)

        self.norm<a id="change"> = </a><a id="change">norm_layer(</a>self.num_features<a id="change">)</a>
        self.avgpool = nn.AdaptiveAvgPool1d(1)
        self.head = nn.Linear(self.num_features, num_classes) if num_classes &gt; 0 else nn.Identity()

        self.apply(self._init_weights)</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 absolute position embedding
        if self.ape:
            pretrain_img_size = to_2tuple(pretrain_img_size)
            patch_size = <a id="change">to_2tuple(</a>patch_size<a id="change">)</a>
            patches_resolution = [pretrain_img_size[0] // patch_size[0], pretrain_img_size[1] // patch_size[1]]

            self.absolute_pos_embed = nn.Parameter(torch.zeros(1, embed_dim, patches_resolution[0], patches_resolution[1]))
            trunc_normal_(self.absolute_pos_embed, std=.02)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/plemeri/inspyrenet/commit/12b05eaf235665fc6d1f89a9055b84d7cdfec923#diff-bfa9144b84aa2908523fe6e28d0f355d5701af250801acefca0ffbeed05bc3dfL483' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4196824</div><div id='project'> Project Name: plemeri/inspyrenet</div><div id='commit'> Commit Name: 12b05eaf235665fc6d1f89a9055b84d7cdfec923</div><div id='time'> Time: 2021-10-14</div><div id='author'> Author: taehoon1018@postech.ac.kr</div><div id='file'> File Name: lib/backbones/SwinTransformer.py</div><div id='m_class'> M Class Name: SwinTransformer</div><div id='n_method'> N Class Name: SwinTransformer</div><div id='m_method'> M Method Name: __init__(20)</div><div id='n_method'> N Method Name: __init__(19)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: lib/backbones/SwinTransformer.py</div><div id='n_file'> N File Name: lib/backbones/SwinTransformer.py</div><div id='m_start'> M Start Line: 483</div><div id='m_end'> M End Line: 539</div><div id='n_start'> N Start Line: 489</div><div id='n_end'> N End Line: 549</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 Classification head(s).
        if not self.return_interm_layers:
            self.norm1<a id="change"> = </a><a id="change">norm_layer(</a>embed_dims[0]<a id="change">)</a>
            self.norm2 = norm_layer(embed_dims[1])
            self.norm3 = norm_layer(embed_dims[2])
            self.norm4 = norm_layer(embed_dims[3])
</code></pre><h3>After Change</h3><pre><code class='java'>
        self.num_classes = num_classes

        &#47&#47 Patch embeddings.
        img_size = <a id="change">to_2tuple(</a>img_size<a id="change">)</a>
        self.patch_embed1 = PatchEmbed(
            img_size=img_size, patch_size=patch_size, in_chans=in_chans,
            embed_dim=embed_dims[0], norm_layer=nn.LayerNorm)
        self.patch_embed2 = PatchEmbed(</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/feng-lab/pytorch-image-models/commit/bfc72f75d3f836ca5545cbe6ec1f8ba67b804b8b#diff-515038d09601bfcc6d6f3a526f98449b70f4b62595ddd47708355d5fa9891311L333' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4196831</div><div id='project'> Project Name: feng-lab/pytorch-image-models</div><div id='commit'> Commit Name: bfc72f75d3f836ca5545cbe6ec1f8ba67b804b8b</div><div id='time'> Time: 2021-05-24</div><div id='author'> Author: rwightman@gmail.com</div><div id='file'> File Name: timm/models/coat.py</div><div id='m_class'> M Class Name: CoaT</div><div id='n_method'> N Class Name: CoaT</div><div id='m_method'> M Method Name: __init__(18)</div><div id='n_method'> N Method Name: __init__(19)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: timm/models/coat.py</div><div id='n_file'> N File Name: timm/models/coat.py</div><div id='m_start'> M Start Line: 335</div><div id='m_end'> M End Line: 439</div><div id='n_start'> N Start Line: 341</div><div id='n_end'> N End Line: 438</div><BR>