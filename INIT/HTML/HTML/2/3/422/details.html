<html><h3>Pattern ID :422
</h3><img src='1269475.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        get_latent_attn = lambda: PreNorm(latent_dim, Attention(latent_dim, heads = latent_heads, dim_head = latent_dim_head))
        get_latent_ff = lambda: PreNorm(latent_dim, FeedForward(latent_dim))

        get_cross_attn<a id="change">, get_cross_ff, get_latent_attn, get_latent_ff</a> = map(cache_fn, (get_cross_attn, get_cross_ff, get_latent_attn, get_latent_ff))

        self.layers = nn.ModuleList([])
        for i in range(depth):</code></pre><h3>After Change</h3><pre><code class='java'>

        get_latent_attn = lambda: PreNorm(latent_dim, Attention(latent_dim, heads = latent_heads, dim_head = latent_dim_head))
        get_latent_ff = lambda: PreNorm(latent_dim, FeedForward(latent_dim))
        get_latent_attn<a id="change">, get_latent_ff = </a><a id="change">map(</a>cache_fn, (get_latent_attn, get_latent_ff)<a id="change">)</a>

        self.layers = nn.ModuleList([])
        cache_args = {&quot_cache&quot: weight_tie_layers}
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lucidrains/perceiver-pytorch/commit/dc530de88e6035a2f08d7e35ce23e57abe8371bd#diff-d109c4942e7a2f6d51cd8e55cbab114efc5eb0b0ce37d8e682449385df84ec13L125' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 1269475</div><div id='project'> Project Name: lucidrains/perceiver-pytorch</div><div id='commit'> Commit Name: dc530de88e6035a2f08d7e35ce23e57abe8371bd</div><div id='time'> Time: 2021-08-30</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: perceiver_pytorch/perceiver_io.py</div><div id='m_class'> M Class Name: PerceiverIO</div><div id='n_method'> N Class Name: PerceiverIO</div><div id='m_method'> M Method Name: __init__(1)</div><div id='n_method'> N Method Name: __init__(1)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: perceiver_pytorch/perceiver_io.py</div><div id='n_file'> N File Name: perceiver_pytorch/perceiver_io.py</div><div id='m_start'> M Start Line: 126</div><div id='m_end'> M End Line: 152</div><div id='n_start'> N Start Line: 125</div><div id='n_end'> N End Line: 143</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        get_latent_ff = lambda: PreNorm(latent_dim, FeedForward(latent_dim, dropout = ff_dropout))

        if weight_tie_layers:
            get_cross_attn<a id="change">, get_cross_ff, get_rev_cross_attn, get_rev_cross_ff, get_latent_attn, get_latent_ff</a> = map(cache_fn, (get_cross_attn, get_cross_ff, get_rev_cross_attn, get_rev_cross_ff, get_latent_attn, get_latent_ff))

        self.layers = nn.ModuleList([])
        for _ in range(depth):</code></pre><h3>After Change</h3><pre><code class='java'>
        get_latent_ff = lambda: PreNorm(latent_dim, FeedForward(latent_dim, dropout = ff_dropout))

        if weight_tie_layers:
            get_cross_attn<a id="change">, get_cross_ff, get_rev_cross_attn, get_rev_cross_ff, get_input_attn, get_latent_attn, get_latent_ff = </a><a id="change">map(</a>cache_fn, (get_cross_attn, get_cross_ff, get_rev_cross_attn, get_rev_cross_ff, get_input_attn, get_latent_attn, get_latent_ff)<a id="change">)</a>

        self.layers = nn.ModuleList([])
        for _ in range(depth):
            self.layers.append(nn.ModuleList([</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/perceiver-pytorch/commit/10a83b0c27f1bf9d0018a1d968a2fa397d8888c9#diff-921b578124ebde37a48a8f5810976c291bc063e74f7eb46ee1fc419b201330a7L15' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 1269477</div><div id='project'> Project Name: lucidrains/perceiver-pytorch</div><div id='commit'> Commit Name: 10a83b0c27f1bf9d0018a1d968a2fa397d8888c9</div><div id='time'> Time: 2021-03-22</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: perceiver_pytorch/experimental.py</div><div id='m_class'> M Class Name: Perceiver</div><div id='n_method'> N Class Name: Perceiver</div><div id='m_method'> M Method Name: __init__(1)</div><div id='n_method'> N Method Name: __init__(1)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: perceiver_pytorch/experimental.py</div><div id='n_file'> N File Name: perceiver_pytorch/experimental.py</div><div id='m_start'> M Start Line: 49</div><div id='m_end'> M End Line: 61</div><div id='n_start'> N Start Line: 87</div><div id='n_end'> N End Line: 107</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        input_size = (dim * self.num_categories) + num_continuous
        l = input_size // 8
        mult1<a id="change">, mult2</a> = mlp_hidden_mults

        self.mlp = nn.Sequential(
            nn.Linear(input_size, l * mult1),</code></pre><h3>After Change</h3><pre><code class='java'>
        input_size = (dim * self.num_categories) + num_continuous
        l = input_size // 8

        hidden_dimensions<a id="change"> = </a>list(<a id="change">map(</a>lambda t: l * t, mlp_hidden_mults<a id="change">)</a>)
        all_dimensions = [input_size, *hidden_dimensions, dim_out]
        self.mlp = MLP(all_dimensions)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/tab-transformer-pytorch/commit/474d9654d739c8004502c08a49ba6fed51afadb6#diff-d87dc12538c5ed85349330c1ea686aed85875355e3b485c6d2ab4ae1d54231c6L75' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 1269471</div><div id='project'> Project Name: lucidrains/tab-transformer-pytorch</div><div id='commit'> Commit Name: 474d9654d739c8004502c08a49ba6fed51afadb6</div><div id='time'> Time: 2020-12-18</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: tab_transformer_pytorch/tab_transformer_pytorch.py</div><div id='m_class'> M Class Name: TabTransformer</div><div id='n_method'> N Class Name: TabTransformer</div><div id='m_method'> M Method Name: __init__(1)</div><div id='n_method'> N Method Name: __init__(1)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: tab_transformer_pytorch/tab_transformer_pytorch.py</div><div id='n_file'> N File Name: tab_transformer_pytorch/tab_transformer_pytorch.py</div><div id='m_start'> M Start Line: 90</div><div id='m_end'> M End Line: 134</div><div id='n_start'> N Start Line: 145</div><div id='n_end'> N End Line: 150</div><BR>