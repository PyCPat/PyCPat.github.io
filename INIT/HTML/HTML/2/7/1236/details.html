<html><h3>Pattern ID :1236
</h3><img src='3429172.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                 cached=False,
                 weight=True,
                 bias=True):
        <a id="change">super(</a>SGConv, self<a id="change">)</a>.__init__()
        self._cached = cached
        self._cached_h = None
        self._k = k</code></pre><h3>After Change</h3><pre><code class='java'>
                 bias=True):
        
        super().__init__()
        <a id="change">if norm not in (&quotnone&quot, &quotboth&quot, &quotright&quot, &quotleft&quot)</a><a id="change">:
            raise </a>DGLError(&quotInvalid norm value. Must be either "none", "both", "right" or "left".&quot
                           &quot But got "{}".&quot.format(norm))     
        self._in_feats<a id="change"> = </a>in_feats
        self._out_feats = out_feats            
        self._cached = cached
        self._cached_h = None
        self._k = k
        self._norm = norm
        self._add_self_loop<a id="change"> = </a>add_self_loop

        self.linear<a id="change"> = </a>Linear(in_feats, out_feats, weight=weight, bias=bias)

    def reset_parameters(self):
        Reinitialize learnable parameters.</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/edisonleeeee/graphwar/commit/c43665fd30401c63acbd50175da1880509a52d21#diff-4e82f29fd5c78eabd4fe1d5867020e786dc0deb6b867e435c11f46885eaadad4L70' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 3429172</div><div id='project'> Project Name: edisonleeeee/graphwar</div><div id='commit'> Commit Name: c43665fd30401c63acbd50175da1880509a52d21</div><div id='time'> Time: 2021-12-06</div><div id='author'> Author: cnljt@outlook.com</div><div id='file'> File Name: graphwar/nn/sgconv.py</div><div id='m_class'> M Class Name: SGConv</div><div id='n_method'> N Class Name: SGConv</div><div id='m_method'> M Method Name: __init__(9)</div><div id='n_method'> N Method Name: __init__(7)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: graphwar/nn/sgconv.py</div><div id='n_file'> N File Name: graphwar/nn/sgconv.py</div><div id='m_start'> M Start Line: 70</div><div id='m_end'> M End Line: 85</div><div id='n_start'> N Start Line: 90</div><div id='n_end'> N End Line: 108</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        steps (int): The total number of convs in this module, 1 conv 1x1 and (steps - 1) conv3x3.
    
    def __init__(self, in_channels: int, out_channels: int, steps: int, stride: int = 1):
        <a id="change">super(</a>STDCBlock, self<a id="change">)</a>.__init__()
        assert steps in [2, 3, 4], f"only 2, 3, 4 steps number are supported, found: {steps}"

        self.stride = stride</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 build first step conv 1x1.
        self.conv_list.append(ConvBNReLU(in_channels, out_channels // 2, kernel_size=1, bias=False))
        &#47&#47 build skip connection after first convolution.
        <a id="change">if stride == 1</a><a id="change">:
            </a>self.skip_step1<a id="change"> = </a>nn.Identity()
        elif stdc_downsample_mode == "avg_pool":
            self.skip_step1<a id="change"> = </a>nn.AvgPool2d(kernel_size=3, stride=2, padding=1)
        elif stdc_downsample_mode == "dw_conv":
            self.skip_step1<a id="change"> = </a>ConvBNReLU(
                out_channels // 2, out_channels // 2, kernel_size=3, stride=2, padding=1, bias=False, groups=out_channels // 2, use_activation=False
            )
        else:
            <a id="change">raise </a>ValueError(f"stdc_downsample mode is not supported: found {stdc_downsample_mode}," f" must be in [avg_pool, dw_conv]")

        in_channels = out_channels // 2
        mid_channels = in_channels</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/deci-ai/super-gradients/commit/98083d4303f887cb29f39029871612fe5e2e4753#diff-8f12293ee8d59da4f2d8522208a7f27d9b4f90502789d26e213681b949e5a90cL33' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 3429127</div><div id='project'> Project Name: deci-ai/super-gradients</div><div id='commit'> Commit Name: 98083d4303f887cb29f39029871612fe5e2e4753</div><div id='time'> Time: 2022-11-02</div><div id='author'> Author: 88616312+lkdci@users.noreply.github.com</div><div id='file'> File Name: src/super_gradients/training/models/segmentation_models/stdc.py</div><div id='m_class'> M Class Name: STDCBlock</div><div id='n_method'> N Class Name: STDCBlock</div><div id='m_method'> M Method Name: __init__(6)</div><div id='n_method'> N Method Name: __init__(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/super_gradients/training/models/segmentation_models/stdc.py</div><div id='n_file'> N File Name: src/super_gradients/training/models/segmentation_models/stdc.py</div><div id='m_start'> M Start Line: 34</div><div id='m_end'> M End Line: 43</div><div id='n_start'> N Start Line: 29</div><div id='n_end'> N End Line: 53</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    expansion = 1

    def __init__(self, in_planes, planes, stride=1):
        <a id="change">super(</a>BasicBlock, self<a id="change">)</a>.__init__()
        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(planes)
        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)</code></pre><h3>After Change</h3><pre><code class='java'>
        super().__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        <a id="change">if </a>groups != 1 or <a id="change">base_width != 64</a><a id="change">:
            raise </a>ValueError("BasicBlock only supports groups=1 and base_width=64")
        if dilation &gt; 1:
            raise NotImplementedError("Dilation &gt; 1 not supported in BasicBlock")
        &#47&#47 Both self.conv1 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.bn1 = norm_layer(planes)
        self.relu<a id="change"> = </a>nn.ReLU(inplace=True)
        self.conv2 = conv3x3(planes, planes)
        self.bn2 = norm_layer(planes)
        self.downsample<a id="change"> = </a>downsample
        self.stride<a id="change"> = </a>stride

    def forward(self, x: Tensor) -&gt; Tensor:
        identity = x</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/decile-team/cords/commit/931f2dbbb853ea9beb25e72b69e473c0365e60ca#diff-580e0813097d831f8f05a21aa69ba247d29cf468b66c336c92f2ad30fa9aa7d9L17' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 3429180</div><div id='project'> Project Name: decile-team/cords</div><div id='commit'> Commit Name: 931f2dbbb853ea9beb25e72b69e473c0365e60ca</div><div id='time'> Time: 2023-02-04</div><div id='author'> Author: 61333497+krishnatejakk@users.noreply.github.com</div><div id='file'> File Name: cords/utils/models/resnet.py</div><div id='m_class'> M Class Name: BasicBlock</div><div id='n_method'> N Class Name: BasicBlock</div><div id='m_method'> M Method Name: __init__(9)</div><div id='n_method'> N Method Name: __init__(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: cords/utils/models/resnet.py</div><div id='n_file'> N File Name: cords/utils/models/resnet.py</div><div id='m_start'> M Start Line: 17</div><div id='m_end'> M End Line: 31</div><div id='n_start'> N Start Line: 66</div><div id='n_end'> N End Line: 90</div><BR>