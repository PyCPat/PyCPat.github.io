<html><h3>Pattern ID :1686
</h3><img src='4344938.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        assert self.gate_type == &quotfeatures&quot or self.gate_type == &quotheads&quot, f&quotGate type must be "features" or "heads"!&quot

        &#47&#47 Initialize gate to 1
        <a id="change">if self.gate_type == &quotfeatures&quot</a><a id="change">:
            </a>self.scale<a id="change"> = </a>nn.Parameter(torch.ones((input_shape[-1],)), requires_grad=True).view(1, 1, input_shape[-1])
        elif <a id="change">self.gate_type == &quotheads&quot</a><a id="change">:
            </a>self.scale<a id="change"> = </a>nn.Parameter(torch.ones((input_shape[1],)), requires_grad=True).view(1, input_shape[1], 1, 1)
            self.scale = self.scale.repeat(1, 1, 1, input_shape[-1])

        &#47&#47 Prepare streams info</code></pre><h3>After Change</h3><pre><code class='java'>

        self.input_shape = _streams[self.input_name]
        assert self.dim_to_scale &gt; 0, f&quotdim_to_scale must be greater than 0!&quot
        <a id="change">assert </a>self.dim_to_scale &lt;= len(self.input_shape), f&quotdim_to_scale must less than or equal to the number of &quot \
                                                           f&quotinput dimensions!&quot
        num_params = self.input_shape[self.dim_to_scale]
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/antofuller/configaformers/commit/587753fa0f50da143bb3a3ad4da1d65e3ee72c60#diff-6104623d9ae05ae1c0cef36e79e444ecc0b3952216b46ead35c829eae2cb8557L106' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4344938</div><div id='project'> Project Name: antofuller/configaformers</div><div id='commit'> Commit Name: 587753fa0f50da143bb3a3ad4da1d65e3ee72c60</div><div id='time'> Time: 2021-11-11</div><div id='author'> Author: afuller187187@gmail.com</div><div id='file'> File Name: norm_module.py</div><div id='m_class'> M Class Name: Gate</div><div id='n_method'> N Class Name: Gate</div><div id='m_method'> M Method Name: __init__(3)</div><div id='n_method'> N Method Name: __init__(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: norm_module.py</div><div id='n_file'> N File Name: norm_module.py</div><div id='m_start'> M Start Line: 106</div><div id='m_end'> M End Line: 123</div><div id='n_start'> N Start Line: 106</div><div id='n_end'> N End Line: 129</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.combining_operation = combining_operation

        &#47&#47 define function for permutation invariant embedding
        <a id="change">if combining_operation == "mean"</a><a id="change">:
            </a>self.combining_function<a id="change"> = </a>torch.mean
        elif <a id="change">self.combining_operation == "sum"</a><a id="change">:
            </a>self.combining_function<a id="change"> = </a>torch.sum
        else:
            raise ValueError("combining_operation must be in [&quotsum&quot, &quotmean&quot].")
</code></pre><h3>After Change</h3><pre><code class='java'>
        super().__init__()
        self.trial_net = trial_net
        self.aggregation_dim = aggregation_dim
        <a id="change">assert </a>aggregation_fn in [
            "mean",
            "sum",
        ], "aggregation_fn must be &quotmean&quot or &quotsum&quot."</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mackelab/sbi/commit/3831fd6d5fda0ca050db8c54868ed30558451042#diff-672ba10e6c3065a6f5554033b9b173c4fe88f4c05ffc31c70a9198691e6c6659L215' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4344937</div><div id='project'> Project Name: mackelab/sbi</div><div id='commit'> Commit Name: 3831fd6d5fda0ca050db8c54868ed30558451042</div><div id='time'> Time: 2023-03-01</div><div id='author'> Author: jan.boelts@tum.de</div><div id='file'> File Name: sbi/neural_nets/embedding_nets.py</div><div id='m_class'> M Class Name: PermutationInvariantEmbedding</div><div id='n_method'> N Class Name: PermutationInvariantEmbedding</div><div id='m_method'> M Method Name: __init__(8)</div><div id='n_method'> N Method Name: __init__(7)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: sbi/neural_nets/embedding_nets.py</div><div id='n_file'> N File Name: sbi/neural_nets/embedding_nets.py</div><div id='m_start'> M Start Line: 219</div><div id='m_end'> M End Line: 260</div><div id='n_start'> N Start Line: 219</div><div id='n_end'> N End Line: 260</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.output_size = trainargs[&quotoutput_size&quot]
        self.num_layers = len(trainargs[&quothidden_sizes&quot]) + 1

        <a id="change">if trainargs[&quotfp_type&quot] == &quotsep&quot</a><a id="change">:
            </a>self.input_dim<a id="change"> = </a>trainargs[&quotrctfp_size&quot] + trainargs[&quotprodfp_size&quot] &#47&#47 will be rctfp_size + prodfp_size for FF_sep
        elif <a id="change">trainargs[&quotfp_type&quot] == &quotdiff&quot</a><a id="change">:
            </a>self.input_dim<a id="change"> = </a>trainargs[&quotrctfp_size&quot]
            assert trainargs[&quotrctfp_size&quot] == trainargs[&quotprodfp_size&quot], &quotrctfp_size != prodfp_size, unable to make difference FPs!!!&quot

        self.create_ffn(trainargs)</code></pre><h3>After Change</h3><pre><code class='java'>
            input_dim = rctfp_size + prodfp_size  
        elif rxn_type == &quotdiff&quot:
            input_dim = rctfp_size
            <a id="change">assert </a>rctfp_size == prodfp_size, &quotrctfp_size must equal prodfp_size for difference fingerprints!&quot

        num_layers = len(hidden_sizes) + 1
        dropout = nn.Dropout(dropout)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/coleygroup/rxn-ebm/commit/2cebee440e16033d54955b9b63de42770780e6d9#diff-d95a78bfa94df73558bb1df5facb084074e52f4d348bdb2eed50ac685aa1cce7L17' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4344940</div><div id='project'> Project Name: coleygroup/rxn-ebm</div><div id='commit'> Commit Name: 2cebee440e16033d54955b9b63de42770780e6d9</div><div id='time'> Time: 2020-09-29</div><div id='author'> Author: linmin001@e.ntu.edu.sg</div><div id='file'> File Name: model/FF.py</div><div id='m_class'> M Class Name: FeedforwardEBM</div><div id='n_method'> N Class Name: FeedforwardEBM</div><div id='m_method'> M Method Name: __init__(8)</div><div id='n_method'> N Method Name: __init__(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: model/FF.py</div><div id='n_file'> N File Name: model/FF.py</div><div id='m_start'> M Start Line: 17</div><div id='m_end'> M End Line: 28</div><div id='n_start'> N Start Line: 22</div><div id='n_end'> N End Line: 37</div><BR>