<html><h3>Pattern ID :731
</h3><img src='2509862.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        self._k = k

        if weight:
            self.weight<a id="change"> = nn</a><a id="change">.Parameter(</a>th.Tensor(in_feats, out_feats)<a id="change">)</a>
        else:
            self.register_parameter(&quotweight&quot, None)

        if bias:
            self.bias<a id="change"> = nn</a><a id="change">.Parameter(</a>th.Tensor(out_feats)<a id="change">)</a>
        else:
            self.register_parameter(&quotbias&quot, None)
</code></pre><h3>After Change</h3><pre><code class='java'>
                 bias=True):
        
        super().__init__()
        <a id="change">if norm not in (&quotnone&quot, &quotboth&quot, &quotright&quot, &quotleft&quot)</a><a id="change">:
            </a>raise DGLError(&quotInvalid norm value. Must be either "none", "both", "right" or "left".&quot
                           &quot But got "{}".&quot.format(norm))     
        self._in_feats<a id="change"> = </a>in_feats
        self._out_feats = out_feats            
        self._cached = cached
        self._cached_h = None
        self._k = k
        self._norm<a id="change"> = </a>norm
        self._add_self_loop<a id="change"> = </a>add_self_loop

        self.linear<a id="change"> = </a>Linear(in_feats, out_feats, weight=weight, bias=bias)

    def reset_parameters(self):
        Reinitialize learnable parameters.</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 10</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/edisonleeeee/greatx/commit/c43665fd30401c63acbd50175da1880509a52d21#diff-4e82f29fd5c78eabd4fe1d5867020e786dc0deb6b867e435c11f46885eaadad4L70' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2509862</div><div id='project'> Project Name: edisonleeeee/greatx</div><div id='commit'> Commit Name: c43665fd30401c63acbd50175da1880509a52d21</div><div id='time'> Time: 2021-12-06</div><div id='author'> Author: cnljt@outlook.com</div><div id='file'> File Name: graphwar/nn/sgconv.py</div><div id='class'> Class Name: SGConv</div><div id='method'> Method Name: __init__</div><div id='parent_class'> Parent Class: nn.Module</div><BR><BR><div id='link'><a href='https://github.com/antocad/focusondepth/commit/705d8789c4e66dbdbfdd3aeb7f20666f019481dd#diff-941ba600a0201cf159de01531ff7e943fc0434587165f1ce11d65e14346b32b6L25' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2509863</div><div id='project'> Project Name: antocad/focusondepth</div><div id='commit'> Commit Name: 705d8789c4e66dbdbfdd3aeb7f20666f019481dd</div><div id='time'> Time: 2022-01-03</div><div id='author'> Author: antoine.cadiou@icloud.com</div><div id='file'> File Name: FOD/FocusOnDepth.py</div><div id='class'> Class Name: FocusOnDepth</div><div id='method'> Method Name: __init__</div><div id='parent_class'> Parent Class: nn.Module</div><BR><BR><div id='link'><a href='https://github.com/edisonleeeee/greatx/commit/c43665fd30401c63acbd50175da1880509a52d21#diff-4e82f29fd5c78eabd4fe1d5867020e786dc0deb6b867e435c11f46885eaadad4L70' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2509860</div><div id='project'> Project Name: edisonleeeee/greatx</div><div id='commit'> Commit Name: c43665fd30401c63acbd50175da1880509a52d21</div><div id='time'> Time: 2021-12-06</div><div id='author'> Author: cnljt@outlook.com</div><div id='file'> File Name: graphwar/nn/sgconv.py</div><div id='class'> Class Name: SGConv</div><div id='method'> Method Name: __init__</div><div id='parent_class'> Parent Class: nn.Module</div><BR>