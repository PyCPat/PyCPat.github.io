<html><h3>Pattern ID :614
</h3><img src='2181233.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        input_dim = self.obs_size

        &#47&#47 Create layers 0 to second-last.
        <a id="change">for </a>out_dim in self.encoder_layer_dim<a id="change">:
            </a>layers.append(
                SlimFC(in_size=input_dim,
                       out_size=out_dim,
                       initializer=normc_initializer(1.0),</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 encoder
        layers = []
        <a id="change">if "fc_layer" in self.custom_config["model_arch_args"]</a><a id="change">:
            </a>if "encode_layer" in self.custom_config["model_arch_args"]:
                encode_layer = self.custom_config["model_arch_args"]["encode_layer"]
                encoder_layer_dim = encode_layer.split("-")
                encoder_layer_dim = [int(i) for i in encoder_layer_dim]
            else:  &#47&#47 default config
                encoder_layer_dim = []
                for i in range(self.custom_config["model_arch_args"]["fc_layer"]):
                    out_dim = self.custom_config["model_arch_args"]["out_dim_fc_{}".format(i)]
                    encoder_layer_dim.append(out_dim)

            self.encoder_layer_dim = encoder_layer_dim
            self.obs_size = self.full_obs_space[&quotobs&quot].shape[0]
            input_dim = self.obs_size
            <a id="change">for </a>out_dim in self.encoder_layer_dim<a id="change">:
                </a>layers.append(
                    SlimFC(in_size=input_dim,
                           out_size=out_dim,
                           initializer=normc_initializer(1.0),
                           activation_fn=self.activation))
                input_dim = out_dim
        elif <a id="change">"conv_layer" in self.custom_config["model_arch_args"]</a><a id="change">:
            </a>self.obs_size<a id="change"> = </a>self.full_obs_space[&quotobs&quot].shape
            input_dim = self.obs_size[2]
            for i in range(self.custom_config["model_arch_args"]["conv_layer"]):
                layers.append(
                    SlimConv2d(
                        in_channels=input_dim,
                        out_channels=self.custom_config["model_arch_args"]["out_channel_layer_{}".format(i)],
                        kernel=self.custom_config["model_arch_args"]["kernel_size_layer_{}".format(i)],
                        stride=self.custom_config["model_arch_args"]["stride_layer_{}".format(i)],
                        padding=self.custom_config["model_arch_args"]["padding_layer_{}".format(i)],
                        activation_fn=self.activation
                    )
                )
                pool_f = nn.MaxPool2d(kernel_size=self.custom_config["model_arch_args"]["pool_size_layer_{}".format(i)])
                layers.append(pool_f)

                input_dim = self.custom_config["model_arch_args"]["out_channel_layer_{}".format(i)]

        else:
            <a id="change">raise </a>ValueError("fc_layer/conv layer not in model arch args")

        self.input_dim = input_dim  &#47&#47 record
        self.p_encoder = nn.Sequential(*layers)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 10</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/replicable-marl/marllib/commit/ad9e882a616f22e8a142a6247723317e04279f18#diff-9612bc7442b1e5b98813c45d6d7ce6f4b535c5fa23529537da70bcef0a322122L30' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2181233</div><div id='project'> Project Name: replicable-marl/marllib</div><div id='commit'> Commit Name: ad9e882a616f22e8a142a6247723317e04279f18</div><div id='time'> Time: 2023-02-24</div><div id='author'> Author: hhhusiyi@163.com</div><div id='file'> File Name: marllib/marl/models/zoo/mlp/base_mlp.py</div><div id='m_class'> M Class Name: Base_MLP</div><div id='n_method'> N Class Name: Base_MLP</div><div id='m_method'> M Method Name: __init__(6)</div><div id='n_method'> N Method Name: __init__(6)</div><div id='m_parent_class'> M Parent Class: nn.Module,TorchModelV2</div><div id='n_parent_class'> N Parent Class: nn.Module,TorchModelV2</div><div id='m_file'> M File Name: marllib/marl/models/zoo/mlp/base_mlp.py</div><div id='n_file'> N File Name: marllib/marl/models/zoo/mlp/base_mlp.py</div><div id='m_start'> M Start Line: 34</div><div id='m_end'> M End Line: 59</div><div id='n_start'> N Start Line: 30</div><div id='n_end'> N End Line: 101</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                for size in kernel_size
            ]
        )
        <a id="change">for </a>size, std, mgrid in zip(kernel_size, sigma, meshgrids)<a id="change">:
            </a>mean = (size - 1) / 2
            kernel *= 1 / (std * math.sqrt(2 * math.pi)) * \
                      torch.exp(-((mgrid - mean) / (2 * std)) ** 2)
</code></pre><h3>After Change</h3><pre><code class='java'>
            kernel_size = [kernel_size] * dim
        if isinstance(sigma, numbers.Number):
            sigma = [sigma] * dim
        <a id="change">self.kernel_f</a> = kernel_f

        &#47&#47 The gaussian kernel is the product of the
        &#47&#47 gaussian function of each dimension.
        kernel = 1
        meshgrids = torch.meshgrid(
            [
                torch.arange(size, dtype=torch.float32)
                for size in kernel_size
            ]
        )
        <a id="change">if self.kernel_f == &quotgaussian&quot</a><a id="change">:
            </a><a id="change">for </a>size, std, mgrid in zip(kernel_size, sigma, meshgrids)<a id="change">:
                </a>mean = (size - 1) / 2
                kernel *= 1 / (std * math.sqrt(2 * math.pi)) * \
                          torch.exp(-((mgrid - mean) / (2 * std)) ** 2)
        elif <a id="change">self.kernel_f == &quotlaplacian&quot</a><a id="change">:
            </a>for size, std, mgrid in zip(kernel_size, sigma, meshgrids):
                mean<a id="change"> = </a>(size - 1) / 2
                kernel *= 1 / (2 * std) * torch.exp(-torch.abs((mgrid - mean)) / std)
        else:
            <a id="change">raise </a>ValueError("Mode must either be gaussian or laplacian.")

        &#47&#47 Make sure sum of values in gaussian kernel equals 1.
        kernel = kernel / torch.sum(kernel)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/turagalab/decode/commit/76fdb7cb7b6d0955b7276439dac11d03e271e104#diff-f8cb129f053716bb72d1410a8577bb01f2695145c4433259a1337e4e732b30cbL95' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2181232</div><div id='project'> Project Name: turagalab/decode</div><div id='commit'> Commit Name: 76fdb7cb7b6d0955b7276439dac11d03e271e104</div><div id='time'> Time: 2019-04-03</div><div id='author'> Author: gitdev@LRM.photo</div><div id='file'> File Name: deepsmlm/generic/noise.py</div><div id='m_class'> M Class Name: GaussianSmoothing</div><div id='n_method'> N Class Name: GaussianSmoothing</div><div id='m_method'> M Method Name: __init__(8)</div><div id='n_method'> N Method Name: __init__(7)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: deepsmlm/generic/noise.py</div><div id='n_file'> N File Name: deepsmlm/generic/noise.py</div><div id='m_start'> M Start Line: 111</div><div id='m_end'> M End Line: 117</div><div id='n_start'> N Start Line: 95</div><div id='n_end'> N End Line: 125</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        input_dim = self.obs_size

        &#47&#47 Create layers 0 to second-last.
        <a id="change">for </a>out_dim in self.encoder_layer_dim<a id="change">:
            </a>layers.append(
                SlimFC(in_size=input_dim,
                       out_size=out_dim,
                       initializer=normc_initializer(1.0),</code></pre><h3>After Change</h3><pre><code class='java'>
        nn.Module.__init__(self)

        &#47&#47 decide the model arch
        <a id="change">self.custom_config</a> = model_config["custom_model_config"]
        self.full_obs_space = getattr(obs_space, "original_space", obs_space)
        self.n_agents = self.custom_config["num_agents"]
        self.activation = model_config.get("fcnet_activation")
        self.obs_size = self.full_obs_space[&quotobs&quot].shape[0]

        &#47&#47 encoder
        layers = []
        <a id="change">if "fc_layer" in self.custom_config["model_arch_args"]</a><a id="change">:
            </a>if "encode_layer" in self.custom_config["model_arch_args"]:
                encode_layer = self.custom_config["model_arch_args"]["encode_layer"]
                encoder_layer_dim = encode_layer.split("-")
                encoder_layer_dim = [int(i) for i in encoder_layer_dim]
            else:  &#47&#47 default config
                encoder_layer_dim = []
                for i in range(self.custom_config["model_arch_args"]["fc_layer"]):
                    out_dim = self.custom_config["model_arch_args"]["out_dim_fc_{}".format(i)]
                    encoder_layer_dim.append(out_dim)

            self.encoder_layer_dim = encoder_layer_dim
            self.obs_size = self.full_obs_space[&quotobs&quot].shape[0]
            input_dim = self.obs_size
            <a id="change">for </a>out_dim in self.encoder_layer_dim<a id="change">:
                </a>layers.append(
                    SlimFC(in_size=input_dim,
                           out_size=out_dim,
                           initializer=normc_initializer(1.0),
                           activation_fn=self.activation))
                input_dim = out_dim
        elif <a id="change">"conv_layer" in self.custom_config["model_arch_args"]</a><a id="change">:
            </a>self.obs_size = self.full_obs_space[&quotobs&quot].shape
            input_dim = self.obs_size[2]
            for i in range(self.custom_config["model_arch_args"]["conv_layer"]):
                layers.append(
                    SlimConv2d(
                        in_channels=input_dim,
                        out_channels=self.custom_config["model_arch_args"]["out_channel_layer_{}".format(i)],
                        kernel=self.custom_config["model_arch_args"]["kernel_size_layer_{}".format(i)],
                        stride=self.custom_config["model_arch_args"]["stride_layer_{}".format(i)],
                        padding=self.custom_config["model_arch_args"]["padding_layer_{}".format(i)],
                        activation_fn=self.activation
                    )
                )
                pool_f<a id="change"> = </a>nn.MaxPool2d(kernel_size=self.custom_config["model_arch_args"]["pool_size_layer_{}".format(i)])
                layers.append(pool_f)

                input_dim = self.custom_config["model_arch_args"]["out_channel_layer_{}".format(i)]

        else:
            <a id="change">raise </a>ValueError("fc_layer/conv layer not in model arch args")

        self.input_dim = input_dim  &#47&#47 record
        self.p_encoder = nn.Sequential(*layers)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/replicable-marl/marllib/commit/ad9e882a616f22e8a142a6247723317e04279f18#diff-9612bc7442b1e5b98813c45d6d7ce6f4b535c5fa23529537da70bcef0a322122L16' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2181235</div><div id='project'> Project Name: replicable-marl/marllib</div><div id='commit'> Commit Name: ad9e882a616f22e8a142a6247723317e04279f18</div><div id='time'> Time: 2023-02-24</div><div id='author'> Author: hhhusiyi@163.com</div><div id='file'> File Name: marllib/marl/models/zoo/mlp/base_mlp.py</div><div id='m_class'> M Class Name: Base_MLP</div><div id='n_method'> N Class Name: Base_MLP</div><div id='m_method'> M Method Name: __init__(6)</div><div id='n_method'> N Method Name: __init__(6)</div><div id='m_parent_class'> M Parent Class: nn.Module,TorchModelV2</div><div id='n_parent_class'> N Parent Class: nn.Module,TorchModelV2</div><div id='m_file'> M File Name: marllib/marl/models/zoo/mlp/base_mlp.py</div><div id='n_file'> N File Name: marllib/marl/models/zoo/mlp/base_mlp.py</div><div id='m_start'> M Start Line: 34</div><div id='m_end'> M End Line: 59</div><div id='n_start'> N Start Line: 30</div><div id='n_end'> N End Line: 101</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                    self.A_s[0][right_index][i] = 1

        self.T_s = torch.zeros((1,time_dim,time_dim), requires_grad=False)
        <a id="change">for </a>i in range(time_dim)<a id="change">:
            </a>if i &gt; 0:
                self.T_s[0][i-1][i] = 1
                self.T_s[0][i][i-1] = 1
</code></pre><h3>After Change</h3><pre><code class='java'>
                    self.A_s[0][i][right_index] = 1
                    self.A_s[0][right_index][i] = 1
        self.T_s = torch.zeros((1,time_dim,time_dim), requires_grad=False)
        <a id="change">if version == &quotlong&quot</a><a id="change">:
            </a><a id="change">for </a>i in range(time_dim)<a id="change">:
                </a>if i &gt; 0:
                    self.T_s[0][i-1][i] = 1
                    self.T_s[0][i][i-1] = 1

                if i &lt; time_dim - 1:
                    self.T_s[0][i+1][i] = 1
                    self.T_s[0][i][i+1] = 1
                
                self.T_s[0][i][i] = 1
        elif <a id="change">version == &quotshort&quot</a><a id="change">:
            </a>self.T_s<a id="change"> = </a>self.T_s + 1
        else:
            <a id="change">raise </a>Exception("model type should be long or short")

        self.joints_dim = joints_dim
        self.time_dim = time_dim</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/sirui-xu/stars/commit/8a3084b91136d606495cd61d63b80b15ba6bf009#diff-96d887d8bc290c5236875097b5e3709772a184ebc0627f6223ef8c7e4ef5c2b6L92' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2181231</div><div id='project'> Project Name: sirui-xu/stars</div><div id='commit'> Commit Name: 8a3084b91136d606495cd61d63b80b15ba6bf009</div><div id='time'> Time: 2022-08-07</div><div id='author'> Author: xusirui@pku.edu.cn</div><div id='file'> File Name: Deterministic/model.py</div><div id='m_class'> M Class Name: ConvTemporalGraphicalEnhanced</div><div id='n_method'> N Class Name: ConvTemporalGraphicalEnhanced</div><div id='m_method'> M Method Name: __init__(8)</div><div id='n_method'> N Method Name: __init__(7)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: Deterministic/model.py</div><div id='n_file'> N File Name: Deterministic/model.py</div><div id='m_start'> M Start Line: 134</div><div id='m_end'> M End Line: 145</div><div id='n_start'> N Start Line: 101</div><div id='n_end'> N End Line: 150</div><BR>