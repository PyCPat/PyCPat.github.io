<html><h3>Pattern ID :1774
</h3><img src='4376482.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            self.trg_embedding = FactorizedEmbedding(trg_vocab_size, 
                                                     embedding_size,
                                                     d_model)
        self.dropout = <a id="change">Dropout(</a>dropout<a id="change">)</a>
        self.pos_embedding = PositionEmbedding(trg_max_len, d_model)
        
        if share_layer_params == False:
            self.layers = nn.ModuleList([</code></pre><h3>After Change</h3><pre><code class='java'>
        self.scale_embedding = scale_embedding
        self.use_pre_norm = use_pre_norm
        self.norm_before_pred = norm_before_pred
        self.norm_after_embedding<a id="change"> = </a>norm_after_embedding
        
        if embedding_size is None:
            self.trg_embedding = Embedding(trg_vocab_size, 
                                           d_model, 
                                           scale_embedding)
        else:
            self.trg_embedding = FactorizedEmbedding(trg_vocab_size, 
                                                     embedding_size,
                                                     d_model)
        self.emb_dropout = Dropout(emb_dropout)
        self.pos_embedding = PositionEmbedding(trg_max_len,
                                               d_model,
                                               pos_need_train)
        <a id="change">if self.norm_after_embedding == True</a><a id="change">:
            </a>self.norm_emb<a id="change"> = </a><a id="change">LayerNorm(</a>self.d_model<a id="change">)</a>
            
        if share_layer_params == False:
            self.layers = nn.ModuleList([
                    LMDecoderLayer(n_heads, 
                                   d_model, 
                                   d_ff, 
                                   d_qk, 
                                   d_v,
                                   dropout=dropout,
                                   attn_dropout=attn_dropout,
                                   ln_eps=ln_eps,
                                   use_pre_norm=use_pre_norm,
                                   activation=activation)
                    for _ in range(n_layers)])
        else:
            layers = []
            for i in range(n_layers):
                if i % n_share_across_layers == 0:
                    layer = LMDecoderLayer(n_heads, 
                                           d_model,
                                           d_ff, 
                                           d_qk,
                                           d_v,
                                           dropout=dropout,
                                           attn_dropout=attn_dropout,
                                           ln_eps=ln_eps,
                                           use_pre_norm=use_pre_norm,
                                           activation=activation)

                    layers.append(layer)
            self.layers = nn.ModuleList(layers)
        
        self.share_emb_out_proj = share_emb_out_proj
        if share_emb_out_proj == False: 
            self.W = nn.Parameter(torch.Tensor(trg_vocab_size, d_model))
        
        self.use_proj_bias<a id="change"> = use_proj_bias</a>
        <a id="change">if use_proj_bias</a><a id="change"> == True:
            </a>self.b = nn.Parameter(torch.Tensor(trg_vocab_size))
        
        <a id="change">if </a><a id="change">self.norm_before_pred == True:
            </a>self.norm<a id="change"> = </a><a id="change">LayerNorm(</a>d_model<a id="change">)</a>
        
        self.reset_parameters()
    
    </code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 13</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/yaoxiaoyuan/mimix/commit/59b6082bb310a2a17c2ac30225e300124904cc2f#diff-a64c2aeac9b9657dde1bded0c4c95edecd9cf7a70d5b67f9fcf61c9864f85f9aL1717' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4376482</div><div id='project'> Project Name: yaoxiaoyuan/mimix</div><div id='commit'> Commit Name: 59b6082bb310a2a17c2ac30225e300124904cc2f</div><div id='time'> Time: 2022-06-21</div><div id='author'> Author: sbsbsbsbsb945@gmail.com</div><div id='file'> File Name: src/layers.py</div><div id='class'> Class Name: LMDecoder</div><div id='method'> Method Name: __init__</div><div id='parent_class'> Parent Class: nn.Module</div><BR><BR><div id='link'><a href='https://github.com/yaoxiaoyuan/mimix/commit/59b6082bb310a2a17c2ac30225e300124904cc2f#diff-a64c2aeac9b9657dde1bded0c4c95edecd9cf7a70d5b67f9fcf61c9864f85f9aL1717' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4376483</div><div id='project'> Project Name: yaoxiaoyuan/mimix</div><div id='commit'> Commit Name: 59b6082bb310a2a17c2ac30225e300124904cc2f</div><div id='time'> Time: 2022-06-21</div><div id='author'> Author: sbsbsbsbsb945@gmail.com</div><div id='file'> File Name: src/layers.py</div><div id='class'> Class Name: LMDecoder</div><div id='method'> Method Name: __init__</div><div id='parent_class'> Parent Class: nn.Module</div><BR><BR><div id='link'><a href='https://github.com/yaoxiaoyuan/mimix/commit/59b6082bb310a2a17c2ac30225e300124904cc2f#diff-a64c2aeac9b9657dde1bded0c4c95edecd9cf7a70d5b67f9fcf61c9864f85f9aL1293' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4376496</div><div id='project'> Project Name: yaoxiaoyuan/mimix</div><div id='commit'> Commit Name: 59b6082bb310a2a17c2ac30225e300124904cc2f</div><div id='time'> Time: 2022-06-21</div><div id='author'> Author: sbsbsbsbsb945@gmail.com</div><div id='file'> File Name: src/layers.py</div><div id='class'> Class Name: Encoder</div><div id='method'> Method Name: __init__</div><div id='parent_class'> Parent Class: nn.Module</div><BR><BR><div id='link'><a href='https://github.com/yaoxiaoyuan/mimix/commit/59b6082bb310a2a17c2ac30225e300124904cc2f#diff-a64c2aeac9b9657dde1bded0c4c95edecd9cf7a70d5b67f9fcf61c9864f85f9aL1468' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4376484</div><div id='project'> Project Name: yaoxiaoyuan/mimix</div><div id='commit'> Commit Name: 59b6082bb310a2a17c2ac30225e300124904cc2f</div><div id='time'> Time: 2022-06-21</div><div id='author'> Author: sbsbsbsbsb945@gmail.com</div><div id='file'> File Name: src/layers.py</div><div id='class'> Class Name: Decoder</div><div id='method'> Method Name: __init__</div><div id='parent_class'> Parent Class: nn.Module</div><BR>