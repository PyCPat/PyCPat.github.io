<html><h3>Pattern ID :1516
</h3><img src='4012889.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    expansion = 4

    def __init__(self, in_planes, planes, stride=1):
        <a id="change">super(</a>Bottleneck, self<a id="change">)</a>.__init__()
        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)
        self.bn1 = nn.BatchNorm2d(planes)
        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)</code></pre><h3>After Change</h3><pre><code class='java'>
        super().__init__()
        assert image_size % patch_size == 0, &quotimage dimensions must be divisible by the patch size&quot
        num_patches = (image_size // patch_size) ** 2
        patch_dim = channels * patch_size<a id="change"> ** 2</a>
        assert num_patches &gt; MIN_NUM_PATCHES, f&quotyour number of patches ({num_patches}) is way too small for attention to be effective. try decreasing your patch size&quot

        self.patch_size = patch_size

        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))
        self.patch_to_embedding = <a id="change">nn.Linear(</a>patch_dim, dim<a id="change">)</a>
        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))
        self.dropout = nn.Dropout(emb_dropout)

        self.transformer = Transformer(dim, depth, heads, mlp_dim, dropout)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/cydia2018/vit-cifar10-pruning/commit/670fb581b519a0875681d2fbf4c4ec824e7fd9a3#diff-dfcdfdb3cc72798869ac0cd03f988cc3a003b313176165f458bb2dee8e033743L42' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4012889</div><div id='project'> Project Name: cydia2018/vit-cifar10-pruning</div><div id='commit'> Commit Name: 670fb581b519a0875681d2fbf4c4ec824e7fd9a3</div><div id='time'> Time: 2020-10-27</div><div id='author'> Author: meathouse47@gmail.com</div><div id='file'> File Name: models/vit.py</div><div id='class'> Class Name: Bottleneck</div><div id='method'> Method Name: __init__</div><div id='parent_class'> Parent Class: nn.Module</div><BR><BR><div id='link'><a href='https://github.com/feng-lab/pytorch-image-models/commit/be99eef9c14fe63a2ebf3cdd2784d16140851004#diff-d29d8e1745b53349586e5304edfb78e4ef269e4b554b184f83588fb5aa157e0fL73' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4012888</div><div id='project'> Project Name: feng-lab/pytorch-image-models</div><div id='commit'> Commit Name: be99eef9c14fe63a2ebf3cdd2784d16140851004</div><div id='time'> Time: 2021-05-20</div><div id='author'> Author: rwightman@gmail.com</div><div id='file'> File Name: timm/models/twins.py</div><div id='class'> Class Name: GroupAttention</div><div id='method'> Method Name: __init__</div><div id='parent_class'> Parent Class: nn.Module</div><BR><BR><div id='link'><a href='https://github.com/shaoeric/torch-atom/commit/87af6f2da4a9d8d8cd3710b0c643085ab8abbec6#diff-32f9903dd9a14d37c5300ee56d88ce85da3b030c80d54d5b026b73976800555cL11' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4012887</div><div id='project'> Project Name: shaoeric/torch-atom</div><div id='commit'> Commit Name: 87af6f2da4a9d8d8cd3710b0c643085ab8abbec6</div><div id='time'> Time: 2022-03-06</div><div id='author'> Author: shaoeric@foxmail.com</div><div id='file'> File Name: src/models/resnet.py</div><div id='class'> Class Name: ResNet</div><div id='method'> Method Name: __init__</div><div id='parent_class'> Parent Class: nn.Module</div><BR>