<html><h3>Pattern ID :1429
</h3><img src='3832152.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 downsample klass

        downsample_klass = DownsampleWithBlur<a id="change"> if </a>antialias_downsample<a id="change"> else </a>Downsample

        if cross_embed_downsample:
            downsample_klass = partial(CrossEmbedLayer, kernel_sizes = cross_embed_downsample_kernel_sizes)</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 downsampling layers

        skip_connect_dims<a id="change"> = []</a> &#47&#47 keep track of skip connection dimensions

        for ind, ((dim_in, dim_out), layer_num_resnet_blocks, groups, layer_attn, layer_cross_attn) in enumerate(zip(in_out, *layer_params)):
            is_last = ind &gt;= (num_resolutions - 1)

            layer_use_linear_cross_attn = not layer_cross_attn and use_linear_cross_attn
            layer_cond_dim = cond_dim if layer_cross_attn or layer_use_linear_cross_attn else None

            transformer_block_klass = TransformerBlock if layer_attn else (LinearAttentionTransformerBlock if use_linear_attn else nn.Identity)

            current_dim = dim_in

            &#47&#47 whether to pre-downsample, from memory efficient unet

            pre_downsample = None

            if memory_efficient:
                pre_downsample = downsample_klass(dim_in, dim_out)
                current_dim = dim_out

            <a id="change">skip_connect_dims.append(</a>current_dim<a id="change">)</a>

            self.downs.append(nn.ModuleList([
                pre_downsample,
                ResnetBlock(current_dim, current_dim, cond_dim = layer_cond_dim, linear_attn = layer_use_linear_cross_attn, time_cond_dim = time_cond_dim, groups = groups),</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lucidrains/imagen-pytorch/commit/36bdefca0e8670ca42b39236315121b703b9533f#diff-edef3c5fe92797a22c0b8fc6cca1d57b4b84ef03dfdfe802ed9147e21fc88109L1148' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 3832152</div><div id='project'> Project Name: lucidrains/imagen-pytorch</div><div id='commit'> Commit Name: 36bdefca0e8670ca42b39236315121b703b9533f</div><div id='time'> Time: 2022-06-27</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: imagen_pytorch/imagen_pytorch.py</div><div id='m_class'> M Class Name: Unet</div><div id='n_method'> N Class Name: Unet</div><div id='m_method'> M Method Name: __init__(1)</div><div id='n_method'> N Method Name: __init__(1)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: imagen_pytorch/imagen_pytorch.py</div><div id='n_file'> N File Name: imagen_pytorch/imagen_pytorch.py</div><div id='m_start'> M Start Line: 1178</div><div id='m_end'> M End Line: 1250</div><div id='n_start'> N Start Line: 1148</div><div id='n_end'> N End Line: 1221</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 whether to do a final residual from initial conv to the final resnet block out

        self.init_conv_to_final_conv_residual = init_conv_to_final_conv_residual
        final_conv_dim = dim * (2<a id="change"> if </a>init_conv_to_final_conv_residual<a id="change"> else </a>1)

        &#47&#47 final optional resnet block and convolution out
</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 upsampling layers

        upsample_fmap_dims<a id="change"> = []</a>

        for ind, ((dim_in, dim_out), layer_num_resnet_blocks, groups, layer_attn, layer_attn_depth, layer_cross_attn) in enumerate(zip(reversed(in_out), *reversed_layer_params)):
            is_last = ind == (len(in_out) - 1)
            layer_use_linear_cross_attn = not layer_cross_attn and use_linear_cross_attn
            layer_cond_dim = cond_dim if layer_cross_attn or layer_use_linear_cross_attn else None
            transformer_block_klass = TransformerBlock if layer_attn else (LinearAttentionTransformerBlock if use_linear_attn else Identity)

            skip_connect_dim = skip_connect_dims.pop()

            <a id="change">upsample_fmap_dims.append(</a>dim_out<a id="change">)</a>

            self.ups.append(nn.ModuleList([
                resnet_klass(dim_out + skip_connect_dim, dim_out, cond_dim = layer_cond_dim, linear_attn = layer_use_linear_cross_attn, time_cond_dim = time_cond_dim, groups = groups),
                nn.ModuleList([ResnetBlock(dim_out + skip_connect_dim, dim_out, time_cond_dim = time_cond_dim, groups = groups, use_gca = use_global_context_attn) for _ in range(layer_num_resnet_blocks)]),</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/imagen-pytorch/commit/a796e7c96e2972906411540d90baec25495f2c1a#diff-edef3c5fe92797a22c0b8fc6cca1d57b4b84ef03dfdfe802ed9147e21fc88109L1021' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 3832153</div><div id='project'> Project Name: lucidrains/imagen-pytorch</div><div id='commit'> Commit Name: a796e7c96e2972906411540d90baec25495f2c1a</div><div id='time'> Time: 2022-07-26</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: imagen_pytorch/imagen_pytorch.py</div><div id='m_class'> M Class Name: Unet</div><div id='n_method'> N Class Name: Unet</div><div id='m_method'> M Method Name: __init__(1)</div><div id='n_method'> N Method Name: __init__(1)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: imagen_pytorch/imagen_pytorch.py</div><div id='n_file'> N File Name: imagen_pytorch/imagen_pytorch.py</div><div id='m_start'> M Start Line: 1305</div><div id='m_end'> M End Line: 1305</div><div id='n_start'> N Start Line: 1322</div><div id='n_end'> N End Line: 1353</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            self.downs.append(nn.ModuleList([
                blocks(dim_in, dim_out),
                blocks(dim_out, dim_out),
                Downsample(dim_out)<a id="change"> if </a>not is_last<a id="change"> else </a>nn.Identity()
            ]))

        mid_dim = dims[-1]</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 modules for all layers

        skip_dims<a id="change"> = []</a>

        for ind, (dim_in, dim_out) in enumerate(in_out):
            is_last = ind &gt;= (num_resolutions - 1)
            <a id="change">skip_dims.append(</a>dim_in<a id="change">)</a>

            self.downs.append(nn.ModuleList([
                blocks(dim_in, dim_in),
                blocks(dim_in, dim_in),</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/x-unet/commit/504472da6fd268c7fb307c7b7e669a9db74ce7d7#diff-6e9e7a6d8d7a8c116b8bdae64f3e845f516adfec59d0379fc01849d294784966L139' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 3832147</div><div id='project'> Project Name: lucidrains/x-unet</div><div id='commit'> Commit Name: 504472da6fd268c7fb307c7b7e669a9db74ce7d7</div><div id='time'> Time: 2022-07-24</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: x_unet/x_unet.py</div><div id='m_class'> M Class Name: XUnet</div><div id='n_method'> N Class Name: XUnet</div><div id='m_method'> M Method Name: __init__(9)</div><div id='n_method'> N Method Name: __init__(8)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: x_unet/x_unet.py</div><div id='n_file'> N File Name: x_unet/x_unet.py</div><div id='m_start'> M Start Line: 156</div><div id='m_end'> M End Line: 195</div><div id='n_start'> N Start Line: 192</div><div id='n_end'> N End Line: 257</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.seq_len = seq_len
        self.prob_survival = prob_survival

        self.to_embed = nn.Embedding(num_tokens, dim)<a id="change"> if </a>exists(num_tokens)<a id="change"> else </a>nn.Identity()

        self.layers = nn.ModuleList([Residual(PreNorm(dim, gMLPBlock(dim = dim, dim_ff = dim_ff, seq_len = seq_len, heads = heads, window = window))) for i in range(depth)])
</code></pre><h3>After Change</h3><pre><code class='java'>
        self.to_embed = nn.Embedding(num_tokens, dim)

        window = cast_tuple(window, depth)
        layers<a id="change"> = </a>nn.ModuleList(<a id="change">[]</a>)

        for ind, w in zip(range(depth), window):
            layer_blocks = nn.ModuleList([
                PreNorm(dim, gMLPBlock(dim = dim, dim_ff = dim_ff, seq_len = seq_len, heads = heads, window = w))
            ])

            if reversible:
                layer_blocks.append(PreNorm(dim, gMLPBlock(dim = dim, dim_ff = dim_ff, seq_len = seq_len, heads = heads, window = w)))

            <a id="change">layers.append(</a>layer_blocks<a id="change">)</a>

        execute_klass = SequentialSequence if not reversible else ReversibleSequence
        self.net = execute_klass(layers)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/g-mlp-gpt/commit/7642e36ff19c6b299a77e5c1ace038e9e6726202#diff-9e1c762f97dc7e52cf231d6bec8dbb8412bc9383faaf89eadd9b1c02e46fea80L171' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 3832151</div><div id='project'> Project Name: lucidrains/g-mlp-gpt</div><div id='commit'> Commit Name: 7642e36ff19c6b299a77e5c1ace038e9e6726202</div><div id='time'> Time: 2021-05-20</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: g_mlp_gpt/g_mlp_gpt.py</div><div id='m_class'> M Class Name: gMLPGPT</div><div id='n_method'> N Class Name: gMLPGPT</div><div id='m_method'> M Method Name: __init__(1)</div><div id='n_method'> N Method Name: __init__(1)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: g_mlp_gpt/g_mlp_gpt.py</div><div id='n_file'> N File Name: g_mlp_gpt/g_mlp_gpt.py</div><div id='m_start'> M Start Line: 188</div><div id='m_end'> M End Line: 195</div><div id='n_start'> N Start Line: 194</div><div id='n_end'> N End Line: 215</div><BR>