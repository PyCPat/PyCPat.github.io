<html><h3>Pattern ID :1899
</h3><img src='4584361.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 have much of an impact on final performance anyway. See page 8 (https://arxiv.org/pdf/2102.11972.pdf)
        super().__init__()

        inner_dim = <a id="change">int(</a>dim<a id="change"> * </a>ff_mult<a id="change">)</a>
        if ffn_type == "GEGLU":
            self.net = nn.Sequential(
                GEGLU(dim, inner_dim),
                nn.Dropout(dropout),
                nn.Linear(inner_dim, dim)
            )
        elif ffn_type == "standard":
            self.net = nn.Sequential(
                nn.Linear(dim, inner_dim),
                nn.GELU(),
                nn.Dropout(dropout),
                nn.Linear(inner_dim, dim)
            )
        elif ffn_type == "bilinear":
            self.net<a id="change"> = </a>nn.Sequential(
                Bilinear(dim, inner_dim),
                nn.Dropout(dropout),
                nn.Linear(inner_dim, dim)</code></pre><h3>After Change</h3><pre><code class='java'>

        rows = []
        for i in range(max_length):  &#47&#47 build the full Alibi relative position bias matrix
            rows.append(torch.LongTensor([x for x in <a id="change">range(</a>0 - i, max_length - i<a id="change">)</a>]).view(1, -1).abs())

        &#47&#47 This implementation alternates between upper triangular and lower triangular biases. Using the full matrix
        &#47&#47 doesn&quott seem to work as well - likely since the forward and backward biases would be identical (i.e. attention</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/antofuller/configaformers/commit/f2fa8c59ce1537b400a3288f9c556e84ca993807#diff-fcf59ce11a888c8312fa1547129217a783407a793109b95d67b265e47d08375bL17' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4584361</div><div id='project'> Project Name: antofuller/configaformers</div><div id='commit'> Commit Name: f2fa8c59ce1537b400a3288f9c556e84ca993807</div><div id='time'> Time: 2021-09-04</div><div id='author'> Author: afuller187187@gmail.com</div><div id='file'> File Name: building_blocks.py</div><div id='class'> Class Name: FeedForward</div><div id='method'> Method Name: __init__</div><div id='parent_class'> Parent Class: nn.Module</div><BR><BR><div id='link'><a href='https://github.com/plemeri/inspyrenet/commit/12b05eaf235665fc6d1f89a9055b84d7cdfec923#diff-bfa9144b84aa2908523fe6e28d0f355d5701af250801acefca0ffbeed05bc3dfL483' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4584373</div><div id='project'> Project Name: plemeri/inspyrenet</div><div id='commit'> Commit Name: 12b05eaf235665fc6d1f89a9055b84d7cdfec923</div><div id='time'> Time: 2021-10-14</div><div id='author'> Author: taehoon1018@postech.ac.kr</div><div id='file'> File Name: lib/backbones/SwinTransformer.py</div><div id='class'> Class Name: SwinTransformer</div><div id='method'> Method Name: __init__</div><div id='parent_class'> Parent Class: nn.Module</div><BR><BR><div id='link'><a href='https://github.com/mackelab/sbi/commit/aeca010c91564a71c6e5a8b7952f479779c1b49e#diff-672ba10e6c3065a6f5554033b9b173c4fe88f4c05ffc31c70a9198691e6c6659L51' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4584368</div><div id='project'> Project Name: mackelab/sbi</div><div id='commit'> Commit Name: aeca010c91564a71c6e5a8b7952f479779c1b49e</div><div id='time'> Time: 2022-11-03</div><div id='author'> Author: jan.boelts@tum.de</div><div id='file'> File Name: sbi/neural_nets/embedding_nets.py</div><div id='class'> Class Name: CNNEmbedding</div><div id='method'> Method Name: __init__</div><div id='parent_class'> Parent Class: nn.Module</div><BR>