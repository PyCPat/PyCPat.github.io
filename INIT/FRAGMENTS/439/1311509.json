{"BEFORE":"        batch_first=True,\n        **kwargs,\n    ):\n        super(MultiheadAttention, self).__init__()\n        self.embed_dim = embed_dim\n        self.num_heads = num_heads\n        self.batch_first = batch_first\n\n        self.attn = nn.MultiheadAttention(\n            embed_dim=embed_dim,\n            num_heads=num_heads,\n            dropout=attn_drop,\n            batch_first=batch_first,\n            **kwargs,\n        )\n\n        self.proj_drop = nn.Dropout(proj_drop)\n","AFTER":"        super().__init__()\n        self.layers = _get_clones(decoder_layer, num_layers)\n        self.num_layers = num_layers\n        self.norm = norm\n        self.return_intermediate = return_intermediate\n"}