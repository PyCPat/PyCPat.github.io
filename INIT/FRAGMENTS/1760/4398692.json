{"BEFORE":"        dim_mults=(1, 2, 4, 8),\n        channels = 3,\n        self_condition = False,\n        resnet_block_groups = 8,\n        conditioning_klass = Conditioning,\n        skip_connect_condition_fmaps = False   # whether to concatenate the conditioning fmaps in the latter decoder upsampling portion of unet\n    ):\n        super().__init__()\n\n        self.image_size = image_size\n\n        # determine dimensions\n\n        self.channels = channels\n        self.self_condition = self_condition\n        input_channels = channels * (2 if self_condition else 1)\n\n        init_dim = default(init_dim, dim)\n\n        self.init_conv = nn.Conv2d(input_channels, init_dim, 7, padding = 3)\n        self.cond_init_conv = nn.Conv2d(channels, init_dim, 7, padding = 3)\n\n        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]\n        in_out = list(zip(dims[:-1], dims[1:]))\n\n        block_klass = partial(ResnetBlock, groups = resnet_block_groups)\n\n        # time embeddings\n\n        time_dim = dim * 4\n\n        self.time_mlp = nn.Sequential(\n            SinusoidalPosEmb(dim),\n            nn.Linear(dim, time_dim),\n            nn.GELU(),\n            nn.Linear(time_dim, time_dim)\n        )\n\n        # layers\n\n        num_resolutions = len(in_out)\n\n        self.conditioners = nn.ModuleList([])\n\n        self.skip_connect_condition_fmaps = skip_connect_condition_fmaps\n\n        # downsampling encoding blocks\n\n        self.downs = nn.ModuleList([])\n\n        curr_fmap_size = image_size\n\n        for ind, (dim_in, dim_out) in enumerate(in_out):\n            is_last = ind >= (num_resolutions - 1)\n\n            self.conditioners.append(conditioning_klass(curr_fmap_size, dim_in))\n\n            self.downs.append(nn.ModuleList([\n                block_klass(dim_in, dim_in, time_emb_dim = time_dim),\n                block_klass(dim_in, dim_in, time_emb_dim = time_dim),\n                Residual(LinearAttention(dim_in)),\n                Downsample(dim_in, dim_out) if not is_last else nn.Conv2d(dim_in, dim_out, 3, padding = 1)\n            ]))\n\n            if not is_last:\n                curr_fmap_size \/\/= 2\n\n        # middle blocks\n\n        mid_dim = dims[-1]\n        self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim = time_dim)\n        self.mid_attn = Residual(Attention(mid_dim))\n        self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim = time_dim)\n\n        # condition encoding path will be the same as the main encoding path\n\n        self.cond_downs = copy.deepcopy(self.downs)\n        self.cond_mid_block1 = copy.deepcopy(self.mid_block1)\n\n        # upsampling decoding blocks\n\n        self.ups = nn.ModuleList([])\n\n        for ind, (dim_in, dim_out) in enumerate(reversed(in_out)):\n","AFTER":"        dim_mults: tuple = (1, 2, 4, 8),\n        channels = 3,\n        full_self_attn: tuple = (False, False, False, True),\n        self_condition = False,\n        resnet_block_groups = 8,\n        conditioning_klass = Conditioning,\n        skip_connect_condition_fmaps = False   # whether to concatenate the conditioning fmaps in the latter decoder upsampling portion of unet\n    ):\n        super().__init__()\n\n        self.image_size = image_size\n\n        # determine dimensions\n\n        self.channels = channels\n        self.self_condition = self_condition\n        input_channels = channels * (2 if self_condition else 1)\n\n        init_dim = default(init_dim, dim)\n\n        self.init_conv = nn.Conv2d(input_channels, init_dim, 7, padding = 3)\n        self.cond_init_conv = nn.Conv2d(channels, init_dim, 7, padding = 3)\n\n        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]\n        in_out = list(zip(dims[:-1], dims[1:]))\n\n        block_klass = partial(ResnetBlock, groups = resnet_block_groups)\n\n        # time embeddings\n\n        time_dim = dim * 4\n\n        self.time_mlp = nn.Sequential(\n            SinusoidalPosEmb(dim),\n            nn.Linear(dim, time_dim),\n            nn.GELU(),\n            nn.Linear(time_dim, time_dim)\n        )\n\n        # layers\n\n        num_resolutions = len(in_out)\n        assert len(full_self_attn) == num_resolutions\n\n        self.conditioners = nn.ModuleList([])\n\n        self.skip_connect_condition_fmaps = skip_connect_condition_fmaps\n\n        # downsampling encoding blocks\n\n        self.downs = nn.ModuleList([])\n\n        curr_fmap_size = image_size\n\n        for ind, ((dim_in, dim_out), full_attn) in enumerate(zip(in_out, full_self_attn)):\n            is_last = ind >= (num_resolutions - 1)\n            attn_klass = Attention if full_attn else LinearAttention\n\n            self.conditioners.append(conditioning_klass(curr_fmap_size, dim_in))\n\n\n            self.downs.append(nn.ModuleList([\n                block_klass(dim_in, dim_in, time_emb_dim = time_dim),\n                block_klass(dim_in, dim_in, time_emb_dim = time_dim),\n                Residual(attn_klass(dim_in)),\n                Downsample(dim_in, dim_out) if not is_last else nn.Conv2d(dim_in, dim_out, 3, padding = 1)\n            ]))\n\n            if not is_last:\n                curr_fmap_size \/\/= 2\n\n        # middle blocks\n\n        mid_dim = dims[-1]\n        self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim = time_dim)\n        self.mid_attn = Residual(Attention(mid_dim))\n        self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim = time_dim)\n\n        # condition encoding path will be the same as the main encoding path\n\n        self.cond_downs = copy.deepcopy(self.downs)\n        self.cond_mid_block1 = copy.deepcopy(self.mid_block1)\n\n        # upsampling decoding blocks\n\n        self.ups = nn.ModuleList([])\n\n        for ind, ((dim_in, dim_out), full_attn) in enumerate(zip(reversed(in_out), reversed(full_self_attn))):\n            is_last = ind == (len(in_out) - 1)\n            attn_klass = Attention if full_attn else LinearAttention\n"}