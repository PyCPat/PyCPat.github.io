{"BEFORE":"        residual_panes=[],\n        se: bool = False,\n        se_reduction_ratio: int = 16,\n        se_context_window=None,\n        se_interpolation_mode: str = \"nearest\",\n        stride_last: bool = False,\n    ):\n        super().__init__()\n        if separable and heads != -1:\n            raise ValueError(\n                \"Separable convolutions are not compatible with multiple heads\"\n            )\n\n        kernel_size_factor = float(kernel_size_factor)\n        kernel_size = [\n            compute_new_kernel_size(k, kernel_size_factor) for k in kernel_size\n        ]\n        padding_val = get_same_padding(kernel_size[0], stride[0], dilation[0])\n\n        self.residual_mode = residual_mode\n        self.inplanes = inplanes\n\n        inplanes_loop = inplanes\n        conv = []\n\n        for _ in range(repeat - 1):\n            # Stride last means only the last convolution in block will have stride\n            if stride_last:\n                stride_val = [1]\n            else:\n                stride_val = stride\n\n            conv.extend(\n                self._get_conv_bn_layer(\n                    inplanes_loop,\n                    planes,\n                    kernel_size=kernel_size,\n                    stride=stride_val,\n                    dilation=dilation,\n                    padding=padding_val,\n                    groups=groups,\n                    heads=heads,\n                    separable=separable,\n                    normalization=normalization,\n                    norm_groups=norm_groups,\n                    bias=False,\n                )\n            )\n\n            conv.extend(\n                self._get_act_dropout_layer(drop_prob=dropout, activation=activation)\n            )\n\n            inplanes_loop = planes\n\n        conv.extend(\n            self._get_conv_bn_layer(\n                inplanes_loop,\n                planes,\n                kernel_size=kernel_size,\n                stride=stride,\n                dilation=dilation,\n                padding=padding_val,\n                groups=groups,\n                heads=heads,\n                separable=separable,\n                normalization=normalization,\n                norm_groups=norm_groups,\n                bias=False,\n            )\n        )\n\n        if se:\n            conv.append(\n                SqueezeExcite(\n                    planes,\n                    reduction_ratio=se_reduction_ratio,\n                    context_window=se_context_window,\n                    interpolation_mode=se_interpolation_mode,\n                    activation=activation,\n                )\n            )\n\n        self.mconv = nn.Sequential(*conv)\n\n        res_panes = residual_panes.copy()\n        self.dense_residual = residual\n\n        if residual:\n            res_list = nn.ModuleList()\n\n            stride_residual = (\n                stride if stride[0] == 1 or stride_last else stride[0] ** repeat\n            )\n            if len(residual_panes) == 0:\n                res_panes = [inplanes]\n                self.dense_residual = False\n            for ip in res_panes:\n                res = nn.Sequential(\n                    *self._get_conv_bn_layer(\n                        ip,\n                        planes,\n                        kernel_size=1,\n                        normalization=normalization,\n                        norm_groups=norm_groups,\n                        stride=stride_residual,\n                        bias=False,\n                    )\n                )\n\n                res_list.append(res)\n\n            self.res = res_list\n","AFTER":"            stride_val = [1] if stride_last else stride\n\n            conv.extend(\n                self._get_conv_bn_layer(\n                    inplanes_loop,\n                    planes,\n                    kernel_size=kernel_size,\n                    stride=stride_val,\n                    dilation=dilation,\n                    padding=padding_val,\n                    groups=groups,\n                    heads=heads,\n                    separable=separable,\n                    normalization=normalization,\n                    norm_groups=norm_groups,\n                    bias=False,\n                )\n            )\n\n            conv.extend(\n                self._get_act_dropout_layer(drop_prob=dropout, activation=activation)\n            )\n\n            inplanes_loop = planes\n\n        conv.extend(\n            self._get_conv_bn_layer(\n                inplanes_loop,\n                planes,\n                kernel_size=kernel_size,\n                stride=stride,\n                dilation=dilation,\n                padding=padding_val,\n                groups=groups,\n                heads=heads,\n                separable=separable,\n                normalization=normalization,\n                norm_groups=norm_groups,\n                bias=False,\n            )\n        )\n\n        if se:\n            conv.append(\n                SqueezeExcite(\n                    planes,\n                    reduction_ratio=se_reduction_ratio,\n                    context_window=se_context_window,\n                    interpolation_mode=se_interpolation_mode,\n                    activation=activation,\n                )\n            )\n\n        self.mconv = nn.Sequential(*conv)\n\n        if residual:\n            stride_residual = (\n                stride if stride[0] == 1 or stride_last else stride[0] ** repeat\n            )\n\n            self.res = nn.Sequential(\n                *self._get_conv_bn_layer(\n                    inplanes,\n                    planes,\n                    kernel_size=1,\n                    normalization=normalization,\n                    norm_groups=norm_groups,\n                    stride=stride_residual,\n                    bias=False,\n                )\n            )\n"}