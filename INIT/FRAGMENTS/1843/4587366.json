{"BEFORE":"    def __init__(self, backbone, num_classes, use_bottleneck=True, bottleneck_dim=1024, head_bottleneck_dim=1024):\n        super(Classifier, self).__init__()\n        self.backbone = backbone\n        if use_bottleneck:\n            self.bottleneck = nn.Sequential(\n                nn.Linear(backbone.out_features, bottleneck_dim),\n                nn.BatchNorm1d(bottleneck_dim),\n                nn.ReLU(),\n                nn.Dropout(0.5)\n            )\n            self.bottleneck[0].weight.data.normal_(0, 0.005)\n            self.bottleneck[0].bias.data.fill_(0.1)\n            in_features = bottleneck_dim\n        else:\n            self.bottleneck = nn.Identity()\n            in_features = backbone.out_features\n        self.head = ClassifierHead(in_features, num_classes, use_bottleneck=True, bottleneck_dim=head_bottleneck_dim)\n        self.use_bottleneck = use_bottleneck\n        self.num_classes = num_classes\n","AFTER":"    def __init__(self, backbone, num_classes, bottleneck_dim=1024, width=1024):\n        super(Classifier, self).__init__()\n        self.backbone = backbone\n        self.grl_layer = WarmStartGradientReverseLayer()\n        self.bottleneck = nn.Sequential(\n            nn.Linear(backbone.out_features, bottleneck_dim),\n            nn.BatchNorm1d(bottleneck_dim),\n            nn.ReLU(),\n            nn.Dropout(0.5)\n        )\n        self.bottleneck[0].weight.data.normal_(0, 0.005)\n        self.bottleneck[0].bias.data.fill_(0.1)\n        # The classifier head used for final predictions.\n        self.head = nn.Sequential(\n            nn.Linear(bottleneck_dim, width),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(width, num_classes)\n        )\n        # The adversarial classifier head\n        self.adv_head = nn.Sequential(\n            nn.Linear(bottleneck_dim, width),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(width, num_classes)\n        )\n        for dep in range(2):\n            self.head[dep * 3].weight.data.normal_(0, 0.01)\n            self.head[dep * 3].bias.data.fill_(0.0)\n            self.adv_head[dep * 3].weight.data.normal_(0, 0.01)\n            self.adv_head[dep * 3].bias.data.fill_(0.0)\n\n    def forward(self, inputs, keep_adv_output=False):\n"}