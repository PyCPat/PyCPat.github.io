{"BEFORE":"        net = []\n\n        res_cum_delay = 0\n        # SEQUENTIAL RESIDUALS\n        for i in range(3):\n            # RESIDUAL BLOCK\n            seq = [nn.LeakyReLU(.2)]\n            seq.append(\n                wn(\n                    cc.Conv1d(\n                        dim,\n                        dim,\n                        kernel_size,\n                        padding=cc.get_padding(\n                            kernel_size,\n                            dilation=3**i,\n                            mode=padding_mode,\n                        ),\n                        dilation=3**i,\n                        bias=bias,\n                    )))\n\n            seq.append(nn.LeakyReLU(.2))\n            seq.append(\n                wn(\n                    cc.Conv1d(\n                        dim,\n                        dim,\n                        kernel_size,\n                        padding=cc.get_padding(kernel_size, mode=padding_mode),\n                        bias=bias,\n                        cumulative_delay=seq[-2].cumulative_delay,\n                    )))\n\n            res_net = cc.CachedSequential(*seq)\n\n            net.append(Residual(res_net, cumulative_delay=res_cum_delay))\n            res_cum_delay = net[-1].cumulative_delay\n\n        self.net = cc.CachedSequential(*net)\n        self.cumulative_delay = self.net.cumulative_delay + cumulative_delay\n","AFTER":"        dilations_list,\n        padding_mode,\n        cumulative_delay=0,\n        bias=False,\n    ) -> None:\n        super().__init__()\n        blocks = []\n        for k in kernel_sizes:\n            blocks.append(\n                ResidualBlock(\n                    dim,\n                    k,\n                    dilations_list,\n                    padding_mode,\n                    bias=bias,\n                ))\n        self.net = cc.AlignBranches(*blocks, cumulative_delay=cumulative_delay)\n        self.cumulative_delay = self.net.cumulative_delay\n"}