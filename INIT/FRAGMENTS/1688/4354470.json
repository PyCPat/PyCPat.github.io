{"BEFORE":"        if not freeze and dropout is not None:\n            overrides = {\n                \"model\": {\n                    \"dropout\": dropout,\n                    \"encoder_layerdrop\": dropout,\n                    \"dropout_input\": dropout,\n                    \"attention_dropout\": dropout,\n                }\n            }\n        else:\n            overrides = {}\n\n        (\n            model,\n            cfg,\n            task,\n        ) = fairseq.checkpoint_utils.load_model_ensemble_and_task(\n            [save_path], arg_overrides=overrides\n        )\n\n        # wav2vec pretrained models may need the input waveform to be normalized\n        # Hence, we check if the model has be trained with or without it.\n        # If the information isn't contained in the checkpoint IT HAS TO BE GIVEN\n        # BY THE USER.\n        if input_norm is None:\n            if hasattr(cfg[\"task\"], \"normalize\"):\n                self.normalize = cfg[\"task\"].normalize\n            elif hasattr(cfg, \"normalize\"):\n                self.normalize = cfg.normalize\n            else:\n                self.normalize = False\n        else:\n            self.normalize = input_norm\n\n        model = model[0]\n        self.model = model\n        self.freeze = freeze\n        self.output_norm = output_norm\n\n        if self.freeze:\n            self.model.eval()\n            # Freeze parameters\n            for param in model.parameters():\n                param.requires_grad = False\n        else:\n            self.model.train()\n            for param in model.parameters():\n","AFTER":"        freeze_feature_extractor=False,\n        pretrain=True,\n        dropout=None,\n        layer_drop=None,\n    ):\n        super().__init__()\n\n        # Download the pretrained wav2vec2 model. It can be local or online.\n        download_file(pretrained_path, save_path)\n\n        # During pretraining dropout might be set to 0. However, we might want\n        # to apply dropout when fine-tuning on a downstream task. Hence we need\n        # to modify the fairseq cfg to activate dropout (if requested).\n        overrides = {}\n        if not freeze and dropout is not None:\n            overrides[\"model\"] = {}\n            if dropout is not None:\n                overrides[\"model\"][\"dropout\"] = dropout\n                overrides[\"model\"][\"dropout_input\"] = dropout\n                overrides[\"model\"][\"attention_dropout\"] = dropout\n            if layer_drop is not None:\n                overrides[\"model\"][\"layer_drop\"] = layer_drop\n\n        (\n            model,\n            cfg,\n            task,\n        ) = fairseq.checkpoint_utils.load_model_ensemble_and_task(\n            [save_path], arg_overrides=overrides\n        )\n\n        print(cfg)\n\n        # wav2vec pretrained models may need the input waveform to be normalized\n        # Hence, we check if the model has be trained with or without it.\n        # If the information isn't contained in the checkpoint IT HAS TO BE GIVEN\n        # BY THE USER.\n        if input_norm is None:\n            if hasattr(cfg[\"task\"], \"normalize\"):\n                self.normalize = cfg[\"task\"].normalize\n            elif hasattr(cfg, \"normalize\"):\n                self.normalize = cfg.normalize\n            else:\n                self.normalize = False\n        else:\n            self.normalize = input_norm\n\n        model = model[0]\n        self.model = model\n        self.freeze = freeze\n        self.output_norm = output_norm\n        self.freeze_feature_extractor = freeze_feature_extractor\n\n        print(self.model)\n\n        if self.freeze:\n            logger.warning(\n                \"speechbrain.lobes.models.fairseq_wav2vec - wav2vec 2.0 is frozen.\"\n            )\n            self.model.eval()\n            # Freeze parameters\n            for param in self.model.parameters():\n                param.requires_grad = False\n        else:\n            self.model.train()\n            for param in self.model.parameters():\n                param.requires_grad = True\n            if self.freeze_feature_extractor:\n                logger.warning(\n                    \"speechbrain.lobes.models.fairseq_wav2vec - wav2vec 2.0 feature extractor is frozen.\"\n                )\n                for param in self.model.feature_extractor.parameters():\n                    param.requires_grad = False\n\n        # Randomly initialized layers if pretrain is False\n        if not (pretrain):\n"}