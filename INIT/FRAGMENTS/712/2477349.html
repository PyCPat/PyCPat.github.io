<link rel="stylesheet" href="../default.css">
<script src="../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            blur_matrix = torch.Tensor([[1., 2., 1]]) / 4  &#47&#47 binomial filter b2
        else:
            pad_size = [2] * 4
            blur_matrix = <a id="change">torch.Tensor(</a>[<a id="change">[</a>1., 4., <a id="change">6.</a>, <a id="change">4.</a>, <a id="change">1.</a>]]<a id="change">)</a> / 16  &#47&#47 binomial filter b4

        self.padding = nn.ReflectionPad2d(pad_size)
        blur_filter = blur_matrix * blur_matrix.T</code></pre><h3>After Change</h3><pre><code class='java'>
        self.padding = nn.ReflectionPad2d(pad_size)

        blur_matrix = (np.poly1d((0.5, 0.5)) ** (blur_filter_size - 1)).coeffs
        blur_filter = <a id="change">torch.Tensor(</a>blur_matrix[:, None] * blur_matrix[None, :]<a id="change">)</a>
        &#47&#47 FIXME figure a clean hack to prevent the filter from getting saved in weights, but still
        &#47&#47 plays nice with recursive module apply for fn like .cuda(), .type(), etc -RW
        self.register_buffer(&quotblur_filter&quot, blur_filter[None, None, :, :].repeat((self.channels, 1, 1, 1)))
</code></pre>