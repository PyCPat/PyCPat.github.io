{"BEFORE":"        in_out = list(zip(dims[:-1], dims[1:]))\n\n        self.downs = nn.ModuleList([])\n        self.ups = nn.ModuleList([])\n\n        num_resolutions = len(in_out)\n\n        # resnet or convnext\n\n        blocks = partial(ConvNextBlock) if use_convnext else partial(ResnetBlock, groups = resnet_groups)\n\n        # modules for all layers\n\n        for ind, (dim_in, dim_out) in enumerate(in_out):\n            is_last = ind >= (num_resolutions - 1)\n\n            self.downs.append(nn.ModuleList([\n                blocks(dim_in, dim_out),\n                blocks(dim_out, dim_out),\n                Downsample(dim_out) if not is_last else nn.Identity()\n            ]))\n\n        mid_dim = dims[-1]\n        self.mid = blocks(mid_dim, mid_dim)\n        self.mid_attn = Attention(mid_dim)\n\n        for ind, (dim_in, dim_out) in enumerate(reversed(in_out)):\n            is_last = ind >= (num_resolutions - 1)\n\n            self.ups.append(nn.ModuleList([\n                blocks(dim_out * 2, dim_in),\n                blocks(dim_in, dim_in),\n                Upsample(dim_in) if not is_last else nn.Identity()\n            ]))\n\n\n        out_dim = default(out_dim, channels)\n\n        self.final_conv = nn.Sequential(\n            blocks(dim * 2, dim),\n","AFTER":"        consolidate_upsample_fmaps = True\n    ):\n        super().__init__()\n        self.channels = channels\n\n        init_dim = default(init_dim, dim)\n        self.init_conv = nn.Conv3d(channels, init_dim, (1, 7, 7), padding = (0, 3, 3))\n\n        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]\n        in_out = list(zip(dims[:-1], dims[1:]))\n\n        self.downs = nn.ModuleList([])\n        self.ups = nn.ModuleList([])\n\n        num_resolutions = len(in_out)\n\n        # resnet or convnext\n\n        blocks = partial(ConvNextBlock) if use_convnext else partial(ResnetBlock, groups = resnet_groups)\n\n        # modules for all layers\n\n        skip_dims = []\n\n        for ind, (dim_in, dim_out) in enumerate(in_out):\n            is_last = ind >= (num_resolutions - 1)\n            skip_dims.append(dim_in)\n\n            self.downs.append(nn.ModuleList([\n                blocks(dim_in, dim_in),\n                blocks(dim_in, dim_in),\n                Downsample(dim_in, dim_out)\n            ]))\n\n        mid_dim = dims[-1]\n        self.mid = blocks(mid_dim, mid_dim)\n        self.mid_attn = Attention(mid_dim)\n        self.mid_after = blocks(mid_dim, mid_dim)\n        self.mid_upsample = Upsample(mid_dim, dims[-2])\n\n        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[:-1])):\n            is_last = ind >= (num_resolutions - 1)\n\n            self.ups.append(nn.ModuleList([\n                blocks(dim_out + skip_dims.pop(), dim_out),\n                blocks(dim_out, dim_out),\n                Upsample(dim_out, dim_in) if not is_last else nn.Identity()\n            ]))\n\n\n        out_dim = default(out_dim, channels)\n\n        if consolidate_upsample_fmaps:\n            self.consolidator = FeatureMapConsolidator(\n                dim,\n                dim_ins = tuple(map(lambda m: dim * m, dim_mults)),\n                dim_outs = (dim,) * len(dim_mults),\n                conv_block_fn = blocks\n            )\n        else:\n            self.consolidator = FeatureMapConsolidator(dim = dim)\n\n        final_dim_in = self.consolidator.final_dim_out\n\n        self.final_conv = nn.Sequential(\n            blocks(final_dim_in + dim, dim),\n"}