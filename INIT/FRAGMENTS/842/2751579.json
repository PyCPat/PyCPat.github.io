{"BEFORE":"        self.register_buffer('embed', embed)\n","AFTER":"        learnable_codebook = False\n    ):\n        super().__init__()\n        self.decay = decay\n\n        if not kmeans_init:\n            embed = l2norm(torch.randn(codebook_size, dim))\n        else:\n            embed = torch.zeros(codebook_size, dim)\n\n        self.codebook_size = codebook_size\n        self.kmeans_iters = kmeans_iters\n        self.eps = eps\n        self.threshold_ema_dead_code = threshold_ema_dead_code\n\n        self.all_reduce_fn = distributed.all_reduce if use_ddp else noop\n        self.register_buffer('initted', torch.Tensor([not kmeans_init]))\n        self.register_buffer('cluster_size', torch.zeros(codebook_size))\n\n        self.learnable_codebook = learnable_codebook\n        if learnable_codebook:\n            self.embed = nn.Parameter(embed)\n        else:\n            self.register_buffer('embed', embed)\n\n    @torch.jit.ignore\n"}