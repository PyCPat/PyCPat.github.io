{"BEFORE":"    def __init__(self, init_weights=True):\n        \"\"\"\n        Args:\n            init_weights (optional, bool): Whether to initialize the initial neural network. (Default: ``True``).\n        \"\"\"\n        super(Discriminator, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),  # input is 3 x 216 x 216\n            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n\n            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),  # state size. (64) x 108 x 108\n            nn.BatchNorm2d(64),\n            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n\n            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),  # state size. 128 x 54 x 54\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n\n            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n\n            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),  # state size. 256 x 27 x 27\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n\n            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n\n            nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),  # state size. 512 x 14 x 14\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n        )\n        self.avgpool = nn.AdaptiveAvgPool2d((14, 14))\n        self.classifier = nn.Sequential(\n            nn.Linear(512 * 14 * 14, 1024),\n            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n            nn.Linear(1024, 1)\n        )\n\n        if init_weights:\n            self._initialize_weights()\n\n    def _initialize_weights(self):\n","AFTER":"    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.main = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),  # input is 3 x 216 x 216\n            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n\n            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),  # state size. (64) x 108 x 108\n            nn.BatchNorm2d(64),\n            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n\n            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),  # state size. 128 x 54 x 54\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n\n            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n\n            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),  # state size. 256 x 27 x 27\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n\n            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n\n            nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),  # state size. 512 x 14 x 14\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n\n            nn.AdaptiveAvgPool2d(1),\n            nn.Conv2d(512, 1024, kernel_size=1),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(1024, 1, kernel_size=1)\n"}