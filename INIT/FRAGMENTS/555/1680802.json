{"BEFORE":"        inner_dim = heads * dim_head\n\n        self.norm = nn.LayerNorm(dim)\n\n        self.alibi = AlibiPositionalBias(heads = heads)\n\n        self.to_q = nn.Sequential(\n            nn.Conv1d(dim, inner_dim, 1, bias = False),\n            nn.Conv1d(inner_dim, inner_dim, 3, bias = False, groups = inner_dim)\n        )\n\n        self.to_k = nn.Sequential(\n            nn.Conv1d(dim, inner_dim, 1, bias = False),\n            nn.Conv1d(inner_dim, inner_dim, 3, bias = False, groups = inner_dim)\n        )\n\n        self.to_v = nn.Sequential(\n            nn.Conv1d(dim, inner_dim, 1, bias = False),\n            nn.Conv1d(inner_dim, inner_dim, 3, bias = False, groups = inner_dim)\n        )\n","AFTER":"        assert heads >= 4 and (heads % 4) == 0, 'heads must be greater than 4 and divisible by 4'\n\n        self.scale = dim_head ** -0.5\n        self.heads = heads\n        inner_dim = heads * dim_head\n\n        self.norm = nn.LayerNorm(dim)\n\n        self.to_qkv = nn.Conv1d(dim, inner_dim * 3, 1, bias = False)\n\n        # ds convs with different kernel sizes for 4 groups of heads\n\n        self.qkv_ds_convs = nn.ModuleList([])\n\n        for _ in range(3): # for queries, keys, values\n            ds_convs = nn.ModuleList([])\n\n            for kernel_size in ds_conv_kernel_sizes:\n                if kernel_size == 0:\n                    ds_convs.append(nn.Identity())\n                    continue\n\n                ds_convs.append(CausalDepthwiseConv1d(inner_dim, kernel_size))\n\n            self.qkv_ds_convs.append(ds_convs)\n\n        # learned alibi positional bias for 4 groups of heads\n\n        self.learned_alibi_pos_biases = nn.ModuleList([LearnedAlibiPosBias(heads = heads \/\/ 4) for _ in range(4)])\n"}