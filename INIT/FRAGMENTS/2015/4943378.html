<link rel="stylesheet" href="../default.css">
<script src="../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        
        self.task_name = task_name
        self.task_num = len(task_name)
        <a id="change">self.device</a> = device
        self.forward_task = None
        
        self.expansion = 4 if resnet_network.feature_dim == 2048 else 1
        ch = np.array([64, 128, 256, 512]) * self.expansion
        self.shared_conv = nn.Sequential(resnet_network.conv1, resnet_network.bn1, 
                                         resnet_network.relu, resnet_network.maxpool)
        self.shared_layer, self.encoder_att, self.encoder_block_att = nn.ModuleDict({}), nn.ModuleDict({}), nn.ModuleList([])
        for i in range(4):
            self.shared_layer[str(i)] = nn.ModuleList([eval(&quotresnet_network.layer&quot+str(i+1)+&quot[:-1]&quot), 
                                                       eval(&quotresnet_network.layer&quot+str(i+1)+&quot[-1]&quot)])
            
            if i == 0:
                self.encoder_att[str(i)] = nn.ModuleList([<a id="change">self._att_layer(ch[0], 
                                                                          ch[0]//self.expansion,
                                                                          ch[0]).to(</a>self.device<a id="change">)</a>]*self.task_num)
            else:
                self.encoder_att[str(i)] = nn.ModuleList([<a id="change">self._att_layer(2*ch[i], 
                                                                            ch[i]//self.expansion, 
                                                                            ch[i]).to(</a>self.device<a id="change">)</a>]*self.task_num)
                
            if i &lt; 3:
                self.encoder_block_att.append(self._conv_layer(ch[i], ch[i+1]//self.expansion).to(self.device))</code></pre><h3>After Change</h3><pre><code class='java'>
        
        self.task_name = task_name
        self.task_num = len(task_name)
        <a id="change">self.device</a> = device
        self.forward_task = None
        
        self.expansion = 4 if resnet_network.feature_dim == 2048 else 1
        ch = np.array([64, 128, 256, 512]) * self.expansion
        self.shared_conv = nn.Sequential(resnet_network.conv1, resnet_network.bn1, 
                                         resnet_network.relu, resnet_network.maxpool)
        self.shared_layer, self.encoder_att, self.encoder_block_att = nn.ModuleDict({}), nn.ModuleDict({}), nn.ModuleList([])
        for i in range(4):
            self.shared_layer[str(i)] = nn.ModuleList([eval(&quotresnet_network.layer&quot+str(i+1)+&quot[:-1]&quot), 
                                                       eval(&quotresnet_network.layer&quot+str(i+1)+&quot[-1]&quot)])
            
            if i == 0:
                self.encoder_att[str(i)] = nn.ModuleList([<a id="change">self._att_layer(ch[0], 
                                                                          ch[0]//self.expansion,
                                                                          ch[0]).to(</a>self.device<a id="change">)</a> for _ in range(self.task_num)])
            else:
                self.encoder_att[str(i)] = nn.ModuleList([<a id="change">self._att_layer(2*ch[i], 
                                                                            ch[i]//self.expansion, 
                                                                            ch[i]).to(</a>self.device<a id="change">)</a> for _ in range(self.task_num)])
                
            if i &lt; 3:
                self.encoder_block_att.append(self._conv_layer(ch[i], ch[i+1]//self.expansion).to(self.device))</code></pre>