{"BEFORE":"        d_pe = int(perc * d_model)\n        d_enc = d_model - d_pe\n\n        # d_pe = 16\n\n        self.pos_encoder = PositionalEncodingTF(d_pe, max_len, MAX)\n\n        self.pos_encoder_value = PositionalEncodingTF(d_pe, max_len, MAX)\n        self.pos_encoder_sensor = PositionalEncodingTF(d_pe, max_len, MAX)\n\n        self.linear_value = nn.Linear(1, 16)\n        self.linear_sensor = nn.Linear(1, 16)\n\n        self.d_K = 2*(d_pe+2)  # 36 = 2*(16+1+1), 16 is positional encoding dimension\n        # self.d_K = 2 * (d_pe*3)\n\n        encoder_layers = TransformerEncoderLayer(self.d_K, nhead, nhid, dropout)\n        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n\n        encoder_layers_f_prime = TransformerEncoderLayer(int(self.d_K\/\/2), 2, nhid, dropout)\n        self.transformer_encoder_f_prime = TransformerEncoder(encoder_layers_f_prime, 2)\n\n        # self.encoder = nn.Linear(d_inp, d_enc)\n        # self.d_model = d_model\n        self.static = static\n        if self.static:\n            self.emb = nn.Linear(d_static, 16)\n\n        self.proj_weight = Parameter(torch.Tensor(self.d_K, 128))\n","AFTER":"        d_pe = 16\n        d_enc = d_inp\n\n        # d_pe = 16\n\n\n        self.pos_encoder = PositionalEncodingTF(d_pe, max_len, MAX)\n        self.pos_encoder_value = PositionalEncodingTF(d_pe, max_len, MAX)\n        self.pos_encoder_sensor = PositionalEncodingTF(d_pe, max_len, MAX)\n\n        self.linear_value = nn.Linear(1, 16)\n        self.linear_sensor = nn.Linear(1, 16)\n\n        # self.d_K = 2*(d_pe+2)  # 36 = 2*(16+1+1), 16 is positional encoding dimension\n        self.d_K = 2 * (d_pe+ 16+16)\n\n\n        encoder_layers = TransformerEncoderLayer(self.d_K, 1, nhid, dropout)\n        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n\n        encoder_layers_f_prime = TransformerEncoderLayer(int(self.d_K\/\/2), 1, nhid, dropout)\n        self.transformer_encoder_f_prime = TransformerEncoder(encoder_layers_f_prime, 2)\n\n        # self.encoder = nn.Linear(d_inp, d_enc)\n        # self.d_model = d_model\n\n        self.emb = nn.Linear(d_static, 16)\n\n        self.proj_weight = Parameter(torch.Tensor(self.d_K, 128))\n\n        self.lin_map = nn.Linear(self.d_K, 128) # why this linear make it worse? All\n        # self.lin_map = nn.Linear(4, 128) # no pe, only values\n\n        d_fi = 128 + 16\n\n        # d_fi = d_inp\n        if static == False:\n            d_fi = 128  # + d_inp  # if static is None\n        else:\n            d_fi = 128 + d_pe\n        self.mlp = nn.Sequential(\n"}