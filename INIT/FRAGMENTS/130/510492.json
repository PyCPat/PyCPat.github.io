{"BEFORE":"            input_dim = self.obs_size\n            for i in range(self.custom_config[\"model_arch_args\"][\"fc_layer\"]):\n                out_dim = self.custom_config[\"model_arch_args\"][\"out_dim_fc_{}\".format(i)]\n                fc_layer = nn.Linear(input_dim, out_dim)\n                layers.append(fc_layer)\n                input_dim = out_dim\n        elif \"conv_layer\" in self.custom_config[\"model_arch_args\"]:\n            self.obs_size = self.full_obs_space['obs'].shape\n            input_dim = self.obs_size[2]\n            for i in range(self.custom_config[\"model_arch_args\"][\"conv_layer\"]):\n                conv_f = nn.Conv2d(\n                    in_channels=input_dim,\n                    out_channels=self.custom_config[\"model_arch_args\"][\"out_channel_layer_{}\".format(i)],\n                    kernel_size=self.custom_config[\"model_arch_args\"][\"kernel_size_layer_{}\".format(i)],\n                    stride=self.custom_config[\"model_arch_args\"][\"stride_layer_{}\".format(i)],\n                    padding=self.custom_config[\"model_arch_args\"][\"padding_layer_{}\".format(i)],\n                )\n                relu_f = nn.ReLU()\n                pool_f = nn.MaxPool2d(kernel_size=self.custom_config[\"model_arch_args\"][\"pool_size_layer_{}\".format(i)])\n\n                layers.append(conv_f)\n                layers.append(relu_f)\n                layers.append(pool_f)\n\n                input_dim = self.custom_config[\"model_arch_args\"][\"out_channel_layer_{}\".format(i)]\n\n        else:\n            raise ValueError()\n\n        self.input_dim = input_dim\n\n        # obs encoder\n        self.encoder = nn.Sequential(\n            *layers\n        )\n        self.vf_encoder = nn.Sequential(\n            *layers\n        )\n\n        # core rnn\n        self.hidden_state_size = self.custom_config[\"model_arch_args\"][\"hidden_state_size\"]\n\n        if self.custom_config[\"model_arch_args\"][\"core_arch\"] == \"gru\":\n            self.rnn = nn.GRU(input_dim, self.hidden_state_size, batch_first=True)\n        elif self.custom_config[\"model_arch_args\"][\"core_arch\"] == \"lstm\":\n            self.rnn = nn.LSTM(input_dim, self.hidden_state_size, batch_first=True)\n        else:\n            raise ValueError()\n","AFTER":"        self.custom_config = model_config[\"custom_model_config\"]\n        self.full_obs_space = getattr(obs_space, \"original_space\", obs_space)\n        self.n_agents = self.custom_config[\"num_agents\"]\n\n        if \"encode_layer\" in self.custom_config[\"model_arch_args\"]:\n            encode_layer = self.custom_config[\"model_arch_args\"][\"encode_layer\"]\n            encoder_layer_dim = encode_layer.split(\"-\")\n            encoder_layer_dim = [int(i) for i in encoder_layer_dim]\n        else:  # default config\n            encoder_layer_dim = []\n            for i in range(self.custom_config[\"model_arch_args\"][\"fc_layer\"]):\n                out_dim = self.custom_config[\"model_arch_args\"][\"out_dim_fc_{}\".format(i)]\n                encoder_layer_dim.append(out_dim)\n\n        self.encoder_layer_dim = encoder_layer_dim\n        self.activation = model_config.get(\"fcnet_activation\")\n\n        # encoder\n        layers = []\n        if \"fc_layer\" in self.custom_config[\"model_arch_args\"]:\n            self.obs_size = self.full_obs_space['obs'].shape[0]\n            input_dim = self.obs_size\n            for out_dim in self.encoder_layer_dim:\n                layers.append(\n                    SlimFC(in_size=input_dim,\n                           out_size=out_dim,\n                           initializer=normc_initializer(1.0),\n                           activation_fn=self.activation))\n                input_dim = out_dim\n        elif \"conv_layer\" in self.custom_config[\"model_arch_args\"]:\n            self.obs_size = self.full_obs_space['obs'].shape\n            input_dim = self.obs_size[2]\n            for i in range(self.custom_config[\"model_arch_args\"][\"conv_layer\"]):\n                conv_f = nn.Conv2d(\n                    in_channels=input_dim,\n                    out_channels=self.custom_config[\"model_arch_args\"][\"out_channel_layer_{}\".format(i)],\n                    kernel_size=self.custom_config[\"model_arch_args\"][\"kernel_size_layer_{}\".format(i)],\n                    stride=self.custom_config[\"model_arch_args\"][\"stride_layer_{}\".format(i)],\n                    padding=self.custom_config[\"model_arch_args\"][\"padding_layer_{}\".format(i)],\n                )\n                relu_f = nn.ReLU()\n                pool_f = nn.MaxPool2d(kernel_size=self.custom_config[\"model_arch_args\"][\"pool_size_layer_{}\".format(i)])\n\n                layers.append(conv_f)\n                layers.append(relu_f)\n                layers.append(pool_f)\n\n                input_dim = self.custom_config[\"model_arch_args\"][\"out_channel_layer_{}\".format(i)]\n\n        else:\n            raise ValueError()\n\n        self.input_dim = input_dim\n\n        # obs encoder\n        self.encoder = nn.Sequential(\n            *layers\n        )\n        self.vf_encoder = nn.Sequential(\n            *layers\n        )\n\n        # core rnn\n        self.hidden_state_size = self.custom_config[\"model_arch_args\"][\"hidden_state_size\"]\n\n        if self.custom_config[\"model_arch_args\"][\"core_arch\"] == \"gru\":\n            self.rnn = nn.GRU(input_dim, self.hidden_state_size, batch_first=True)\n        elif self.custom_config[\"model_arch_args\"][\"core_arch\"] == \"lstm\":\n            self.rnn = nn.LSTM(input_dim, self.hidden_state_size, batch_first=True)\n        else:\n            raise ValueError(\n                \"should be either gru or lstm, got {}\".format(self.custom_config[\"model_arch_args\"][\"core_arch\"]))\n"}