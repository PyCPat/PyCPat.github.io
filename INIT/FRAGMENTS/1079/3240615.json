{"BEFORE":"                ResnetBlock(dim_out, dim_out, cond_dim = layer_cond_dim, time_cond_dim = time_cond_dim, groups = groups),\n                downsample_klass(dim_out) if not is_last else nn.Identity()\n            ]))\n\n        mid_dim = dims[-1]\n\n        self.mid_block1 = ResnetBlock(mid_dim, mid_dim, cond_dim = cond_dim, time_cond_dim = time_cond_dim, groups = resnet_groups[-1])\n        self.mid_attn = EinopsToAndFrom('b c h w', 'b (h w) c', Residual(Attention(mid_dim, **attn_kwargs))) if attend_at_middle else None\n        self.mid_block2 = ResnetBlock(mid_dim, mid_dim, cond_dim = cond_dim, time_cond_dim = time_cond_dim, groups = resnet_groups[-1])\n\n        for ind, ((dim_in, dim_out), groups) in enumerate(zip(reversed(in_out[1:]), reversed(resnet_groups))):\n            is_last = ind >= (num_resolutions - 2)\n            layer_cond_dim = cond_dim if not is_last else None\n\n            self.ups.append(nn.ModuleList([\n                ResnetBlock(dim_out * 2, dim_in, cond_dim = layer_cond_dim, time_cond_dim = time_cond_dim, groups = groups),\n                Residual(LinearAttention(dim_in, **attn_kwargs)) if sparse_attn else nn.Identity(),\n                ResnetBlock(dim_in, dim_in, cond_dim = layer_cond_dim, time_cond_dim = time_cond_dim, groups = groups),\n","AFTER":"        in_out = list(zip(dims[:-1], dims[1:]))\n\n        # time, image embeddings, and optional text encoding\n\n        cond_dim = default(cond_dim, dim)\n        time_cond_dim = dim * 4\n\n        self.to_time_hiddens = nn.Sequential(\n            SinusoidalPosEmb(dim),\n            nn.Linear(dim, time_cond_dim),\n            nn.GELU()\n        )\n\n        self.to_lowres_time_hiddens = None\n        if lowres_cond:\n            self.to_lowres_time_hiddens = nn.Sequential(\n                SinusoidalPosEmb(dim),\n                nn.Linear(dim, time_cond_dim),\n                nn.GELU()\n            )\n            time_cond_dim *= 2\n\n        # project to time tokens as well as time hiddens\n\n        self.to_time_tokens = nn.Sequential(\n            nn.Linear(time_cond_dim, cond_dim * num_time_tokens),\n            Rearrange('b (r d) -> b r d', r = num_time_tokens)\n        )\n\n        self.to_time_cond = nn.Sequential(\n            nn.Linear(time_cond_dim, time_cond_dim)\n        )\n\n        self.norm_cond = nn.LayerNorm(cond_dim)\n        self.norm_mid_cond = nn.LayerNorm(cond_dim)\n\n        # text encoding conditioning (optional)\n\n        self.text_to_cond = None\n\n        if cond_on_text:\n            assert exists(text_embed_dim), 'text_embed_dim must be given to the unet if cond_on_text is True'\n            self.text_to_cond = nn.Linear(text_embed_dim, cond_dim)\n\n        # finer control over whether to condition on text encodings\n\n        self.cond_on_text = cond_on_text\n\n        # for classifier free guidance\n\n        self.null_image_embed = nn.Parameter(torch.randn(1, num_image_tokens, cond_dim))\n\n        self.max_text_len = max_text_len\n        self.null_text_embed = nn.Parameter(torch.randn(1, max_text_len, cond_dim))\n\n        # attention related params\n\n        attn_kwargs = dict(heads = attn_heads, dim_head = attn_dim_head)\n\n        # resnet block klass\n\n        num_resnet_blocks = cast_tuple(num_resnet_blocks, len(in_out))\n        resnet_groups = cast_tuple(resnet_groups, len(in_out))\n\n        assert len(resnet_groups) == len(in_out)\n\n        # downsample klass\n\n        downsample_klass = Downsample\n        if cross_embed_downsample:\n            downsample_klass = partial(CrossEmbedLayer, kernel_sizes = cross_embed_downsample_kernel_sizes)\n\n        # layers\n\n        self.downs = nn.ModuleList([])\n        self.ups = nn.ModuleList([])\n        num_resolutions = len(in_out)\n\n        for ind, ((dim_in, dim_out), layer_num_resnet_blocks, groups) in enumerate(zip(in_out, num_resnet_blocks, resnet_groups)):\n            is_first = ind == 0\n            is_last = ind >= (num_resolutions - 1)\n            layer_cond_dim = cond_dim if not is_first else None\n\n            self.downs.append(nn.ModuleList([\n                ResnetBlock(dim_in, dim_out, time_cond_dim = time_cond_dim, groups = groups),\n                Residual(LinearAttention(dim_out, **attn_kwargs)) if sparse_attn else nn.Identity(),\n                nn.ModuleList([ResnetBlock(dim_out, dim_out, cond_dim = layer_cond_dim, time_cond_dim = time_cond_dim, groups = groups) for _ in range(layer_num_resnet_blocks)]),\n                downsample_klass(dim_out) if not is_last else nn.Identity()\n            ]))\n\n        mid_dim = dims[-1]\n\n        self.mid_block1 = ResnetBlock(mid_dim, mid_dim, cond_dim = cond_dim, time_cond_dim = time_cond_dim, groups = resnet_groups[-1])\n        self.mid_attn = EinopsToAndFrom('b c h w', 'b (h w) c', Residual(Attention(mid_dim, **attn_kwargs))) if attend_at_middle else None\n        self.mid_block2 = ResnetBlock(mid_dim, mid_dim, cond_dim = cond_dim, time_cond_dim = time_cond_dim, groups = resnet_groups[-1])\n\n        for ind, ((dim_in, dim_out), layer_num_resnet_blocks, groups) in enumerate(zip(reversed(in_out[1:]), reversed(num_resnet_blocks), reversed(resnet_groups))):\n            is_last = ind >= (num_resolutions - 2)\n            layer_cond_dim = cond_dim if not is_last else None\n\n            self.ups.append(nn.ModuleList([\n                ResnetBlock(dim_out * 2, dim_in, cond_dim = layer_cond_dim, time_cond_dim = time_cond_dim, groups = groups),\n                Residual(LinearAttention(dim_in, **attn_kwargs)) if sparse_attn else nn.Identity(),\n                nn.ModuleList([ResnetBlock(dim_in, dim_in, cond_dim = layer_cond_dim, time_cond_dim = time_cond_dim, groups = groups) for _ in range(layer_num_resnet_blocks)]),\n"}