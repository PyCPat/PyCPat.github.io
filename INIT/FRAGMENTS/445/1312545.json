{"BEFORE":"    def __init__(self, input_features: int, num_of_filters: int, kernel_size: Tuple = (2, 2), stride: Tuple = (1, 1),\n                 activation: str = 'relu', padding: int = 0) -> None:\n        \"\"\"\n        Arguments:\n          x - input layer\n          num_of_filters - no. of filter outputs\n          filters - shape of the filters to be used\n          stride - stride dimension\n          activation -activation function to be used\n        Returns - None\n        \"\"\"\n        super().__init__()\n        self.activation = activation\n        self.conv1 = nn.Conv1d(in_channels=input_features, out_channels=num_of_filters, kernel_size=kernel_size,\n                               stride=stride, padding=padding)\n        self.batchnorm = nn.BatchNorm1d(num_of_filters, affine=False)\n","AFTER":"    def __init__(self, in_channel, filters, num_row, num_col, padding='same', strides=(1, 1), activation='relu',\n                 name=None):\n        super(conv2d_bn, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv1d(in_channels=in_channel, out_channels=filters, kernel_size=3, padding=padding),\n            nn.BatchNorm1d(num_features=filters)\n        )\n        if activation is None:\n            pass\n        else:\n            self.conv = nn.Sequential(self.conv, nn.ReLU())\n\n    def forward(self, x):\n"}