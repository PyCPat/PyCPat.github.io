{"BEFORE":"        self.conv1 = RobustConv(in_features,\n                                hids[0],\n                                bias=bias,\n                                activation=activations.get(acts[0]))\n","AFTER":"                 bn: bool = False,\n                 gamma: float = 1.0):\n        r\"\"\"\n        Parameters\n        ----------\n        in_features : int, \n            the input dimmensions of model\n        out_features : int, \n            the output dimensions of model\n        hids : list, optional\n            the number of hidden units of each hidden layer, by default [16]\n        acts : list, optional\n            the activaction function of each hidden layer, by default ['relu']\n        dropout : float, optional\n            the dropout ratio of model, by default 0.5\n        bias : bool, optional\n            whether to use bias in the layers, by default True\n        bn: bool, optional\n            whether to use `BatchNorm1d` after the convolution layer, by default False            \n        gamma : float, optional\n            the attention weight, by default 1.0\n        \"\"\"\n\n        super().__init__()\n\n        assert len(hids) > 0\n        conv1 = []\n        conv1.append(RobustConv(in_features,\n                                hids[0],\n                                bias=bias,\n                                activation=activations.get(acts[0])))\n\n        if bn:\n            conv1.append(nn.BatchNorm1d(hids[0]))\n        self.conv1 = Sequential(*conv1)\n\n        conv2 = nn.ModuleList()\n        in_features = hids[0]\n\n        for hid, act in zip(hids[1:], acts[1:]):\n            conv2.append(RobustConv(in_features,\n                                    hid,\n                                    bias=bias,\n                                    gamma=gamma,\n                                    activation=activations.get(act)))\n            if bn:\n                conv2.append(nn.BatchNorm1d(hid))\n\n            in_features = hid\n        if bn:\n            conv2.append(nn.BatchNorm1d(in_features))\n        conv2.append(RobustConv(in_features, out_features, gamma=gamma, bias=bias))\n"}