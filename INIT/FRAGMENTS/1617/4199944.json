{"BEFORE":"        self.image_size = to_2tuple(image_size)\n        self.patch_size = to_2tuple(patch_size)\n        self.grid_size = (self.image_size[0] \/\/ self.patch_size[0], self.image_size[1] \/\/ self.patch_size[1])\n        self.output_dim = output_dim\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=width, kernel_size=patch_size, stride=patch_size, bias=False)\n","AFTER":"            dual_patchnorm: bool = False,\n            act_layer: Callable = nn.GELU,\n            norm_layer: Callable = LayerNorm,\n            output_tokens: bool = False\n    ):\n        super().__init__()\n        self.output_tokens = output_tokens\n        image_height, image_width = self.image_size = to_2tuple(image_size)\n        patch_height, patch_width = self.patch_size = to_2tuple(patch_size)\n        self.grid_size = (image_height \/\/ patch_height, image_width \/\/ patch_width)\n        self.output_dim = output_dim\n\n        # to patches related hyperparameters and projections\n        self.dual_patchnorm = dual_patchnorm\n\n        if dual_patchnorm:\n            patch_input_dim = patch_height * patch_width * 3\n            self.patchnorm_pre_ln = LayerNorm(patch_input_dim)\n            self.conv1 = nn.Linear(patch_input_dim, width)\n        else:\n            self.patchnorm_pre_ln = nn.Identity()\n            self.conv1 = nn.Conv2d(in_channels=3, out_channels=width, kernel_size=patch_size, stride=patch_size, bias=False)\n\n        # class embeddings and positional embeddings\n        scale = width ** -0.5\n"}