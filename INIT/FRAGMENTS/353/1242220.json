{"BEFORE":"            self.networks.extend([curr_network, act_cls()])\n","AFTER":"    def __init__(self,input_dim, action_space, hidden_dims, act_fn=\"relu\", out_act_fn=\"identity\", deterministic=False, re_parameterize=True, use_batch_norm=False, **kwargs):\n        super(PolicyNetwork, self).__init__()\n        if type(hidden_dims) == int:\n            hidden_dims = [hidden_dims]\n        hidden_dims = [input_dim] + hidden_dims \n        if action_space.__class__.__name__ == \"Discrete\":\n            action_dim = action_space.n\n            self.dist_cls = torch.distributions.Categorical\n            self.policy_type = \"discrete\"\n        elif action_space.__class__.__name__ == \"Box\":\n            action_dim = action_space.shape[0]\n            self.dist_cls = torch.distributions.Normal\n            self.policy_type = \"gaussian\"\n        elif action_space.__class__.__name__ == \"MultiBinary\":\n            action_dim = action_space.shape[0]\n            self.dist_cls = torch.distributions.Bernouli\n            self.policy_type = 'MultiBinary'\n        else:\n            raise NotImplementedError\n        self.networks = []\n        act_cls = get_act_cls(act_fn)\n        out_act_cls = get_act_cls(out_act_fn)\n        for i in range(len(hidden_dims)-1):\n            curr_shape, next_shape = hidden_dims[i], hidden_dims[i+1]\n            curr_network = get_network([curr_shape, next_shape])\n            if use_batch_norm:\n                self.networks.extend([curr_network, act_cls()])\n            else:\n                bn_layer = torch.nn.BatchNorm1d(hidden_dims[i+1])\n                self.networks.extend([curr_network, act_cls(), bn_layer])\n        if self.policy_type == \"gaussian\":\n"}