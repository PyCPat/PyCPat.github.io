{"BEFORE":"        num_heads: int = 4,\n        encoder_dim: int = 144,\n        num_layers: int = 16,\n        feed_forward_expansion_factor: int = 4,\n        conv_expansion_factor: int = 2,\n        conv_kernel_size: int = 31,\n        dropout: float = 0.1,\n        subsampling_factor: int = 4,\n        half_step_residual: bool = True,\n        freq_masks: int = 2,\n        time_masks: int = 10,\n        freq_width: int = 27,\n        time_width: float = 0.05,\n        grad_ckpt_batchsize: int = 4,\n    ):\n        super().__init__()\n        self.grad_ckpt_batchsize = grad_ckpt_batchsize\n\n        self.conv_subsampling = ConvSubsampling(\n            input_dim=input_dim,\n            feat_out=encoder_dim,\n            conv_channels=encoder_dim,\n            subsampling_factor=subsampling_factor,\n        )\n        self.input_projection = nn.Sequential(\n            nn.Linear(encoder_dim, encoder_dim), nn.Dropout(p=dropout)\n        )\n        module_list = [\n            ConformerBlock(\n                encoder_dim=encoder_dim,\n                num_attention_heads=num_heads,\n                feed_forward_expansion_factor=feed_forward_expansion_factor,\n                conv_expansion_factor=conv_expansion_factor,\n                feed_forward_dropout_p=dropout,\n                attention_dropout_p=dropout,\n                conv_dropout_p=dropout,\n                conv_kernel_size=conv_kernel_size,\n                half_step_residual=half_step_residual,\n            )\n            for _ in range(num_layers)\n        ]\n        self.layers = nn.Sequential(*module_list)\n","AFTER":"        num_attention_heads: int = 8,\n        feed_forward_expansion_factor: int = 4,\n        conv_expansion_factor: int = 2,\n        input_dropout_p: float = 0.1,\n        feed_forward_dropout_p: float = 0.1,\n        attention_dropout_p: float = 0.1,\n        conv_dropout_p: float = 0.1,\n        conv_kernel_size: int = 31,\n        half_step_residual: bool = True,\n    ):\n        super(ConformerEncoder, self).__init__()\n        self.conv_subsample = ConvSubsampling(\n            input_dim=input_dim, feat_out=encoder_dim, conv_channels=encoder_dim\n        )\n        self.input_dropout = nn.Dropout(p=input_dropout_p)\n        self.layers = nn.ModuleList(\n            [\n                ConformerBlock(\n                    encoder_dim=encoder_dim,\n                    num_attention_heads=num_attention_heads,\n                    feed_forward_expansion_factor=feed_forward_expansion_factor,\n                    conv_expansion_factor=conv_expansion_factor,\n                    feed_forward_dropout_p=feed_forward_dropout_p,\n                    attention_dropout_p=attention_dropout_p,\n                    conv_dropout_p=conv_dropout_p,\n                    conv_kernel_size=conv_kernel_size,\n                    half_step_residual=half_step_residual,\n                )\n                for _ in range(num_layers)\n            ]\n        )\n"}