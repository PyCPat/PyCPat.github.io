{"BEFORE":"                 anchor_ratios=[0.5, 1.0, 2.0],\n                 anchor_strides=[4, 8, 16, 32, 64],\n                 anchor_base_sizes=None,\n                 bbox_coder=dict(\n                     type='DeltaXYWHBBoxCoder',\n                     target_means=(.0, .0, .0, .0),\n                     target_stds=(1.0, 1.0, 1.0, 1.0)),\n                 reg_decoded_bbox=False,\n                 background_label=None,\n                 loss_cls=dict(\n                     type='CrossEntropyLoss',\n                     use_sigmoid=True,\n                     loss_weight=1.0),\n                 loss_bbox=dict(\n                     type='SmoothL1Loss', beta=1.0 \/ 9.0, loss_weight=1.0),\n                 train_cfg=None,\n                 test_cfg=None):\n        super(AnchorHead, self).__init__()\n        self.in_channels = in_channels\n        self.num_classes = num_classes\n        self.feat_channels = feat_channels\n        self.anchor_scales = anchor_scales\n        self.anchor_ratios = anchor_ratios\n        self.anchor_strides = anchor_strides\n        self.anchor_base_sizes = list(\n            anchor_strides) if anchor_base_sizes is None else anchor_base_sizes\n\n        self.use_sigmoid_cls = loss_cls.get('use_sigmoid', False)\n        # TODO better way to determine whether sample or not\n        self.sampling = loss_cls['type'] not in ['FocalLoss', 'GHMC']\n        if self.use_sigmoid_cls:\n            self.cls_out_channels = num_classes\n        else:\n            self.cls_out_channels = num_classes + 1\n\n        if self.cls_out_channels <= 0:\n            raise ValueError('num_classes={} is too small'.format(num_classes))\n        self.reg_decoded_bbox = reg_decoded_bbox\n\n        self.background_label = (\n            num_classes if background_label is None else background_label)\n        # background_label should be either 0 or num_classes\n        assert (self.background_label == 0\n                or self.background_label == num_classes)\n\n        self.bbox_coder = build_bbox_coder(bbox_coder)\n        self.loss_cls = build_loss(loss_cls)\n        self.loss_bbox = build_loss(loss_bbox)\n        self.train_cfg = train_cfg\n        self.test_cfg = test_cfg\n        if self.train_cfg:\n            self.assigner = build_assigner(self.train_cfg.assigner)\n            # use PseudoSampler when sampling is False\n            if self.sampling and hasattr(self.train_cfg, 'sampler'):\n                sampler_cfg = self.train_cfg.sampler\n            else:\n                sampler_cfg = dict(type='PseudoSampler')\n            self.sampler = build_sampler(sampler_cfg, context=self)\n        self.fp16_enabled = False\n\n        self.anchor_generators = []\n        for anchor_base in self.anchor_base_sizes:\n            self.anchor_generators.append(\n                AnchorGenerator(anchor_base, anchor_scales, anchor_ratios))\n\n        self.num_anchors = len(self.anchor_ratios) * len(self.anchor_scales)\n","AFTER":"        self.anchor_generator = build_anchor_generator(anchor_generator)\n        # usually the numbers of anchors for each level are the same\n        # except SSD detectors\n        self.num_anchors = self.anchor_generator.num_base_anchors[0]\n"}