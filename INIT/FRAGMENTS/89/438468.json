{"BEFORE":"            hidden_features = [hidden_features]\n        self.layers = nn.ModuleList()\n\n        if layer_norm:\n            self.layers.append(nn.LayerNorm(in_features))\n\n        self.layers.append(GINConv(in_features, hidden_features[0], activation=activation, dropout=dropout))\n        for i in range(len(hidden_features) - 1):\n            if layer_norm:\n                self.layers.append(nn.LayerNorm(hidden_features[i]))\n            self.layers.append(\n                GINConv(hidden_features[i], hidden_features[i + 1], activation=activation))\n","AFTER":"                 batch_norm=True,\n                 eps=0.0,\n                 feat_norm=None,\n                 adj_norm_func=None,\n                 dropout=0.0):\n        super(GIN, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.feat_norm = feat_norm\n        self.adj_norm_func = adj_norm_func\n        if type(hidden_features) is int:\n            hidden_features = [hidden_features]\n        self.layers = nn.ModuleList()\n\n        if layer_norm:\n            self.layers.append(nn.LayerNorm(in_features))\n\n        self.layers.append(GINConv(in_features=in_features,\n                                   out_features=hidden_features[0],\n                                   batch_norm=batch_norm,\n                                   eps=eps,\n                                   activation=activation,\n                                   dropout=dropout))\n        for i in range(len(hidden_features) - 1):\n            if layer_norm:\n                self.layers.append(nn.LayerNorm(hidden_features[i]))\n            self.layers.append(GINConv(in_features=hidden_features[i],\n                                       out_features=hidden_features[i + 1],\n                                       batch_norm=batch_norm,\n                                       eps=eps,\n                                       activation=activation,\n                                       dropout=dropout))\n        self.linear1 = nn.Linear(hidden_features[-2], hidden_features[-1])\n        self.linear2 = nn.Linear(hidden_features[-1], out_features)\n        if dropout > 0.0:\n            self.dropout = nn.Dropout(dropout)\n        else:\n            self.dropout = None\n        self.reset_parameters()\n"}