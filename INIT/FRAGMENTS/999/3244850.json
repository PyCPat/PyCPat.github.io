{"BEFORE":"        self.level_sizes = [1, 2, 4, 8, 16]\n        self.levels = len(self.level_sizes)\n        self.encoder = architecture.Encoder(32, levels=self.levels)\n        \n        self.latent_channels = 20\n        self.decoder = architecture.DecoderNVAE(\n            example_features=self.encoder(torch.zeros(\n                1, 3, problem.settings.HEIGHT, problem.settings.WIDTH\n            )),\n            latent_channels=self.latent_channels,\n            level_sizes=self.level_sizes,\n        )\n\n        def add_sn(m):\n            if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n                if len(m._forward_pre_hooks) == 0:\n                    return torch.nn.utils.spectral_norm(m)\n            else:\n                return m\n\n        self.apply(add_sn)\n","AFTER":"        self.level_sizes = [2, 2, 2, 4, 8]\n        self.levels = len(self.level_sizes)\n        self.encoder = architecture.Encoder(32, levels=self.levels)\n        \n        self.latent_channels = 20\n        self.decoder = architecture.DecoderNVAE(\n            example_features=self.encoder(torch.zeros(\n                1, 3, problem.settings.HEIGHT, problem.settings.WIDTH\n            )),\n            latent_channels=self.latent_channels,\n            level_sizes=self.level_sizes,\n        )\n\n        for module in self.modules():\n            if (\n                isinstance(module, (nn.Conv2d, nn.ConvTranspose2d))\n                and len(module._forward_pre_hooks) == 0\n            ):\n                torch.nn.utils.spectral_norm(module)\n\n    def forward(self, image_batch):\n"}