{"BEFORE":"        self.num_features = channels[-1]\n        self.global_pool = SelectAdaptivePool2d(pool_type=global_pool)\n        self.fc = nn.Conv2d(self.num_features * self.global_pool.feat_mult(), num_classes, 1, bias=True)\n","AFTER":"        self.num_classes = num_classes\n        self.cardinality = cardinality\n        self.base_width = base_width\n        self.drop_rate = drop_rate\n        assert output_stride == 32  # FIXME support dilation\n\n        self.base_layer = nn.Sequential(\n            nn.Conv2d(in_chans, channels[0], kernel_size=7, stride=1, padding=3, bias=False),\n            nn.BatchNorm2d(channels[0]),\n            nn.ReLU(inplace=True))\n        self.level0 = self._make_conv_level(channels[0], channels[0], levels[0])\n        self.level1 = self._make_conv_level(channels[0], channels[1], levels[1], stride=2)\n        cargs = dict(cardinality=cardinality, base_width=base_width, root_residual=residual_root)\n        self.level2 = DlaTree(levels[2], block, channels[1], channels[2], 2, level_root=False, **cargs)\n        self.level3 = DlaTree(levels[3], block, channels[2], channels[3], 2, level_root=True, **cargs)\n        self.level4 = DlaTree(levels[4], block, channels[3], channels[4], 2, level_root=True, **cargs)\n        self.level5 = DlaTree(levels[5], block, channels[4], channels[5], 2, level_root=True, **cargs)\n        self.feature_info = [\n            dict(num_chs=channels[0], reduction=1, module='level0'),  # rare to have a meaningful stride 1 level\n            dict(num_chs=channels[1], reduction=2, module='level1'),\n            dict(num_chs=channels[2], reduction=4, module='level2'),\n            dict(num_chs=channels[3], reduction=8, module='level3'),\n            dict(num_chs=channels[4], reduction=16, module='level4'),\n            dict(num_chs=channels[5], reduction=32, module='level5'),\n        ]\n\n        self.num_features = channels[-1]\n        self.global_pool, self.fc = create_classifier(\n            self.num_features, self.num_classes, pool_type=global_pool, use_conv=True)\n"}