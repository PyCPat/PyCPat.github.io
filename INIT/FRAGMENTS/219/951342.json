{"BEFORE":"                 activation=None,\r\n                 allow_zero_in_degree=False):\r\n        super(MedianConv, self).__init__()\r\n        if norm not in ('none', 'both', 'right', 'left'):\r\n            raise DGLError('Invalid norm value. Must be either \"none\", \"both\", \"right\" or \"left\".'\r\n                           ' But got \"{}\".'.format(norm))\r\n        self._in_feats = in_feats\r\n        self._out_feats = out_feats\r\n        self._norm = norm\r\n        self._allow_zero_in_degree = allow_zero_in_degree\r\n\r\n        if weight:\r\n            self.weight = nn.Parameter(th.Tensor(in_feats, out_feats))\r\n        else:\r\n            self.register_parameter('weight', None)\r\n\r\n        if bias:\r\n            self.bias = nn.Parameter(th.Tensor(out_feats))\r\n        else:\r\n            self.register_parameter('bias', None)\r\n\r\n        self.reset_parameters()\r\n","AFTER":"                 add_self_loop=True,\r\n                 norm='none',\r\n                 activation=None,\r\n                 weight=True,\r\n                 bias=True):\r\n        \r\n        super().__init__()\r\n        if norm not in ('none', 'both', 'right', 'left'):\r\n            raise DGLError('Invalid norm value. Must be either \"none\", \"both\", \"right\" or \"left\".'\r\n                           ' But got \"{}\".'.format(norm))      \r\n        self._in_feats = in_feats\r\n        self._out_feats = out_feats            \r\n        self._norm = norm\r\n        self._add_self_loop = add_self_loop\r\n        self._activation = activation\r\n\r\n        self.linear = Linear(in_feats, out_feats, weight=weight, bias=bias)\r\n"}