<link rel="stylesheet" href="../default.css">
<script src="../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 figure out how big the convolution output will be
        conv_arch = DEFAULT_CNN_ARCHITECTURE[&quotCONV&quot]
        dense_arch = DEFAULT_CNN_ARCHITECTURE[&quotDENSE&quot].copy()  &#47&#47 copy to mutate
        dense_in_dim = np.prod(sb_conv_arch_output_size(<a id="change">obs_space.shape[1:]</a>,
                                                        conv_arch))
        dense_arch[0][&quotin_dim&quot] = dense_in_dim
</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 now customise the dense layers to handle an appropriate-sized conv output
        dense_in_dim, = compute_output_shape(observation_space, shared_network_layers)
        dense_arch<a id="change"> = </a>[
            &#47&#47 this input size is accurate for Atari, but will be ovewritten for other envs
            {&quotin_dim&quot: 64*7*7},
        ]
        dense_arch[0][&quotin_dim&quot] = dense_in_dim
        dense_arch[-1][&quotout_dim&quot] = representation_dim

        &#47&#47 apply the dense layers
        for ind, layer_spec in enumerate(dense_arch[:-1]):
            shared_network_layers.append(nn.Linear(layer_spec[&quotin_dim&quot], layer_spec[&quotout_dim&quot]))
            shared_network_layers.append(nn.ReLU())
        &#47&#47 no ReLU after last layer
        last_layer_spec = dense_arch[-1]
        <a id="change">shared_network_layers.append(
            </a>nn.Linear(last_layer_spec[&quotin_dim&quot], last_layer_spec[&quotout_dim&quot])<a id="change">)</a>

        self.shared_network = nn.Sequential(*shared_network_layers)

    def forward(self, x):</code></pre>