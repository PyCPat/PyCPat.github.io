{"BEFORE":"        self_condition = False,\n        resnet_block_groups = 8,\n        random_fourier_features = False,\n        learned_sinusoidal_dim = 16\n    ):\n        super().__init__()\n\n        # determine dimensions\n\n        self.channels = channels\n        self.self_condition = self_condition\n        input_channels = channels * (2 if self_condition else 1)\n\n        init_dim = default(init_dim, dim)\n        self.init_conv = nn.Conv2d(input_channels, init_dim, 7, padding = 3)\n\n        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]\n        in_out = list(zip(dims[:-1], dims[1:]))\n\n        block_klass = partial(ResnetBlock, groups = resnet_block_groups)\n\n        # time embeddings\n\n        time_dim = dim * 4\n\n        sinu_pos_emb = RandomOrLearnedSinusoidalPosEmb(learned_sinusoidal_dim, random_fourier_features)\n        fourier_dim = learned_sinusoidal_dim + 1\n\n        self.time_mlp = nn.Sequential(\n            sinu_pos_emb,\n            nn.Linear(fourier_dim, time_dim),\n            nn.GELU(),\n            nn.Linear(time_dim, time_dim)\n        )\n\n        # layers\n\n        self.downs = nn.ModuleList([])\n        self.ups = nn.ModuleList([])\n        num_resolutions = len(in_out)\n\n        for ind, (dim_in, dim_out) in enumerate(in_out):\n            is_last = ind >= (num_resolutions - 1)\n\n            self.downs.append(nn.ModuleList([\n                block_klass(dim_in, dim_in, time_emb_dim = time_dim),\n                block_klass(dim_in, dim_in, time_emb_dim = time_dim),\n                Residual(LinearAttention(dim_in)),\n                Downsample(dim_in, dim_out) if not is_last else nn.Conv2d(dim_in, dim_out, 3, padding = 1)\n            ]))\n\n        mid_dim = dims[-1]\n\n        self.vit = Transformer(\n            dim = mid_dim,\n            time_cond_dim = time_dim,\n            depth = vit_depth,\n            dim_head = attn_dim_head,\n            heads = attn_heads,\n            ff_mult = ff_mult,\n            dropout = vit_dropout\n        )\n\n        for ind, (dim_in, dim_out) in enumerate(reversed(in_out)):\n            is_last = ind == (len(in_out) - 1)\n\n            self.ups.append(nn.ModuleList([\n                block_klass(dim_out + dim_in, dim_out, time_emb_dim = time_dim),\n                block_klass(dim_out + dim_in, dim_out, time_emb_dim = time_dim),\n                Residual(LinearAttention(dim_out)),\n                Upsample(dim_out, dim_in) if not is_last else  nn.Conv2d(dim_out, dim_in, 3, padding = 1)\n            ]))\n\n        default_out_dim = channels\n","AFTER":"        init_img_transform: callable = None,\n        final_img_itransform: callable = None,\n        patch_size = 1,\n    ):\n        super().__init__()\n\n        # for initial dwt transform (or whatever transform researcher wants to try here)\n\n        if exists(init_img_transform) and exists(final_img_itransform):\n            init_shape = torch.Size(1, 1, 32, 32)\n            mock_tensor = torch.randn(init_shape)\n            assert final_img_itransform(init_img_transform(mock_tensor)).shape == init_shape\n\n        self.init_img_transform = default(init_img_transform, identity)\n        self.final_img_itransform = default(final_img_itransform, identity)\n\n        input_channels = channels\n\n        # whether to do initial patching, as alternative to dwt\n\n        self.patchify = self.unpatchify = identity\n\n        if patch_size > 1:\n            input_channels = channels * (patch_size ** 2)\n            self.patchify = nn.Conv2d(channels, input_channels, patch_size, stride = patch_size)\n            self.unpatchify = nn.ConvTranspose2d(input_channels, channels, patch_size, stride = patch_size)\n\n        # determine dimensions\n\n        init_dim = default(init_dim, dim)\n        self.init_conv = nn.Conv2d(input_channels, init_dim, 7, padding = 3)\n\n        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]\n        in_out = list(zip(dims[:-1], dims[1:]))\n\n        block_klass = partial(ResnetBlock, groups = resnet_block_groups)\n\n        # time embeddings\n\n        time_dim = dim * 4\n\n        sinu_pos_emb = RandomOrLearnedSinusoidalPosEmb(learned_sinusoidal_dim, random_fourier_features)\n        fourier_dim = learned_sinusoidal_dim + 1\n\n        self.time_mlp = nn.Sequential(\n            sinu_pos_emb,\n            nn.Linear(fourier_dim, time_dim),\n            nn.GELU(),\n            nn.Linear(time_dim, time_dim)\n        )\n\n        # layers\n\n        self.downs = nn.ModuleList([])\n        self.ups = nn.ModuleList([])\n        num_resolutions = len(in_out)\n\n        for ind, (dim_in, dim_out) in enumerate(in_out):\n            is_last = ind >= (num_resolutions - 1)\n\n            self.downs.append(nn.ModuleList([\n                block_klass(dim_in, dim_in, time_emb_dim = time_dim),\n                block_klass(dim_in, dim_in, time_emb_dim = time_dim),\n                Residual(LinearAttention(dim_in)),\n                Downsample(dim_in, dim_out) if not is_last else nn.Conv2d(dim_in, dim_out, 3, padding = 1)\n            ]))\n\n        mid_dim = dims[-1]\n\n        self.vit = Transformer(\n            dim = mid_dim,\n            time_cond_dim = time_dim,\n            depth = vit_depth,\n            dim_head = attn_dim_head,\n            heads = attn_heads,\n            ff_mult = ff_mult,\n            dropout = vit_dropout\n        )\n\n        for ind, (dim_in, dim_out) in enumerate(reversed(in_out)):\n            is_last = ind == (len(in_out) - 1)\n\n            self.ups.append(nn.ModuleList([\n                block_klass(dim_out + dim_in, dim_out, time_emb_dim = time_dim),\n                block_klass(dim_out + dim_in, dim_out, time_emb_dim = time_dim),\n                Residual(LinearAttention(dim_out)),\n                Upsample(dim_out, dim_in) if not is_last else  nn.Conv2d(dim_out, dim_in, 3, padding = 1)\n            ]))\n\n        default_out_dim = input_channels\n"}