{"BEFORE":"        self.embedding = TokenEmbedding(c_in=dec_in, d_model=emb_dim)\n        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout, batch_first=True)\n        \n        self.fc_out = nn.Linear(hid_dim, dec_in)\n        \n        self.dropout = nn.Dropout(dropout)\n","AFTER":"    def __init__(self, dec_in, emb_dim, hid_dim, n_layers, embed, freq, dropout):\n        super().__init__()\n        \n        self.hid_dim = hid_dim\n        self.n_layers = n_layers\n        \n        self.embedding = DataEmbedding_ED(dec_in, emb_dim, embed, freq, dropout)\n"}