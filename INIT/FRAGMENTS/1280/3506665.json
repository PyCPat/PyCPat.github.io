{"BEFORE":"    def __init__(self,F_g,F_l,F_int):\n        super(Attention_block,self).__init__()\n        self.W_g = nn.Sequential(\n            nn.Conv2d(F_g, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n            nn.BatchNorm2d(F_int)\n            )\n        \n        self.W_x = nn.Sequential(\n            nn.Conv2d(F_l, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n            nn.BatchNorm2d(F_int)\n        )\n\n        self.psi = nn.Sequential(\n            nn.Conv2d(F_int, 1, kernel_size=1,stride=1,padding=0,bias=True),\n            nn.BatchNorm2d(1),\n            nn.Sigmoid()\n        )\n","AFTER":"    def __init__(self, in_channels, out_channels, numResNetBlocks, num_groups = 32, skip_connection_scale=1, swish=1.0, use_conv=False, skip_path=False) -> None:\n        super(DBlock, self).__init__()\n        self.max_pool = nn.MaxPool2d(2, 2)\n        self.use_conv = use_conv\n        if use_conv:\n            self.down_sample_conv = nn.Conv2d(in_channels, out_channels, 3, 2, 1)\n        else:\n            self.down_sample_conv = nn.Conv2d(in_channels, out_channels, 3, 1, 1)\n        self.resblocks = nn.ModuleList([ResNetBlock(out_channels, num_groups, skip_connection_scale, swish, skip_path=skip_path) for i in range(numResNetBlocks)])\n"}