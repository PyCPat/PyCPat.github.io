{"BEFORE":"        if self.width == 0.5:\n            stages_repeats=[4, 8, 4]\n            stages_out_channels=[24, 48, 96, 192, 1024]\n        elif self.width == 1.0:\n            stages_repeats=[4, 8, 4]\n            stages_out_channels=[24, 116, 232, 464, 1024]\n        else:\n            raise ValueError\n        inverted_residual=InvertedResidual\n\n        if len(stages_repeats) != 3:\n            raise ValueError('expected stages_repeats as list of 3 positive ints')\n        if len(stages_out_channels) != 5:\n            raise ValueError('expected stages_out_channels as list of 5 positive ints')\n        self._stage_out_channels = stages_out_channels\n\n        input_channels = 3\n        output_channels = self._stage_out_channels[0]\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(input_channels, output_channels, 3, 2, 1, bias=False),\n            nn.BatchNorm2d(output_channels),\n            nn.ReLU(inplace=True),\n        )\n        input_channels = output_channels\n\n        stage_names = ['stage{}'.format(i) for i in [2, 3, 4]]\n        for name, repeats, output_channels in zip(\n                stage_names, stages_repeats, self._stage_out_channels[1:]):\n            seq = [inverted_residual(input_channels, output_channels, 2)]\n            for i in range(repeats - 1):\n                seq.append(inverted_residual(output_channels, output_channels, 1))\n            setattr(self, name, nn.Sequential(*seq))\n            input_channels = output_channels\n\n        if pretrained:\n            self.load_pre_trained_weights()\n\n    def load_pre_trained_weights(self):\n","AFTER":"        self.version = version\n        if self.version == \"shufflenet-0.5\":\n            self._stage_out_channels = [24, 48, 96, 192, 1024]\n            self.out_channels = (96, 192)\n        elif self.version == \"shufflenet-1.0\":\n            self._stage_out_channels = [24, 116, 232, 464, 1024]\n            self.out_channels = (232, 464)\n        elif self.version == \"shufflenet-1.5\":\n            self._stage_out_channels = [24, 176, 352, 704, 1024]\n            self.out_channels = (352, 704)\n        elif self.version == \"shufflenet-2.0\":\n            self._stage_out_channels = [24, 244, 488, 976, 2048]\n            self.out_channels = (488, 976)\n        else:\n            raise ValueError\n\n        input_channels = 3\n        stages_repeats = [4, 8, 4]\n        output_channels = self._stage_out_channels[0]\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(input_channels, output_channels, 3, 2, 1, bias=False),\n            nn.BatchNorm2d(output_channels),\n            nn.ReLU(inplace=True),\n        )\n        input_channels = output_channels\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        stage_names = [\"stage{}\".format(i) for i in [2, 3, 4]]\n        for name, repeats, output_channels in zip(\n            stage_names, stages_repeats, self._stage_out_channels[1:]\n        ):\n            seq = [InvertedResidual(input_channels, output_channels, 2)]\n            for i in range(repeats - 1):\n                seq.append(InvertedResidual(output_channels, output_channels, 1))\n            setattr(self, name, nn.Sequential(*seq))\n            input_channels = output_channels\n\n        if pretrained:\n            self.load_pre_trained_weights()\n\n            self.conv1.eval()\n            for param in self.conv1.parameters():\n                param.requires_grad = False\n\n    def load_pre_trained_weights(self):\n"}