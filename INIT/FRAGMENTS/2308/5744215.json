{"BEFORE":"    def __init__(self, hparams):\n        super(Postnet, self).__init__()\n        self.convolutions = nn.ModuleList()\n\n        self.convolutions.append(\n            nn.Sequential(\n                ConvNorm(hparams.n_mel_channels, hparams.postnet_embedding_dim,\n                         kernel_size=hparams.postnet_kernel_size, stride=1,\n                         padding=int((hparams.postnet_kernel_size - 1) \/ 2),\n                         dilation=1, w_init_gain='tanh'),\n                nn.BatchNorm1d(hparams.postnet_embedding_dim))\n        )\n\n        for i in range(1, hparams.postnet_n_convolutions - 1):\n            self.convolutions.append(\n                nn.Sequential(\n                    ConvNorm(hparams.postnet_embedding_dim,\n                             hparams.postnet_embedding_dim,\n                             kernel_size=hparams.postnet_kernel_size, stride=1,\n                             padding=int((hparams.postnet_kernel_size - 1) \/ 2),\n                             dilation=1, w_init_gain='tanh'),\n                    nn.BatchNorm1d(hparams.postnet_embedding_dim))\n            )\n\n        self.convolutions.append(\n            nn.Sequential(\n                ConvNorm(hparams.postnet_embedding_dim, hparams.n_mel_channels,\n                         kernel_size=hparams.postnet_kernel_size, stride=1,\n                         padding=int((hparams.postnet_kernel_size - 1) \/ 2),\n                         dilation=1, w_init_gain='linear'),\n                nn.BatchNorm1d(hparams.n_mel_channels))\n            )\n","AFTER":"    def __init__(self, mel_dim, num_convs=5, conv_channels=512, conv_kernel_size=5, conv_dropout=0.5):\n        super(Postnet, self).__init__()\n\n        activations = [torch.tanh] * (num_convs - 1) + [None]\n        conv_channels = [conv_channels] * (num_convs - 1) + [mel_dim]\n        self.conv1ds = BatchNormConv1dStack(mel_dim, conv_channels, kernel_size=conv_kernel_size,\n                                            stride=1, padding=(conv_kernel_size -1) \/\/ 2,\n                                            activations=activations, dropout=conv_dropout)\n"}