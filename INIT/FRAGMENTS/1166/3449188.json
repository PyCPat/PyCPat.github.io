{"BEFORE":"        self.loss_fn = lambda x, y: weighted_tversky_bce_loss(x, y, alpha=0.2, beta=0.8, gamma=2)\n        self.depth_loss_fn = nn.MSELoss()\n        self.pyramidal_consistency_loss_fn = nn.L1Loss()\n        \n        self.rgb_encoder = Encoder(in_channels, depth)\n        self.rgb_decoder = Decoder(in_channels, depth, self.loss_fn)\n        \n        self.d_encoder = Encoder(in_channels, depth)\n        self.d_decoder = Decoder(in_channels, depth, self.depth_loss_fn)\n        \n        self.decoder = PAA_d(depth * 2)\n        \n        self.attention0 = DACA(depth, depth, dmap_in=True)\n        self.attention1 = DACA(depth * 3, depth, dmap_in=True)\n        self.attention2 = DACA(depth * 4, depth, dmap_in=True)\n","AFTER":"        self.in_channels = in_channels\n        self.depth = depth\n        \n        self.reduce = conv(4, 3, 3)\n        self.induce = conv(3, 4, 3)\n        \n        self.context1 = PAA_e(self.in_channels[0], self.depth)\n        self.context2 = PAA_e(self.in_channels[1], self.depth)\n        self.context3 = PAA_e(self.in_channels[2], self.depth)\n        self.context4 = PAA_e(self.in_channels[3], self.depth)\n        self.context5 = PAA_e(self.in_channels[4], self.depth)\n\n        self.decoder = PAA_d(self.depth)\n\n        self.attention0 = ASCA(self.depth    , depth, lmap_in=True)\n        self.attention1 = ASCA(self.depth * 2, depth, lmap_in=True)\n        self.attention2 = ASCA(self.depth * 2, depth)\n\n        self.loss_fn = lambda x, y: weighted_tversky_bce_loss(x, y, alpha=0.2, beta=0.8, gamma=2)\n        self.pyramidal_consistency_loss_fn = nn.L1Loss()\n"}