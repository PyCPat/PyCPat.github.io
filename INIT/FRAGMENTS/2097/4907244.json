{"BEFORE":"        for ind, layer_spec in enumerate(architecture['DENSE']):\n            in_dim, out_dim = layer_spec.get('in_dim'), layer_spec.get('out_dim')\n            if out_dim is None:\n                # For the final layer, we don't have an out_dim because it is specified by representation_dim\n                assert ind == len(architecture['DENSE']) - 1, \"Non-final dense layers require an out_dim\"\n                out_dim = representation_dim\n            self.dense_layers.append(nn.Linear(in_dim, out_dim))\n","AFTER":"    def __init__(self, obs_shape, representation_dim, architecture=DEFAULT_CNN_ARCHITECTURE, learn_stddev=False):\n        super(CNNEncoder, self).__init__()\n\n        self.input_channel = obs_shape[2]\n        self.conv_layers = []\n        self.dense_layers = []\n        for layer_spec in architecture['CONV']:\n            self.conv_layers.append(nn.Conv2d(self.input_channel, layer_spec['out_dim'],\n                                              kernel_size=layer_spec['kernel_size'], stride=layer_spec['stride']))\n            self.input_channel = layer_spec['out_dim']\n        # Needs to be a ModuleList rather than just a list for the parameters of the listed layers\n        # to be visible as part of the module .parameters() return\n        self.conv_layers = nn.ModuleList(self.conv_layers)\n\n        for ind, layer_spec in enumerate(architecture['DENSE'][:-1]):\n            in_dim, out_dim = layer_spec.get('in_dim'), layer_spec.get('out_dim')\n            self.dense_layers.append(nn.Linear(in_dim, out_dim))\n        self.mean_layer = nn.Linear(architecture['DENSE'][-1]['in_dim'], representation_dim)\n        if learn_stddev:\n            self.stddev_layer = nn.Linear(architecture['DENSE'][-1]['in_dim'], representation_dim)\n        else:\n            self.stddev_layer = None\n\n        self.dense_layers = nn.ModuleList(self.dense_layers)\n"}