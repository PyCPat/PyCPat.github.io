{"BEFORE":"    def __init__(self, img_size, z_dim, in_channels, img_channels=3):\n        super(Discriminator, self).__init__()\n        self.prog_blocks, self.rgb_layers = nn.ModuleList([]), nn.ModuleList([])\n\n        # Create progression blocks and rgb layers\n        channels = in_channels\n        for idx in range(int(log2(img_size\/4)) + 1):\n            conv_in = int(in_channels * factors[idx])\n            conv_out = channels\n            self.rgb_layers.append(WSConv2d(img_channels, conv_in, kernel_size=1, stride=1, padding=0))\n            self.prog_blocks.append(ConvBlock(conv_in, conv_out, use_pixelnorm=False))\n            channels = conv_in\n\n        self.avg_pool = nn.AvgPool2d(kernel_size=2, stride=2)\n        # +1 to in_channels because we concatenate from minibatch std\n        self.conv = WSConv2d(in_channels + 1, z_dim, kernel_size=4, stride=1, padding=0)\n        self.linear = nn.Linear(z_dim, 1)\n","AFTER":"        self.leaky = nn.LeakyReLU(0.2)\n\n        # here we work back ways from factors because the discriminator\n        # should be mirrored from the generator. So the first prog_block and\n        # rgb layer we append will work for input size 1024x1024, then 512->256-> etc\n        for i in range(len(factors) - 1, 0, -1):\n            conv_in = int(in_channels * factors[i])\n            conv_out = int(in_channels * factors[i - 1])\n            self.prog_blocks.append(ConvBlock(conv_in, conv_out, use_pixelnorm=False))\n            self.rgb_layers.append(\n                WSConv2d(img_channels, conv_in, kernel_size=1, stride=1, padding=0)\n            )\n\n        # perhaps confusing name \"initial_rgb\" this is just the RGB layer for 4x4 input size\n        # did this to \"mirror\" the generator initial_rgb\n        self.initial_rgb = WSConv2d(\n            img_channels, in_channels, kernel_size=1, stride=1, padding=0\n        )\n        self.rgb_layers.append(self.initial_rgb)\n        self.avg_pool = nn.AvgPool2d(\n            kernel_size=2, stride=2\n        )  # down sampling using avg pool\n\n        # this is the block for 4x4 input size\n        self.final_block = nn.Sequential(\n            # +1 to in_channels because we concatenate from MiniBatch std\n            WSConv2d(in_channels + 1, in_channels, kernel_size=3, padding=1),\n            nn.LeakyReLU(0.2),\n            WSConv2d(in_channels, in_channels, kernel_size=4, padding=0, stride=1),\n            nn.LeakyReLU(0.2),\n            WSConv2d(\n                in_channels, 1, kernel_size=1, padding=0, stride=1\n            ),  # we use this instead of linear layer\n        )\n"}