{"BEFORE":"        self.n_dim = len(layer_configs[0]['n_modes'])\n        self.hidden_channels = hidden_channels\n        self.lifting_channels = lifting_channels\n        self.projection_channels = projection_channels\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.n_layers = n_layers\n        self.layer_configs = layer_configs\n        self.horizontal_skips_map = horizontal_skips_map\n        self.joint_factorization = joint_factorization\n        self.non_linearity = non_linearity\n        self.rank = rank\n        self.factorization = factorization\n        self.fixed_rank_modes = fixed_rank_modes\n        self.decomposition_kwargs = decomposition_kwargs\n        self.fno_skip = fno_skip,\n        self.mlp_skip = mlp_skip,\n        self.fft_norm = fft_norm\n        self.implementation = implementation\n        self.separable = separable\n        self.preactivation = preactivation\n        self._incremental_n_modes = incremental_n_modes\n\n        assert len(self.layer_configs) == n_layers\n","AFTER":"        self.n_layers = n_layers\n        assert uno_layers is not None\n\n        assert len(uno_layers['out_channels']) == n_layers, \"Output channels for all layers are not given\"\n        assert len(uno_layers['n_modes']) == n_layers, \"number of modes for all layers are not given\"\n        assert len(uno_layers['res_scaling']) == n_layers, \"Scaling factor for all layers are not given\"\n\n        self.n_dim = len(uno_layers['n_modes'][0])\n        self.hidden_channels = hidden_channels\n        self.lifting_channels = lifting_channels\n        self.projection_channels = projection_channels\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.horizontal_skips_map = horizontal_skips_map\n        self.joint_factorization = joint_factorization\n        self.non_linearity = non_linearity\n        self.rank = rank\n        self.factorization = factorization\n        self.fixed_rank_modes = fixed_rank_modes\n        self.decomposition_kwargs = decomposition_kwargs\n        self.fno_skip = fno_skip,\n        self.mlp_skip = mlp_skip,\n        self.fft_norm = fft_norm\n        self.implementation = implementation\n        self.separable = separable\n        self.preactivation = preactivation\n        self._incremental_n_modes = incremental_n_modes\n\n        \n\n        self.layer_configs = []\n        for l in range(n_layers):\n            l_config = {}\n            l_config['out_channels'] = uno_layers['out_channels'][l]\n            l_config['n_modes'] = uno_layers['n_modes'][l]\n            l_config['res_scaling'] = uno_layers['res_scaling'][l]\n            self.layer_configs.append(l_config)\n        \n        if self.horizontal_skips_map is None:\n            self.horizontal_skips_map = {}\n            for i in range(n_layers\/\/2,0,):\n                self.horizontal_skips_map[n_layers - i -1] = i\n        \n\n        if domain_padding is not None and domain_padding > 0:\n"}