{"BEFORE":"    def __init__(self, in_planes, out_planes, expansion, stride):\n        super(Block, self).__init__()\n        self.stride = stride\n\n        planes = expansion * in_planes\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, groups=planes, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn3 = nn.BatchNorm2d(out_planes)\n\n        self.shortcut = nn.Sequential()\n        if stride == 1 and in_planes != out_planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False),\n                nn.BatchNorm2d(out_planes),\n            )\n\n    def forward(self, x):\n","AFTER":"        inp: int,\n        oup: int,\n        stride: int,\n        expand_ratio: int,\n    ) -> None:\n        super(InvertedResidual, self).__init__()\n        self.stride = stride\n\n        norm_layer = nn.BatchNorm2d\n\n        hidden_dim = int(round(inp * expand_ratio))\n        self.use_res_connect = self.stride == 1 and inp == oup\n\n        layers: List[nn.Module] = []\n        if expand_ratio != 1:\n            layers.append(ConvBNReLU(inp, hidden_dim, kernel_size=1))\n        layers.extend([\n            ConvBNReLU(hidden_dim, hidden_dim,\n                       stride=stride, groups=hidden_dim),\n            nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n            norm_layer(oup),\n        ])\n        self.conv = nn.Sequential(*layers)\n        self.out_channels = oup\n"}