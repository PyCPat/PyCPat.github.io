{"BEFORE":"        self.noise_scheduler = GaussianDiffusion(beta_schedule = beta_schedule, timesteps = timesteps)\n        self.num_timesteps = self.noise_scheduler.num_timesteps\n\n        # loss\n\n        if loss_type == 'l1':\n            loss_fn = F.l1_loss\n        elif loss_type == 'l2':\n            loss_fn = F.mse_loss\n        elif loss_type == 'huber':\n            loss_fn = F.smooth_l1_loss\n        else:\n            raise NotImplementedError()\n\n        self.loss_type = loss_type\n        self.loss_fn = loss_fn\n\n        # conditioning hparams\n\n        self.condition_on_text = condition_on_text\n        self.unconditional = not condition_on_text\n\n        # channels\n\n        self.channels = channels\n\n        # automatically take care of ensuring that first unet is unconditional\n        # while the rest of the unets are conditioned on the low resolution image produced by previous unet\n\n        unets = cast_tuple(unets)\n\n        # whether to use learned variance, defaults to True for the first unet in the cascade, as in paper\n\n        learned_variance = pad_tuple_to_length(cast_tuple(learned_variance), len(unets), fillvalue = False)\n        self.learned_variance = learned_variance\n        self.vb_loss_weight = vb_loss_weight\n\n        # get text encoder\n\n        self.text_encoder_name = text_encoder_name\n        self.text_embed_dim = get_encoded_dim(text_encoder_name)\n\n        # construct unets\n\n        self.unets = nn.ModuleList([])\n\n        for ind, (one_unet, one_unet_learned_var) in enumerate(zip(unets, learned_variance)):\n            assert isinstance(one_unet, Unet)\n            is_first = ind == 0\n\n            unet_channels_out = self.channels * (1 if not one_unet_learned_var else 2)\n\n            one_unet = one_unet.cast_model_parameters(\n                lowres_cond = not is_first,\n                cond_on_text = self.condition_on_text,\n                text_embed_dim = self.text_embed_dim if self.condition_on_text else None,\n                channels = self.channels,\n                channels_out = unet_channels_out\n            )\n\n            self.unets.append(one_unet)\n\n        # unet image sizes\n\n        assert len(self.unets) == len(image_sizes), f'you did not supply the correct number of u-nets ({len(self.unets)}) for resolutions {image_sizes}'\n        self.image_sizes = cast_tuple(image_sizes)\n        self.sample_channels = cast_tuple(self.channels, len(image_sizes))\n\n        # random crop sizes (for super-resoluting unets at the end of cascade?)\n\n        self.random_crop_sizes = cast_tuple(random_crop_sizes, len(image_sizes))\n","AFTER":"        unets = cast_tuple(unets)\n        num_unets = len(unets)\n\n        # determine noise schedules per unet\n\n        timesteps = cast_tuple(timesteps, num_unets)\n        beta_schedules = cast_tuple(beta_schedules, num_unets)\n\n        self.noise_schedulers = nn.ModuleList([])\n\n        for timestep, beta_schedule in zip(timesteps, beta_schedules):\n            noise_scheduler = GaussianDiffusion(beta_schedule = beta_schedule, timesteps = timestep)\n            self.noise_schedulers.append(noise_scheduler)\n\n        # whether to use learned variance, defaults to True for the first unet in the cascade, as in paper\n\n        learned_variance = pad_tuple_to_length(cast_tuple(learned_variance), num_unets, fillvalue = False)\n        self.learned_variance = learned_variance\n        self.vb_loss_weight = vb_loss_weight\n\n        # get text encoder\n\n        self.text_encoder_name = text_encoder_name\n        self.text_embed_dim = get_encoded_dim(text_encoder_name)\n\n        # construct unets\n\n        self.unets = nn.ModuleList([])\n\n        for ind, (one_unet, one_unet_learned_var) in enumerate(zip(unets, learned_variance)):\n            assert isinstance(one_unet, Unet)\n            is_first = ind == 0\n\n            unet_channels_out = self.channels * (1 if not one_unet_learned_var else 2)\n\n            one_unet = one_unet.cast_model_parameters(\n                lowres_cond = not is_first,\n                cond_on_text = self.condition_on_text,\n                text_embed_dim = self.text_embed_dim if self.condition_on_text else None,\n                channels = self.channels,\n                channels_out = unet_channels_out\n            )\n\n            self.unets.append(one_unet)\n\n        # unet image sizes\n\n        assert num_unets == len(image_sizes), f'you did not supply the correct number of u-nets ({len(self.unets)}) for resolutions {image_sizes}'\n        self.image_sizes = cast_tuple(image_sizes)\n        self.sample_channels = cast_tuple(self.channels, num_unets)\n"}