{"BEFORE":"    def __init__(self, num_classes=1000, stripes=[2, 3], num_layers=50):\n        super(MGN, self).__init__()\n        self.stripes = stripes\n        if num_layers == 50:\n            resnet = resnet50(pretrained=True, last_stride=1)\n        elif num_layers == 101:\n            resnet = resnet101(pretrained=True, last_stride=1)\n        elif num_layers == '101_32x8d':\n            resnet = resnext101_32x8d(pretrained=True, last_stride=1)\n        elif num_layers == '50_ibn':\n            resnet = resnet50_ibn_a(pretrained=True, last_stride=1)\n        elif num_layers == '101_ibn':\n            resnet = resnet101_ibn_a(pretrained=True, last_stride=1)\n        self.backone = nn.Sequential(\n","AFTER":"    def __init__(self,\n                 last_stride=1,\n                 use_non_local=False,\n                 num_classes=1000,\n                 stripes=[2, 3],\n                 num_layers=50,\n                 loss_type=['softmax, triplet'],\n                 margin=0.5\n                 ):\n        super(MGN, self).__init__()\n        self.stripes = stripes\n        self.margin = margin\n        self.loss_type= loss_type\n        kwargs = {\n            'use_non_local': use_non_local\n        }\n        resnet = model_zoo[num_layers](\n            pretrained=True, last_stride=last_stride,\n            **kwargs\n        )\n        self.backone = nn.Sequential(\n            resnet.conv1,\n            resnet.bn1,\n            resnet.relu,\n            resnet.maxpool,\n            resnet.layer1,\n            resnet.layer2,\n            resnet.layer3[0],\n        )\n\n        res_conv4 = nn.Sequential(*resnet.layer3[1:])\n        self.gap = nn.AdaptiveAvgPool2d(1)\n\n        reduction = nn.Sequential(nn.Conv2d(2048, 256, 1, bias=False), nn.BatchNorm2d(256))  # , nn.ReLU())\n        self._init_reduction(reduction)\n        fc_layer = nn.Sequential(nn.Dropout(), nn.Linear(256, num_classes))\n        self._init_fc(fc_layer)\n\n        branches = []\n        for stripe_id, stripe in enumerate(stripes):\n            embedding_layers = nn.ModuleList([copy.deepcopy(reduction) for _ in range(stripe+1)])\n            fc_layers = nn.ModuleList([copy.deepcopy(fc_layer) for _ in range(stripe+1)])\n            branches.append(\n                nn.ModuleList([\n                    nn.Sequential(copy.deepcopy(res_conv4), copy.deepcopy(resnet.layer4)),\n                    embedding_layers, fc_layers])\n            )\n        self.branches = nn.ModuleList(branches)\n\n        if 'softmax' in self.loss_type:\n            if 'labelsmooth' in self.loss_type:\n                self.ce_loss = CrossEntropyLabelSmooth(num_classes)\n            else:\n                self.ce_loss = nn.CrossEntropyLoss()  # .cuda()\n\n        if 'triplet' in self.loss_type:\n            self.tri_loss = TripletLoss(margin, normalize_feature=not 'circle' in self.loss_type) #.cuda()\n        if 'soft_triplet' in self.loss_type:\n            self.tri_loss = SoftTripletLoss(margin, normalize_feature=not 'circle' in self.loss_type) #.cuda()\n\n    @staticmethod\n"}