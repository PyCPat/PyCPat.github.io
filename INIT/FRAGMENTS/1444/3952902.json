{"BEFORE":"        hidden_units = [inputs_dim] + list(hidden_units)\n\n        self.linear_layers = nn.ModuleList(\n            [nn.Linear(\n                hidden_units[i],\n                hidden_units[i + 1]) for i in range(len(hidden_units) - 1)\n            ])\n        if self.use_bn:\n            self.bn_layers = nn.ModuleList(\n                [nn.BatchNorm1d(\n                    hidden_units[i + 1]) for i in range(len(hidden_units) - 1)\n                ])\n        self.activation_layers = nn.ModuleList(\n            [activation_gen(\n                activation,\n                hidden_units[i + 1],\n                dice_dim) for i in range(len(hidden_units) - 1)\n            ])\n","AFTER":"        self.use_bn = use_bn\n        hidden_units = [inputs_dim] + list(hidden_units)\n\n        # setup layers of dnn network\n        self.linear_layers = nn.ModuleList()\n        self.activation_layers = nn.ModuleList()\n        if self.use_bn:\n            self.bn_layers = nn.ModuleList()\n        \n        for i in range(len(hidden_units) - 1):\n            self.linear_layers.append(\n                nn.Linear(hidden_units[i], hidden_units[i + 1]))\n            self.activation_layers.append(\n                activation_gen(activation, hidden_units[i + 1], dice_dim))\n            if self.use_bn:\n                self.bn_layers.append(nn.BatchNorm1d(hidden_units[i + 1]))\n\n        for name, tensor in self.linear_layers.named_parameters():\n"}