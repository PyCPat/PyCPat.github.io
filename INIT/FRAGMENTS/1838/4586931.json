{"BEFORE":"    def __init__(self,input_dim, out_dim, hidden_dims, reparameterize=True, act_fn=\"relu\", out_act_fn=\"identity\", use_batch_norm=False, **kwargs):\n        super(VNetwork, self).__init__()\n        if type(hidden_dims) == int:\n            hidden_dims = [hidden_dims]\n        hidden_dims = [input_dim] + hidden_dims \n        self.networks = []\n        act_cls = get_act_cls(act_fn)\n        out_act_cls = get_act_cls(out_act_fn)\n        for i in range(len(hidden_dims)-1):\n            curr_shape, next_shape = hidden_dims[i], hidden_dims[i+1]\n            curr_network = get_network([curr_shape, next_shape])\n            if use_batch_norm:\n                self.networks.extend([curr_network, act_cls()])\n            else:\n                bn_layer = torch.nn.BatchNorm1d(hidden_dims[i+1])\n                self.networks.extend([curr_network, act_cls(), bn_layer])\n        final_network = get_network([hidden_dims[-1],out_dim])\n","AFTER":"        print(\"redundant parameters for V network: {}\".format(kwargs))\n        if type(hidden_dims) == int:\n            hidden_dims = [hidden_dims]\n        hidden_dims = [input_dim] + hidden_dims \n        self.networks = []\n        act_cls = get_act_cls(act_fn)\n        out_act_cls = get_act_cls(out_act_fn)\n        for i in range(len(hidden_dims)-1):\n            curr_shape, next_shape = hidden_dims[i], hidden_dims[i+1]\n            curr_network = get_network([curr_shape, next_shape])\n            self.networks.extend([curr_network, act_cls()])\n"}