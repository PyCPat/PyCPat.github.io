{"BEFORE":"        self.to_embed = nn.Embedding(num_tokens, dim) if exists(num_tokens) else nn.Identity()\n\n        self.layers = nn.ModuleList([Residual(PreNorm(dim, gMLPBlock(dim = dim, dim_ff = dim_ff, seq_len = seq_len, heads = heads, window = window))) for i in range(depth)])\n\n        self.to_logits = nn.Sequential(\n            nn.LayerNorm(dim),\n            nn.Linear(dim, num_tokens)\n        ) if exists(num_tokens) else nn.Identity()\n","AFTER":"        self.to_embed = nn.Embedding(num_tokens, dim)\n\n        window = cast_tuple(window, depth)\n        layers = nn.ModuleList([])\n\n        for ind, w in zip(range(depth), window):\n            layer_blocks = nn.ModuleList([\n                PreNorm(dim, gMLPBlock(dim = dim, dim_ff = dim_ff, seq_len = seq_len, heads = heads, window = w))\n            ])\n\n            if reversible:\n                layer_blocks.append(PreNorm(dim, gMLPBlock(dim = dim, dim_ff = dim_ff, seq_len = seq_len, heads = heads, window = w)))\n\n            layers.append(layer_blocks)\n\n        execute_klass = SequentialSequence if not reversible else ReversibleSequence\n        self.net = execute_klass(layers)\n\n        self.to_logits = nn.Sequential(\n            nn.LayerNorm(dim),\n            nn.Linear(dim, num_tokens)\n        )\n"}