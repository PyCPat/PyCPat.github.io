<html><h3>Pattern ID :368
</h3><img src='762435.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        self.dim = dim
        self.total_dimensions = num_dimensions + 2
        self.dim_index = dim_index if dim_index &gt; 0 else (dim_index + self.total_dimensions)
        self.axial_attentions = nn.ModuleList(<a id="change">[SelfAttention(dim, heads, dim_heads) for _ in range(num_dimensions)]</a>)
        self.permutations = calculate_permutations(num_dimensions, dim_index)

    def forward(self, x):</code></pre><h3>After Change</h3><pre><code class='java'>
        self.total_dimensions = num_dimensions + 2
        self.dim_index = dim_index if dim_index &gt; 0 else (dim_index + self.total_dimensions)

        attentions<a id="change"> = </a><a id="change">[]</a>
        <a id="change">for </a>permutation in calculate_permutations(num_dimensions, dim_index)<a id="change">:
            </a><a id="change">attentions.append(</a>PermuteToFrom(permutation, SelfAttention(dim, heads, dim_heads))<a id="change">)</a>

        self.axial_attentions = nn.ModuleList(attentions)

    def forward(self, x):</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lucidrains/axial-attention/commit/0ee301467cd8880a20db97be63eba8d6dd2e0fcf#diff-0a9a9c32bfb8ecf216b7529ebcde433cf33984c2c4039ad1dc7c1cba576834c7L66' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 762435</div><div id='project'> Project Name: lucidrains/axial-attention</div><div id='commit'> Commit Name: 0ee301467cd8880a20db97be63eba8d6dd2e0fcf</div><div id='time'> Time: 2020-06-01</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: axial_attention/axial_attention.py</div><div id='class'> Class Name: AxialAttention</div><div id='method'> Method Name: __init__</div><div id='parent_class'> Parent Class: nn.Module</div><BR><BR><div id='link'><a href='https://github.com/lucidrains/linear-attention-transformer/commit/a0a35e7e9727b6428c7527ec34f5192529ab5e82#diff-eee6cf669463e9683bcf9643c4b19a493056f98ded32854287144d47f02a7032L191' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 762434</div><div id='project'> Project Name: lucidrains/linear-attention-transformer</div><div id='commit'> Commit Name: a0a35e7e9727b6428c7527ec34f5192529ab5e82</div><div id='time'> Time: 2020-06-04</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: linear_attention_transformer/linear_attention_transformer.py</div><div id='class'> Class Name: LinearAttentionTransformer</div><div id='method'> Method Name: __init__</div><div id='parent_class'> Parent Class: nn.Module</div><BR><BR><div id='link'><a href='https://github.com/lucidrains/g-mlp-gpt/commit/7642e36ff19c6b299a77e5c1ace038e9e6726202#diff-9e1c762f97dc7e52cf231d6bec8dbb8412bc9383faaf89eadd9b1c02e46fea80L188' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 762433</div><div id='project'> Project Name: lucidrains/g-mlp-gpt</div><div id='commit'> Commit Name: 7642e36ff19c6b299a77e5c1ace038e9e6726202</div><div id='time'> Time: 2021-05-20</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: g_mlp_gpt/g_mlp_gpt.py</div><div id='class'> Class Name: gMLPGPT</div><div id='method'> Method Name: __init__</div><div id='parent_class'> Parent Class: nn.Module</div><BR>