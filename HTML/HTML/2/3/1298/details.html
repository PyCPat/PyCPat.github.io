<html><h3>Pattern ID :1298
</h3><img src='2484021.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            qkv_bias=qkv_bias, attn_drop=attn_drop, proj_drop=drop,
            pretrained_window_size=to_2tuple(pretrained_window_size))
        self.norm1 = norm_layer(dim)
        self.drop_path1 = DropPath(drop_path)<a id="change"> if </a>drop_path &gt; 0.<a id="change"> else </a>nn.Identity()

        self.mlp = Mlp(in_features=dim, hidden_features=int(dim * mlp_ratio), act_layer=act_layer, drop=drop)
        self.norm2 = norm_layer(dim)</code></pre><h3>After Change</h3><pre><code class='java'>

        self.drop_path = DropPath(drop_path) if drop_path &gt; 0. else nn.Identity()
        self.norm2 = norm_layer(dim)
        mlp_hidden_dim = <a id="change">int(</a>dim<a id="change"> * </a>mlp_ratio<a id="change">)</a>
        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)

        if self.shift_size &gt; 0:
            &#47&#47 calculate attention mask for SW-MSA</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/eora-ai/torchok/commit/ab2534f05b48a529d03f8c28af2579245772f4e0#diff-8341451f0cc24d6c15a35a4d4f9dfb66429235a10c33fa87d8ecf5664e38a1c2L73' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2484021</div><div id='project'> Project Name: eora-ai/torchok</div><div id='commit'> Commit Name: ab2534f05b48a529d03f8c28af2579245772f4e0</div><div id='time'> Time: 2022-07-11</div><div id='author'> Author: rashit.bayazitov.1995@gmail.com</div><div id='file'> File Name: src/models/modules/blocks/swin_block.py</div><div id='class'> Class Name: SwinTransformerBlock</div><div id='method'> Method Name: __init__</div><div id='parent_class'> Parent Class: nn.Module</div><BR><BR><div id='link'><a href='https://github.com/lucidrains/linear-attention-transformer/commit/75a6cefd9d7facce1ff162dc70138a6e32358f3c#diff-eee6cf669463e9683bcf9643c4b19a493056f98ded32854287144d47f02a7032L280' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2484041</div><div id='project'> Project Name: lucidrains/linear-attention-transformer</div><div id='commit'> Commit Name: 75a6cefd9d7facce1ff162dc70138a6e32358f3c</div><div id='time'> Time: 2020-06-29</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: linear_attention_transformer/linear_attention_transformer.py</div><div id='class'> Class Name: SelfAttention</div><div id='method'> Method Name: __init__</div><div id='parent_class'> Parent Class: nn.Module</div><BR><BR><div id='link'><a href='https://github.com/szq0214/cmc_with_image_mixture/commit/c3b36d304fce8787925aa2d9c2415849c9dd0390#diff-da62ce430302dcb6718b9a6a36a17d97e7ef64d1ecba8920e816a058c59c6816L117' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2484043</div><div id='project'> Project Name: szq0214/cmc_with_image_mixture</div><div id='commit'> Commit Name: c3b36d304fce8787925aa2d9c2415849c9dd0390</div><div id='time'> Time: 2019-11-25</div><div id='author'> Author: yonglong@mit.edu</div><div id='file'> File Name: models/resnet.py</div><div id='class'> Class Name: ResNet</div><div id='method'> Method Name: __init__</div><div id='parent_class'> Parent Class: nn.Module</div><BR>