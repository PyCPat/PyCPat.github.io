<html><h3>Pattern ID :671
</h3><img src='1642537.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        sparse_layer = cast_tuple(sparse_attn, depth)

        for _, sparse_attn in zip(range(depth), sparse_layer):
            attn_class = Attention<a id="change"> if </a>not sparse_attn<a id="change"> else </a>partial(SparseAttention, sparse_attn_global_indices = sparse_attn_global_indices)

            layers.append(nn.ModuleList([
                PreNorm(dim, attn_class(dim, causal = causal, seq_len = seq_len, heads = heads, dim_head = dim_head, dropout = attn_dropout, noncausal_attn_len = noncausal_attn_len)),</code></pre><h3>After Change</h3><pre><code class='java'>
            elif attn_type == &quotsparse&quot:
                attn_class = partial(SparseAttention, sparse_attn_global_indices = sparse_attn_global_indices)
            elif attn_type == &quotaxial_row&quot:
                attn_class<a id="change"> = </a><a id="change">partial(</a>SparseAxialCausalAttention<a id="change">, seq_len = seq_len, axis = 0, image_size = image_fmap_size)</a>
            elif attn_type == &quotaxial_col&quot:
                attn_class = partial(SparseAxialCausalAttention, seq_len = seq_len, axis = 1, image_size = image_fmap_size)
            elif attn_type == &quotconv_like&quot:
                attn_class = partial(SparseConvCausalAttention, seq_len = seq_len, image_size = image_fmap_size)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lucidrains/dalle-pytorch/commit/de732e8756750e161f0e51fac8baf9bcdb13182e#diff-ee397916e2ccc5603bb55b6ea44f20d581aae722f1e26d17108234ff0411b1beL67' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 1642537</div><div id='project'> Project Name: lucidrains/dalle-pytorch</div><div id='commit'> Commit Name: de732e8756750e161f0e51fac8baf9bcdb13182e</div><div id='time'> Time: 2021-02-10</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: dalle_pytorch/transformer.py</div><div id='class'> Class Name: Transformer</div><div id='method'> Method Name: __init__</div><div id='parent_class'> Parent Class: nn.Module</div><BR><BR><div id='link'><a href='https://github.com/lucidrains/x-transformers/commit/257fee10394c3cfb3467537dba53d8a610dc8aee#diff-2e64ac8840195d7dc3e07a3aac70b50bbab1cdf80f3a7432be40105e6097fc0aL288' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 1642541</div><div id='project'> Project Name: lucidrains/x-transformers</div><div id='commit'> Commit Name: 257fee10394c3cfb3467537dba53d8a610dc8aee</div><div id='time'> Time: 2020-12-27</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: x_transformers/x_transformers.py</div><div id='class'> Class Name: AttentionLayers</div><div id='method'> Method Name: __init__</div><div id='parent_class'> Parent Class: nn.Module</div><BR><BR><div id='link'><a href='https://github.com/lucidrains/imagen-pytorch/commit/f5d904c44c2dd9cb89fc7f729e7546a263b2f91f#diff-edef3c5fe92797a22c0b8fc6cca1d57b4b84ef03dfdfe802ed9147e21fc88109L1227' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 1642540</div><div id='project'> Project Name: lucidrains/imagen-pytorch</div><div id='commit'> Commit Name: f5d904c44c2dd9cb89fc7f729e7546a263b2f91f</div><div id='time'> Time: 2022-06-26</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: imagen_pytorch/imagen_pytorch.py</div><div id='class'> Class Name: Unet</div><div id='method'> Method Name: __init__</div><div id='parent_class'> Parent Class: nn.Module</div><BR>