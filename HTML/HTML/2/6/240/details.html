<html><h3>Pattern ID :240
</h3><img src='696475.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    def __init__(self, config):
        super().__init__()
        if config.hidden_size % config.num_attention_heads != 0:
            <a id="change">raise </a><a id="change">ValueError(
                </a>"The hidden size (%d) is not a multiple of the number of attention "
                "heads (%d)" %
                (config.hidden_size, config.num_attention_heads)<a id="change">)</a>
        self.output_attentions = config.output_attentions

        self.num_attention_heads = config.num_attention_heads
        self.attention_head_size = int(config.hidden_size /</code></pre><h3>After Change</h3><pre><code class='java'>
class RoFormerSelfAttention(nn.Module):
    def __init__(self, config):
        super().__init__()
        if config.hidden_size % config.num_attention_heads != 0 and <a id="change">not</a> hasattr(config, "embedding_size"):
            <a id="change">raise ValueError(
                f"The hidden size ({config.hidden_size}) is not a multiple of the number of attention "
                f"heads ({config.num_attention_heads})"</a><a id="change">
            )</a>

        self.num_attention_heads = config.num_attention_heads
        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)
        self.all_head_size = self.num_attention_heads * self.attention_head_size</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/junnyu/roformer_pytorch/commit/0cb5500e1ca9c8634d63a5231883b1a99ef0f7f8#diff-388300e635e246b74cd576c31aab2e537de66997dcd887af09d4b884e8606f25L187' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 696475</div><div id='project'> Project Name: junnyu/roformer_pytorch</div><div id='commit'> Commit Name: 0cb5500e1ca9c8634d63a5231883b1a99ef0f7f8</div><div id='time'> Time: 2021-05-17</div><div id='author'> Author: 573009727@qq.com</div><div id='file'> File Name: src/roformer/modeling_roformer.py</div><div id='class'> Class Name: RoFormerSelfAttention</div><div id='method'> Method Name: __init__</div><div id='parent_class'> Parent Class: nn.Module</div><BR><BR><div id='link'><a href='https://github.com/rikorose/deepfilternet/commit/0f69126117f7331f093ff1ca76cf0977bd9d6507#diff-5334ed6884f81bc804d2bd390857a20259928c0ff4353d022d636e6017920ce9L339' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 696472</div><div id='project'> Project Name: rikorose/deepfilternet</div><div id='commit'> Commit Name: 0f69126117f7331f093ff1ca76cf0977bd9d6507</div><div id='time'> Time: 2022-04-12</div><div id='author'> Author: h.schroeter@pm.me</div><div id='file'> File Name: DeepFilterNet/df/multistagenet.py</div><div id='class'> Class Name: FreqStage</div><div id='method'> Method Name: __init__</div><div id='parent_class'> Parent Class: nn.Module</div><BR><BR><div id='link'><a href='https://github.com/ryantd/veloce/commit/6275f02f012cd48b84824b7d67f3b13f7a778b3b#diff-1fae5f29f685e022e7bee571c33f34a6d639ca10ff29fed7d4d103e75251f34cL56' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 696468</div><div id='project'> Project Name: ryantd/veloce</div><div id='commit'> Commit Name: 6275f02f012cd48b84824b7d67f3b13f7a778b3b</div><div id='time'> Time: 2022-01-04</div><div id='author'> Author: xiaoyu.zhai@hotmail.com</div><div id='file'> File Name: phetware/layer/core.py</div><div id='class'> Class Name: OutputLayer</div><div id='method'> Method Name: __init__</div><div id='parent_class'> Parent Class: nn.Module</div><BR>