<html><h3>Pattern ID :2630
</h3><img src='15006948.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        encoded: torch.Tensor [batch, series, time steps, output embedding dimension]
            The encoded embedding for each series and time step.
        
        <a id="change">pass</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 [batch, series, time steps, embedding]
            data = data.flatten(start_dim=0, end_dim=1)
            &#47&#47 [batch * series, time steps, embedding]
            data<a id="change"> = </a>data.transpose(0, 1)
            &#47&#47 [time steps, batch * series, embedding] Correct order for PyTorch module
            data<a id="change"> = </a>mod_timesteps(data)
            data<a id="change"> = </a>data.transpose(0, 1)
            &#47&#47 [batch * series, time steps, embedding]
            data<a id="change"> = </a>data.unflatten(dim=0, sizes=(num_batches, num_series))
            &#47&#47 [batch, series, time steps, embedding]

            &#47&#47 Treat the various time steps as a batch dimension
            mod_series = self.layer_series[i]
            data = data.transpose(0, 1)
            &#47&#47 [series, batch, time steps, embedding]
            data = data.flatten(start_dim=1, end_dim=2)
            &#47&#47 [series, batch * time steps, embedding] Correct order for PyTorch module
            data = mod_series(data)
            data<a id="change"> = </a>data.unflatten(dim=1, sizes=(num_batches, num_timesteps))
            &#47&#47 [series, batch, time steps, embedding]
            data<a id="change"> = </a>data.transpose(0, 1)
            &#47&#47 [batch, series, time steps, embedding]

        &#47&#47 The resulting tensor may not be contiguous, which can cause problems further down the line.
        output = data.contiguous()

        <a id="change">return </a>output
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/servicenow/tactis/commit/0ba7dc5856d92dd6b1809b0a34a89bfed9086738#diff-359f80214ebbb3d54906470271f38934e825eb5142fe784be60c2deeff917579L157' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 15006948</div><div id='project'> Project Name: servicenow/tactis</div><div id='commit'> Commit Name: 0ba7dc5856d92dd6b1809b0a34a89bfed9086738</div><div id='time'> Time: 2022-06-06</div><div id='author'> Author: etienne.marcotte@servicenow.com</div><div id='file'> File Name: tactis/model/encoder.py</div><div id='m_class'> M Class Name: TemporalEncoder</div><div id='n_method'> N Class Name: TemporalEncoder</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: tactis/model/encoder.py</div><div id='n_file'> N File Name: tactis/model/encoder.py</div><div id='m_start'> M Start Line: 157</div><div id='m_end'> M End Line: 157</div><div id='n_start'> N Start Line: 220</div><div id='n_end'> N End Line: 255</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        Returns:
            output (batch_size, num_features, S, chunk_size)
        
        <a id="change">pass</a>

def _test_global_attentive_block():
    pass
</code></pre><h3>After Change</h3><pre><code class='java'>
        Returns:
            output (batch_size, num_features, S, chunk_size)
        
        x<a id="change"> = </a>input &#47&#47 (T, batch_size, embed_dim)

        residual = x
        x, _ = self.multihead_attn(x, x, x) &#47&#47 (T_tgt, batch_size, embed_dim), (batch_size, T_tgt, T_src), where T_tgt = T_src = T
        x<a id="change"> = </a>x + residual
        
        if self.norm:
            x<a id="change"> = </a>x.permute(1,2,0) &#47&#47 (batch_size, embed_dim, T)
            x<a id="change"> = </a>self.norm1d(x) &#47&#47 (batch_size, embed_dim, T)
            x<a id="change"> = </a>x.permute(2,0,1).contiguous() &#47&#47 (batch_size, embed_dim, T) -&gt; (T, batch_size, embed_dim)
        
        output<a id="change"> = </a>x

        <a id="change">return </a>output

def _test_global_attentive_block():
    pass</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/tky823/dnn-based_source_separation/commit/2ae0c6bb1d1c77a93ef4714007f3ce36bc92882a#diff-06c10b6d8080cf8c8c704e3471156b1561fbdc13706f27b3b6c703559c2b5e19L57' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 15006599</div><div id='project'> Project Name: tky823/dnn-based_source_separation</div><div id='commit'> Commit Name: 2ae0c6bb1d1c77a93ef4714007f3ce36bc92882a</div><div id='time'> Time: 2021-01-28</div><div id='author'> Author: 40362510+tky823@users.noreply.github.com</div><div id='file'> File Name: src/models/galr.py</div><div id='m_class'> M Class Name: GloballyAttentiveBlock</div><div id='n_method'> N Class Name: GloballyAttentiveBlock</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/models/galr.py</div><div id='n_file'> N File Name: src/models/galr.py</div><div id='m_start'> M Start Line: 64</div><div id='m_end'> M End Line: 64</div><div id='n_start'> N Start Line: 72</div><div id='n_end'> N End Line: 85</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        encoded: torch.Tensor [batch, series, time steps, output embedding dimension]
            The encoded embedding for each series and time step.
        
        <a id="change">pass</a>


class TemporalEncoder(nn.Module):
    </code></pre><h3>After Change</h3><pre><code class='java'>
        
        num_batches = encoded.shape[0]
        num_series = encoded.shape[1]
        num_timesteps<a id="change"> = </a>encoded.shape[2]

        &#47&#47 Merge the series and time steps, since the PyTorch attention implementation only accept three-dimensional input,
        &#47&#47 and the attention is applied between all tokens, no matter their series or time step.
        encoded<a id="change"> = </a>encoded.view(num_batches, num_series * num_timesteps, self.embedding_dim)

        &#47&#47 The PyTorch implementation wants the following order: [tokens, batch, embedding]
        encoded<a id="change"> = </a>encoded.transpose(0, 1)

        output<a id="change"> = </a>self.transformer_encoder(
            encoded, mask=torch.zeros(encoded.shape[0], encoded.shape[0], device=encoded.device)
        )

        &#47&#47 Reset to the original shape
        output<a id="change"> = </a>output.transpose(0, 1)
        output<a id="change"> = </a>output.view(num_batches, num_series, num_timesteps, self.embedding_dim)

        <a id="change">return </a>output


class TemporalEncoder(nn.Module):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/servicenow/tactis/commit/2be3c24d698d2ec447e2a7b8e85cafbbbfa74f67#diff-359f80214ebbb3d54906470271f38934e825eb5142fe784be60c2deeff917579L38' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 15006670</div><div id='project'> Project Name: servicenow/tactis</div><div id='commit'> Commit Name: 2be3c24d698d2ec447e2a7b8e85cafbbbfa74f67</div><div id='time'> Time: 2022-06-06</div><div id='author'> Author: etienne.marcotte@servicenow.com</div><div id='file'> File Name: tactis/model/encoder.py</div><div id='m_class'> M Class Name: Encoder</div><div id='n_method'> N Class Name: Encoder</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: tactis/model/encoder.py</div><div id='n_file'> N File Name: tactis/model/encoder.py</div><div id='m_start'> M Start Line: 53</div><div id='m_end'> M End Line: 53</div><div id='n_start'> N Start Line: 100</div><div id='n_end'> N End Line: 119</div><BR>