<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        total_len = mem.shape[2] + lmem.shape[2] + self.seq_len
        pos_emb = self.pos_emb[:, (self.seq_len - t):total_len]

        next_mem<a id="change"> = </a><a id="change">[]</a>
        next_lmem<a id="change"> = </a>[]

        mem_iter, lmem_iter = map(iterate_tensor, (mem, lmem))

        for ind, (attn, ff) in enumerate(zip(self.attn_layers, self.ff_layers)):
            layer_num = ind + 1
            use_memory = layer_num in self.memory_layers

            memories = None
            if use_memory:
                memories = (next(mem_iter), next(lmem_iter))

            x, (mem_out, lmem_out) = attn(x, memories = memories, calc_memory = use_memory, input_mask = mask, pos_emb = pos_emb)
            x, = ff(x)

            if use_memory:
                next_mem.append(mem_out)
                next_lmem.append(lmem_out)

        out = self.to_logits(x)

        next_mem, next_lmem = map(torch.stack, (next_mem, next_lmem))
        next_mem<a id="change">, next_lmem = </a>map(torch.detach, (next_mem, next_lmem))

        return out, Memory(short = next_mem, long = next_lmem)
</code></pre><h3>After Change</h3><pre><code class='java'>
        pos_emb = self.pos_emb[:, (self.seq_len - t):total_len]
        mem_iter, lmem_iter = map(iterate_tensor, (mem, lmem))

        hiddens<a id="change"> = </a><a id="change">[]</a>

        for ind, (attn, ff) in enumerate(zip(self.attn_layers, self.ff_layers)):
            layer_num = ind + 1
            use_memory = layer_num in self.memory_layers
            memories = map(next, (mem_iter, lmem_iter)) if use_memory else None

            if use_memory:
                <a id="change">hiddens.append(</a>x<a id="change">)</a>

            x = attn(x, memories = memories, calc_memory = use_memory, input_mask = mask, pos_emb = pos_emb)
            x = ff(x)

        hiddens = torch.stack(hiddens)
        out = self.to_logits(x)

        &#47&#47 calculate next memory state

        next_memory = self.memory_network(lmem, mem, hiddens)
        <a id="change">return </a>out, next_memory
</code></pre>