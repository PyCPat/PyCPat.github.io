<html><h3>Pattern ID :724
</h3><img src='2732633.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            quantizeds.append(deTransformed)
            codes.append(sample.argmax(-1).reshape(n, h, w))
            logits.append(logit.reshape(n, h, w, -1))
        <a id="change">return </a>quantizeds<a id="change">, codes, logits, xs</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
        codes = list()
        logits = list()
        xs = list()
        <a id="change">transformedCodewords</a><a id="change"> = </a><a id="change">list()</a>
        for xRaw in latents:
            n, c, h, w = xRaw.shape
            &#47&#47 [1, k, c]
            codebook = getattr(self, "codebook")[None, ...]
            &#47&#47 [n, c, h, w] -&gt; [n, h, w, c]
            encoderIn = xRaw.permute(0, 2, 3, 1)
            &#47&#47 [n, h, w, c] -&gt; [n, h*w, c]
            encoderIn = self._position(encoderIn).reshape(n, -1, c)
            &#47&#47 [1, k, c]
            codebookQ = self._codebookQuery(codebook)
            transformedCodewords.append(codebookQ)
            &#47&#47 [n, h*w, c]
            x = self._encoder(encoderIn, codebookQ)
            xs.append(x)
            &#47&#47 [n, h*w, k]
            logit = self._select(x)

            &#47&#47 [k]
            bernoulli = Bernoulli(probs=maskProb)
            &#47&#47 [n, h*w, k] (0 or 1 -&gt; choose or not choose)
            randomFalseMask = bernoulli.sample((n, h*w, )).bool()

            maskedLogit = logit.masked_fill(randomFalseMask, -1e9)

            &#47&#47 randomFalseMask *= -1e9
            &#47&#47 maskedLogit = logit + randomFalseMask &#47&#47 + randomTrueMask

            sample = F.gumbel_softmax(maskedLogit, temperature, True)
            &#47&#47 [1, k, c]
            codewords = self._codebookEncoder(codebook)
            <a id="change">transformedCodewords.append(</a>codewords<a id="change">)</a>
            &#47&#47 [n, h*w, c]
            quantized = sample @ codewords[0, ...]
            &#47&#47 [n, h*w, c]
            posistedQuantized = self._position(quantized.reshape(n, h, w, c)).reshape(n, -1, c)
            &#47&#47 [1, k, c]
            decodedCodes = self._codebookDecoder(codebook)
            &#47&#47 [n, c, h, w]
            deTransformed = self._decoder(posistedQuantized, decodedCodes).reshape(n, h, w, c).permute(0, 3, 1, 2)

            &#47&#47 [n, c, h, w]
            quantizeds.append(deTransformed)
            codes.append(sample.argmax(-1).reshape(n, h, w))
            logits.append(logit.reshape(n, h, w, -1))
        <a id="change">return </a>quantizeds, codes, logits, (xs<a id="change">, transformedCodewords</a>)
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 5</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/xiaosu-zhu/mcquic/commit/73a9bbcd4d2b8eef6cbb10a03e44936a46d8e153#diff-6b290d83a36e7951ea6e9dbd33da6b8e0b6f40c45926540ce74b74ea4ab48a24L507' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2732633</div><div id='project'> Project Name: xiaosu-zhu/mcquic</div><div id='commit'> Commit Name: 73a9bbcd4d2b8eef6cbb10a03e44936a46d8e153</div><div id='time'> Time: 2021-05-12</div><div id='author'> Author: xiaosu.zhu@outlook.com</div><div id='file'> File Name: src/mcqc/models/quantizer.py</div><div id='m_class'> M Class Name: TransformerQuantizer</div><div id='n_method'> N Class Name: TransformerQuantizer</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/mcqc/models/quantizer.py</div><div id='n_file'> N File Name: src/mcqc/models/quantizer.py</div><div id='m_start'> M Start Line: 508</div><div id='m_end'> M End Line: 554</div><div id='n_start'> N Start Line: 507</div><div id='n_end'> N End Line: 557</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            logits = [l.permute(1, 0, 2).reshape(n, h, w, k) for l in logits]
            &#47&#47 codes.append(samples.argmax(-1).permute(1, 0).reshape(n, h, w))
            &#47&#47 logits.append(logit.permute(1, 0, 2).reshape(n, h, w, k))
        <a id="change">return </a>quantizeds<a id="change">, codes, logits</a>


class TransformerQuantizer(nn.Module):
    def __init__(self, k: List[int], cin: int, rate: float = 0.1):</code></pre><h3>After Change</h3><pre><code class='java'>
    def forward(self, latents, temp, *_):
        quantizeds = list()
        codes = list()
        <a id="change">softQs</a><a id="change"> = </a><a id="change">list()</a>
        &#47&#47 logits = list()
        for _, (xRaw, k) in enumerate(zip(latents, self._k)):
            n, c, h, w = xRaw.shape
            &#47&#47 [n, c, h, w] -&gt; [h, w, n, c]
             *************** TODO: NEED DETACH? ******************* 
            &#47&#47 encoderIn = xRaw.detach().permute(2, 3, 0, 1)
            encoderIn = xRaw.permute(2, 3, 0, 1)
            &#47&#47 [h, w, n, c] -&gt; [h*w, n, c]
            x = encoderIn.reshape(-1, n ,c)
            &#47&#47 similar to scaled dot-product attention
            &#47&#47 [h*w, N, Cin],    M * [h*w, n, k]
            quantized, samples, softQ, logits = self._attention(x, temp, True)
            &#47&#47 [h*w, n, c] -&gt; [n, c, h*w] -&gt; [n, c, h, w]
            deTransformed = quantized.reshape(h, w, n, c).permute(2, 3, 0, 1)

            &#47&#47 mask = torch.rand_like(xRaw) &gt; coeff
            &#47&#47 mixed = mask * xRaw.detach() + torch.logical_not(mask) * deTransformed
            &#47&#47 [n, c, h, w]
            quantizeds.append(deTransformed)
            <a id="change">softQs.append(</a>softQ.reshape(h, w, n, c).permute(2, 3, 0, 1)<a id="change">)</a>
            samples = [s.argmax(-1).permute(1, 0).reshape(n, h, w) for s in samples]
            logits = [l.permute(1, 0, 2).reshape(n, h, w, k) for l in logits]
            &#47&#47 codes.append(samples.argmax(-1).permute(1, 0).reshape(n, h, w))
            &#47&#47 logits.append(logit.permute(1, 0, 2).reshape(n, h, w, k))
        <a id="change">return </a>quantizeds<a id="change">, softQs, codes, logits</a>


class TransformerQuantizer(nn.Module):
    def __init__(self, k: List[int], cin: int, rate: float = 0.1):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/xiaosu-zhu/mcquic/commit/e12be331e275549e5b8a7ef6a7c8dbf6d4e387bf#diff-6b290d83a36e7951ea6e9dbd33da6b8e0b6f40c45926540ce74b74ea4ab48a24L114' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2732632</div><div id='project'> Project Name: xiaosu-zhu/mcquic</div><div id='commit'> Commit Name: e12be331e275549e5b8a7ef6a7c8dbf6d4e387bf</div><div id='time'> Time: 2021-04-08</div><div id='author'> Author: xiaosu.zhu@outlook.com</div><div id='file'> File Name: src/mcqc/models/quantizer.py</div><div id='m_class'> M Class Name: AttentiveQuantizer</div><div id='n_method'> N Class Name: AttentiveQuantizer</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/mcqc/models/quantizer.py</div><div id='n_file'> N File Name: src/mcqc/models/quantizer.py</div><div id='m_start'> M Start Line: 115</div><div id='m_end'> M End Line: 140</div><div id='n_start'> N Start Line: 123</div><div id='n_end'> N End Line: 150</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            quantizeds.append(deTransformed)
            codes.append(sample.argmax(-1).reshape(n, h, w))
            logits.append(logit.reshape(n, h, w, -1))
        <a id="change">return </a>quantizeds<a id="change">, codes, logits, xs</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
        codes = list()
        logits = list()
        xs = list()
        <a id="change">transformedCodewords</a><a id="change"> = </a><a id="change">list()</a>
        for xRaw in latents:
            n, c, h, w = xRaw.shape
            &#47&#47 [1, k, c]
            codebook = getattr(self, "codebook")[None, ...]
            &#47&#47 [n, c, h, w] -&gt; [n, h, w, c]
            encoderIn = xRaw.permute(0, 2, 3, 1)
            &#47&#47 [n, h, w, c] -&gt; [n, h*w, c]
            encoderIn = self._position(encoderIn).reshape(n, -1, c)
            &#47&#47 [1, k, c]
            codebookQ = self._codebookQuery(codebook)
            <a id="change">transformedCodewords.append(</a>codebookQ<a id="change">)</a>
            &#47&#47 [n, h*w, c]
            x = self._encoder(encoderIn, codebookQ)
            xs.append(x)
            &#47&#47 [n, h*w, k]
            logit = self._select(x)

            &#47&#47 [k]
            bernoulli = Bernoulli(probs=maskProb)
            &#47&#47 [n, h*w, k] (0 or 1 -&gt; choose or not choose)
            randomFalseMask = bernoulli.sample((n, h*w, )).bool()

            maskedLogit = logit.masked_fill(randomFalseMask, -1e9)

            &#47&#47 randomFalseMask *= -1e9
            &#47&#47 maskedLogit = logit + randomFalseMask &#47&#47 + randomTrueMask

            sample = F.gumbel_softmax(maskedLogit, temperature, True)
            &#47&#47 [1, k, c]
            codewords = self._codebookEncoder(codebook)
            transformedCodewords.append(codewords)
            &#47&#47 [n, h*w, c]
            quantized = sample @ codewords[0, ...]
            &#47&#47 [n, h*w, c]
            posistedQuantized = self._position(quantized.reshape(n, h, w, c)).reshape(n, -1, c)
            &#47&#47 [1, k, c]
            decodedCodes = self._codebookDecoder(codebook)
            &#47&#47 [n, c, h, w]
            deTransformed = self._decoder(posistedQuantized, decodedCodes).reshape(n, h, w, c).permute(0, 3, 1, 2)

            &#47&#47 [n, c, h, w]
            quantizeds.append(deTransformed)
            codes.append(sample.argmax(-1).reshape(n, h, w))
            logits.append(logit.reshape(n, h, w, -1))
        <a id="change">return </a>quantizeds, codes, logits, (xs<a id="change">, transformedCodewords</a>)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/xiaosu-zhu/mcquic/commit/73a9bbcd4d2b8eef6cbb10a03e44936a46d8e153#diff-6b290d83a36e7951ea6e9dbd33da6b8e0b6f40c45926540ce74b74ea4ab48a24L507' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2732635</div><div id='project'> Project Name: xiaosu-zhu/mcquic</div><div id='commit'> Commit Name: 73a9bbcd4d2b8eef6cbb10a03e44936a46d8e153</div><div id='time'> Time: 2021-05-12</div><div id='author'> Author: xiaosu.zhu@outlook.com</div><div id='file'> File Name: src/mcqc/models/quantizer.py</div><div id='m_class'> M Class Name: TransformerQuantizer</div><div id='n_method'> N Class Name: TransformerQuantizer</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/mcqc/models/quantizer.py</div><div id='n_file'> N File Name: src/mcqc/models/quantizer.py</div><div id='m_start'> M Start Line: 508</div><div id='m_end'> M End Line: 554</div><div id='n_start'> N Start Line: 507</div><div id='n_end'> N End Line: 557</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            quantizeds.append(deTransformed)
            codes.append(sample.argmax(-1).reshape(n, h, w))
            logits.append(logit.reshape(n, h, w, -1))
        <a id="change">return </a>quantizeds<a id="change">, codes, logits</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
        quantizeds = list()
        codes = list()
        logits = list()
        <a id="change">xs</a><a id="change"> = </a><a id="change">list()</a>
        for xRaw in latents:
            n, c, h, w = xRaw.shape
            &#47&#47 [1, k, c]
            codebook = getattr(self, "codebook")[None, ...]
            &#47&#47 [n, c, h, w] -&gt; [n, h, w, c]
            encoderIn = xRaw.permute(0, 2, 3, 1)
            &#47&#47 [n, h, w, c] -&gt; [n, h*w, c]
            encoderIn = self._position(encoderIn).reshape(n, -1, c)
            &#47&#47 [1, k, c]
            codebookQ = self._codebookQuery(codebook)
            &#47&#47 [n, h*w, c]
            x = self._encoder(encoderIn, codebookQ)
            <a id="change">xs.append(</a>x<a id="change">)</a>
            &#47&#47 [n, h*w, k]
            logit = self._select(x)

            &#47&#47 [k]
            bernoulli = Bernoulli(probs=maskProb)
            &#47&#47 [n, h*w, k] (0 or 1 -&gt; choose or not choose)
            randomFalseMask = bernoulli.sample((n, h*w, )).bool()

            maskedLogit = logit.masked_fill(randomFalseMask, -1e9)

            &#47&#47 randomFalseMask *= -1e9
            &#47&#47 maskedLogit = logit + randomFalseMask &#47&#47 + randomTrueMask

            sample = F.gumbel_softmax(maskedLogit, 1.0, True)
            &#47&#47 [1, k, c]
            codewords = self._codebookEncoder(codebook)
            &#47&#47 [n, h*w, c]
            quantized = sample @ codewords[0, ...]
            &#47&#47 [n, h*w, c]
            posistedQuantized = self._position(quantized.reshape(n, h, w, c)).reshape(n, -1, c)
            &#47&#47 [1, k, c]
            decodedCodes = self._codebookDecoder(codebook)
            &#47&#47 [n, c, h, w]
            deTransformed = self._decoder(posistedQuantized, decodedCodes).reshape(n, h, w, c).permute(0, 3, 1, 2)

            &#47&#47 [n, c, h, w]
            quantizeds.append(deTransformed)
            codes.append(sample.argmax(-1).reshape(n, h, w))
            logits.append(logit.reshape(n, h, w, -1))
        <a id="change">return </a>quantizeds<a id="change">, codes, logits, xs</a>
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/xiaosu-zhu/mcquic/commit/ff056abb47b531e42496967adda543c562e1cefd#diff-6b290d83a36e7951ea6e9dbd33da6b8e0b6f40c45926540ce74b74ea4ab48a24L504' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2732634</div><div id='project'> Project Name: xiaosu-zhu/mcquic</div><div id='commit'> Commit Name: ff056abb47b531e42496967adda543c562e1cefd</div><div id='time'> Time: 2021-05-12</div><div id='author'> Author: xiaosu.zhu@outlook.com</div><div id='file'> File Name: src/mcqc/models/quantizer.py</div><div id='m_class'> M Class Name: TransformerQuantizer</div><div id='n_method'> N Class Name: TransformerQuantizer</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/mcqc/models/quantizer.py</div><div id='n_file'> N File Name: src/mcqc/models/quantizer.py</div><div id='m_start'> M Start Line: 505</div><div id='m_end'> M End Line: 554</div><div id='n_start'> N Start Line: 508</div><div id='n_end'> N End Line: 554</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            samples.append(sample)
            logits.append(logit.reshape(n, h, w, k).permute(0, 3, 1, 2))

        <a id="change">return </a>quantizeds<a id="change">, samples, logits</a>

    &#47&#47 @Module.register("quantize")
    &#47&#47 def _quantize(self, logits, temperature, hard):
    &#47&#47     logits = logits.permute(0, 2, 3, 1)</code></pre><h3>After Change</h3><pre><code class='java'>
        quantizeds = list()
        samples = list()
        logits = list()
        <a id="change">targets</a><a id="change"> = </a><a id="change">list()</a>
        for xRaw, net, codebook, k in zip(latents, self._prob, self._codebook, self._k):
            <a id="change">targets.append(</a>xRaw<a id="change">)</a>
            n, c, h, w = xRaw.shape
            &#47&#47 [n, c, h, w] -&gt; [h, w, n, c] -&gt; [h*w, n, c]
            encoderIn = xRaw.permute(2, 3, 0, 1).reshape(-1, n, c)
            x = self._encoder(encoderIn)
            &#47&#47 [h*w, n, k] -&gt; [n, h*w, k]
            logit = net(x).permute(1, 0, 2)
            sample = F.gumbel_softmax(logit * self._d, temperature, hard)
            &#47&#47 [N, h*w, c] &lt;- [N, h*w, k] @ [k, C]
            quantized = codebook(sample)
            &#47&#47 [n, h*w, c] -&gt; [h*w, n, c]
            quantized = quantized.permute(1, 0, 2)
            mixed = temperature * encoderIn / (temperature + 1) + quantized / (temperature + 1)
            &#47&#47 [h*w, n, c] -&gt; [n, h*w, c] -&gt; [n, h, w, c]
            deTransformed = self._decoder(mixed, quantized).permute(1, 0, 2).reshape(n, h, w, c)
            &#47&#47 [n, c, h, w]
            quantizeds.append(deTransformed.permute(0, 3, 1, 2))
            samples.append(sample)
            logits.append(logit.reshape(n, h, w, k).permute(0, 3, 1, 2))

        <a id="change">return </a>quantizeds<a id="change">, targets, samples, logits</a>

    &#47&#47 @Module.register("quantize")
    &#47&#47 def _quantize(self, logits, temperature, hard):
    &#47&#47     logits = logits.permute(0, 2, 3, 1)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/xiaosu-zhu/mcquic/commit/1651f1f4f7d28d9afa1ca7abafa2af0d6140309a#diff-6b290d83a36e7951ea6e9dbd33da6b8e0b6f40c45926540ce74b74ea4ab48a24L100' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2732637</div><div id='project'> Project Name: xiaosu-zhu/mcquic</div><div id='commit'> Commit Name: 1651f1f4f7d28d9afa1ca7abafa2af0d6140309a</div><div id='time'> Time: 2021-01-14</div><div id='author'> Author: xiaosu.zhu@outlook.com</div><div id='file'> File Name: src/mcqc/models/quantizer.py</div><div id='m_class'> M Class Name: TransformerQuantizer</div><div id='n_method'> N Class Name: TransformerQuantizer</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/mcqc/models/quantizer.py</div><div id='n_file'> N File Name: src/mcqc/models/quantizer.py</div><div id='m_start'> M Start Line: 101</div><div id='m_end'> M End Line: 120</div><div id='n_start'> N Start Line: 101</div><div id='n_end'> N End Line: 126</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            quantizeds.append(deTransformed)
            codes.append(sample.argmax(-1).permute(1, 0).reshape(n, h, w))
            logits.append(logit.reshape(n, h, w, k))
        <a id="change">return </a>quantizeds<a id="change">, codes, logits</a>


class VQuantizer(nn.Module):
    def __init__(self, k: List[int], cin: int, rate: float = 0.1):</code></pre><h3>After Change</h3><pre><code class='java'>
        quantizeds = list()
        codes = list()
        logits = list()
        <a id="change">allCodewords</a><a id="change"> = </a><a id="change">list()</a>
        &#47&#47 probability = mixin / (mixin + 1.0)
        &#47&#47 rolloutDistribution = Bernoulli(probs=torch.tensor(probability).to(latents[0].device))
        for xRaw, prob, squeeze, codebook, k in zip(latents, self._prob, self._squeeze, self._codebook, self._k):
            n, c, h, w = xRaw.shape
            &#47&#47 [c, k]
            codewords = codebook.weight
            &#47&#47 [n, c, h, w] -&gt; [h, w, n, c]
            encoderIn = xRaw.permute(2, 3, 0, 1)
            &#47&#47 [h, w, n, c] -&gt; [h*w, n, c]
            encoderIn = self._position(encoderIn).reshape(-1, n, c)
            &#47&#47 [h*w, n, c]
            &#47&#47 x = self._encoder(posisted)
            x = self._encoder(encoderIn)
            &#47&#47 x = self._dePosition(x.reshape(h, w, n, c)).reshape(-1, n, c)
            &#47&#47 x = encoderIn
            &#47&#47 [h*w, n, k]
            &#47&#47 logit = prob(x, h, w)
            &#47&#47 logit = torch.matmul(x / (x ** 2).sum(-1, keepdim=True), codewords / (codewords ** 2).sum(0, keepdim=True))
            logit = x @ codewords
            soft = (logit / temperature).softmax(-1)
            if hard:
                hard = logit.argmax(-1)
                hard = F.one_hot(hard, k)
                sample = (hard - soft).detach() + soft
            else:
                sample = soft
            &#47&#47 sample = F.gumbel_softmax(logit, temperature, hard)
            &#47&#47 sample = logit
            &#47&#47 [h*w, N, c] &lt;- [h*w, N, k] @ [k, C]
            quantized = codebook(sample)

            quantized += torch.randn_like(quantized)
            &#47&#47 quantized = sample

            &#47&#47 normalize
            &#47&#47 quantized /= (k - 0.5) / (2 * k - 2)
            &#47&#47 quantized -= 0.5 / (k - 1)
            &#47&#47 [h*w, n, c]
            &#47&#47 quantized = squeeze(sample, h, w)
            posistedQuantized = self._position(quantized.reshape(h, w, n, c)).reshape(-1, n, c)

            &#47&#47 mixed = (mixin * encoderIn / (mixin + 1)) + (quantized / (mixin + 1))

            &#47&#47 mask = rolloutDistribution.sample((h*w, n, 1)).bool()

            &#47&#47 mixed = mask * encoderIn.detach() + torch.logical_not(mask) * quantized
            &#47&#47 [h*w, n, c] -&gt; [n, c, h*w] -&gt; [n, c, h, w]
            deTransformed = self._decoder(posistedQuantized, posistedQuantized).reshape(h, w, n, c).permute(2, 3, 0, 1)
            &#47&#47 deTransformed = quantized.permute(1, 2, 0).reshape(n, c, h, w)
            &#47&#47 deTransformed = self._dePosition(deTransformed.reshape(h, w, n, c)).permute(2, 3, 0, 1)
            &#47&#47 [n, c, h, w]
            quantizeds.append(deTransformed)
            codes.append(sample.argmax(-1).permute(1, 0).reshape(n, h, w))
            logits.append(logit.reshape(n, h, w, k))
            <a id="change">allCodewords.append(</a>codewords.t()<a id="change">)</a>
        <a id="change">return </a>quantizeds<a id="change">, codes, logits, allCodewords</a>


class VQuantizer(nn.Module):
    def __init__(self, k: List[int], cin: int, rate: float = 0.1):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/xiaosu-zhu/mcquic/commit/96e69f8763c2cf2c9cf0695159db17ddf4e0c857#diff-6b290d83a36e7951ea6e9dbd33da6b8e0b6f40c45926540ce74b74ea4ab48a24L279' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2732636</div><div id='project'> Project Name: xiaosu-zhu/mcquic</div><div id='commit'> Commit Name: 96e69f8763c2cf2c9cf0695159db17ddf4e0c857</div><div id='time'> Time: 2021-02-15</div><div id='author'> Author: xiaosu.zhu@outlook.com</div><div id='file'> File Name: src/mcqc/models/quantizer.py</div><div id='m_class'> M Class Name: TransformerQuantizer</div><div id='n_method'> N Class Name: TransformerQuantizer</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/mcqc/models/quantizer.py</div><div id='n_file'> N File Name: src/mcqc/models/quantizer.py</div><div id='m_start'> M Start Line: 280</div><div id='m_end'> M End Line: 335</div><div id='n_start'> N Start Line: 280</div><div id='n_end'> N End Line: 339</div><BR>