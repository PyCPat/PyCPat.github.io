<html><h3>Pattern ID :2888
</h3><img src='15935879.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            img_size = x.shape[-2:]  &#47&#47 height, width
            s = [0.83, 0.67]  &#47&#47 scales
            y = []
            <a id="change">for </a>i, xi in <a id="change">enumerate(</a>(x,
                                    torch_utils.scale_img(x.flip(3), s[0]),  &#47&#47 flip-lr and scale
                                    torch_utils.scale_img(x, s[1]),  &#47&#47 scale
                                    )<a id="change">):
                &#47&#47 cv2.imwrite(&quotimg%g.jpg&quot % i, 255 * xi[0].numpy().transpose((1, 2, 0))[:, :, ::-1])
                </a>y.append(self.forward_once(xi)[0])

            y[1][..., :4] /= s[0]  &#47&#47 scale
            y[1][..., 0] = img_size[1] - y[1][..., 0]  &#47&#47 flip lr</code></pre><h3>After Change</h3><pre><code class='java'>
        if augment:
            img_size = x.shape[-2:]  &#47&#47 height, width
            s = [1, 0.83, 0.67]  &#47&#47 scales
            f<a id="change"> = </a><a id="change">[</a>None, 3, None<a id="change"></a>]  &#47&#47 flips (2-ud, 3-lr)
            y = []  &#47&#47 outputs
            for si, fi in zip(s, f):
                xi = torch_utils.scale_img(x.flip(fi) if fi else x, si)
                <a id="change">yi</a> = self.forward_once(xi)[0]  &#47&#47 forward
                &#47&#47 cv2.imwrite(&quotimg%g.jpg&quot % s, 255 * xi[0].numpy().transpose((1, 2, 0))[:, :, ::-1])  &#47&#47 save
                yi[..., :4] /= si  &#47&#47 de-scale
                if fi is 2:
                    <a id="change">yi[..., 1]</a> = img_size[0] - yi[..., 1]  &#47&#47 de-flip ud
                elif fi is 3:
                    yi[..., 0] = img_size[1] - yi[..., 0]  &#47&#47 de-flip lr
                y.append(yi)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 5</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/jeffwang0325/image-identification-for-self-driving-cars/commit/1d17b9af0f68ee97f9edc5f10fea51e9af9ef14e#diff-2cd118cbb69c9ca7b5544f4187b11335fc3addbaf2c3c5bb45435cac648c957bL84' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 15935879</div><div id='project'> Project Name: jeffwang0325/image-identification-for-self-driving-cars</div><div id='commit'> Commit Name: 1d17b9af0f68ee97f9edc5f10fea51e9af9ef14e</div><div id='time'> Time: 2020-07-24</div><div id='author'> Author: glenn.jocher@ultralytics.com</div><div id='file'> File Name: models/yolo.py</div><div id='m_class'> M Class Name: Model</div><div id='n_method'> N Class Name: Model</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/yolo.py</div><div id='n_file'> N File Name: models/yolo.py</div><div id='m_start'> M Start Line: 85</div><div id='m_end'> M End Line: 96</div><div id='n_start'> N Start Line: 84</div><div id='n_end'> N End Line: 98</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            img_size = x.shape[-2:]  &#47&#47 height, width
            s = [0.83, 0.67]  &#47&#47 scales
            y = []
            <a id="change">for </a>i, xi in <a id="change">enumerate(</a>(x,
                                    torch_utils.scale_img(x.flip(3), s[0]),  &#47&#47 flip-lr and scale
                                    torch_utils.scale_img(x, s[1]),  &#47&#47 scale
                                    )<a id="change">):
                &#47&#47 cv2.imwrite(&quotimg%g.jpg&quot % i, 255 * xi[0].numpy().transpose((1, 2, 0))[:, :, ::-1])
                </a>y.append(self.forward_once(xi)[0])

            y[1][..., :4] /= s[0]  &#47&#47 scale
            y[1][..., 0] = img_size[1] - y[1][..., 0]  &#47&#47 flip lr</code></pre><h3>After Change</h3><pre><code class='java'>
        if augment:
            img_size = x.shape[-2:]  &#47&#47 height, width
            s = [1, 0.83, 0.67]  &#47&#47 scales
            f<a id="change"> = </a><a id="change">[</a>None, 3, None<a id="change"></a>]  &#47&#47 flips (2-ud, 3-lr)
            y = []  &#47&#47 outputs
            for si, fi in zip(s, f):
                xi = torch_utils.scale_img(x.flip(fi) if fi else x, si)
                <a id="change">yi</a> = self.forward_once(xi)[0]  &#47&#47 forward
                &#47&#47 cv2.imwrite(&quotimg%g.jpg&quot % s, 255 * xi[0].numpy().transpose((1, 2, 0))[:, :, ::-1])  &#47&#47 save
                yi[..., :4] /= si  &#47&#47 de-scale
                if fi is 2:
                    <a id="change">yi[..., 1]</a> = img_size[0] - yi[..., 1]  &#47&#47 de-flip ud
                elif fi is 3:
                    yi[..., 0] = img_size[1] - yi[..., 0]  &#47&#47 de-flip lr
                y.append(yi)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/positive666/yolov5_research/commit/1d17b9af0f68ee97f9edc5f10fea51e9af9ef14e#diff-2cd118cbb69c9ca7b5544f4187b11335fc3addbaf2c3c5bb45435cac648c957bL82' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 15935883</div><div id='project'> Project Name: positive666/yolov5_research</div><div id='commit'> Commit Name: 1d17b9af0f68ee97f9edc5f10fea51e9af9ef14e</div><div id='time'> Time: 2020-07-24</div><div id='author'> Author: glenn.jocher@ultralytics.com</div><div id='file'> File Name: models/yolo.py</div><div id='m_class'> M Class Name: Model</div><div id='n_method'> N Class Name: Model</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/yolo.py</div><div id='n_file'> N File Name: models/yolo.py</div><div id='m_start'> M Start Line: 85</div><div id='m_end'> M End Line: 96</div><div id='n_start'> N Start Line: 84</div><div id='n_end'> N End Line: 98</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def forward(self, x: List[torch.Tensor]) -&gt; List[torch.Tensor]:
        &#47&#47 top-down
        inters = [x[-1]]                                                        &#47&#47 P7in
        <a id="change">for </a>i, conv in <a id="change">enumerate(</a>self.inter_convs<a id="change">):
            </a>out = F.interpolate(inters[-1], scale_factor=2., mode="nearest")    &#47&#47 resize(P7td)
            out = self.fuse([x[-2-i], out])                                     &#47&#47 P6in + resize(P7td)
            inters.append(conv(out))                                            &#47&#47 P6td = conv(P6in + resize(P7td))
            </code></pre><h3>After Change</h3><pre><code class='java'>

    def forward(self, x: List[torch.Tensor]) -&gt; List[torch.Tensor]:
        &#47&#47 top-down
        <a id="change">tds</a><a id="change"> = </a><a id="change">[</a>None<a id="change"></a>] * self.num_levels
        tds[-1] = x[-1]
        for i in range(self.num_levels - 2, -1 , -1):
            <a id="change">tds[i]</a> = self.td_fuses[i]([x[i], self.upsample(tds[i+1])])      &#47&#47 P6td = conv(P6in + resize(P7td))
        
        &#47&#47 bottom-up
        outs = [None] * self.num_levels</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/gau-nernst/vision-toolbox/commit/0844b6bcb142e63b09cf6ae44e5087c20d52c380#diff-885dedfcd4036693f75ac69100e9ef7734b059807b782809a75be8b18762d0bdL161' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 15935881</div><div id='project'> Project Name: gau-nernst/vision-toolbox</div><div id='commit'> Commit Name: 0844b6bcb142e63b09cf6ae44e5087c20d52c380</div><div id='time'> Time: 2022-04-10</div><div id='author'> Author: gau.nernst@yahoo.com.sg</div><div id='file'> File Name: vision_toolbox/necks.py</div><div id='m_class'> M Class Name: BiFPNLayer</div><div id='n_method'> N Class Name: BiFPNLayer</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: vision_toolbox/necks.py</div><div id='n_file'> N File Name: vision_toolbox/necks.py</div><div id='m_start'> M Start Line: 163</div><div id='m_end'> M End Line: 180</div><div id='n_start'> N Start Line: 160</div><div id='n_end'> N End Line: 172</div><BR>