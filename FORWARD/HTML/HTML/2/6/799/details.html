<html><h3>Pattern ID :799
</h3><img src='2881385.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        oC, iC, kH, kW = self.weight.size()

        affined_style = self.style_fc(style)
        weight = self.elr_scale * <a id="change">self.weight.view(1</a>, oC, iC, kH, kW<a id="change">)</a> * affined_style.view(B, 1, iC, 1, 1)
    
        if self.demod:
            norm = 1 / ((weight**2).sum([2, 3, 4]) + 1.e-8)**0.5
            weight = weight * norm.view(B, oC, 1, 1, 1)

        out = F.conv2d(
            x.contiguous().view(1, B*iC, H, W), weight.view(B*oC, iC, kH, kW),
            stride=self.stride, padding=self.padding, groups=B
        )

        _, _, H, W = out.size()
        out = <a id="change">out.view(</a>B, <a id="change">-1</a>, H, W<a id="change">)</a>
        return out

class Bias(nn.Module):
    def __init__(self, out_channels, bias_init=0, lr=1.):</code></pre><h3>After Change</h3><pre><code class='java'>
            weight = weight * d

        &#47&#47 reshaping for conv input
        x<a id="change"> = </a><a id="change">x.reshape(</a>1, -1, H, W<a id="change">)</a>
        _, _, *ws = weight.size()
        weight = weight.reshape(B*self.out_channels, *ws)
        pad = self._get_same_padding(H)
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/stomoya/animeface/commit/b3652bae109c713da926d5532eb014b02135da52#diff-0383c3e0d2575e5076916c51cfa38d4b02353d9aef3e245e35d328bb2169f279L71' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2881385</div><div id='project'> Project Name: stomoya/animeface</div><div id='commit'> Commit Name: b3652bae109c713da926d5532eb014b02135da52</div><div id='time'> Time: 2020-12-14</div><div id='author'> Author: blackie0110@gmail.com</div><div id='file'> File Name: implementations/StyleGAN2/model.py</div><div id='m_class'> M Class Name: EqualizedModulatedConv2d</div><div id='n_method'> N Class Name: ModulatedConv2d</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: implementations/StyleGAN2/model.py</div><div id='n_file'> N File Name: implementations/StyleGAN2/model.py</div><div id='m_start'> M Start Line: 71</div><div id='m_end'> M End Line: 87</div><div id='n_start'> N Start Line: 109</div><div id='n_end'> N End Line: 131</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 if no NaNs for padding varying trial lengths we can batch the computation
        if not torch.isnan(x).any():
            trial_embeddings = <a id="change">self.trial_net(x.view(batch * permutation_dim, -1)).view(
                </a>batch, permutation_dim, <a id="change">-1</a><a id="change">
            )</a>
            combined_embedding = self.combining_function(trial_embeddings, dim=1)
            trial_counts = torch.ones(batch, 1, dtype=torch.float32) * permutation_dim

        &#47&#47 otherwise we need to loop over the batch to account for varying trial lengths</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 Get number of trials from non-nan entries
        num_batch, max_num_trials = x.shape[0], x.shape[self.aggregation_dim]
        nan_counts = (
            <a id="change">torch.isnan(x)
            .sum(dim=self.aggregation_dim)  &#47&#47 count nans over trial dimension
            .reshape(</a>-1<a id="change">)</a>[:num_batch]  &#47&#47 counts are the same across data dims
            .unsqueeze(-1)  &#47&#47 make it (batch, 1) to match embeddings below
        )
        &#47&#47 number of non-nan trials
        trial_counts<a id="change"> = </a>max_num_trials - nan_counts

        &#47&#47 get nan entries
        is_nan = torch.isnan(x)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mackelab/sbi/commit/3831fd6d5fda0ca050db8c54868ed30558451042#diff-672ba10e6c3065a6f5554033b9b173c4fe88f4c05ffc31c70a9198691e6c6659L267' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2881411</div><div id='project'> Project Name: mackelab/sbi</div><div id='commit'> Commit Name: 3831fd6d5fda0ca050db8c54868ed30558451042</div><div id='time'> Time: 2023-03-01</div><div id='author'> Author: jan.boelts@tum.de</div><div id='file'> File Name: sbi/neural_nets/embedding_nets.py</div><div id='m_class'> M Class Name: PermutationInvariantEmbedding</div><div id='n_method'> N Class Name: PermutationInvariantEmbedding</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: sbi/neural_nets/embedding_nets.py</div><div id='n_file'> N File Name: sbi/neural_nets/embedding_nets.py</div><div id='m_start'> M Start Line: 274</div><div id='m_end'> M End Line: 300</div><div id='n_start'> N Start Line: 279</div><div id='n_end'> N End Line: 306</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            item_eb_hat = torch.sum(self.w[:, :self.seq_len, :, :] * u,
                                    -1)  &#47&#47 shape=(batch_size, seq_len, hidden_size*interest_num)

        item_eb_hat = <a id="change">item_eb_hat.view(-1</a>, self.seq_len, self.interest_num, self.hidden_size<a id="change">)</a>
        item_eb_hat = item_eb_hat.permute(0, 2, 1, 3).contiguous()
        item_eb_hat = <a id="change">item_eb_hat.view(-1</a>, self.interest_num, self.seq_len,
                                       self.hidden_size<a id="change">)</a>  &#47&#47 [batch_size, num_interest, seq_len, hidden_size]

        &#47&#47 [batch_size, num_interest, seq_len, hidden_size]
        if self.stop_grad:  &#47&#47 Clip signal for backpropagation, item_emb_hat is not included in gradient calculation</code></pre><h3>After Change</h3><pre><code class='java'>
            item_eb_hat = torch.sum(self.w[:, :self.seq_len, :, :] * u,
                                    dim=3)  &#47&#47 shape=(batch_size, maxlen, hidden_size*interest_num)

        item_eb_hat = <a id="change">torch.reshape(</a>item_eb_hat, (-1, self.seq_len, self.interest_num, self.hidden_size)<a id="change">)</a>
        item_eb_hat<a id="change"> = </a>torch.transpose(item_eb_hat, 1, 2).contiguous()
        item_eb_hat = torch.reshape(item_eb_hat, (-1, self.interest_num, self.seq_len, self.hidden_size))

        &#47&#47 [b, in, s, h]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/hasai666/rec_pangu/commit/edb52c9a2e35045250d5fda164df336768f37599#diff-16584232aba0343bfbe840c65428273f6373d78df60d98d31ac5c2a5f4a698dcL102' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2881314</div><div id='project'> Project Name: hasai666/rec_pangu</div><div id='commit'> Commit Name: edb52c9a2e35045250d5fda164df336768f37599</div><div id='time'> Time: 2023-03-24</div><div id='author'> Author: wangkai@fuzhi.ai</div><div id='file'> File Name: rec_pangu/models/layers/multi_interest.py</div><div id='m_class'> M Class Name: CapsuleNetwork</div><div id='n_method'> N Class Name: CapsuleNetwork</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: rec_pangu/models/layers/multi_interest.py</div><div id='n_file'> N File Name: rec_pangu/models/layers/multi_interest.py</div><div id='m_start'> M Start Line: 102</div><div id='m_end'> M End Line: 172</div><div id='n_start'> N Start Line: 94</div><div id='n_end'> N End Line: 154</div><BR>