<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    def forward(self, logits, samples, soft):
        if samples is None:
            <a id="change">return </a>self.gumbel_softmax(logits, self._temperature, self._eps, hard=True)
        else:
            return -torch.sum(-samples * F.log_softmax(logits, -1), -1)
</code></pre><h3>After Change</h3><pre><code class='java'>

class GumbelSoftmax(nn.Module):
    def forward(self, logits: torch.Tensor, tau: float = 1, hard: bool = False, dim: int = -1):
        gumbels<a id="change"> = </a>-<a id="change">torch.empty_like(logits, memory_format=torch.legacy_contiguous_format).exponential_().log()</a>  &#47&#47 ~Gumbel(0,1)
        gumbels = (logits<a id="change"> + </a>gumbels) / tau  &#47&#47 ~Gumbel(logits,tau)
        y_soft = gumbels.softmax(dim)

        if hard:
            &#47&#47 Straight through.
            index = y_soft.max(dim, keepdim=True)[1]
            y_hard = torch.zeros_like(logits, memory_format=torch.legacy_contiguous_format).scatter_(dim, index, 1.0)
            ret<a id="change"> = </a>y_hard<a id="change"> - y_soft.detach() + </a>y_soft
        else:
            &#47&#47 Reparametrization trick.
            ret = y_soft</code></pre>