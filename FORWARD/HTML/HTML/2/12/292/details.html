<html><h3>Pattern ID :292
</h3><img src='961228.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        seq_len = history.size()[1]
        state_len = out_state.size()[1]
        batch_size = history.size()[0]
        attn_energies<a id="change"> = </a><a id="change">torch.zeros(
            batch_size</a>, state_len, seq_len<a id="change">)</a>.to(self.device)
        for i in range(state_len):
            for j in range(seq_len):
                <a id="change">for k</a> in <a id="change">range(batch_size</a><a id="change">):
                    </a>attn_energies[k, i, j]<a id="change"> = </a>self.score(
                        out_state[k][i], history[k][j])
        return F.softmax(attn_energies, dim=2)
</code></pre><h3>After Change</h3><pre><code class='java'>
        Returns:
            [tensor]: (batch_size, state_len, history_len)
        
        <a id="change">if self.method == &quotdot&quot</a><a id="change">:
            </a>history = history.permute(0, 2, 1)  &#47&#47 batch_size * hidden_size * history_len
            attn_energies<a id="change"> = </a>torch.bmm(out_state, history)
        elif self.method == &quotgeneral&quot:
            history = self.attn(history)
            history<a id="change"> = </a>history.permute(0, 2, 1)
            attn_energies = torch.bmm(out_state, history)
        return F.softmax(attn_energies, dim=2)
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 9</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/libcity/bigscity-libcity/commit/ec61c9cd984d1c86ee715380ed3b65b4222c8d1f#diff-e952722699ca3186325fca5947706a0f1eb9b447d1d51063beaddb3480efa998L33' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 961228</div><div id='project'> Project Name: libcity/bigscity-libcity</div><div id='commit'> Commit Name: ec61c9cd984d1c86ee715380ed3b65b4222c8d1f</div><div id='time'> Time: 2021-05-06</div><div id='author'> Author: 33283819+WenMellors@users.noreply.github.com</div><div id='file'> File Name: trafficdl/model/trajectory_loc_prediction/DeepMove.py</div><div id='m_class'> M Class Name: Attn</div><div id='n_method'> N Class Name: Attn</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: trafficdl/model/trajectory_loc_prediction/DeepMove.py</div><div id='n_file'> N File Name: trafficdl/model/trajectory_loc_prediction/DeepMove.py</div><div id='m_start'> M Start Line: 33</div><div id='m_end'> M End Line: 43</div><div id='n_start'> N Start Line: 38</div><div id='n_end'> N End Line: 45</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def forward(self, out_state, history):
        seq_len = history.size()[1]
        state_len = out_state.size()[1]
        <a id="change">batch_size</a> = history.size()[0]
        attn_energies<a id="change"> = </a><a id="change">torch.zeros(
            </a>batch_size, state_len, seq_len<a id="change">)</a>.to(self.device)
        for i in range(state_len):
            for j in range(seq_len):
                <a id="change">for k</a> in <a id="change">range(</a>batch_size<a id="change">):
                    </a>attn_energies[k, i, j]<a id="change"> = </a>self.score(
                        out_state[k][i], history[k][j])
        return F.softmax(attn_energies, dim=2)
</code></pre><h3>After Change</h3><pre><code class='java'>
        Returns:
            [tensor]: (batch_size, state_len, history_len)
        
        <a id="change">if self.method == &quotdot&quot</a><a id="change">:
            </a>history = history.permute(0, 2, 1)  &#47&#47 batch_size * hidden_size * history_len
            attn_energies<a id="change"> = </a>torch.bmm(out_state, history)
        elif self.method == &quotgeneral&quot:
            history<a id="change"> = </a>self.attn(history)
            history = history.permute(0, 2, 1)
            attn_energies = torch.bmm(out_state, history)
        return F.softmax(attn_energies, dim=2)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/libtraffic/bigscity-libtraffic/commit/ec61c9cd984d1c86ee715380ed3b65b4222c8d1f#diff-e952722699ca3186325fca5947706a0f1eb9b447d1d51063beaddb3480efa998L32' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 961165</div><div id='project'> Project Name: libtraffic/bigscity-libtraffic</div><div id='commit'> Commit Name: ec61c9cd984d1c86ee715380ed3b65b4222c8d1f</div><div id='time'> Time: 2021-05-06</div><div id='author'> Author: 33283819+WenMellors@users.noreply.github.com</div><div id='file'> File Name: trafficdl/model/trajectory_loc_prediction/DeepMove.py</div><div id='m_class'> M Class Name: Attn</div><div id='n_method'> N Class Name: Attn</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: trafficdl/model/trajectory_loc_prediction/DeepMove.py</div><div id='n_file'> N File Name: trafficdl/model/trajectory_loc_prediction/DeepMove.py</div><div id='m_start'> M Start Line: 33</div><div id='m_end'> M End Line: 43</div><div id='n_start'> N Start Line: 38</div><div id='n_end'> N End Line: 45</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 otherwise we need to loop over the batch to account for varying trial lengths
        else:
            combined_embedding = []
            trial_counts<a id="change"> = </a><a id="change">torch.zeros(</a>batch, 1<a id="change">)</a>
            <a id="change">for i</a> in <a id="change">range(</a>batch<a id="change">):
                &#47&#47 remove NaNs
                </a>valid_x<a id="change"> = </a>x[i, ~torch.isnan(x[i, :, 0]), :]
                trial_counts[i] = valid_x.shape[0]
                trial_embeddings = self.trial_net(valid_x)
                &#47&#47 apply combining operation over permutation dimension</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 Take mean over permutation dimension divide by number of trials
        &#47&#47 (instead of just taking torch.mean) to account for masking.
        <a id="change">if self.aggregation_fn == "mean"</a><a id="change">:
            </a>combined_embedding<a id="change"> = </a>(
                trial_embeddings.sum(dim=self.aggregation_dim) / trial_counts
            )
        else:
            combined_embedding<a id="change"> = </a>trial_embeddings.sum(dim=self.aggregation_dim)

        assert not torch.isnan(combined_embedding).any(), "NaNs in embedding."
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mackelab/sbi/commit/3831fd6d5fda0ca050db8c54868ed30558451042#diff-672ba10e6c3065a6f5554033b9b173c4fe88f4c05ffc31c70a9198691e6c6659L267' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 961159</div><div id='project'> Project Name: mackelab/sbi</div><div id='commit'> Commit Name: 3831fd6d5fda0ca050db8c54868ed30558451042</div><div id='time'> Time: 2023-03-01</div><div id='author'> Author: jan.boelts@tum.de</div><div id='file'> File Name: sbi/neural_nets/embedding_nets.py</div><div id='m_class'> M Class Name: PermutationInvariantEmbedding</div><div id='n_method'> N Class Name: PermutationInvariantEmbedding</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: sbi/neural_nets/embedding_nets.py</div><div id='n_file'> N File Name: sbi/neural_nets/embedding_nets.py</div><div id='m_start'> M Start Line: 274</div><div id='m_end'> M End Line: 300</div><div id='n_start'> N Start Line: 279</div><div id='n_end'> N End Line: 306</div><BR>