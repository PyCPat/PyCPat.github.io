<html><h3>Pattern ID :2428
</h3><img src='14595501.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        q = self.proj_q(q).view(-1, q.size(1), self._head_dims)
        k = self.proj_k(k).view(-1, k.size(1), self._head_dims)
        v = self.proj_v(v).view(-1, <a id="change">v.size(1</a><a id="change">)</a>, self._head_dims)

        att = torch.bmm(q, k.transpose(1, 2)) / self._h_dims**0.5
</code></pre><h3>After Change</h3><pre><code class='java'>
        v = v if torch.is_tensor(v) else k if torch.is_tensor(k) else q
        k = k if torch.is_tensor(k) else q

        q<a id="change"> = </a>q.transpose(0, 1).contiguous()
        k = k.transpose(0, 1).contiguous()
        v = v.transpose(0, 1).contiguous()

        b = q.size(1)<a id="change"> * </a>self._heads

        q<a id="change"> = </a>self.q(q).view(-1, b, self._head_dims).transpose(0, 1)
        k = self.k(k).view(-1, b, self._head_dims).transpose(0, 1)
        v = self.v(v).view(-1, b, self._head_dims).transpose(0, 1)

        att = torch.bmm(q, k.transpose(1, 2)) / self._h_dims**0.5

        if mask is not None:
            mask = torch.where(mask &gt; 0, .0, float(&quot-inf&quot))
            mask = mask.repeat_interleave(self._heads, dim=0)
            att += mask.unsqueeze(1).expand(-1, att.size(1), -1)

        att = att.softmax(-1)

        if self.dropout is not None:
            att = self.dropout(att)

        m<a id="change"> = </a><a id="change">torch.bmm(att, v).transpose(0, 1).contiguous()</a>
        m = self.m(m).view(m.size(0), -1, self._h_dims).transpose(0, 1)

        return m
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/yeliudev/nncore/commit/e58a22da4dce9778c38aae284b0c80d84937b04c#diff-b66764790ba7b310b71bcb990fc01ea802675de40cfbd1e8da361bbc4827b8c3L79' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 14595501</div><div id='project'> Project Name: yeliudev/nncore</div><div id='commit'> Commit Name: e58a22da4dce9778c38aae284b0c80d84937b04c</div><div id='time'> Time: 2021-11-05</div><div id='author'> Author: yeliudev@outlook.com</div><div id='file'> File Name: nncore/nn/blocks/transformer.py</div><div id='m_class'> M Class Name: MultiHeadAttention</div><div id='n_method'> N Class Name: MultiHeadAttention</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: nncore/nn/blocks/transformer.py</div><div id='n_file'> N File Name: nncore/nn/blocks/transformer.py</div><div id='m_start'> M Start Line: 79</div><div id='m_end'> M End Line: 98</div><div id='n_start'> N Start Line: 79</div><div id='n_end'> N End Line: 105</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if isinstance(factor, (int, float)):
            out = image * (self.c_table * factor)
        else:
            b = <a id="change">factor.size(0</a><a id="change">)</a>
            table = self.c_table.expand(b, 1, 8, 8) * factor.view(b, 1, 1, 1)
            out = image * table
        return out
</code></pre><h3>After Change</h3><pre><code class='java'>
        super(_DeBlockSplitting, self).__init__()

    def forward(self, x: torch.Tensor, height: int, width: int) -&gt; torch.Tensor:
        k<a id="change"> = </a>8
        batch_size = x.shape[0]
        x_reshaped = x.view(batch_size, height<a id="change"> // </a>k, width // k, k, k)
        x_transposed<a id="change"> = </a>x_reshaped.permute(0, 1, 3, 2, 4)
        out<a id="change"> = </a><a id="change">x_transposed.contiguous()</a>.view(batch_size, height, width)

        return out
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lornatang/real_esrgan-pytorch/commit/edfbb6820fc2084c2ffe132e9b64a348a323d1e7#diff-91082468503b154b2d3c94cbaadeb7add2ea070f5f30593233516dd4b7e2ac5bL1698' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 14595530</div><div id='project'> Project Name: lornatang/real_esrgan-pytorch</div><div id='commit'> Commit Name: edfbb6820fc2084c2ffe132e9b64a348a323d1e7</div><div id='time'> Time: 2022-06-16</div><div id='author'> Author: liuchangyu1111@gmail.com</div><div id='file'> File Name: imgproc.py</div><div id='m_class'> M Class Name: CDequantize</div><div id='n_method'> N Class Name: _DeBlockSplitting</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: imgproc.py</div><div id='n_file'> N File Name: imgproc.py</div><div id='m_start'> M Start Line: 1698</div><div id='m_end'> M End Line: 1711</div><div id='n_start'> N Start Line: 1374</div><div id='n_end'> N End Line: 1379</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            Args:
                input: N x T x D
        
        length = <a id="change">input.size(1</a><a id="change">)</a>

        return self.pe[:, :length]

</code></pre><h3>After Change</h3><pre><code class='java'>

    def forward(self, x):

        x<a id="change"> = </a>x.permute(0, 2, 1).contiguous()

        &#47&#47 x is seq_len, batch, channels
        &#47&#47 x = x + self.pe[:x.size(0), :]

        &#47&#47 x is batch, channels, seq_len
        x = x<a id="change"> + </a>self.pe[:, :, :x.size(2)]

        x<a id="change"> = </a>self.dropout(x)

        x<a id="change"> = </a><a id="change">x.permute(0, 2, 1).contiguous()</a>

        return x

</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/zhongyang-debug/attention-is-all-you-need-in-speech-separation/commit/361486e2e14685189e9a65a81fa779b4728c6e18#diff-7c8acbb8793a584bfe2ae80520bfb2e801e64479bf65e6f723edd575961f9c17L128' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 14595506</div><div id='project'> Project Name: zhongyang-debug/attention-is-all-you-need-in-speech-separation</div><div id='commit'> Commit Name: 361486e2e14685189e9a65a81fa779b4728c6e18</div><div id='time'> Time: 2022-08-16</div><div id='author'> Author: 68770882+Zhongyang-debug@users.noreply.github.com</div><div id='file'> File Name: model/sepformer.py</div><div id='m_class'> M Class Name: Positional_Encoding</div><div id='n_method'> N Class Name: Positional_Encoding</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: model/sepformer.py</div><div id='n_file'> N File Name: model/sepformer.py</div><div id='m_start'> M Start Line: 133</div><div id='m_end'> M End Line: 135</div><div id='n_start'> N Start Line: 143</div><div id='n_end'> N End Line: 155</div><BR>