<html><h3>Pattern ID :1210
</h3><img src='4377731.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

            y[1][..., :4] /= s[0]  &#47&#47 scale
            y[1][..., 0] = img_size[1] - y[1][..., 0]  &#47&#47 flip lr
            y[2][..., <a id="change">:4</a>] /= s[1]  &#47&#47 scale
            return torch.cat(y, 1), None  &#47&#47 augmented inference, train
        else:
            return self.forward_once(x, profile)  &#47&#47 single-scale inference, train</code></pre><h3>After Change</h3><pre><code class='java'>
            s = [1, 0.83, 0.67]  &#47&#47 scales
            f = [None, 3, None]  &#47&#47 flips (2-ud, 3-lr)
            y = []  &#47&#47 outputs
            <a id="change">for </a>si, fi in zip(s, f)<a id="change">:
                </a>xi = torch_utils.scale_img(x.flip(fi) if fi else x, si)
                yi<a id="change"> = </a>self.forward_once(xi)[0]  &#47&#47 forward
                &#47&#47 cv2.imwrite(&quotimg%g.jpg&quot % s, 255 * xi[0].numpy().transpose((1, 2, 0))[:, :, ::-1])  &#47&#47 save
                yi[..., :4] /= si  &#47&#47 de-scale
                if fi is 2:
                    yi[..., 1]<a id="change"> = </a>img_size[0] - yi[..., 1]  &#47&#47 de-flip ud
                elif <a id="change"></a>fi is 3<a id="change">:
                    </a>yi[..., 0] = img_size[1] - yi[..., 0]  &#47&#47 de-flip lr
                y.append(yi)
            return torch.cat(y, 1), None  &#47&#47 augmented inference, train
        else:</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 6</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/positive666/yolov5_research/commit/1d17b9af0f68ee97f9edc5f10fea51e9af9ef14e#diff-2cd118cbb69c9ca7b5544f4187b11335fc3addbaf2c3c5bb45435cac648c957bL84' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4377731</div><div id='project'> Project Name: positive666/yolov5_research</div><div id='commit'> Commit Name: 1d17b9af0f68ee97f9edc5f10fea51e9af9ef14e</div><div id='time'> Time: 2020-07-24</div><div id='author'> Author: glenn.jocher@ultralytics.com</div><div id='file'> File Name: models/yolo.py</div><div id='m_class'> M Class Name: Model</div><div id='n_method'> N Class Name: Model</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/yolo.py</div><div id='n_file'> N File Name: models/yolo.py</div><div id='m_start'> M Start Line: 85</div><div id='m_end'> M End Line: 96</div><div id='n_start'> N Start Line: 84</div><div id='n_end'> N End Line: 98</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

            y[1][..., :4] /= s[0]  &#47&#47 scale
            y[1][..., 0] = img_size[1] - y[1][..., 0]  &#47&#47 flip lr
            y[2][..., <a id="change">:4</a>] /= s[1]  &#47&#47 scale
            return torch.cat(y, 1), None  &#47&#47 augmented inference, train
        else:
            return self.forward_once(x, profile)  &#47&#47 single-scale inference, train</code></pre><h3>After Change</h3><pre><code class='java'>
            s = [1, 0.83, 0.67]  &#47&#47 scales
            f = [None, 3, None]  &#47&#47 flips (2-ud, 3-lr)
            y = []  &#47&#47 outputs
            <a id="change">for </a>si, <a id="change">fi</a> in zip(s, f)<a id="change">:
                </a>xi<a id="change"> = </a>torch_utils.scale_img(x.flip(fi) if fi else x, si)
                yi = self.forward_once(xi)[0]  &#47&#47 forward
                &#47&#47 cv2.imwrite(&quotimg%g.jpg&quot % s, 255 * xi[0].numpy().transpose((1, 2, 0))[:, :, ::-1])  &#47&#47 save
                yi[..., :4] /= si  &#47&#47 de-scale
                if fi is 2:
                    yi[..., 1]<a id="change"> = </a>img_size[0] - yi[..., 1]  &#47&#47 de-flip ud
                elif <a id="change"></a>fi is 3<a id="change">:
                    </a>yi[..., 0] = img_size[1] - yi[..., 0]  &#47&#47 de-flip lr
                y.append(yi)
            return torch.cat(y, 1), None  &#47&#47 augmented inference, train
        else:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/positive666/yolov5_research/commit/1d17b9af0f68ee97f9edc5f10fea51e9af9ef14e#diff-2cd118cbb69c9ca7b5544f4187b11335fc3addbaf2c3c5bb45435cac648c957bL82' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4377728</div><div id='project'> Project Name: positive666/yolov5_research</div><div id='commit'> Commit Name: 1d17b9af0f68ee97f9edc5f10fea51e9af9ef14e</div><div id='time'> Time: 2020-07-24</div><div id='author'> Author: glenn.jocher@ultralytics.com</div><div id='file'> File Name: models/yolo.py</div><div id='m_class'> M Class Name: Model</div><div id='n_method'> N Class Name: Model</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/yolo.py</div><div id='n_file'> N File Name: models/yolo.py</div><div id='m_start'> M Start Line: 85</div><div id='m_end'> M End Line: 96</div><div id='n_start'> N Start Line: 84</div><div id='n_end'> N End Line: 98</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        sim = einsum(&quotb h i d, b h j d -&gt; b h i j&quot, q, k)

        i, j = sim.shape[<a id="change">-2:</a>]

        mask_value = -torch.finfo(sim.dtype).max
</code></pre><h3>After Change</h3><pre><code class='java'>

        max_heads = self.max_heads_process

        <a id="change">for </a>q_chunk, k_chunk, <a id="change">v_chunk</a> in zip(q.split(max_heads, dim = 1), k.split(max_heads, dim = 1), v.split(max_heads, dim = 1))<a id="change">:
            </a>sim<a id="change"> = </a>einsum(&quotb h i d, b h j d -&gt; b h i j&quot, q_chunk, k_chunk)

            <a id="change">if </a>exists(context_mask)<a id="change">:
                </a>sim = sim.masked_fill(~context_mask, mask_value)

            sim = sim.masked_fill(causal_mask, mask_value)

            attn = sim.softmax(dim = -1)
            attn = self.dropout(attn)

            out_chunk<a id="change"> = </a>einsum(&quotb h i j, b h j d -&gt; b h i d&quot, attn, v_chunk)
            out.append(out_chunk)

        &#47&#47 concat all the heads together</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/perceiver-ar-pytorch/commit/be3765300f5aae03b779edf0e256b7a74bda5fc8#diff-5ab51011b3cb840590737cf5342761683a8f59ac8817bfe6b989cf9e213218e4L121' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4377751</div><div id='project'> Project Name: lucidrains/perceiver-ar-pytorch</div><div id='commit'> Commit Name: be3765300f5aae03b779edf0e256b7a74bda5fc8</div><div id='time'> Time: 2022-06-21</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: perceiver_ar_pytorch/perceiver_ar_pytorch.py</div><div id='m_class'> M Class Name: CausalPrefixAttention</div><div id='n_method'> N Class Name: CausalPrefixAttention</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: perceiver_ar_pytorch/perceiver_ar_pytorch.py</div><div id='n_file'> N File Name: perceiver_ar_pytorch/perceiver_ar_pytorch.py</div><div id='m_start'> M Start Line: 130</div><div id='m_end'> M End Line: 159</div><div id='n_start'> N Start Line: 133</div><div id='n_end'> N End Line: 178</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            video = torch.cat([image.unsqueeze(2), video], dim=2)  &#47&#47 1 x 64 x 21 x 16 x 16
        else:
            video = image.unsqueeze(2)
        video = video.view(*video.shape[<a id="change">:3</a>], -1).permute(0, 2, 3, 1)  &#47&#47 B x T x (H x W) x C -&gt; 1 x 21 x (16*16) x 64
        video = self.attention(video)  &#47&#47 1 x 21 x 256 x 64
        return video
</code></pre><h3>After Change</h3><pre><code class='java'>
        video = self.stem(video)
        s = None
        if len(self.encoder) &gt; 0:
            <a id="change">for </a>block, <a id="change">remapper</a> in zip(self.encoder, self.remapper)<a id="change">:
                if </a>block.scaler is not None<a id="change">:
                    </a>prev_s = nn.functional.interpolate(video, scale_factor=(1, 0.5, 0.5), recompute_scale_factor=False)
                else:
                    prev_s = video
                video<a id="change"> = </a>block(video, s)
                if block.scaler is not None:
                    video<a id="change"> = </a>remapper(video)
                s = prev_s
        video = self.bottleneck(video)
        return video</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/laion-ai/phenaki/commit/e510eaef70feb098d2c1b5fac8b34291c1955c9e#diff-d2675e29d21c30767dbf4b16980547aac6cc99b46ce44781ec89d09ee7193467L60' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4377772</div><div id='project'> Project Name: laion-ai/phenaki</div><div id='commit'> Commit Name: e510eaef70feb098d2c1b5fac8b34291c1955c9e</div><div id='time'> Time: 2022-10-17</div><div id='author'> Author: d6582533@gmail.com</div><div id='file'> File Name: vivq.py</div><div id='m_class'> M Class Name: Encoder</div><div id='n_method'> N Class Name: Encoder</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: vivq.py</div><div id='n_file'> N File Name: vivq.py</div><div id='m_start'> M Start Line: 62</div><div id='m_end'> M End Line: 70</div><div id='n_start'> N Start Line: 90</div><div id='n_end'> N End Line: 104</div><BR>