<html><h3>Pattern ID :2716
</h3><img src='15165829.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    def forward(self, audio, audio_len):
        if random.random() &lt; 0.2:
            audio_mask = (torch.arange(audio.shape[1], device=audio.device)[None, :, None] &lt; audio_len[:, None, None]).float()
            x<a id="change"> = </a><a id="change">torch.exp(</a>audio - 1e-6<a id="change">) * </a>audio_mask
            y = torch.cat([x[1:], x[:1]])
            <a id="change">return </a>torch.log(0.9 * x + 0.1 * y + 1e-6) * audio_mask<a id="change">, audio_len</a>
        return audio, audio_len
</code></pre><h3>After Change</h3><pre><code class='java'>
            audio, audio_len = self.timestretch(audio, audio_len)
        if random.random() &lt; AUGUMENT_RATE:
            audio = self.pitchshift(audio)
        <a id="change">if random.random() &lt; AUGUMENT_RATE</a><a id="change">:
            </a>audio = self.timemask(audio)
        if random.random() &lt; AUGUMENT_RATE:
            audio = self.freqmask(audio)
        if random.random() &lt; AUGUMENT_RATE:</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/kaiidams/voice100/commit/dfe0234fcc858357cb2a91bcba1da06792eabab7#diff-45ca1489e7a6bb94fd69ca7ad1bd30c3de58adc27fb2b6c0b31cafc1bf90ceffL73' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 15165829</div><div id='project'> Project Name: kaiidams/voice100</div><div id='commit'> Commit Name: dfe0234fcc858357cb2a91bcba1da06792eabab7</div><div id='time'> Time: 2021-06-25</div><div id='author'> Author: katsuya.iida@gmail.com</div><div id='file'> File Name: voice100/audio.py</div><div id='m_class'> M Class Name: BatchSpectrogramAugumentation</div><div id='n_method'> N Class Name: BatchSpectrogramAugumentation</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: voice100/audio.py</div><div id='n_file'> N File Name: voice100/audio.py</div><div id='m_start'> M Start Line: 73</div><div id='m_end'> M End Line: 78</div><div id='n_start'> N Start Line: 80</div><div id='n_end'> N End Line: 95</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 attention GMM parameters
        g_t = torch.softmax(g_t, dim=-1) + self.epsilon  &#47&#47 distribution weight
        sig_t = torch.exp(b_t) + self.epsilon  &#47&#47 variance
        mu_t<a id="change"> = </a>self.mu_tm1<a id="change"> + </a>self.attention_alignment * <a id="change">torch.exp(</a>k_t<a id="change">)</a>  &#47&#47 mean

        g_t = g_t.unsqueeze(2).expand(g_t.size(0),
                                      g_t.size(1),
                                      inputs.size(1))
        sig_t = sig_t.unsqueeze(2).expand_as(g_t)
        mu_t_ = mu_t.unsqueeze(2).expand_as(g_t)
        j = self.J[:g_t.size(0), :, :inputs.size(1)]

        &#47&#47 attention weights
        phi_t = g_t * torch.exp(-0.5 * sig_t * (mu_t_ - j)**2)
        alpha_t = self.COEF * torch.sum(phi_t, 1)

        &#47&#47 apply masking
        &#47&#47 if mask is not None:
        &#47&#47     alpha_t.data.masked_fill_(~mask, self._mask_value)
        
        breakpoint()

        c_t = torch.bmm(alpha_t.unsqueeze(1), inputs).squeeze(1)
        self.mu_tm1 = mu_t
        <a id="change">return </a>c_t<a id="change">, mu_t, alpha_t</a>


class Attention(nn.Module):
    &#47&#47 Pylint gets confused by PyTorch conventions here</code></pre><h3>After Change</h3><pre><code class='java'>
        alpha_t = torch.sum(phi_t, 1)

        &#47&#47 apply masking
        <a id="change">if mask is not None</a><a id="change">:
            </a>alpha_t.data.masked_fill_(~mask, self._mask_value)

        context = torch.bmm(alpha_t.unsqueeze(1), inputs).squeeze(1)
        self.attention_weights = alpha_t</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/coqui-ai/tts/commit/adf9ebd629abc21e0969db2a1c29f389b5301c9d#diff-1ca76b8dab5cda419aaf68884653245f0428af8e57cdb707fc538936bb59af29L129' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 15165871</div><div id='project'> Project Name: coqui-ai/tts</div><div id='commit'> Commit Name: adf9ebd629abc21e0969db2a1c29f389b5301c9d</div><div id='time'> Time: 2019-11-12</div><div id='author'> Author: egolge@mozilla.com</div><div id='file'> File Name: layers/common_layers.py</div><div id='m_class'> M Class Name: GravesAttention</div><div id='n_method'> N Class Name: GravesAttention</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: layers/common_layers.py</div><div id='n_file'> N File Name: layers/common_layers.py</div><div id='m_start'> M Start Line: 141</div><div id='m_end'> M End Line: 169</div><div id='n_start'> N Start Line: 149</div><div id='n_end'> N End Line: 180</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 w_1 = torch.exp(-0.1*(range_param.unsqueeze(-1) ** -2) * (t - c) ** 2)  &#47&#47 [B, L, T]
        &#47&#47 w_2 = torch.sum(torch.exp(-0.1*(range_param.unsqueeze(-1) ** -2) * (t - c) ** 2), dim=1, keepdim=True)  &#47&#47 [B, 1, T]
        w_1 = <a id="change">torch.exp(</a>-0.1 * (t - c) ** 2<a id="change">)</a>  &#47&#47 [B, L, T]
        w_2 = torch.sum(torch.exp(-0.1 * (t - c) ** 2), dim=1, keepdim=True)  &#47&#47 [B, 1, T]
        w_2[w_2==0.] = 1.

        &#47&#47 w_1 = self.normpdf(t, c, range_param.unsqueeze(-1))  &#47&#47 [B, L, T]
        &#47&#47 w_1 = torch.distributions.normal.Normal(c, 0.1).log_prob(t)  &#47&#47 [B, L, T]
        &#47&#47 w_2 = torch.sum(w_1, dim=1, keepdim=True)  &#47&#47 [B, 1, T]
        &#47&#47 w_2[w_2==0.] = 1.

        w<a id="change"> = </a>w_1<a id="change"> / </a>w_2

        out = torch.matmul(w.transpose(1, 2), encoder_outputs)

        <a id="change">return </a>out<a id="change">, w</a>


class DurationPredictor(nn.Module):
     Duration Parameter Predictor </code></pre><h3>After Change</h3><pre><code class='java'>

        w = self.get_alignment_energies(g, t)  &#47&#47 [B, L, T]

        <a id="change">if mask is not None</a><a id="change">:
            </a>w = w.masked_fill(mask.unsqueeze(-1), 0.0)

        attn = w / (torch.sum(w, dim=1).unsqueeze(1) + 1e-8)  &#47&#47 [B, L, T]
        out = torch.bmm(attn.transpose(1, 2), encoder_outputs)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/keonlee9420/wavegrad2/commit/523ec241c64ab635218f32d071fd85fbc469e178#diff-44dac3f4f06b62a8129520d279f589b0b2144de4f2a7720992f263c496651b43L105' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 15165836</div><div id='project'> Project Name: keonlee9420/wavegrad2</div><div id='commit'> Commit Name: 523ec241c64ab635218f32d071fd85fbc469e178</div><div id='time'> Time: 2021-07-13</div><div id='author'> Author: keonlee9420@gmail.com</div><div id='file'> File Name: model/modules.py</div><div id='m_class'> M Class Name: GaussianUpsampling</div><div id='n_method'> N Class Name: GaussianUpsampling</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: model/modules.py</div><div id='n_file'> N File Name: model/modules.py</div><div id='m_start'> M Start Line: 115</div><div id='m_end'> M End Line: 135</div><div id='n_start'> N Start Line: 120</div><div id='n_end'> N End Line: 134</div><BR>