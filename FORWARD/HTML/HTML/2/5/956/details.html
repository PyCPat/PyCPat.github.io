<html><h3>Pattern ID :956
</h3><img src='3479637.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    device = torch.device(&quotcuda&quot) if torch.cuda.is_available() else torch.device(&quotcpu&quot)
    batch_size = anchor_output.shape[0]
    targets_sketch = torch.zeros(batch_size)
    targets_photos<a id="change"> = </a><a id="change">torch.zeros(</a>batch_size<a id="change">)</a>

    if epoch &lt; 5:
      lmbda = 0
    elif epoch &lt; 25:
      lmbda = (epoch-5)/20.0
    else:
      lmbda = 1.0


    loss_domain = self.domain_loss(grad_reverse(anchor_output, lmbda), targets_sketch) + self.domain_loss(grad_reverse(positive_output, lmbda), targets_photos) + self.domain_loss(grad_reverse(negative_output, lmbda), targets_photos)
    loss_domain /= 3.0


    total_loss = self.w_dom * loss_domain + self.w_sem * loss_semantic + self.w_triplet * loss_triplet &#47&#47 Our network minimizes this loss

    <a id="change">return </a>total_loss


</code></pre><h3>After Change</h3><pre><code class='java'>
    device = torch.device(&quotcuda&quot) if torch.cuda.is_available() else torch.device(&quotcpu&quot)
    batch_size = anchor_output.shape[0]
    targets_sketch = torch.zeros(batch_size)
    targets_photos<a id="change"> = </a>torch.ones(batch_size)

    if epoch &lt; 5:
      lmbda = 0
    elif epoch &lt; 25:
      lmbda = (epoch-5)/20.0
    else:
      lmbda = 1.0


    loss_domain = self.domain_loss(grad_reverse(anchor_output, lmbda), targets_sketch) + self.domain_loss(grad_reverse(positive_output, lmbda), targets_photos) + self.domain_loss(grad_reverse(negative_output, lmbda), targets_photos)
    loss_domain /= 3.0


    total_loss = self.w_dom * loss_domain + self.w_sem * loss_semantic + self.w_triplet * loss_triplet &#47&#47 Our network minimizes this loss

    return total_loss<a id="change">, loss_domain, loss_triplet, loss_semantic</a>



</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/ashok-arjun/zero-shot-sketch-based-image-retrieval/commit/408fd9d1d064dfa075be91fb92f8cbac8001eec4#diff-5ea2db96a36360fc43da9b22eaf6dcb593b698b98e6bf32ebfdef3a7589dd912L106' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 3479637</div><div id='project'> Project Name: ashok-arjun/zero-shot-sketch-based-image-retrieval</div><div id='commit'> Commit Name: 408fd9d1d064dfa075be91fb92f8cbac8001eec4</div><div id='time'> Time: 2020-07-31</div><div id='author'> Author: arjun2000ashok@gmail.com</div><div id='file'> File Name: model/loss.py</div><div id='m_class'> M Class Name: DetangledJointDomainLoss</div><div id='n_method'> N Class Name: DetangledJointDomainLoss</div><div id='m_method'> M Method Name: forward(6)</div><div id='n_method'> N Method Name: forward(6)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: model/loss.py</div><div id='n_file'> N File Name: model/loss.py</div><div id='m_start'> M Start Line: 112</div><div id='m_end'> M End Line: 130</div><div id='n_start'> N Start Line: 106</div><div id='n_end'> N End Line: 130</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            dec_enc_attns.append(dec_enc_attn)
        predictions = self.projection(dec_outputs)
        &#47&#47 TODO: 暂时全部为0, return dec_self_attns, dec_enc_attns
        alphas<a id="change"> = </a>torch.tensor(<a id="change">np.zeros(</a>(batch_size, 52, 196)<a id="change">)</a>).to(device)
        <a id="change">return </a>predictions, encoded_captions, decode_lengths, alphas, sort_ind


class EncoderLayer(nn.Module):</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 0 0 0 0 1 2
        &#47&#47 0 0 0 0 1 1
        dec_outputs = self.tgt_emb(encoded_captions) + self.pos_emb(torch.LongTensor([list(range(52))]*batch_size).to(device))
        dec_outputs<a id="change"> = </a>self.dropout(dec_outputs)
        dec_self_attn_pad_mask = self.get_attn_pad_mask(encoded_captions, encoded_captions)
        dec_self_attn_subsequent_mask = self.get_attn_subsequent_mask(encoded_captions)
        dec_self_attn_mask = torch.gt((dec_self_attn_pad_mask + dec_self_attn_subsequent_mask), 0)
        dec_enc_attn_mask = (torch.tensor(np.zeros((batch_size, 52, 196))).to(device) == torch.tensor(np.ones((batch_size, 52, 196))).to(device))

        dec_self_attns, dec_enc_attns = [], []
        for layer in self.layers:
            &#47&#47 attn: [batch_size, n_heads, len_q, len_k]
            dec_outputs, dec_self_attn, dec_enc_attn = layer(dec_outputs, encoder_out, dec_self_attn_mask, dec_enc_attn_mask)
            dec_self_attns.append(dec_self_attn)
            dec_enc_attns.append(dec_enc_attn)
        predictions = self.projection(dec_outputs)
        return predictions<a id="change">, encoded_captions, decode_lengths, sort_ind, dec_self_attns, dec_enc_attns</a>


class EncoderLayer(nn.Module):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/royalskye/image-caption/commit/569502dd85be28a1e6a10bc8873b7cd0446556b8#diff-7b7030687899150ad5cd420914b35858a8cc34b1d59e5cab0d629393a328448cL144' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 3479636</div><div id='project'> Project Name: royalskye/image-caption</div><div id='commit'> Commit Name: 569502dd85be28a1e6a10bc8873b7cd0446556b8</div><div id='time'> Time: 2020-04-06</div><div id='author'> Author: a19970417b@qq.com</div><div id='file'> File Name: transformer.py</div><div id='m_class'> M Class Name: Decoder</div><div id='n_method'> N Class Name: Decoder</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: transformer.py</div><div id='n_file'> N File Name: transformer.py</div><div id='m_start'> M Start Line: 150</div><div id='m_end'> M End Line: 189</div><div id='n_start'> N Start Line: 160</div><div id='n_end'> N End Line: 191</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        )
        &#47&#47 Handle the case of no hidden state provided
        if hx is None:
            hx<a id="change"> = </a><a id="change">torch.zeros(</a>input.size(0), self.h_channels, output_size<a id="change">, device=input.device)</a>
        &#47&#47 Run the optimized convgru-cell
        <a id="change">return </a>_opt_convgrucell_1d(
            input,
            hx,
            self.h_channels,</code></pre><h3>After Change</h3><pre><code class='java'>
    def forward(self, input, h_prev=None):
        &#47&#47 init hidden on forward
        if h_prev is None:
            h_prev<a id="change"> = </a>self.init_hidden(input)
        print(f"input: {input.shape} prev: {h_prev.shape}")
        combined = torch.cat((input<a id="change">, h_prev</a>), dim=1)  &#47&#47 concatenate along channel axis

        combined_conv = F.sigmoid(self.conv_zr(combined))
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/openclimatefix/skillful_nowcasting/commit/02c5ceadd01484d6ac8bce848ff76446fe7a6917#diff-cee00a565d888c684ec40bd3eac27669aa3223b223a80ae9f871383a9fb64917L82' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 3479639</div><div id='project'> Project Name: openclimatefix/skillful_nowcasting</div><div id='commit'> Commit Name: 02c5ceadd01484d6ac8bce848ff76446fe7a6917</div><div id='time'> Time: 2021-10-18</div><div id='author'> Author: jacob@bieker.tech</div><div id='file'> File Name: nowcasting_gan/layers/ConvGRU.py</div><div id='m_class'> M Class Name: ConvGRU1DCell</div><div id='n_method'> N Class Name: ConvGRUCell</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: nowcasting_gan/layers/ConvGRU.py</div><div id='n_file'> N File Name: nowcasting_gan/layers/ConvGRU.py</div><div id='m_start'> M Start Line: 83</div><div id='m_end'> M End Line: 101</div><div id='n_start'> N Start Line: 69</div><div id='n_end'> N End Line: 82</div><BR>