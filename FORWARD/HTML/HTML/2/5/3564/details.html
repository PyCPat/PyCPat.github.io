<html><h3>Pattern ID :3564
</h3><img src='17645903.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        x = x.unsqueeze(-1)
        x = self.project_to_steps(x)  &#47&#47 BxCxTxS
        x = self.dropout(x)
        x = <a id="change">x.unsqueeze(0).expand(</a>targets.size(0), -1, -1, -1, -1<a id="change">)</a>

        copies, bsz, dim, tsz, steps = x.shape
        steps = min(steps, tsz - self.offset)
        predictions = x.new(bsz * copies * (tsz - self.offset + 1) * steps - ((steps + 1) * steps // 2) * copies * bsz)</code></pre><h3>After Change</h3><pre><code class='java'>
            else:
                pos_num = (end - start) // copies
                predictions[start:end] = torch.einsum(
                    "bct,nbct-&gt;nbt", <a id="change">x[..., :-offset, i]</a>, <a id="change">targets</a>[<a id="change">...</a>, offset:]
                ).flatten()
                labels[start : start + pos_num] = 1.0
                if weights is not None:</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/kssteven418/i-bert/commit/3335de5f441ee1b3824e16dcd98db620e40beaba#diff-9b4dd2bdb515c86c631253c805af3041e9bbf4ce7f68af6a1900ef5b4ffa5c5aL411' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 17645903</div><div id='project'> Project Name: kssteven418/i-bert</div><div id='commit'> Commit Name: 3335de5f441ee1b3824e16dcd98db620e40beaba</div><div id='time'> Time: 2020-02-29</div><div id='author'> Author: alexei.b@gmail.com</div><div id='file'> File Name: fairseq/models/wav2vec.py</div><div id='m_class'> M Class Name: Wav2VecPredictionsModel</div><div id='n_method'> N Class Name: Wav2VecPredictionsModel</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: fairseq/models/wav2vec.py</div><div id='n_file'> N File Name: fairseq/models/wav2vec.py</div><div id='m_start'> M Start Line: 411</div><div id='m_end'> M End Line: 439</div><div id='n_start'> N Start Line: 638</div><div id='n_end'> N End Line: 691</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        x = x.unsqueeze(-1)
        x = self.project_to_steps(x)  &#47&#47 BxCxTxS
        x = self.dropout(x)
        x = <a id="change">x.unsqueeze(0).expand(</a>targets.size(0), -1, -1, -1, -1<a id="change">)</a>

        copies, bsz, dim, tsz, steps = x.shape
        steps = min(steps, tsz - self.offset)
        predictions = x.new(bsz * copies * (tsz - self.offset + 1) * steps - ((steps + 1) * steps // 2) * copies * bsz)</code></pre><h3>After Change</h3><pre><code class='java'>
            else:
                pos_num = (end - start) // copies
                predictions[start:end] = torch.einsum(
                    "bct,nbct-&gt;nbt", <a id="change">x</a>[..., :-offset, i], <a id="change">targets[..., offset:]</a>
                ).flatten()
                labels[start : start + pos_num] = 1.0
                if weights is not None:
                    weights[start : start + pos_num] = 1.0</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/kssteven418/i-bert/commit/3335de5f441ee1b3824e16dcd98db620e40beaba#diff-9b4dd2bdb515c86c631253c805af3041e9bbf4ce7f68af6a1900ef5b4ffa5c5aL408' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 17645899</div><div id='project'> Project Name: kssteven418/i-bert</div><div id='commit'> Commit Name: 3335de5f441ee1b3824e16dcd98db620e40beaba</div><div id='time'> Time: 2020-02-29</div><div id='author'> Author: alexei.b@gmail.com</div><div id='file'> File Name: fairseq/models/wav2vec.py</div><div id='m_class'> M Class Name: Wav2VecPredictionsModel</div><div id='n_method'> N Class Name: Wav2VecPredictionsModel</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: fairseq/models/wav2vec.py</div><div id='n_file'> N File Name: fairseq/models/wav2vec.py</div><div id='m_start'> M Start Line: 411</div><div id='m_end'> M End Line: 439</div><div id='n_start'> N Start Line: 638</div><div id='n_end'> N End Line: 691</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        device = x.device
        b, t, e, m = *x.shape, self.num_mem_kv

        mem = <a id="change">self.mem_kv.expand(</a>m, b, e<a id="change">)</a>
        keys = default(keys, torch.empty(b, 0, e, device=device))

        x, keys = x.transpose(0, 1), keys.transpose(0, 1)
</code></pre><h3>After Change</h3><pre><code class='java'>
        dot = torch.einsum(&quotbie,bje-&gt;bij&quot, q, qk)

        &#47&#47 qk attention requires tokens not attend to self
        <a id="change">i</a> = torch.arange(t)
        <a id="change">dot[:, i, i]</a> = -1e-5 

        if self.causal:
            i, j = torch.triu_indices(t, t, 1)
            <a id="change">dot</a>[:, i, j] = float(&quot-inf&quot)

        dot = dot.softmax(dim=-1)
        out = torch.einsum(&quotbij,bje-&gt;bie&quot, dot, v)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/reformer-pytorch/commit/d2462f9b33944e20f5fbeaf19efaa9591378ba65#diff-7e740488ff2ce47996cfdd5356981ed3e6ac2bb38739a71b400275ac91d1c3bfL385' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 17645904</div><div id='project'> Project Name: lucidrains/reformer-pytorch</div><div id='commit'> Commit Name: d2462f9b33944e20f5fbeaf19efaa9591378ba65</div><div id='time'> Time: 2020-01-28</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: reformer_pytorch/reformer_pytorch.py</div><div id='m_class'> M Class Name: SelfAttention</div><div id='n_method'> N Class Name: FullQKAttention</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: reformer_pytorch/reformer_pytorch.py</div><div id='n_file'> N File Name: reformer_pytorch/reformer_pytorch.py</div><div id='m_start'> M Start Line: 386</div><div id='m_end'> M End Line: 403</div><div id='n_start'> N Start Line: 330</div><div id='n_end'> N End Line: 349</div><BR>