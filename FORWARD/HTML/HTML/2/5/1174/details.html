<html><h3>Pattern ID :1174
</h3><img src='4126926.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                &#47&#47 diversity = torch.minimum(var, torch.ones_like(var))
                &#47&#47 reg -= diversity

                diversity<a id="change"> = </a><a id="change">batchWiseLogit.std(1).mean(-1).sigmoid()</a>

                &#47&#47 summedProb = batchWiseLogit.sum(1)
                &#47&#47 posterior = OneHotCategorical(logits=summedProb)
                &#47&#47 prior = OneHotCategorical(probs=torch.ones_like(summedProb) / summedProb.shape[-1])
                &#47&#47 reg = torch.distributions.kl_divergence(posterior, prior) / diversity
                reg = compute_penalties(batchWiseLogit, allowed_entropy=0.1, individual_entropy_coeff=cv, allowed_js=4.0, js_coeff=cv, cv_coeff=cv, eps=Consts.Eps)
                reg<a id="change"> = </a>reg<a id="change"> / </a>diversity
                regs.append(reg)
            regs = sum(regs)
        return ssimLoss, l1Loss + l2Loss, l1QLoss + l2QLoss, regs &#47&#47 + 10 * stdReg</code></pre><h3>After Change</h3><pre><code class='java'>
            for latent, q in zip(latents, quantizeds):
                l2QLoss.append(F.mse_loss(latent.detach(), q, reduction=&quotnone&quot).mean(axis=(1, 2, 3)))
                l1QLoss.append(F.l1_loss(latent.detach(), q, reduction=&quotnone&quot).mean(axis=(1, 2, 3)))
                l2QLoss.append(0.00001 * <a id="change">F.mse_loss(latent, q.detach(), reduction=&quotnone&quot).mean(axis=(1, 2, 3))</a>)
                l1QLoss.append(0.00001 * F.l1_loss(latent, q.detach(), reduction=&quotnone&quot).mean(axis=(1, 2, 3)))

        l1QLoss = sum(l1QLoss)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/xiaosu-zhu/mcquic/commit/fea4d517415acb825c6282b84ea39c0989abf5fc#diff-93a462c5d42bc45838b4e4215cbb88d97c7a71ce0ceb9af896a4f1b48e34e718L53' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4126926</div><div id='project'> Project Name: xiaosu-zhu/mcquic</div><div id='commit'> Commit Name: fea4d517415acb825c6282b84ea39c0989abf5fc</div><div id='time'> Time: 2021-03-23</div><div id='author'> Author: xiaosu.zhu@outlook.com</div><div id='file'> File Name: src/mcqc/losses/structural.py</div><div id='m_class'> M Class Name: CompressionLossTwoStage</div><div id='n_method'> N Class Name: CompressionLossTwoStage</div><div id='m_method'> M Method Name: forward(8)</div><div id='n_method'> N Method Name: forward(8)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/mcqc/losses/structural.py</div><div id='n_file'> N File Name: src/mcqc/losses/structural.py</div><div id='m_start'> M Start Line: 69</div><div id='m_end'> M End Line: 91</div><div id='n_start'> N Start Line: 53</div><div id='n_end'> N End Line: 60</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    

    def forward(self, chosen_reward: torch.Tensor, reject_reward: torch.Tensor) -&gt; torch.Tensor:
        probs<a id="change"> = </a><a id="change">torch.sigmoid(</a>chosen_reward - reject_reward<a id="change">)</a>
        log_probs = torch.log(probs)
        loss<a id="change"> = </a><a id="change">-log_probs.mean()</a>
        return loss
</code></pre><h3>After Change</h3><pre><code class='java'>
    Details: https://arxiv.org/abs/2204.05862
    
    def forward(self, chosen_reward: torch.Tensor, reject_reward: torch.Tensor) -&gt; torch.Tensor:
        loss = <a id="change">torch.log(1 + torch.exp(reject_reward - chosen_reward)).mean()</a>
        return loss
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/hpcaitech/colossalai/commit/7548ca5a54ed117f03247dcb43ec1dd962ae04e0#diff-696c99967a2485cd7213f1d30101901d5cd35e832060e56662f1a7092f8618b1L101' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4126927</div><div id='project'> Project Name: hpcaitech/colossalai</div><div id='commit'> Commit Name: 7548ca5a54ed117f03247dcb43ec1dd962ae04e0</div><div id='time'> Time: 2023-03-19</div><div id='author'> Author: 70618399+ht-zhou@users.noreply.github.com</div><div id='file'> File Name: applications/ChatGPT/chatgpt/models/loss.py</div><div id='m_class'> M Class Name: PairWiseLoss</div><div id='n_method'> N Class Name: LogExpLoss</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: applications/ChatGPT/chatgpt/models/loss.py</div><div id='n_file'> N File Name: applications/ChatGPT/chatgpt/models/loss.py</div><div id='m_start'> M Start Line: 102</div><div id='m_end'> M End Line: 104</div><div id='n_start'> N Start Line: 114</div><div id='n_end'> N End Line: 114</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                batchWiseLogit = logit.reshape(len(logit), -1, logit.shape[-1])

                &#47&#47 [n, k]
                summedProb<a id="change"> = </a><a id="change">batchWiseLogit.mean(1).sigmoid()</a>

                target = torch.ones_like(summedProb)<a id="change"> / </a>2.0
                &#47&#47 [n, ]
                reg = F.binary_cross_entropy(summedProb, target, reduction=&quotnone&quot).sum(-1)

                &#47&#47 [n, k] -&gt; [n, ]
                diversity = batchWiseLogit.var(1).sum(-1)
                reg<a id="change"> -= </a>diversity

                &#47&#47 posterior = OneHotCategorical(logits=summedLogit, validate_args=False)
                &#47&#47 prior = OneHotCategorical(probs=torch.ones_like(summedLogit) / summedLogit.shape[-1], validate_args=False)</code></pre><h3>After Change</h3><pre><code class='java'>
                l2QLoss.append(F.mse_loss(latent.detach(), q, reduction=&quotnone&quot).mean(axis=(1, 2, 3)))
                l1QLoss.append(F.l1_loss(latent.detach(), q, reduction=&quotnone&quot).mean(axis=(1, 2, 3)))
                l2QLoss.append(0.1 * F.mse_loss(latent, q.detach(), reduction=&quotnone&quot).mean(axis=(1, 2, 3)))
                l1QLoss.append(0.1 * <a id="change">F.l1_loss(latent, q.detach(), reduction=&quotnone&quot).mean(axis=(1, 2, 3))</a>)

        l1QLoss = sum(l1QLoss)
        l2QLoss = sum(l2QLoss)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/xiaosu-zhu/mcquic/commit/a70c627dfb797c38494d697f152f70f80bea53e3#diff-93a462c5d42bc45838b4e4215cbb88d97c7a71ce0ceb9af896a4f1b48e34e718L48' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4126925</div><div id='project'> Project Name: xiaosu-zhu/mcquic</div><div id='commit'> Commit Name: a70c627dfb797c38494d697f152f70f80bea53e3</div><div id='time'> Time: 2021-03-21</div><div id='author'> Author: xiaosu.zhu@outlook.com</div><div id='file'> File Name: src/mcqc/losses/structural.py</div><div id='m_class'> M Class Name: CompressionLossTwoStage</div><div id='n_method'> N Class Name: CompressionLossTwoStage</div><div id='m_method'> M Method Name: forward(8)</div><div id='n_method'> N Method Name: forward(8)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/mcqc/losses/structural.py</div><div id='n_file'> N File Name: src/mcqc/losses/structural.py</div><div id='m_start'> M Start Line: 49</div><div id='m_end'> M End Line: 86</div><div id='n_start'> N Start Line: 49</div><div id='n_end'> N End Line: 93</div><BR>