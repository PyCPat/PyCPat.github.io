<html><h3>Pattern ID :1831
</h3><img src='13087695.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        x = torch.cat((x, static_x), dim=1)

        &#47&#47 take the mean of all time steps (rows) with additional row for static features; output size = (batch_size, 64)
        x = <a id="change">torch.mean(</a>x, 1<a id="change">)</a>

        &#47&#47 pass through fully-connected part to lower dimension to 2 (binary classification)
        return self.feed_forward(x)
</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 x = torch.mean(x, 1)

        &#47&#47 take the masked mean of all time steps (rows) with additional row for static features; output size = (batch_size, 64)
        mask = <a id="change">torch.cat((mask, torch.ones((x.size()[0], 1), dtype=torch.bool)), dim=1).unsqueeze(2</a><a id="change">)</a>.long()
        time_length = torch.FloatTensor(time_length).unsqueeze(1)
        x = torch.sum(x * (1 - mask), dim=1) / (time_length + 1)    &#47&#47 masked aggregation
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 2</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/mims-harvard/raindrop/commit/c78a0c22f831e2f0ee3f125343ad6e4a2894d680#diff-9130f919aee7ec822bf1d82f703744c78d2ed7fa68b5691eab535c724d94934aL146' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 13087695</div><div id='project'> Project Name: mims-harvard/raindrop</div><div id='commit'> Commit Name: c78a0c22f831e2f0ee3f125343ad6e4a2894d680</div><div id='time'> Time: 2021-08-19</div><div id='author'> Author: mz4730@student.uni-lj.si</div><div id='file'> File Name: code/baselines/Transformer_baseline.py</div><div id='m_class'> M Class Name: Transformer_P12</div><div id='n_method'> N Class Name: Transformer_P12</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: code/baselines/Transformer_baseline.py</div><div id='n_file'> N File Name: code/baselines/Transformer_baseline.py</div><div id='m_start'> M Start Line: 147</div><div id='m_end'> M End Line: 163</div><div id='n_start'> N Start Line: 146</div><div id='n_end'> N End Line: 167</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    batch_features = self.__cnn__(images) &#47&#47 (N, features_dim, block_num, block_num)
    
    conv_features = self.__img2embed_conv__(batch_features).permute(0, 2, 3, 1) &#47&#47 (N, block_num, block_num, embed_dim * 0.5)
    apool = <a id="change">torch.mean(</a>conv_features<a id="change">, dim = 1)</a> &#47&#47 (N, block_num, embed_dim * 0.5)
    mpool, _ = torch.max(conv_features, dim = 1) &#47&#47 (N, block_num, embed_dim * 0.5)

    imgs_embed = torch.cat([apool, mpool], dim = 2) &#47&#47 (N, block_num, embed_dim)</code></pre><h3>After Change</h3><pre><code class='java'>
    &#47&#47batch_texts = self.__clip__.encode_text(text_input)

    &#47&#47tags_embed = self.__text2embed__(self.__clip_drop__(batch_texts.float())).unsqueeze(1)
    imgs_embed = <a id="change">self.__img2embed__(self.__clip_drop__(batch_features.float())).unsqueeze(1</a><a id="change">)</a>

    words_embed = self.__content_embed__(input_ids) 
    indices  = torch.arange(self.seq_len + self.tags_num + self.block_num).expand(batch, -1).to(device)
    position_embed = self.__position_embed__(indices)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/siwooyong/codalab-microsoft-coco-image-captioning-challenge/commit/d24b22ec9f0be1acd2f307be20ec85f84f8d8795#diff-7c1ece53a18959b293126dd93f3cf0f768220f50d2c1201e1601681873e6f6e4L54' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 13087694</div><div id='project'> Project Name: siwooyong/codalab-microsoft-coco-image-captioning-challenge</div><div id='commit'> Commit Name: d24b22ec9f0be1acd2f307be20ec85f84f8d8795</div><div id='time'> Time: 2021-07-08</div><div id='author'> Author: 68500343+yongsiwoo@users.noreply.github.com</div><div id='file'> File Name: models/base_model.py</div><div id='m_class'> M Class Name: decoder</div><div id='n_method'> N Class Name: decoder</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/base_model.py</div><div id='n_file'> N File Name: models/base_model.py</div><div id='m_start'> M Start Line: 57</div><div id='m_end'> M End Line: 74</div><div id='n_start'> N Start Line: 75</div><div id='n_end'> N End Line: 97</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                mean_matrix = self.mean_table[top:down + 1, left:right + 1, :]
                std_matrix = self.std_table[top:down + 1, left:right + 1, :]
                x_mean = mean_matrix.mean(dim=0).mean(dim=0).unsqueeze(0).unsqueeze(-1).unsqueeze(-1) &#47&#47self.kernel *  &#47&#47 should deal with the boundary
                x_std = <a id="change">std_matrix.mean(dim=0)</a>.mean(dim=0).unsqueeze(0).unsqueeze(-1).unsqueeze(-1) &#47&#47self.kernel * 
                &#47&#47x_mean = x_mean.unsqueeze(-1).unsqueeze(-1)
                &#47&#47x_std = x_std.unsqueeze(-1).unsqueeze(-1)
</code></pre><h3>After Change</h3><pre><code class='java'>
                x_std = x_std * self.kernel &#47&#47 1, C, H, W
                x_mean = x_mean.flatten(start_dim=2).sum(dim=2) &#47&#47 [1, C, H, W] -&gt; [1, C, H * W] -&gt; [1, C]
                x_std = x_std.flatten(start_dim=2).sum(dim=2) &#47&#47 [1, C, H, W] -&gt; [1, C, H * W] -&gt; [1, C]
                x_mean = <a id="change">x_mean.unsqueeze(-1).unsqueeze(-1</a><a id="change">)</a> &#47&#47 [1, C] -&gt; [1, C, 1, 1]
                x_std = x_std.unsqueeze(-1).unsqueeze(-1) &#47&#47 [1, C] -&gt; [1, C, 1, 1]

                &#47&#47top, down, left, right = self.query_neighbors(y_anchor=y_anchor, x_anchor=x_anchor, padding=padding)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/kaminyou/urust/commit/63159b688ad053bad7fd41015170f131d547439d#diff-a975422337f96b3fbd8d66278ef6f8ddcf4a1907e7f6fec6d44ff39c9836145eL74' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 13087693</div><div id='project'> Project Name: kaminyou/urust</div><div id='commit'> Commit Name: 63159b688ad053bad7fd41015170f131d547439d</div><div id='time'> Time: 2022-01-27</div><div id='author'> Author: kaminyouho@aetherai.com</div><div id='file'> File Name: models/kin.py</div><div id='m_class'> M Class Name: KernelizedInstanceNorm</div><div id='n_method'> N Class Name: KernelizedInstanceNorm</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/kin.py</div><div id='n_file'> N File Name: models/kin.py</div><div id='m_start'> M Start Line: 83</div><div id='m_end'> M End Line: 96</div><div id='n_start'> N Start Line: 89</div><div id='n_end'> N End Line: 115</div><BR>