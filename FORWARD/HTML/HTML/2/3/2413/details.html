<html><h3>Pattern ID :2413
</h3><img src='14544872.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                norm_w=None,
                norm_b=None,
                alibi=None):
        output = <a id="change">DeepSpeedSelfAttentionFunction.apply(
            </a>input,
            input_mask,
            head_mask,
            layer_past,
            get_present,
            encoder_hidden_states,
            encoder_attention_mask,
            output_attentions,
            norm_w,
            norm_b,
            self.config,
            self.attn_qkvw,
            self.attn_qkvb,
            self.num_attention_heads_per_partition,
            self.norm_factor,
            self.hidden_size_per_partition,
            self.attn_ow,
            self.attn_ob,
            self.mp_group,
            self.q_scales,
            self.q_groups,
            self.merge_count,
            self.qkv_merging,
            self.score_context_func,
            alibi<a id="change">)</a>

        <a id="change">return </a>output
</code></pre><h3>After Change</h3><pre><code class='java'>

        output = self.vector_matmul_func(input=context_layer, weight=self.attn_ow)

        inp_norm = <a id="change">qkv_out[-1]</a>

        if self.config.mlp_after_attn and self.mp_group is not None and dist.get_world_size(
                group=self.mp_group) &gt; 1:
            dist.all_reduce(output, group=self.mp_group)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/microsoft/deepspeed/commit/bb68c526ad2c267dfb235db9c0d0fb1413d19a34#diff-88a3148746124b4093264a91ae8cac5be0bb592bfb2868d5df944836e55d93dbL120' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 14544872</div><div id='project'> Project Name: microsoft/deepspeed</div><div id='commit'> Commit Name: bb68c526ad2c267dfb235db9c0d0fb1413d19a34</div><div id='time'> Time: 2022-12-22</div><div id='author'> Author: jerasley@microsoft.com</div><div id='file'> File Name: deepspeed/ops/transformer/inference/ds_attention.py</div><div id='m_class'> M Class Name: DeepSpeedSelfAttention</div><div id='n_method'> N Class Name: DeepSpeedSelfAttention</div><div id='m_method'> M Method Name: forward(12)</div><div id='n_method'> N Method Name: forward(12)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: deepspeed/ops/transformer/inference/ds_attention.py</div><div id='n_file'> N File Name: deepspeed/ops/transformer/inference/ds_attention.py</div><div id='m_start'> M Start Line: 458</div><div id='m_end'> M End Line: 485</div><div id='n_start'> N Start Line: 120</div><div id='n_end'> N End Line: 151</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.static_weight = torch.cat( (bup,bdown),dim=0)

    def forward(self,input):
        <a id="change">return </a><a id="change">JastrowFunction.apply(</a>input, self.weight, self.static_weight<a id="change">)</a>

class JastrowFunction(torch.autograd.Function):

    @staticmethod</code></pre><h3>After Change</h3><pre><code class='java'>
        factors_updown = factors[:,:nup,nup:]

        &#47&#47 electron pairs up up
        factors_upup = <a id="change">factors_[:,:nup,:nup]</a>
        factors_upup = factors_upup[:,torch.tril(torch.ones(nup,nup))==0]

        &#47&#47 electron pairs down,down
        factors_downdown = factors_[:,nup:,nup:]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/nlesc-jcer/qmctorch/commit/0175b9c86ca7dcb14e33c7ba4af8bbe1232c8790#diff-0daf4a9de2606308323da4dce765f4ac36d2892c25e6116bf91d95094b8f1fa2L62' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 14544869</div><div id='project'> Project Name: nlesc-jcer/qmctorch</div><div id='commit'> Commit Name: 0175b9c86ca7dcb14e33c7ba4af8bbe1232c8790</div><div id='time'> Time: 2019-06-25</div><div id='author'> Author: nicolas.gm.renaud@gmail.com</div><div id='file'> File Name: pyCHAMP/wavefunction/wave_modules.py</div><div id='m_class'> M Class Name: TwoBodyJastrowFactor</div><div id='n_method'> N Class Name: TwoBodyJastrowFactor</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: pyCHAMP/wavefunction/wave_modules.py</div><div id='n_file'> N File Name: pyCHAMP/wavefunction/wave_modules.py</div><div id='m_start'> M Start Line: 63</div><div id='m_end'> M End Line: 63</div><div id='n_start'> N Start Line: 97</div><div id='n_end'> N End Line: 110</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.blocks = nn.ModuleList([ReversibleBlock(f=f, g=g) for f, g in blocks])

    def forward(self, x):
        <a id="change">return </a><a id="change">_ReversibleFunction.apply(</a>x, self.blocks<a id="change">)</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
        if self.layer_dropout &gt; 0:
            to_drop = torch.empty(len(self.blocks)).uniform_(0, 1) &lt; self.layer_dropout
            blocks = [block for block, drop in zip(self.blocks, to_drop) if not drop]
            blocks = <a id="change">self.blocks[:1]</a> if len(blocks) == 0 else blocks

        return _ReversibleFunction.apply(x, blocks)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/reformer-pytorch/commit/f989c1483f6f3d108722cfc1070933b6bee9a274#diff-dc60757400f2449a79aac7063816b042a374dc2d771caf95f56cc2d14775084bL117' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 14544871</div><div id='project'> Project Name: lucidrains/reformer-pytorch</div><div id='commit'> Commit Name: f989c1483f6f3d108722cfc1070933b6bee9a274</div><div id='time'> Time: 2020-02-23</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: reformer_pytorch/reversible.py</div><div id='m_class'> M Class Name: ReversibleSequence</div><div id='n_method'> N Class Name: ReversibleSequence</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: reformer_pytorch/reversible.py</div><div id='n_file'> N File Name: reformer_pytorch/reversible.py</div><div id='m_start'> M Start Line: 118</div><div id='m_end'> M End Line: 118</div><div id='n_start'> N Start Line: 118</div><div id='n_end'> N End Line: 125</div><BR>