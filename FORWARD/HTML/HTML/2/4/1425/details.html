<html><h3>Pattern ID :1425
</h3><img src='4851834.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 otherwise we need to loop over the batch to account for varying trial lengths
        else:
            combined_embedding = <a id="change">[]</a>
            trial_counts = torch.zeros(batch, 1)
            for i in range(batch):
                &#47&#47 remove NaNs
                valid_x = x[i, ~torch.isnan(x[i, :, 0]), :]
                trial_counts[i] = valid_x.shape[0]
                trial_embeddings = self.trial_net(valid_x)
                &#47&#47 apply combining operation over permutation dimension
                combined_embedding.append(
                    self.combining_function(trial_embeddings, dim=0)
                )

            combined_embedding<a id="change"> = </a>torch.stack(combined_embedding, dim=0)

        assert not torch.isnan(combined_embedding).any(), "NaNs in embedding."
</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 Get number of trials from non-nan entries
        num_batch, max_num_trials = x.shape[0], x.shape[self.aggregation_dim]
        nan_counts = (
            <a id="change">torch.isnan(x)
            .sum(dim=self.aggregation_dim)  &#47&#47 count nans over trial dimension
            .reshape(</a>-1<a id="change">)</a>[:num_batch]  &#47&#47 counts are the same across data dims
            .unsqueeze(-1)  &#47&#47 make it (batch, 1) to match embeddings below
        )
        &#47&#47 number of non-nan trials
        trial_counts = max_num_trials - nan_counts

        &#47&#47 get nan entries
        is_nan = torch.isnan(x)
        &#47&#47 apply trial net with nan entries replaced with 0
        masked_x = torch.nan_to_num(x, nan=0.0)
        trial_embeddings = self.trial_net(masked_x)
        &#47&#47 replace previous nan entries with zeros
        trial_embeddings = trial_embeddings * (~is_nan.all(-1, keepdim=True)).float()

        &#47&#47 Take mean over permutation dimension divide by number of trials
        &#47&#47 (instead of just taking torch.mean) to account for masking.
        if self.aggregation_fn == "mean":
            combined_embedding<a id="change"> = </a>(
                trial_embeddings.sum(dim=self.aggregation_dim) / trial_counts
            )
        else:</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/mackelab/sbi/commit/3831fd6d5fda0ca050db8c54868ed30558451042#diff-672ba10e6c3065a6f5554033b9b173c4fe88f4c05ffc31c70a9198691e6c6659L274' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4851834</div><div id='project'> Project Name: mackelab/sbi</div><div id='commit'> Commit Name: 3831fd6d5fda0ca050db8c54868ed30558451042</div><div id='time'> Time: 2023-03-01</div><div id='author'> Author: jan.boelts@tum.de</div><div id='file'> File Name: sbi/neural_nets/embedding_nets.py</div><div id='m_class'> M Class Name: PermutationInvariantEmbedding</div><div id='n_method'> N Class Name: PermutationInvariantEmbedding</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: sbi/neural_nets/embedding_nets.py</div><div id='n_file'> N File Name: sbi/neural_nets/embedding_nets.py</div><div id='m_start'> M Start Line: 274</div><div id='m_end'> M End Line: 300</div><div id='n_start'> N Start Line: 279</div><div id='n_end'> N End Line: 306</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def forward(self, x):
        if self.training:
            total_blocks = sum([len(sx) for sx in x])
            mask_size = torch.Size(<a id="change">[</a>total_blocks<a id="change"></a>])
            binomial = torch.distributions.binomial.Binomial(probs=1 - self.p)
            mask = binomial.sample(mask_size) * (1.0 / (1 - self.p))
            mask_id = 0
            for mod in x:
                for x_mod in mod:
                    x_mod<a id="change"> *= </a>mask[mask_id]
                    mask_id += 1
            return x, mask
        return x, None</code></pre><h3>After Change</h3><pre><code class='java'>
            mask = binomial.sample(mask_size) * (1.0 / (1 - self.p))
            mask_shapes = [list(x.shape[:2]) + [1] * (x.dim() - 2) for x in X]
            grouped_masks = torch.split(mask, blocks_per_mod, dim=1)
            grouped_masks = [<a id="change">m.reshape(</a>s<a id="change">)</a> for m, s in zip(grouped_masks, mask_shapes)]
            X<a id="change"> = </a>[x * m for x, m in zip(X, grouped_masks)]
            return X, grouped_masks
        return X, None
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/anita-hu/msaf/commit/a2c91bd6e186680ca2c41bbf22c9b57aff4654d2#diff-d68e3105d0084e846106ad79a39721b487918159e4343a84f4ae68b3d6eadc0cL38' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4851833</div><div id='project'> Project Name: anita-hu/msaf</div><div id='commit'> Commit Name: a2c91bd6e186680ca2c41bbf22c9b57aff4654d2</div><div id='time'> Time: 2020-12-30</div><div id='author'> Author: anitahu113@gmail.com</div><div id='file'> File Name: MSAF.py</div><div id='m_class'> M Class Name: BlockDropout</div><div id='n_method'> N Class Name: BlockDropout</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: MSAF.py</div><div id='n_file'> N File Name: MSAF.py</div><div id='m_start'> M Start Line: 40</div><div id='m_end'> M End Line: 49</div><div id='n_start'> N Start Line: 39</div><div id='n_end'> N End Line: 47</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        batch_size, num_of_vertices, in_channels, num_of_timesteps = x.shape
        data = Data(edge_index=edge_index, edge_attr=None, num_nodes=num_nodes)
        lambda_max = LaplacianLambdaMax()(data).lambda_max
        outputs<a id="change"> = </a><a id="change">[]</a>
        for time_step in range(num_of_timesteps):
            outputs.append(torch.unsqueeze(self.cheb_conv(x=x[:,:,:,time_step], edge_index=edge_index,
                batch = batch_size, lambda_max=lambda_max), -1))
</code></pre><h3>After Change</h3><pre><code class='java'>
        tmp = tmp.permute(2,0,1) &#47&#47 (B*T_in, N_nodes, F_in)
        output = F.relu(self.cheb_conv(x=tmp, edge_index=edge_index,
                batch = batch_size*num_of_timesteps, lambda_max=lambda_max))
        spatial_gcn<a id="change"> = </a><a id="change">output.permute(1,2,0).reshape(</a>num_of_vertices,self.nb_time_filter,batch_size,num_of_timesteps<a id="change">)</a>.permute(2,0,1,3) &#47&#47 (B,N_nodes,F_out,T_in)

        &#47&#47 convolution along the time axis
        time_conv_output = self.time_conv(spatial_gcn.permute(0, 2, 1, 3))  &#47&#47 (b,F,N,T)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/benedekrozemberczki/pytorch_geometric_temporal/commit/509a541a01913f5b45859b801c48b5fd264bd94a#diff-21666376be83b64a4fa768847ddfc3e4e7076772ef843870e346158dd7205045L18' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4851840</div><div id='project'> Project Name: benedekrozemberczki/pytorch_geometric_temporal</div><div id='commit'> Commit Name: 509a541a01913f5b45859b801c48b5fd264bd94a</div><div id='time'> Time: 2021-03-18</div><div id='author'> Author: He_YX@outlook.com</div><div id='file'> File Name: torch_geometric_temporal/nn/convolutional/mstgcn.py</div><div id='m_class'> M Class Name: MSTGCN_block</div><div id='n_method'> N Class Name: MSTGCN_block</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: torch_geometric_temporal/nn/convolutional/mstgcn.py</div><div id='n_file'> N File Name: torch_geometric_temporal/nn/convolutional/mstgcn.py</div><div id='m_start'> M Start Line: 36</div><div id='m_end'> M End Line: 41</div><div id='n_start'> N Start Line: 44</div><div id='n_end'> N End Line: 48</div><BR>