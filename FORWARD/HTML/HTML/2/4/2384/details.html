<html><h3>Pattern ID :2384
</h3><img src='14498813.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 assert the input shape is : batch_seq_size x entities_size x embeding_size
        &#47&#47 note: because the feature size of entity is not equal to 256, so it can not fed into transformer directly.
        &#47&#47 thus, we add a embedding layer to transfer it to right size.
        <a id="change">print(</a>&quotentity_input is nan:&quot, torch.isnan(x).any()<a id="change">)</a> if debug else None

        &#47&#47 calculate there are how many real entities in each batch
        tmp_x = torch.mean(x, dim=2, keepdim=False)</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 AlphaStar: The mean of the transformer output across across the units (masked by the missing entries) 
        &#47&#47 is fed through a linear layer of size 256 and a ReLU to yield `embedded_entity`
        masked_out = out * <a id="change">mask.unsqueeze(2</a><a id="change">)</a>

        &#47&#47 sum over across the units
        &#47&#47 masked_out: [batch_seq_size x entities_size x embeding_size]
        &#47&#47 z: [batch_size, embeding_size]
        z<a id="change"> = </a>masked_out.sum(dim=1, keepdim=False)

        &#47&#47 here we should dived by the entity_num, not the cls.max_entities
        &#47&#47 z: [batch_size, embeding_size]</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/liuruoze/mini-alphastar/commit/612d42a7bf5ef827e1e919198d839fce106155cd#diff-71869e70f9cb835282d541d2d3529d25b6ed6795c79bc770e860e9318619f6b1L716' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 14498813</div><div id='project'> Project Name: liuruoze/mini-alphastar</div><div id='commit'> Commit Name: 612d42a7bf5ef827e1e919198d839fce106155cd</div><div id='time'> Time: 2021-11-25</div><div id='author'> Author: liuruoze@163.com</div><div id='file'> File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='m_class'> M Class Name: EntityEncoder</div><div id='n_method'> N Class Name: EntityEncoder</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='n_file'> N File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='m_start'> M Start Line: 721</div><div id='m_end'> M End Line: 758</div><div id='n_start'> N Start Line: 716</div><div id='n_end'> N End Line: 778</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if self.resample&gt;1:
            x = audio.pt_resample_audio(audio=x, sr=self.sampling_rate,
                        target_sr=int(self.sampling_rate * self.resample))
        <a id="change">print(</a>"resampled-&gt;",x.shape<a id="change">)</a>
        encoder_outputs = []
        for encoder in self.encoder:
            x = encoder(x)
            print(x.shape)</code></pre><h3>After Change</h3><pre><code class='java'>
    def forward(self,mixed_signal):

        if mixed_signal.dim() == 2:
            mixed_signal<a id="change"> = </a><a id="change">mixed_signal.unsqueeze(1</a><a id="change">)</a>

        length = mixed_signal.shape[-1]
        x = F.pad(mixed_signal, (0,self.get_padding_length(length) - length)) 
        if self.resample&gt;1:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/shahules786/mayavoz/commit/4edc90deb0f36a17404b2e78ed4faf210ed7c9d0#diff-ae222fe663e9b184f8fdc35f842fee011444775d4757dbff087f2e43e1eedf0fL87' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 14498806</div><div id='project'> Project Name: shahules786/mayavoz</div><div id='commit'> Commit Name: 4edc90deb0f36a17404b2e78ed4faf210ed7c9d0</div><div id='time'> Time: 2022-09-06</div><div id='author'> Author: shahules786@gmail.com</div><div id='file'> File Name: enhancer/models/demucs.py</div><div id='m_class'> M Class Name: Demucs</div><div id='n_method'> N Class Name: Demucs</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: enhancer/models/demucs.py</div><div id='n_file'> N File Name: enhancer/models/demucs.py</div><div id='m_start'> M Start Line: 90</div><div id='m_end'> M End Line: 101</div><div id='n_start'> N Start Line: 89</div><div id='n_end'> N End Line: 104</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    def forward(self, seq):
        &#47&#47 seq - [batch_size, seq_len]
        <a id="change">print(</a>self.transformer(seq, seq).shape<a id="change">)</a></code></pre><h3>After Change</h3><pre><code class='java'>

    def forward(self, seq):
        &#47&#47 seq - [batch_size, seq_len]
        pos = <a id="change">torch.arange(0, seq[1]).unsqueeze(0</a><a id="change">)</a>.repeat(seq[0], 1)
        seq<a id="change"> = </a>self.dropout((self.tok_embed(seq) * self.scale) + self.pos_encoding(pos))
        return self.transformer(seq, seq)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ammesatyajit/videobert/commit/8327374fe54e685ccb4dee5be64421b56903873d#diff-bfbdfcab00b44379d0d84330903c598d633961fc4e68d6adc21c8b9cea49fc5aL144' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 14498832</div><div id='project'> Project Name: ammesatyajit/videobert</div><div id='commit'> Commit Name: 8327374fe54e685ccb4dee5be64421b56903873d</div><div id='time'> Time: 2020-09-19</div><div id='author'> Author: ammesatyajit@gmail.com</div><div id='file'> File Name: VideoBERT/train/custom_vid_transformer.py</div><div id='m_class'> M Class Name: VideoTransformer</div><div id='n_method'> N Class Name: VideoTransformer</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: VideoBERT/train/custom_vid_transformer.py</div><div id='n_file'> N File Name: VideoBERT/train/custom_vid_transformer.py</div><div id='m_start'> M Start Line: 146</div><div id='m_end'> M End Line: 147</div><div id='n_start'> N Start Line: 155</div><div id='n_end'> N End Line: 158</div><BR>