<html><h3>Pattern ID :1203
</h3><img src='4348162.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        super().__init__()

    def forward(self, x):
        <a id="change">return </a>x
</code></pre><h3>After Change</h3><pre><code class='java'>
        self.level_stack = LevelStack()

    def forward(self, x, *, num_steps_forecast):
        z = <a id="change">self.embed(</a>x<a id="change">)</a>

        for freq_attn, mhes_attn, attn_post_ln, ff_block, level in self.encoder_layers:
            latent_seasonal = freq_attn(z)
            z = z - latent_seasonal

            latent_growth = mhes_attn(z)
            z = z -latent_growth

            z = attn_post_ln(z)

            if exists(ff_block):
                z = ff_block(z)

            x = level(x, latent_seasonal, latent_growth)

        level<a id="change"> = </a>self.level_stack(x, num_steps_forecast = num_steps_forecast)
        <a id="change">return </a>level
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lucidrains/etsformer-pytorch/commit/45c37c88fd1418716daf54cd865109160492e830#diff-b4b8264f25f5dfdaf86bc5e5eff19dd88e54974eb3ebdbb09741da0265b56130L191' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4348162</div><div id='project'> Project Name: lucidrains/etsformer-pytorch</div><div id='commit'> Commit Name: 45c37c88fd1418716daf54cd865109160492e830</div><div id='time'> Time: 2022-03-14</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: etsformer_pytorch/etsformer_pytorch.py</div><div id='m_class'> M Class Name: ETSFormer</div><div id='n_method'> N Class Name: ETSFormer</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: etsformer_pytorch/etsformer_pytorch.py</div><div id='n_file'> N File Name: etsformer_pytorch/etsformer_pytorch.py</div><div id='m_start'> M Start Line: 191</div><div id='m_end'> M End Line: 191</div><div id='n_start'> N Start Line: 267</div><div id='n_end'> N End Line: 284</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            )

        &#47&#47 shape (batch_size, target_seq_len, d_model)
        <a id="change">return </a>x
</code></pre><h3>After Change</h3><pre><code class='java'>
        target_mask: Optional[torch.Tensor] = None,
    ) -&gt; torch.Tensor:

        tgt = <a id="change">self.embed(</a>tgt<a id="change">)</a> * math.sqrt(self.d_model)
        pos_enc_tgt = self.positional_encoding(tgt)
        output<a id="change"> = </a>pos_enc_tgt

        for i in range(self.num_layers):
            normed_output = self.layer_norm(output)
            output = output + self.dropout(
                self.attention[i](normed_output, normed_output, normed_output, target_mask)
            )
            normed_output = self.layer_norm(output)
            output = output + self.dropout(
                self.source_attention[i](normed_output, memory, memory, source_mask)
            )
            normed_output = self.layer_norm(output)
            output = output + self.dropout(self.position_feed_forward[i](normed_output))

        <a id="change">return </a>self.layer_norm(output)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mindee/doctr/commit/fddceba7bee5098b4219b7ba6a0bdf4f4a98adfe#diff-5eb4b6b7a215017ac91351a0c5e665af04fa644ddf1ecd5037545ba096ec1337L69' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4348160</div><div id='project'> Project Name: mindee/doctr</div><div id='commit'> Commit Name: fddceba7bee5098b4219b7ba6a0bdf4f4a98adfe</div><div id='time'> Time: 2022-06-09</div><div id='author'> Author: felixdittrich92@gmail.com</div><div id='file'> File Name: doctr/models/recognition/transformer/pytorch.py</div><div id='m_class'> M Class Name: Decoder</div><div id='n_method'> N Class Name: Decoder</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: doctr/models/recognition/transformer/pytorch.py</div><div id='n_file'> N File Name: doctr/models/recognition/transformer/pytorch.py</div><div id='m_start'> M Start Line: 74</div><div id='m_end'> M End Line: 91</div><div id='n_start'> N Start Line: 147</div><div id='n_end'> N End Line: 167</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        batch_size = len(sparse_features.lengths()) // len(keys) // self.world_size
        flattened_sparse_embeddings = self.embed(flattened_sparse_features, batch_offsets)
        <a id="change">return </a>flattened_sparse_embeddings.view(batch_size, len(keys), -1)


class FusedDenseModules(nn.Module):</code></pre><h3>After Change</h3><pre><code class='java'>

        batch_size = len(sparse_features.lengths()) // len(keys)
        feature_size = len(keys)
        flattened_sparse_embeddings<a id="change"> = </a><a id="change">self.embed(</a>flattened_sparse_features,
                                                 batch_offsets<a id="change">,
                                                 send_shape=(batch_size, feature_size, -1))</a>
        <a id="change">return </a>flattened_sparse_embeddings


class FusedDenseModules(nn.Module):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/hpcaitech/cachedembedding/commit/6b7be0fc3709abc8e34c88cd2e135f3b195f86cc#diff-cdf35683f2809927ff133660ab3e3618fac92f2aa4a351fec2f085cbb5ebd0e9L303' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4348161</div><div id='project'> Project Name: hpcaitech/cachedembedding</div><div id='commit'> Commit Name: 6b7be0fc3709abc8e34c88cd2e135f3b195f86cc</div><div id='time'> Time: 2022-06-23</div><div id='author'> Author: zhangg1998@outlook.com</div><div id='file'> File Name: recsys/models/dlrm.py</div><div id='m_class'> M Class Name: FusedSparseModules</div><div id='n_method'> N Class Name: FusedSparseModules</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: recsys/models/dlrm.py</div><div id='n_file'> N File Name: recsys/models/dlrm.py</div><div id='m_start'> M Start Line: 304</div><div id='m_end'> M End Line: 314</div><div id='n_start'> N Start Line: 143</div><div id='n_end'> N End Line: 156</div><BR>