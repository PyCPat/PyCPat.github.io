<link rel="stylesheet" href="../default.css">
<script src="../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        embedding = self.dropout(self.embed(x))
        conv_in = embedding.permute(0, 2, 1)
        conv_out = self.conv(conv_in)
        values, indices = <a id="change">conv_out.max(dim=-1)</a>
        conv_out = conv_out.permute(2, 0, 1)
        rnn_out, _ = self.rnn(conv_out)
        attention = (self.mask * rnn_out).mean(dim=0)
        output = self.fc(attention).squeeze(1)</code></pre><h3>After Change</h3><pre><code class='java'>
        rnn_out, _ = self.rnn(conv_out)
        global_rnn_out = rnn_out.mean(dim=0)
        attention = torch.tanh(
            self.local2attn(rnn_out)<a id="change"> + </a>self.global2attn(global_rnn_out)
        ).permute(1, 0, 2)
        alpha = F.softmax(attention.matmul(self.attn_scale), dim=-1)
        rnn_out = rnn_out.permute(1, 0, 2)
        memory = <a id="change">(alpha * rnn_out).sum(dim=1)</a>
        output = self.fc(memory).squeeze(1)
        return output

</code></pre>