{"BEFORE":"    def forward(self, pred, target, mask=None):\n\n        pred = pred.contiguous().view(pred.size()[0], -1)\n        target = target.contiguous().view(target.size()[0], -1)\n\n        if mask is not None:\n            mask = mask.contiguous().view(mask.size()[0], -1)\n            pred = pred * mask\n            target = target * mask\n\n        a = torch.sum(pred * target)\n        b = torch.sum(pred)\n        c = torch.sum(target)\n        d = (2 * a) \/ (b + c + self.eps)\n\n        return 1 - d\n","AFTER":"                pred: torch.Tensor,\n                gt: torch.Tensor,\n                mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n        \"\"\"Forward function.\n\n        Args:\n            pred (torch.Tensor): The prediction in any shape.\n            gt (torch.Tensor): The learning target of the prediction in the\n                same shape as pred.\n            mask (torch.Tensor, optional): Binary mask in the same shape of\n                pred, indicating positive regions to calculate the loss. Whole\n                region will be taken into account if not provided. Defaults to\n                None.\n\n        Returns:\n            torch.Tensor: The loss value.\n        \"\"\"\n\n        assert pred.size() == gt.size() and gt.numel() > 0\n        if mask is None:\n            mask = torch.ones_like(gt)\n        assert mask.size() == gt.size()\n\n        pred = pred.contiguous().view(pred.size(0), -1)\n        gt = gt.contiguous().view(gt.size(0), -1)\n\n        mask = mask.contiguous().view(mask.size(0), -1)\n        pred = pred * mask\n        gt = gt * mask\n\n        dice_coeff = (2 * (pred * gt).sum()) \/ (\n            pred.sum() + gt.sum() + self.eps)\n\n        return 1 - dice_coeff\n"}