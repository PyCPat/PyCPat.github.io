{"BEFORE":"        batch_size, channels, width, height = x.size()\n\n        # (b, 1, 28, 28) -> (b, 1*28*28)\n        x = x.view(batch_size, -1)\n        x = self.layer_1(x)\n        x = F.relu(x)\n        x = self.layer_2(x)\n        x = F.relu(x)\n        x = self.layer_3(x)\n        x = F.relu(x)\n        x = self.layer_4(x)\n\n        return F.log_softmax(x, dim=1)\n","AFTER":"        x = self.model(x)\n        x = F.relu(x)\n        x = self.drop1(x)\n        x = self.lin_1(x)\n        x = F.relu(x)\n        x = self.drop2(x)\n        x = self.lin_2(x)\n        return torch.sigmoid(x)\n"}