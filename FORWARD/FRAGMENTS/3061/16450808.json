{"BEFORE":"        x = self.resnet18(frame)\n\n        # input should be (seq_len, batch, input_size)\n        output, h_n = self.rnn(x.unsqueeze(1))\n        output = self.fc(output.flatten())\n        # print(output)\n        # return torch.mean(output, dim=0)\n        return output\n","AFTER":"        output_per_clip = []\n        # so as to reflect a batch_size = 1\n        st_maps = st_maps.unsqueeze(0)\n        for t in range(st_maps.size(1)):\n            with torch.no_grad():\n                x = self.resnet18(st_maps[:, t, :, :, :])\n                # collapse dimensions to BSx512 (resnet o\/p)\n                x = x.view(x.size(0), -1)\n            # output dim: BSx1\n            x = self.fc_resnet(x)\n            # For now since we're working with BS = 1, lets collapse that dimension\n            output_per_clip.append(x.squeeze(0))\n            # input should be (seq_len, batch, input_size)\n\n        output_seq = torch.stack(output_per_clip, dim=0).transpose_(0, 1)\n        gru_output, h_n = self.rnn(output_seq.unsqueeze(1))\n        return output_seq, gru_output.squeeze(0)\n"}