{"BEFORE":"        x, exact_match_pos = inputs\n        \n        x = x + self.em_embedding(exact_match_pos) # (8, 384(문장길이), 768(임베딩)) => x[2] + em_embedding[2] \/ x[8] + em_embedding[8]\n        x, (_, _) = self.lstm(x) \n\n        x = x.transpose(1, 2).contiguous()\n        conv1_out = self.conv_1(x).transpose(1, 2).contiguous().squeeze(-1)\n        conv3_out = self.conv_3(x).transpose(1, 2).contiguous().squeeze(-1)\n        conv5_out = self.conv_5(x).transpose(1, 2).contiguous().squeeze(-1)\n        x = self.fc(torch.cat((conv1_out, conv3_out, conv5_out), -1))\n","AFTER":"        x, (_, _) = self.lstm(inputs)\n        x = x.transpose(1, 2).contiguous()\n        \n        conv1_out = self.relu(self.conv_1(x).transpose(1, 2).contiguous().squeeze(-1))\n        conv3_out = self.relu(self.conv_3(x).transpose(1, 2).contiguous().squeeze(-1))\n        conv5_out = self.relu(self.conv_5(x).transpose(1, 2).contiguous().squeeze(-1))\n        x = self.fc(self.dropout(torch.cat((conv1_out, conv3_out, conv5_out), -1)))\n"}