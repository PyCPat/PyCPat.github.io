{"BEFORE":"        content_out = einsum('nde,ndxy->nexy', context, content_q)\n\n        # this largely follows the mathematical implementation details\n        # spelled out in appendix B (6) - (8)\n        if exists(self.rel_pos_length):\n            Ix = calc_reindexing_tensor(x, L, device)\n            Px = einsum('xir,rd->xid', Ix, self.rel_rows)\n            Sx = einsum('ndxy,xid->nixy', q, Px)\n            Yh = einsum('nixy,neiy->nexy', Sx, v)\n            del Ix\n\n            Yh = self.norm(Yh)\n\n            Iy = calc_reindexing_tensor(y, L, device)\n            Py = einsum('xir,rd->xid', Iy, self.rel_columns)\n            Sy = einsum('ndxy,xid->nixy', q, Py)\n            rel_pos_out = einsum('nixy,neiy->nexy', Sy, Yh)\n            del Iy\n\n            content_out = content_out + rel_pos_out\n\n        content_out = rearrange(content_out, '(b h) c x y -> b (h c) x y', b = b, h = h)\n","AFTER":"        content_out = einsum('nde,ndm->nem', context, content_q)\n        content_out = rearrange(content_out, 'n d (x y) -> n d x y', x = x, y = y)\n\n        # this largely follows the mathematical implementation details\n        # spelled out in appendix B (6) - (8)\n        if exists(self.rel_pos_length):\n            q, v = map(lambda t: rearrange(t, 'n c (x y) -> n c x y', x = x, y = y), (q, v))\n\n            Ix = calc_reindexing_tensor(x, L, device)\n            Px = einsum('xir,rd->xid', Ix, self.rel_rows)\n            Sx = einsum('ndxy,xid->nixy', q, Px)\n            Yh = einsum('nixy,neiy->nexy', Sx, v)\n\n            Yh = self.norm(Yh)\n\n            Iy = calc_reindexing_tensor(y, L, device)\n            Py = einsum('xir,rd->xid', Iy, self.rel_columns)\n            Sy = einsum('ndxy,xid->nixy', q, Py)\n            rel_pos_out = einsum('nixy,neiy->nexy', Sy, Yh)\n\n            content_out = content_out + rel_pos_out\n\n        content_out = content_out.reshape(b, -1, x, y).contiguous()\n"}