<link rel="stylesheet" href="../default.css">
<script src="../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    def forward(self, out_state, history):
        seq_len = history.size()[1]
        state_len = out_state.size()[1]
        <a id="change">batch_size</a> = history.size()[0]
        <a id="change">attn_energies</a><a id="change"> = </a><a id="change">torch.zeros(
            </a>batch_size, state_len, seq_len<a id="change">)</a>.to(self.device)
        for i in range(state_len):
            for j in range(seq_len):
                <a id="change">for k</a> in <a id="change">range(</a>batch_size<a id="change">):
                    </a><a id="change">attn_energies[k, i, j]</a> = self.score(
                        <a id="change">out_state[k]</a>[i], <a id="change">history[k][j]</a>)
        return F.softmax(attn_energies, dim=2)

    def score(self, hidden, encoder_output):</code></pre><h3>After Change</h3><pre><code class='java'>
        Returns:
            [tensor]: (batch_size, state_len, history_len)
        
        <a id="change">if self.method == &quotdot&quot</a><a id="change">:
            </a>history = history.permute(0, 2, 1)  &#47&#47 batch_size * hidden_size * history_len
            attn_energies<a id="change"> = </a>torch.bmm(out_state, history)
        elif self.method == &quotgeneral&quot:
            history = self.attn(history)
            history = history.permute(0, 2, 1)
            attn_energies<a id="change"> = </a>torch.bmm(out_state, history)
        return F.softmax(attn_energies, dim=2)

</code></pre>