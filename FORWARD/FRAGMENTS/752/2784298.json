{"BEFORE":"        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C \/\/ self.num_heads).permute(2, 0, 3, 1, 4)\n        q, k, v = qkv[0] * self.scale, qkv[1], qkv[2]\n\n        attn = (q @ k.transpose(-2, -1))\n\n        attn = self.proj_l(attn.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n\n        attn = attn.softmax(dim=-1)\n\n        attn = self.proj_w(attn.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n        attn = self.attn_drop(attn)\n\n        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n        x = self.proj(x)\n        x = self.proj_drop(x)\n        return x\n","AFTER":"        q = self.q(x[:, 0]).unsqueeze(1).reshape(B, 1, self.num_heads, C \/\/ self.num_heads).permute(0, 2, 1, 3)\n        k = self.k(x).reshape(B, N, self.num_heads, C \/\/ self.num_heads).permute(0, 2, 1, 3)\n\n        q = q * self.scale\n        v = self.v(x).reshape(B, N, self.num_heads, C \/\/ self.num_heads).permute(0, 2, 1, 3)\n\n        attn = (q @ k.transpose(-2, -1))\n        attn = attn.softmax(dim=-1)\n        attn = self.attn_drop(attn)\n\n        x_cls = (attn @ v).transpose(1, 2).reshape(B, 1, C)\n        x_cls = self.proj(x_cls)\n        x_cls = self.proj_drop(x_cls)\n\n        return x_cls\n"}