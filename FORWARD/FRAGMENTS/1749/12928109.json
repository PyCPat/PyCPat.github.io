{"BEFORE":"        output = []\n\n        for i, (mdef, module) in enumerate(zip(self.module_defs, self.module_list)):\n            mtype = mdef['type']\n            if mtype in ['convolutional', 'upsample', 'maxpool']:\n                x = module(x)\n            elif mtype == 'route':\n                layers = [int(x) for x in mdef['layers'].split(',')]\n                if len(layers) == 1:\n                    x = layer_outputs[layers[0]]\n                else:\n                    try:\n                        x = torch.cat([layer_outputs[i] for i in layers], 1)\n                    except:  # apply stride 2 for darknet reorg layer\n                        layer_outputs[layers[1]] = F.interpolate(layer_outputs[layers[1]], scale_factor=[0.5, 0.5])\n                        x = torch.cat([layer_outputs[i] for i in layers], 1)\n                    # print(''), [print(layer_outputs[i].shape) for i in layers], print(x.shape)\n            elif mtype == 'shortcut':\n                x = x + layer_outputs[int(mdef['from'])]\n            elif mtype == 'yolo':\n                output.append(module(x, img_size))\n            layer_outputs.append(x if i in self.routs else [])\n\n        if self.training:\n            return output\n        elif ONNX_EXPORT:\n            output = torch.cat(output, 1)  # cat 3 layers 85 x (507, 2028, 8112) to 85 x 10647\n            nc = self.module_list[self.yolo_layers[0]].nc  # number of classes\n            return output[4:4 + nc].t(), output[0:4].t()  # ONNX scores, boxes\n","AFTER":"        output = []\n\n        for i, (mdef, module) in enumerate(zip(self.module_defs, self.module_list)):\n            mtype = mdef['type']\n            if mtype in ['convolutional', 'upsample', 'maxpool']:\n                x = module(x)\n            elif mtype == 'route':\n                layers = [int(x) for x in mdef['layers'].split(',')]\n                if len(layers) == 1:\n                    x = layer_outputs[layers[0]]\n                else:\n                    try:\n                        x = torch.cat([layer_outputs[i] for i in layers], 1)\n                    except:  # apply stride 2 for darknet reorg layer\n                        layer_outputs[layers[1]] = F.interpolate(layer_outputs[layers[1]], scale_factor=[0.5, 0.5])\n                        x = torch.cat([layer_outputs[i] for i in layers], 1)\n                    # print(''), [print(layer_outputs[i].shape) for i in layers], print(x.shape)\n            elif mtype == 'shortcut':\n                x = x + layer_outputs[int(mdef['from'])]\n            elif mtype == 'yolo':\n                output.append(module(x, img_size))\n            layer_outputs.append(x if i in self.routs else [])\n\n        if self.training:\n            return output\n        elif ONNX_EXPORT:\n            x = [torch.cat(x, 0) for x in zip(*output)]\n            return x[0], torch.cat(x[1:3], 1)  # scores, boxes: 3780x80, 3780x4\n"}