{"BEFORE":"        bsz, seq_len = input.size()\n        max_pos = self.padding_idx + 1 + seq_len\n        if self.weights is None or max_pos > self.weights.size(0):\n            self.weights = SinusoidalPositionalEmbedding.get_embedding(\n                max_pos,\n                self.embedding_dim,\n                self.padding_idx,\n            )\n        self.weights = self.weights.type_as(self._float_tensor)\n\n        if incremental_state is not None:\n            # positions is the same for every token when decoding a single step\n            return self.weights[self.padding_idx + seq_len, :].expand(bsz, 1, -1)\n\n        positions = utils.make_positions(input, self.padding_idx, self.left_pad, self.onnx_trace)\n        if self.onnx_trace:\n            bsz = torch.onnx.operators.shape_as_tensor(input)[0]\n            seq_len = torch.onnx.operators.shape_as_tensor(input)[1]\n","AFTER":"    def forward(self, input, incremental_state=None, timestep=None):\n        \"\"\"Input is expected to be of size [bsz x seqlen].\"\"\"\n        bsz, seq_len = torch.onnx.operators.shape_as_tensor(input)\n        max_pos = self.padding_idx + 1 + seq_len\n        if self.weights is None or max_pos > self.weights.size(0):\n            # recompute\/expand embeddings if needed\n            self.weights = SinusoidalPositionalEmbedding.get_embedding(\n                max_pos,\n                self.embedding_dim,\n                self.padding_idx,\n            )\n        self.weights = self.weights.type_as(self._float_tensor)\n\n        if incremental_state is not None:\n            # positions is the same for every token when decoding a single step\n            pos = (timestep.int() + 1).long() if timestep is not None else seq_len\n            if self.onnx_trace:\n                return self.weights[self.padding_idx + pos, :].unsqueeze(1).repeat(bsz, 1, 1)\n            return self.weights[self.padding_idx + pos, :].expand(bsz, 1, -1)\n\n        positions = utils.make_positions(input, self.padding_idx, self.left_pad, self.onnx_trace)\n        if self.onnx_trace:\n"}