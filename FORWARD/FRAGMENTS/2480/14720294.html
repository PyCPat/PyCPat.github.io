<link rel="stylesheet" href="../default.css">
<script src="../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        patches = self.proj(x)  &#47&#47 BCHW

        B, C, H, W = <a id="change">patches.size()</a>
        patches = patches.view(B, C, -1).permute(0, 2, 1)  &#47&#47 (batch_size, num_patches, d_model)
        cls_tokens = self.cls_token.expand(B, -1, -1)  &#47&#47 (batch_size, 1, d_model)
        &#47&#47 concate cls_tokens to patches
        embeddings = torch.cat([cls_tokens, patches], dim=1)  &#47&#47 (batch_size, num_patches + 1, d_model)</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial15/Vision_Transformer.html
        &#47&#47 NOTE: patchify with Conv2d works only with padding="valid" correctly on smaller images
        &#47&#47 and has currently no ONNX support so we use this workaround
        x = <a id="change">x.reshape(
            </a>B, C, (H // self.patch_size[0]), self.patch_size[0], (W<a id="change"> // </a>self.patch_size[1]), self.patch_size[1]<a id="change">
        )</a>
        &#47&#47 (B, H&quot, W&quot, C, ph, pw) -&gt; (B, H&quot*W&quot, C*ph*pw)
        patches = x.permute(0, 2, 4, 1, 3, 5).flatten(1, 2).flatten(2, 4)
        patches = self.proj(patches)  &#47&#47 (batch_size, num_patches, d_model)
</code></pre>