{"BEFORE":"        sparse_emb_list = self.embedding_layer(data)\n        feature_emb = torch.stack(sparse_emb_list, dim=1).squeeze(2)\n        dnn_out = self.dnn(feature_emb.flatten(start_dim=1))\n","AFTER":"        feature_emb = self.embedding_layer(data)\n        dense_input = get_linear_input(self.enc_dict, data)\n        emb_flatten = feature_emb.flatten(start_dim=1)\n        dnn_out = self.dnn(torch.cat([emb_flatten, dense_input], dim=1))\n"}