<link rel="stylesheet" href="../default.css">
<script src="../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        x = x.reshape(B, inputs.shape[2] // self.patch_size,
                      inputs.shape[3] // self.patch_size,
                      C).permute(0, 3, 1, 2)
        <a id="change">return </a>[x]

    def train(self, mode=True):
        super(VisionTransformer, self).train(mode)</code></pre><h3>After Change</h3><pre><code class='java'>
        return pos_embed

    def forward(self, inputs):
        B<a id="change"> = </a>inputs.shape[0]

        x = self.patch_embed(inputs)

        cls_tokens = <a id="change">self.cls_token.expand(</a>B, <a id="change">-1</a>, <a id="change">-1</a><a id="change">)</a>
        x<a id="change"> = </a>torch.cat((cls_tokens, x), dim=1)
        x = self._pos_embeding(inputs, x, self.pos_embed)

        if not self.with_cls_token:
            &#47&#47 Remove class token for transformer input
            x = x[:, 1:]

        outs = []
        for i, blk in enumerate(self.blocks):
            x = blk(x)
            if i == len(self.blocks) - 1:
                if self.final_norm:
                    x = self.norm(x)
            if i in self.out_indices:
                if self.with_cls_token:
                    &#47&#47 Remove class token and reshape token for decoder head
                    out = x[:, 1:]
                else:
                    out<a id="change"> = </a>x
                B, _, C = out.shape
                out = out.reshape(B, inputs.shape[2] // self.patch_size,
                                  inputs.shape[3] // self.patch_size,</code></pre>