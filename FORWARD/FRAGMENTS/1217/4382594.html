<link rel="stylesheet" href="../default.css">
<script src="../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        )

        if self.combining_operation == "mean":
            e = <a id="change">iid_embeddings.mean(dim=1)</a>
        elif self.combining_operation == "sum":
            e = iid_embeddings.sum(dim=1)
        else:
            raise ValueError("combining_operation must be in [&quotsum&quot, &quotmean&quot].")</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 otherwise we need to loop over the batch to account for varying trial lengths
        else:
            combined_embedding<a id="change"> = </a><a id="change">[]</a>
            trial_counts = torch.zeros(batch, 1)
            <a id="change">for </a>i in range(batch)<a id="change">:
                &#47&#47 remove NaNs
                </a>valid_x = x[i, ~torch.isnan(x[i, :, 0]), :]
                trial_counts[i]<a id="change"> = </a>valid_x.shape[0]
                trial_embeddings = self.trial_net(valid_x)
                &#47&#47 apply combining operation over permutation dimension
                <a id="change">combined_embedding.append(
                    </a>self.combining_function(trial_embeddings, dim=0)<a id="change">
                )</a>

            combined_embedding<a id="change"> = </a>torch.stack(combined_embedding, dim=0)

        assert not torch.isnan(combined_embedding).any(), "NaNs in embedding."
</code></pre>