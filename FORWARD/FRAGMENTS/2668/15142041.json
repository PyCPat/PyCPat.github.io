{"BEFORE":"            ids = rearrange(ids, 'b (s d) -> b s d', d = self.depth_seq_len)\n        else:\n            seq_len = ids.shape[1] * ids.shape[2]\n\n        # bump space by one to account for a boundary case\n\n        ids = F.pad(ids, (0, 0, 0, 1))\n\n        b, space, depth, device = *ids.shape, ids.device\n        assert space <= (self.max_spatial_seq_len + 1), 'spatial dimension is greater than the max_spatial_seq_len set'\n        assert depth == self.depth_seq_len, 'depth dimension must be equal to depth_seq_len'\n\n        # get token embeddings\n\n        tokens = self.token_emb(ids)\n\n        spatial_pos = self.spatial_pos_emb(torch.arange(space, device = device))\n        depth_pos = self.depth_pos_emb(torch.arange(depth, device = device))\n\n        tokens_with_depth_pos = tokens + depth_pos\n\n        # spatial tokens is tokens with depth pos reduced along depth dimension + spatial positions\n\n        spatial_tokens = reduce(tokens_with_depth_pos, 'b s d f -> b s f', 'sum') + spatial_pos\n\n        spatial_tokens = torch.cat((\n            repeat(self.spatial_start_token, 'f -> b 1 f', b = b),\n            spatial_tokens\n        ), dim = -2)\n\n        spatial_tokens = spatial_tokens[:, :-1]\n\n        spatial_tokens = self.spatial_transformer(spatial_tokens)\n\n        spatial_tokens = rearrange(spatial_tokens, 'b s f -> b s 1 f')\n\n        # spatial tokens become the start tokens of the depth dimension\n\n        depth_tokens = torch.cat((spatial_tokens, tokens_with_depth_pos), dim = -2)\n\n        depth_tokens = rearrange(depth_tokens, '... n d -> (...) n d')\n\n        depth_tokens = self.depth_transformer(depth_tokens)\n\n        depth_tokens = rearrange(depth_tokens, '(b s) d f -> b s d f', b = b)\n\n        logits = self.to_logits(depth_tokens)\n\n        if not return_loss:\n            logits = logits[..., :-1, :]\n\n            logits = rearrange(logits, 'b ... n -> b (...) n')\n\n            logits = logits[:, 1:(seq_len + 1)] # exclude first start token\n\n            if flattened_dim:\n                return logits\n\n            return rearrange(logits, 'b (s d) n -> b s d n', d = depth)\n\n        logits = logits[..., :-1, :]\n","AFTER":"        tokens_with_depth_pos = tokens + depth_pos\n\n        # spatial tokens is tokens with depth pos reduced along depth dimension + spatial positions\n\n        spatial_tokens = reduce(tokens_with_depth_pos, 'b s d f -> b s f', 'sum') + spatial_pos\n\n        spatial_tokens = torch.cat((\n            repeat(self.spatial_start_token, 'f -> b 1 f', b = b),\n            spatial_tokens\n        ), dim = -2)        \n\n        spatial_tokens = self.spatial_transformer(spatial_tokens)\n\n        spatial_tokens = rearrange(spatial_tokens, 'b s f -> b s 1 f')\n\n        # spatial tokens become the start tokens of the depth dimension\n\n        tokens_with_depth_pos = F.pad(tokens_with_depth_pos, (0, 0, 0, 0, 0, 1), value = 0.)\n\n        depth_tokens = torch.cat((spatial_tokens, tokens_with_depth_pos), dim = -2)\n\n        depth_tokens = rearrange(depth_tokens, '... n d -> (...) n d')\n\n        depth_tokens = self.depth_transformer(depth_tokens)\n\n        depth_tokens = rearrange(depth_tokens, '(b s) d f -> b s d f', b = b)\n\n        logits = self.to_logits(depth_tokens)\n        logits = rearrange(logits, 'b ... f -> b (...) f')\n        logits = logits[:, :(seq_len + 1)]\n\n        if not return_loss:\n            logits = logits[:, 1:]\n\n            if flattened_dim:\n                return rearrange(logits, 'b ... n -> b (...) n')\n\n            return logits\n\n        logits = logits[:, :-1]\n"}