{"BEFORE":"            NUM_NEGATIVES = 5\n\n            distance_matrix = pdist(embeddings, eps=0, dist_metric=self.dist_metric)\n\n            # Get tensor with unique labels (<= (batch_size * 2))\n            unique_labels, counts = torch.unique(labels, return_counts=True)\n\n            # Assert that there is no -1 (noise) label\n            assert(-1 not in unique_labels)\n\n            loss = torch.zeros(1).cuda()\n            anchor_pos_count = 0\n\n            for label in unique_labels:\n\n                # Get embeddings indices with current label\n                label_mask = labels == label\n                label_indices = torch.where(label_mask)[0]\n                if label_indices.shape[0] < 2:  # must have at least anchor and positive with same label\n                    continue\n\n                # Get embeddings indices without current label\n                negative_indices = torch.where(torch.logical_not(label_mask))[0] \n                if negative_indices.shape[0] == 0:  # must have at least one negative\n                    continue\n\n                pos_indices = label_indices\n\n                # Get combinations of possible anchor\/positive pairs\n                # TODO: If there's > 2 pos_indices, what if 2 embeddings are from the same video?\n                anchor_positives = list(combinations(pos_indices, 2))\n\n                # For each anchor\/positive pair, pick a negative and append triplet\n                for anchor_positive in anchor_positives:\n                    anchor_idx = anchor_positive[0]\n                    pos_idx = anchor_positive[1]\n\n                    # Compute anchor\/postive dist (dim: []) and anchor\/negative dists (dim: [negatives_indices.shape[0]])\n                    ap_dist = distance_matrix[anchor_idx, pos_idx]\n                    an_dists = distance_matrix[anchor_idx, negative_indices]\n\n                    # all random semi hard indices (or hardest easy if not enough semi hard)\n                    neg_list_idx = all_semi_hard(ap_dist, an_dists, self.margin)\n                    num_missing_negatives = NUM_NEGATIVES - neg_list_idx.shape[0]\n                    if num_missing_negatives > 0:\n                        hardest_easy_neg_idx = torch.topk(an_dists, NUM_NEGATIVES, largest=False)[1]\n                        added_negs = hardest_easy_neg_idx[neg_list_idx.shape[0]:NUM_NEGATIVES]\n                        neg_list_idx = torch.cat((neg_list_idx, added_negs), 0)\n\n                    # randomly pick NUM_NEGATIVES of the neg_list_idx\n                    neg_list_idx_val = random.sample(list(enumerate(neg_list_idx)), k=NUM_NEGATIVES)\n                    neg_list_idx = [idx for idx,val in neg_list_idx_val]\n\n                    # Get selected an_dists \n                    an_dists_selected = an_dists[neg_list_idx]\n\n                    # Use ap_dist and an_dists_selected to compute info nce loss\n\n                    temperature = 0.5\n                    # TODO: this only works for cosine dist\n                    ap_sim = (1 - ap_dist) \/ temperature\n                    an_sim = (1 - an_dists_selected) \/ temperature\n","AFTER":"            NUM_NEGATIVES = 5\n\n            distance_matrix = pdist(embeddings, eps=0, dist_metric=self.dist_metric)\n\n            # Get tensor with unique labels (<= (batch_size * 2))\n            unique_labels, counts = torch.unique(labels, return_counts=True)\n\n            # Assert that there is no -1 (noise) label\n            assert(-1 not in unique_labels)\n\n            loss = torch.zeros(1).cuda()\n            anchor_pos_count = 0\n\n            for label in unique_labels:\n\n                # Get embeddings indices with current label\n                label_mask = labels == label\n                label_indices = torch.where(label_mask)[0]\n                if label_indices.shape[0] < 2:  # must have at least anchor and positive with same label\n                    continue\n\n                # Get embeddings indices without current label\n                negative_indices = torch.where(torch.logical_not(label_mask))[0] \n                if negative_indices.shape[0] == 0:  # must have at least one negative\n                    continue\n\n                pos_indices = label_indices\n\n                # Get combinations of possible anchor\/positive pairs\n                # TODO: If there's > 2 pos_indices, what if 2 embeddings are from the same video?\n                anchor_positives = list(combinations(pos_indices, 2))\n\n                # For each anchor\/positive pair, pick a negative and append triplet\n                for anchor_positive in anchor_positives:\n                    anchor_idx = anchor_positive[0]\n                    pos_idx = anchor_positive[1]\n\n                    # Compute anchor\/postive dist (dim: []) and anchor\/negative dists (dim: [negatives_indices.shape[0]])\n                    ap_dist = distance_matrix[anchor_idx, pos_idx]\n                    an_dists = distance_matrix[anchor_idx, negative_indices]\n\n                    # all random semi hard indices (or hardest easy if not enough semi hard)\n                    neg_list_idx = all_semi_hard(ap_dist, an_dists, self.margin)\n                    if neg_list_idx is None:\n                        num_missing_negatives = NUM_NEGATIVES\n                        num_picked_negatives = 0\n                    else:\n                        num_picked_negatives = neg_list_idx.shape[0]\n                        num_missing_negatives = NUM_NEGATIVES - num_picked_negatives\n                    if num_missing_negatives > 0:\n                        hardest_easy_neg_idx = torch.topk(an_dists, NUM_NEGATIVES, largest=False)[1]\n                        added_negs = hardest_easy_neg_idx[num_picked_negatives:NUM_NEGATIVES]\n                        if neg_list_idx is not None:\n                            neg_list_idx = torch.cat((neg_list_idx, added_negs), 0)\n                        else:\n                            neg_list_idx = added_negs\n\n                    # randomly pick NUM_NEGATIVES of the neg_list_idx\n                    neg_list_idx_val = random.sample(list(enumerate(neg_list_idx)), k=NUM_NEGATIVES)\n                    neg_list_idx = [idx for idx,val in neg_list_idx_val]\n\n                    # Get selected an_dists \n                    an_dists_selected = an_dists[neg_list_idx]\n\n                    # Use ap_dist and an_dists_selected to compute info nce loss\n\n                    temperature = 0.5\n                    if self.dist_metric == 'cosine':\n                        ap_sim = torch.exp((1 - ap_dist) \/ temperature)\n                        an_sim = torch.exp((1 - an_dists_selected) \/ temperature)\n                    else:\n                        print('Euclidean dist not supported with infonce loss')\n                        assert(0)\n\n                    loss_info_nce = -torch.log(ap_sim \/ (torch.sum(an_sim) + ap_sim))\n"}