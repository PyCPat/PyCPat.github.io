{"BEFORE":"\t\tself.assign_adain_params(class_adain_params)\n\n\t\tx = self.fc_layers(content_code)\n\t\tx = x.reshape(-1, self.__adain_dim, self.__initial_height, self.__initial_width)\n\t\tx = self.adain_conv_layers(x)\n\t\tx = self.last_conv_layers(x)\n\n\t\treturn x\n","AFTER":"\t\th = self.shared(z)\n\t\tout = []\n\t\tfor layer in self.unshared:\n\t\t\tout += [layer(h)]\n\t\tout = torch.stack(out, dim=1)  # (batch, num_domains, style_dim)\n\t\tidx = torch.LongTensor(range(y.size(0))).to(y.device)\n\t\ts = out[idx, y]  # (batch, style_dim)\n\t\treturn s\n"}