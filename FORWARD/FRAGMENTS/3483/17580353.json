{"BEFORE":"        pass\n","AFTER":"        num_batches = encoded.shape[0]\n        num_series = encoded.shape[1]\n        num_timesteps = encoded.shape[2]\n\n        # Merge the series and time steps, since the PyTorch attention implementation only accept three-dimensional input,\n        # and the attention is applied between all tokens, no matter their series or time step.\n        encoded = encoded.view(num_batches, num_series * num_timesteps, self.embedding_dim)\n\n        # The PyTorch implementation wants the following order: [tokens, batch, embedding]\n        encoded = encoded.transpose(0, 1)\n\n        output = self.transformer_encoder(\n            encoded, mask=torch.zeros(encoded.shape[0], encoded.shape[0], device=encoded.device)\n        )\n\n        # Reset to the original shape\n        output = output.transpose(0, 1)\n        output = output.view(num_batches, num_series, num_timesteps, self.embedding_dim)\n\n        return output\n"}