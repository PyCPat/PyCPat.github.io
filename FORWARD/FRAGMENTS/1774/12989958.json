{"BEFORE":"        context = torch.bmm(align.unsqueeze(dim=1), value).squeeze(dim=1)\n        return context, align\n","AFTER":"        residual = query\n\n        # Initialize previous attention (alignment) to zeros\n        if prev_attn is None:\n            prev_attn = value.new_zeros(batch_size, seq_len)\n\n        conv_feat = torch.transpose(self.loc_conv(prev_attn.unsqueeze(1)), 1, 2)\n        score = self.score_projection(torch.tanh(\n                self.query_projection(query.reshape(-1, hidden_dim)).view(batch_size, -1, self.dim)\n                + self.value_projection(value.reshape(-1, hidden_dim)).view(batch_size, -1, self.dim)\n                + self.loc_projection(conv_feat)\n                + self.bias\n        )).squeeze(dim=-1)\n\n        if self.smoothing:\n            score = torch.sigmoid(score)\n            attn = torch.div(score, score.sum(dim=-1).unsqueeze(dim=-1))\n\n        else:\n            attn = F.softmax(score, dim=-1)\n\n        context = torch.bmm(attn.unsqueeze(dim=1), value).squeeze(dim=1)\n\n        # Get output\n        combined = torch.cat([context, residual], dim=2)\n        output = self.out_projection(combined.view(-1, self.hidden_dim << 1)).view(batch_size, -1, self.hidden_dim)\n        return output, attn\n"}