<link rel="stylesheet" href="../default.css">
<script src="../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        max_number_negative = (
            torch_mask_time_indices.sum(dim=-1).min() // self.negative_threshold
        )
        <a id="change">if </a>self.config.num_negatives &gt; max_number_negative<a id="change">:
            </a>dynamic_num_negatives = max_number_negative
        else:
            dynamic_num_negatives = torch.tensor(
                self.config.num_negatives,</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 Fairseq does it only on the masked indices, but this only work if you
        &#47&#47 have long sentences. For more versatily, we sample on the entire sequence.
        &#47&#47 value.
        full_sentence_indices = <a id="change">np.ones(</a>(batch_size<a id="change">, sequence_length</a>)<a id="change">)</a>

        &#47&#47 print(np.sum(mask_time_indices, axis=1))
        negative_sample_indices = torch.tensor(
            transformers.models.wav2vec2.modeling_wav2vec2._sample_negative_indices(</code></pre>