<link rel="stylesheet" href="../default.css">
<script src="../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        l1 = l1.mean((2,3))
        l2 = l2.mean((2,3))

        posterior1<a id="change"> = </a>torch.distributions.Categorical(logits=l1)
        posterior2 = torch.distributions.Categorical(logits=l2)

        prior1 = torch.distributions.Categorical(logits=torch.zeros_like(l1))
        prior2 = torch.distributions.Categorical(logits=torch.zeros_like(l2))

        reg = torch.distributions.kl_divergence(posterior1, prior1).mean()<a id="change"> + </a>torch.distributions.kl_divergence(posterior2, prior2).mean()

        <a id="change">return </a>ssimLoss<a id="change">, contextLoss, reg</a>


class CompressionLossQ(nn.Module):
    def __init__(self):</code></pre><h3>After Change</h3><pre><code class='java'>
        l1Loss = 0.0 &#47&#47 F.l1_loss(restored, images)
        ssimLoss = 1 - self._msssim(restored + 1, images + 1)
        &#47&#47 [N, K, M, H, W], [N, M, H, W]
        contextLoss<a id="change"> = </a>0.0 &#47&#47 F.cross_entropy(predict, c1)
        &#47&#47 [n, m, h, w, k] -&gt; [n, k, m, h, w]
        &#47&#47 l1, l2 = l1.permute(0, 4, 1, 2, 3), l2.permute(0, 4, 1, 2, 3)
        &#47&#47 [N, K, M, H, W], [N, M, H, W]
        &#47&#47 sum(-logP) / ()
        &#47&#47 bppLoss = (F.cross_entropy(l1, c1, reduction="mean") + F.cross_entropy(l2, c2, reduction="mean")) / math.log(2)

        &#47&#47 l1 = l1.mean((2,3))
        &#47&#47 l2 = l2.mean((2,3))
        regs = list()
        for l in allLogits:
            posterior = torch.distributions.Categorical(logits=l)
            prior = torch.distributions.Categorical(logits=torch.zeros_like(l))
            reg = torch.distributions.kl_divergence(posterior, prior).mean()
            regs.append(reg)

        <a id="change">return </a>ssimLoss<a id="change">, contextLoss, sum(regs)</a>


class CompressionLossQ(nn.Module):
    def __init__(self):</code></pre>