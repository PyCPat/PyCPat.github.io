{"BEFORE":"        a = torch.clamp_min(inp + self.m, min=0).detach()\n        src = torch.clamp_min(\n            - inp.gather(dim=1, index=label.unsqueeze(1)) + 1 + self.m,\n            min=0,\n        ).detach()\n        a.scatter_(dim=1, index=label.unsqueeze(1), src=src)\n\n        sigma = torch.ones_like(inp, device=inp.device, dtype=inp.dtype) * self.m\n        src = torch.ones_like(label.unsqueeze(1), dtype=inp.dtype, device=inp.device) - self.m\n        sigma.scatter_(dim=1, index=label.unsqueeze(1), src=src)\n\n        return self.loss(a * (inp - sigma) * self.gamma, label)\n","AFTER":"        ap = torch.clamp_min(- sp.detach() + 1 + self.m, min=0.)\n        an = torch.clamp_min(sn.detach() + self.m, min=0.)\n\n        delta_p = 1 - self.m\n        delta_n = self.m\n\n        logit_p = - ap * (sp - delta_p) * self.gamma\n        logit_n = an * (sn - delta_n) * self.gamma\n\n        loss = self.soft_plus(torch.logsumexp(logit_n, dim=0) + torch.logsumexp(logit_p, dim=0))\n\n        return loss\n"}