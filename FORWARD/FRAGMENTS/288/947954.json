{"BEFORE":"        nbatch = input.shape[0]\n        out = torch.zeros(nbatch,self.nconfs)\n                \n        for ic,(cup,cdown) in enumerate(zip(self.configs[0],self.configs[1])):\n\n            mo_up = input.index_select(1,self.index_up).index_select(2,cup)\n            mo_down = input.index_select(1,self.index_down).index_select(2,cdown)\n\n            # a batch version of det is on its way (end July 2019)\n            # https:\/\/github.com\/pytorch\/pytorch\/issues\/7500\n            # we'll move to that asap but in the mean time we loop\n            for isample in range(nbatch):\n                out[isample,ic] = (torch.det(mo_up[isample]) * torch.det(mo_down[isample]))\n\n        return out\n","AFTER":"        out = torch.zeros(nbatch,self.nconfs)\n                \n        for ic,(cup,cdown) in enumerate(zip(self.configs[0],self.configs[1])):\n\n            mo_up = input.index_select(1,self.index_up).index_select(2,cup)\n            mo_down = input.index_select(1,self.index_down).index_select(2,cdown)\n\n            # a batch version of det is on its way (end July 2019)\n            # https:\/\/github.com\/pytorch\/pytorch\/issues\/7500\n            # we'll move to that asap but in the mean time we loop\n            #for isample in range(nbatch):\n            #    out[isample,ic] = (torch.det(mo_up[isample]) * torch.det(mo_down[isample]))\n\n            # using my own BatchDeterminant\n            out[:,ic] = BatchDeterminant.apply(mo_up) * BatchDeterminant.apply(mo_down)\n"}