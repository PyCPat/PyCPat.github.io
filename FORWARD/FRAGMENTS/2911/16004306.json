{"BEFORE":"        return emb[None, :, :, :orig_ch].repeat(tensor.shape[0], 1, 1, 1)\n","AFTER":"        if self.cached_penc is not None and self.cached_penc.shape == tensor.shape:\n            return self.cached_penc\n\n        self.cached_penc = None\n        batch_size, x, y, orig_ch = tensor.shape\n        pos_x = torch.arange(x, device=tensor.device).type(self.inv_freq.type())\n        pos_y = torch.arange(y, device=tensor.device).type(self.inv_freq.type())\n        sin_inp_x = torch.einsum(\"i,j->ij\", pos_x, self.inv_freq)\n        sin_inp_y = torch.einsum(\"i,j->ij\", pos_y, self.inv_freq)\n        emb_x = torch.cat((sin_inp_x.sin(), sin_inp_x.cos()), dim=-1).unsqueeze(1)\n        emb_y = torch.cat((sin_inp_y.sin(), sin_inp_y.cos()), dim=-1)\n        emb = torch.zeros((x, y, self.channels * 2), device=tensor.device).type(\n            tensor.type()\n        )\n        emb[:, :, : self.channels] = emb_x\n        emb[:, :, self.channels : 2 * self.channels] = emb_y\n\n        self.cached_penc = emb[None, :, :, :orig_ch].repeat(tensor.shape[0], 1, 1, 1)\n        return self.cached_penc\n"}