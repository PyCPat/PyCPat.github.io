{"BEFORE":"        text_latents = self.encode_text(input)\n        image_latents = self.encode_image(image)\n        logit_scale = self.logit_scale.exp()\n\n        text_latents, image_latents = map(lambda t: F.normalize(t, p = 2, dim = -1), (text_latents, image_latents))\n        labels = torch.arange(input.size(0), device = image_latents.device)\n        sim_i_2_t = torch.matmul(torch.mul(logit_scale, image_latents), torch.t(text_latents))\n        sim_t_2_i = torch.matmul(torch.mul(logit_scale, text_latents), torch.t(image_latents))\n        \n        loss_t_2_i = F.cross_entropy(sim_t_2_i, labels)\n        loss_i_2_t = F.cross_entropy(sim_i_2_t, labels)\n        \n        return sim_i_2_t, sim_t_2_i, loss_i_2_t, loss_t_2_i\n","AFTER":"    def forward(self, image, input, return_loss=False):\n        text_latents = self.encode_text(input)\n        image_latents = self.encode_image(image)\n        logit_scale = self.logit_scale.exp()\n\n        text_latents, image_latents = map(lambda t: F.normalize(t, p = 2, dim = -1), (text_latents, image_latents))\n        sim_i_2_t = torch.matmul(torch.mul(logit_scale, image_latents), torch.t(text_latents))\n        sim_t_2_i = sim_i_2_t.t() #torch.matmul(torch.mul(logit_scale, text_latents), torch.t(image_latents))\n        \n        if return_loss:\n            assert image.size(0) == input.size(0), \"Not Support for unbalanced image-text pair\"\n            loss_t_2_i = F.cross_entropy(sim_t_2_i, torch.arange(input.size(0), device = image_latents.device))\n            loss_i_2_t = F.cross_entropy(sim_i_2_t, torch.arange(image.size(0), device = image_latents.device))\n            return sim_i_2_t, sim_t_2_i, loss_i_2_t, loss_t_2_i\n        else:\n            return sim_i_2_t, sim_t_2_i\n"}