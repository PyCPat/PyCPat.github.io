{"BEFORE":"        batch_size, embedded_dims, n_bins, n_frames = input.size()\n        batch_size, n_sources, n_bins, n_frames = target.size()\n\n        input = input.view(batch_size, embedded_dims, n_bins * n_frames)\n        target = target.view(batch_size, n_sources, n_bins * n_frames)\n        input_transposed = input.permute(0, 2, 1).contiguous() # (batch_size, n_bins * n_frames, embedded_dims)\n        target_transposed = target.permute(0, 2, 1).contiguous() # (batch_size, n_bins * n_frames, n_sources)\n\n        affinity_input = torch.bmm(input, input_transposed) # (batch_size, embedded_dims, embedded_dims)\n        affinity_target = torch.bmm(target, target_transposed) # (batch_size, n_sources, n_sources)\n        affinity_correlation = torch.bmm(input, target_transposed) # (batch_size, embedded_dims, n_sources)\n\n        loss_input = torch.sum(affinity_input**2, dim=(1,2))\n        loss_target = torch.sum(affinity_target**2, dim=(1,2))\n        loss_correlation = torch.sum(affinity_correlation**2, dim=(1,2))\n        loss = loss_input + loss_target - 2 * loss_correlation # (batch_size,)\n","AFTER":"        eps = self.eps\n        V, Y = input, target\n        trans_V, trans_Y = V.permute(0, 2, 1), Y.permute(0, 2, 1) # (batch_size, embed_dim1, n_samples), (batch_size, embed_dim2, n_samples)\n\n        YY = torch.bmm(Y, trans_Y) # (batch_size, n_samples, n_samples)\n        YY1 = YY.sum(dim=-1) # (batch_size, n_samples)\n        D = torch.diag_embed(1 \/ torch.sqrt(YY1 + eps)) # (batch_size, n_samples, n_samples)\n        VD, YD = torch.bmm(trans_V, D), torch.bmm(trans_Y, D) # (batch_size, embed_dim1, n_samples), (batch_size, embed_dim2, n_samples)\n        VDV, YDY = torch.bmm(VD, V), torch.bmm(YD, Y) # (batch_size, embed_dim1, embed_dim1), (batch_size, embed_dim2, embed_dim2)\n        VDY = torch.bmm(VD, Y) # (batch_size, embed_dim, embed_dim2)\n\n        loss = torch.sum(VDV**2, dim=(1, 2)) + torch.sum(YDY**2, dim=(1, 2)) - 2 * torch.sum(VDY**2, dim=(1, 2)) # (batch_size,)\n"}