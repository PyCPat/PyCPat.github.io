{"BEFORE":"            attn_bias = F.pad(attn_bias, (1, 0), value = 0.)\n","AFTER":"            null_attn_bias = repeat(self.null_attn_bias, 'h -> h n 1', n = n)\n            attn_bias = torch.cat((null_attn_bias, attn_bias), dim = -1)\n"}