<link rel="stylesheet" href="../default.css">
<script src="../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        enc_output: batch_size, max_length, dec_embed_dim
        hidden: n_layer, batch_size, hidden_size
        &quot&quot&quot
        <a id="change">assert </a>(hidden is not None) or self.use_attention, "No use of a decoder with No attention and No Hidden"

        batch_sz = x.shape[0]
</code></pre><h3>After Change</h3><pre><code class='java'>
        enc_output: batch_size, max_length, dec_embed_dim
        hidden: n_layer, batch_size, hidden_size | lstm: (h_n, c_n)
        &quot&quot&quot
        <a id="change">if </a>(hidden is None) and <a id="change">(self.use_attention is False)</a><a id="change">:
            </a>raise Exception( "No use of a decoder with No attention and No Hidden")

        batch_sz = x.shape[0]

        if hidden is None:
            &#47&#47 hidden: n_layers, batch_size, hidden_dim
            hid_for_att = torch.zeros((self.dec_layers, batch_sz,
                                    self.dec_hidden_dim )).to(self.device)
        elif <a id="change">self.dec_rnn_type == &quotlstm&quot</a><a id="change">:
            </a>hid_for_att<a id="change"> = </a>hidden[1] &#47&#47 c_n

        &#47&#47 x (batch_size, 1, dec_embed_dim) -&gt; after embedding
        x = self.embedding(x)</code></pre>