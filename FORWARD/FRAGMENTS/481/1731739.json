{"BEFORE":"        return emb[None, :, :, :, :orig_ch].repeat(batch_size, 1, 1, 1, 1)\n","AFTER":"        if self.cached_penc is not None and self.cached_penc.shape == tensor.shape:\n            return self.cached_penc\n\n        self.cached_penc = None\n        batch_size, x, y, z, orig_ch = tensor.shape\n        pos_x = torch.arange(x, device=tensor.device).type(self.inv_freq.type())\n        pos_y = torch.arange(y, device=tensor.device).type(self.inv_freq.type())\n        pos_z = torch.arange(z, device=tensor.device).type(self.inv_freq.type())\n        sin_inp_x = torch.einsum(\"i,j->ij\", pos_x, self.inv_freq)\n        sin_inp_y = torch.einsum(\"i,j->ij\", pos_y, self.inv_freq)\n        sin_inp_z = torch.einsum(\"i,j->ij\", pos_z, self.inv_freq)\n        emb_x = (\n            torch.cat((sin_inp_x.sin(), sin_inp_x.cos()), dim=-1)\n            .unsqueeze(1)\n            .unsqueeze(1)\n        )\n        emb_y = torch.cat((sin_inp_y.sin(), sin_inp_y.cos()), dim=-1).unsqueeze(1)\n        emb_z = torch.cat((sin_inp_z.sin(), sin_inp_z.cos()), dim=-1)\n        emb = torch.zeros((x, y, z, self.channels * 3), device=tensor.device).type(\n            tensor.type()\n        )\n        emb[:, :, :, : self.channels] = emb_x\n        emb[:, :, :, self.channels : 2 * self.channels] = emb_y\n        emb[:, :, :, 2 * self.channels :] = emb_z\n\n        self.cached_penc = emb[None, :, :, :, :orig_ch].repeat(batch_size, 1, 1, 1, 1)\n        return self.cached_penc\n"}