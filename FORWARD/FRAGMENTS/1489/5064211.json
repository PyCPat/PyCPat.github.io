{"BEFORE":"        batch_size, c_in, T, n_vertex = x.shape\r\n\r\n        # Using recurrence relation to reduce time complexity from O(n^2) to O(K|E|),\r\n        # where K = Ks - 1\r\n        x = x.reshape(n_vertex, -1)\r\n        x_0 = x\r\n        x_1 = torch.mm(self.chebconv_matrix, x)\r\n        if self.Ks - 1 < 0:\r\n            raise ValueError(f'ERROR: the graph convolution kernel size Ks has to be a positive integer, but received {self.Ks}.')  \r\n        elif self.Ks - 1 == 0:\r\n            x_list = [x_0]\r\n        elif self.Ks - 1 == 1:\r\n            x_list = [x_0, x_1]\r\n        elif self.Ks - 1 >= 2:\r\n            x_list = [x_0, x_1]\r\n            for k in range(2, self.Ks):\r\n                x_list.append(torch.mm(2 * self.chebconv_matrix, x_list[k - 1]) - x_list[k - 2])\r\n        x_tensor = torch.stack(x_list, dim=2)\r\n\r\n        x_mul = torch.mm(x_tensor.view(-1, self.Ks * c_in), self.weight.view(self.Ks * c_in, -1)).view(-1, self.c_out)\r\n\r\n        if self.bias is not None:\r\n            x_chebconv = x_mul + self.bias\r\n        else:\r\n            x_chebconv = x_mul\r\n        \r\n        return x_chebconv\r\n","AFTER":"        x = torch.permute(x, (0, 2, 3, 1))\r\n\r\n        if self.Ks - 1 < 0:\r\n            raise ValueError(f'ERROR: the graph convolution kernel size Ks has to be a positive integer, but received {self.Ks}.')  \r\n        elif self.Ks - 1 == 0:\r\n            x_0 = x\r\n            x_list = [x_0]\r\n        elif self.Ks - 1 == 1:\r\n            x_0 = x\r\n            x_1 = torch.einsum('hi,btij->bthj', self.gso, x)\r\n            x_list = [x_0, x_1]\r\n        elif self.Ks - 1 >= 2:\r\n            x_0 = x\r\n            x_1 = torch.einsum('hi,btij->bthj', self.gso, x)\r\n            x_list = [x_0, x_1]\r\n            for k in range(2, self.Ks):\r\n                x_list.append(torch.einsum('hi,btij->bthj', 2 * self.gso, x_list[k - 1]) - x_list[k - 2])\r\n        \r\n        x = torch.stack(x_list, dim=2)\r\n\r\n        cheb_graph_conv = torch.einsum('btkhi,kij->bthj', x, self.weight)\r\n\r\n        if self.bias is not None:\r\n            cheb_graph_conv = torch.add(cheb_graph_conv, self.bias)\r\n        else:\r\n            cheb_graph_conv = cheb_graph_conv\r\n        \r\n        return cheb_graph_conv\r\n"}