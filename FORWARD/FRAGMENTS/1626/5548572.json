{"BEFORE":"        return DeepSpeedMLPFunction.apply(input,\n                                          residual,\n                                          residual_norm,\n                                          bias,\n                                          self.inter_w,\n                                          self.inter_b,\n                                          self.attn_nw,\n                                          self.attn_nb,\n                                          self.config,\n                                          self.mp_group,\n                                          self.output_b,\n                                          self.output_w,\n                                          self.q_scales,\n                                          self.q_groups,\n                                          self.merge_count,\n                                          self.mlp_gemm_func,\n                                          self.fused_gemm_gelu,\n                                          self.vector_matmul_func,\n                                          self.bias_residual_func,\n                                          self.residual_add_func)\n","AFTER":"        residual_add = None\n        if self.attn_nw is None:\n            output = self.fused_gemm_gelu(input=residual_norm,\n                                          weight=self.inter_w,\n                                          bias=self.inter_b,\n                                          weight_out=self.output_w)\n        else:\n            output, residual_add = self.mlp_gemm_func(input=input,\n                                                      residual=residual,\n                                                      input_bias=bias,\n                                                      weight_interm=self.inter_w,\n                                                      weight_out=self.output_w,\n                                                      bias=self.inter_b,\n                                                      gamma=self.attn_nw,\n                                                      beta=self.attn_nb)\n        residual = self.residual_add_func(\n            hidden_state=output,\n            residual=residual,\n            attention_output=input,\n            attention_bias=bias if bias is not None else self.output_b,\n            final_bias=self.output_b,\n            add_bias=bias is not None,\n            residual_add=residual_add)\n\n        if self.mp_group is not None and dist.get_world_size(group=self.mp_group) > 1:\n            dist.all_reduce(residual, group=self.mp_group)\n\n        return residual\n"}