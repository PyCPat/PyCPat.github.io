{"BEFORE":"    def forward(self, input, demo):\n        batch_size = input.size(0)\n        time_step = input.size(1)\n        feature_dim = input.size(2)\n        assert feature_dim == self.n_input\n\n        self.agent1_action = []\n        self.agent1_prob = []\n        self.agent1_entropy = []\n        self.agent1_baseline = []\n        self.agent2_action = []\n        self.agent2_prob = []\n        self.agent2_entropy = []\n        self.agent2_baseline = []\n\n        cur_h = self.init_h(demo)\n        if self.cell == \"lstm\":\n            cur_c = self.init_c(demo)\n\n        for cur_time in range(time_step):\n            cur_input = input[:, cur_time, :]\n\n            if cur_time == 0:\n                obs_1 = cur_h\n                obs_2 = cur_input\n                obs_1 = torch.cat((obs_1, demo), dim=1)\n                obs_2 = torch.cat((obs_2, demo), dim=1)\n                self.choose_action(obs_1, 1).long()\n                self.choose_action(obs_2, 2).long()\n\n                observed_h = (\n                    torch.zeros_like(cur_h, dtype=torch.float32)\n                    .view(-1)\n                    .repeat(self.n_actions)\n                    .view(self.n_actions, batch_size, self.n_hidden)\n                )\n                action_h = cur_h\n                if self.cell == \"lstm\":\n                    observed_c = (\n                        torch.zeros_like(cur_c, dtype=torch.float32)\n                        .view(-1)\n                        .repeat(self.n_actions)\n                        .view(self.n_actions, batch_size, self.n_hidden)\n                    )\n                    action_c = cur_c\n\n            else:\n                observed_h = torch.cat((observed_h[1:], cur_h.unsqueeze(0)), 0)\n\n                obs_1 = observed_h.mean(dim=0)\n                obs_2 = cur_input\n                obs_1 = torch.cat((obs_1, demo), dim=1)\n                obs_2 = torch.cat((obs_2, demo), dim=1)\n                act_idx1 = self.choose_action(obs_1, 1).long()\n                act_idx2 = self.choose_action(obs_2, 2).long()\n                batch_idx = (\n                    torch.arange(batch_size, dtype=torch.long)\n                    .unsqueeze(-1)\n                    .to(self.device)\n                )\n                action_h1 = observed_h[act_idx1, batch_idx, :].squeeze(1)\n                action_h2 = observed_h[act_idx2, batch_idx, :].squeeze(1)\n                action_h = (action_h1 + action_h2) \/ 2\n                if self.cell == \"lstm\":\n                    observed_c = torch.cat((observed_c[1:], cur_c.unsqueeze(0)), 0)\n                    action_c1 = observed_c[act_idx1, batch_idx, :].squeeze(1)\n                    action_c2 = observed_c[act_idx2, batch_idx, :].squeeze(1)\n                    action_c = (action_c1 + action_c2) \/ 2\n\n            if self.cell == \"lstm\":\n                weighted_h = self.lamda * action_h + (1 - self.lamda) * cur_h\n                weighted_c = self.lamda * action_c + (1 - self.lamda) * cur_c\n                rnn_state = (weighted_h, weighted_c)\n                cur_h, cur_c = self.rnn(cur_input, rnn_state)\n            else:\n                weighted_h = self.lamda * action_h + (1 - self.lamda) * cur_h\n                cur_h = self.rnn(cur_input, weighted_h)\n\n        if self.dropout > 0.0:\n            cur_h = self.nn_dropout(cur_h)\n        cur_h = torch.cat((cur_h, demo), dim=1)\n        cur_h = self.fusion(cur_h)\n        cur_h = self.relu(cur_h)\n        output = self.output(cur_h)\n        output = self.sigmoid(output)\n\n        return output\n","AFTER":"        demo = x[:, :, : self.demo_dim]\n        labtest = x[:, :, self.demo_dim :]\n\n        batch_size = labtest.size(0)\n        time_step = labtest.size(1)\n        feature_dim = labtest.size(2)\n        assert feature_dim == self.lab_dim\n\n        self.agent1_action = []\n        self.agent1_prob = []\n        self.agent1_entropy = []\n        self.agent1_baseline = []\n        self.agent2_action = []\n        self.agent2_prob = []\n        self.agent2_entropy = []\n        self.agent2_baseline = []\n\n        cur_h = self.init_h(demo)\n        if self.cell == \"lstm\":\n            cur_c = self.init_c(demo)\n\n        for cur_time in range(time_step):\n            cur_input = labtest[:, cur_time, :]\n\n            if cur_time == 0:\n                obs_1 = cur_h\n                obs_2 = cur_input\n                obs_1 = torch.cat((obs_1, demo), dim=1)\n                obs_2 = torch.cat((obs_2, demo), dim=1)\n                self.choose_action(obs_1, 1).long()\n                self.choose_action(obs_2, 2).long()\n\n                observed_h = (\n                    torch.zeros_like(cur_h, dtype=torch.float32)\n                    .view(-1)\n                    .repeat(self.n_actions)\n                    .view(self.n_actions, batch_size, self.n_hidden)\n                )\n                action_h = cur_h\n                if self.cell == \"lstm\":\n                    observed_c = (\n                        torch.zeros_like(cur_c, dtype=torch.float32)\n                        .view(-1)\n                        .repeat(self.n_actions)\n                        .view(self.n_actions, batch_size, self.n_hidden)\n                    )\n                    action_c = cur_c\n\n            else:\n                observed_h = torch.cat((observed_h[1:], cur_h.unsqueeze(0)), 0)\n\n                obs_1 = observed_h.mean(dim=0)\n                obs_2 = cur_input\n                obs_1 = torch.cat((obs_1, demo), dim=1)\n                obs_2 = torch.cat((obs_2, demo), dim=1)\n                act_idx1 = self.choose_action(obs_1, 1).long()\n                act_idx2 = self.choose_action(obs_2, 2).long()\n                batch_idx = torch.arange(batch_size, dtype=torch.long).unsqueeze(-1)\n                action_h1 = observed_h[act_idx1, batch_idx, :].squeeze(1)\n                action_h2 = observed_h[act_idx2, batch_idx, :].squeeze(1)\n                action_h = (action_h1 + action_h2) \/ 2\n                if self.cell == \"lstm\":\n                    observed_c = torch.cat((observed_c[1:], cur_c.unsqueeze(0)), 0)\n                    action_c1 = observed_c[act_idx1, batch_idx, :].squeeze(1)\n                    action_c2 = observed_c[act_idx2, batch_idx, :].squeeze(1)\n                    action_c = (action_c1 + action_c2) \/ 2\n\n            if self.cell == \"lstm\":\n                weighted_h = self.lamda * action_h + (1 - self.lamda) * cur_h\n                weighted_c = self.lamda * action_c + (1 - self.lamda) * cur_c\n                rnn_state = (weighted_h, weighted_c)\n                cur_h, cur_c = self.rnn(cur_input, rnn_state)\n            else:\n                weighted_h = self.lamda * action_h + (1 - self.lamda) * cur_h\n                cur_h = self.rnn(cur_input, weighted_h)\n\n        if self.dropout > 0.0:\n            cur_h = self.nn_dropout(cur_h)\n        cur_h = torch.cat((cur_h, demo), dim=1)\n        cur_h = self.fusion(cur_h)\n        cur_h = self.relu(cur_h)\n        # output = self.output(cur_h)\n        # output = self.sigmoid(output)\n\n        return cur_h\n"}