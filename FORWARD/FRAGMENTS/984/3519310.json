{"BEFORE":"            feat = self._cached_h\r\n        else:\r\n            assert edge_weight is None or edge_weight.size(0) == graph.num_edges()\r\n\r\n            if self._add_self_loop:\r\n                graph = graph.add_self_loop()\r\n                if edge_weight is not None:\r\n                    size = (graph.num_nodes(),) + edge_weight.size()[1:]\r\n                    self_loop = edge_weight.new_ones(size)\r\n                    edge_weight = torch.cat([edge_weight, self_loop])\r\n            else:\r\n                graph = graph.local_var()\r\n\r\n            edge_weight = dgl_normalize(graph, self._norm, edge_weight)\r\n            graph.edata['_edge_weight'] = edge_weight\r\n\r\n            for _ in range(self._k):\r\n                graph.ndata['h'] = feat\r\n                graph.update_all(fn.u_mul_e('h', '_edge_weight', 'm'),\r\n                                 fn.sum('m', 'h'))\r\n                feat = graph.ndata.pop('h')\r\n\r\n            # cache feature\r\n            if self._cached:\r\n                self._cached_h = feat\r\n\r\n        return self.linear(feat)\r\n","AFTER":"            feat = self._cached_h\r\n        else:\r\n            assert edge_weight is None or edge_weight.size(0) == graph.num_edges()\r\n\r\n            if self._add_self_loop:\r\n                graph = graph.add_self_loop()\r\n                if edge_weight is not None:\r\n                    size = (graph.num_nodes(),) + edge_weight.size()[1:]\r\n                    self_loop = edge_weight.new_ones(size)\r\n                    edge_weight = torch.cat([edge_weight, self_loop])\r\n            else:\r\n                graph = graph.local_var()\r\n\r\n            edge_weight = dgl_normalize(graph, self._norm, edge_weight)\r\n            graph.edata['_edge_weight'] = edge_weight\r\n\r\n            for _ in range(self._k):\r\n                graph.ndata['h'] = feat\r\n                graph.update_all(fn.u_mul_e('h', '_edge_weight', 'm'),\r\n                                 fn.sum('m', 'h'))\r\n                feat = graph.ndata.pop('h')\r\n\r\n            # cache feature\r\n            if self._cached:\r\n                self._cached_h = feat\r\n\r\n        if self.weight is not None:\r\n            feat = feat @ self.weight\r\n\r\n        if self.bias is not None:\r\n            feat = feat + self.bias\r\n\r\n        return feat\r\n"}