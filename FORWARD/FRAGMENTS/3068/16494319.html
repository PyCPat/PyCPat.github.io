<link rel="stylesheet" href="../default.css">
<script src="../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 Apply feature randomization for each repetition
        x = self._randomize(x)

        log_p<a id="change"> = </a>self.leaf(x)

        &#47&#47 Forward through all layers, bottom up
        for layer in self.layers:
            log_p<a id="change"> = </a>layer(log_p)

        &#47&#47 Root layer merges all scopes that are left
        log_p = self.prod(log_p)

        &#47&#47 Shift repetition dimension to build sum over repetitions
        log_p = <a id="change">log_p.permute(0</a>, <a id="change">1</a>, <a id="change">3</a>, <a id="change">2</a><a id="change">)</a>
        log_p = self.root(log_p)
        log_p<a id="change"> = </a><a id="change">log_p.view(</a>x.shape[0]<a id="change">)</a>

        <a id="change">return </a>log_p

    def sample(self, n: int) -&gt; torch.Tensor:
        Sample from the Einet model.</code></pre><h3>After Change</h3><pre><code class='java'>
        batch_size, features, channels, repetitions = x.size()
        assert features == 1  &#47&#47 number of features should be 1 at this point
        assert channels == 1  &#47&#47 number of channels should be 1 at this point
        x = <a id="change">x.view(</a>batch_size, <a id="change">1</a>, repetitions, 1<a id="change">)</a>

        &#47&#47 Apply C sum node outputs
        x = self.root(x)

        &#47&#47 Remove repetition dimension
        x = x.squeeze(3)

        &#47&#47 Remove in_features dimension
        x = x.squeeze(1)

        <a id="change">return </a>x

    def _forward_layers(self, x):
        </code></pre>