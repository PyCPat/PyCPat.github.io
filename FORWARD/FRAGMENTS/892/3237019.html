<link rel="stylesheet" href="../default.css">
<script src="../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        
        &#47&#47 TODO: loop if window_size is greater than 2 (for cycle loss)
        bsz, encoder_dim, n_points = keypoint_desc.size()
        batch_size<a id="change"> = </a>int(bsz / self.window_size)
        _, _, height, width = desc_dense.size()

        src_desc = keypoint_desc[::self.window_size]  &#47&#47 B x C x N
        src_desc = F.normalize(src_desc, dim=1)

        tgt_desc_dense = desc_dense[1::self.window_size]  &#47&#47 B x C x H x W
        tgt_desc_unrolled = F.normalize(tgt_desc_dense.view(batch_size, encoder_dim, -1), dim=1)  &#47&#47 B x C x HW

        match_vals = torch.matmul(src_desc.transpose(2, 1), tgt_desc_unrolled)  &#47&#47 B x N x HW
        soft_match_vals = F.softmax(match_vals / self.softmax_temp, dim=2)  &#47&#47 B x N x HW

        v_coord, u_coord = torch.meshgrid([torch.arange(0, height), torch.arange(0, width)])
        v_coord = v_coord.reshape(height * width).float()  &#47&#47 HW
        u_coord = u_coord.reshape(height * width).float()
        coords = torch.stack((u_coord, v_coord), dim=1)  &#47&#47 HW x 2
        tgt_coords_dense = coords.unsqueeze(0).expand(batch_size, height * width, 2).to(self.gpuid)  &#47&#47 B x HW x 2

        pseudo_coords = torch.matmul(tgt_coords_dense.transpose(2, 1),
                                     soft_match_vals.transpose(2, 1)).transpose(2, 1)  &#47&#47 BxNx2

        &#47&#47 GET SCORES for pseudo point locations
        pseudo_norm = normalize_coords(pseudo_coords, height, width).unsqueeze(1)          &#47&#47 B x 1 x N x 2
        tgt_scores_dense = scores_dense[1::self.window_size]
        pseudo_scores = F.grid_sample(tgt_scores_dense, pseudo_norm, mode=&quotbilinear&quot)           &#47&#47 B x 1 x 1 x N
        pseudo_scores = pseudo_scores.reshape(batch_size, 1, n_points)                          &#47&#47 B x 1 x N
        &#47&#47 GET DESCRIPTORS for pseudo point locations
        pseudo_desc = F.grid_sample(tgt_desc_dense, pseudo_norm, mode=&quotbilinear&quot)               &#47&#47 B x C x 1 x N
        pseudo_desc = pseudo_desc.reshape(batch_size, encoder_dim, n_points)                    &#47&#47 B x C x N

        desc_match_score = torch.sum(src_desc * pseudo_desc, dim=1, keepdim=True) / float(encoder_dim)  &#47&#47 Bx1xN
        src_scores = keypoint_scores[::self.window_size]
        if self.score_comp:
            match_weights = 0.5 * (desc_match_score + 1) * src_scores * pseudo_scores
        else:
            match_weights = pseudo_scores

        <a id="change">return </a>pseudo_coords<a id="change">, match_weights</a>

def normalize_coords(coords_2D, width, height):
    Normalizes coords_2D (B x N x 2) to be within [-1, 1] 
    batch_size = coords_2D.size(0)</code></pre><h3>After Change</h3><pre><code class='java'>

        src_desc = keypoint_desc[kp_inds]  &#47&#47 B x C x N
        src_desc = F.normalize(src_desc, dim=1)
        B<a id="change"> = </a><a id="change">src_desc.size(0</a><a id="change">)</a>

        tgt_desc_dense<a id="change"> = </a>desc_dense[dense_inds]  &#47&#47 B x C x H x W
        tgt_desc_unrolled = F.normalize(tgt_desc_dense.view(B, encoder_dim, -1), dim=1)  &#47&#47 B x C x HW

        match_vals = torch.matmul(src_desc.transpose(2, 1), tgt_desc_unrolled)  &#47&#47 B x N x HW
        soft_match_vals = F.softmax(match_vals / self.softmax_temp, dim=2)  &#47&#47 B x N x HW

        v_coord, u_coord = torch.meshgrid([torch.arange(0, height), torch.arange(0, width)])
        v_coord = v_coord.reshape(height * width).float()  &#47&#47 HW
        u_coord = u_coord.reshape(height * width).float()
        coords = torch.stack((u_coord, v_coord), dim=1)  &#47&#47 HW x 2
        tgt_coords_dense = coords.unsqueeze(0).expand(B, height * width, 2).to(self.gpuid)  &#47&#47 B x HW x 2

        pseudo_coords = torch.matmul(tgt_coords_dense.transpose(2, 1),
                                     soft_match_vals.transpose(2, 1)).transpose(2, 1)  &#47&#47 BxNx2

        &#47&#47 GET SCORES for pseudo point locations
        pseudo_norm = normalize_coords(pseudo_coords, height, width).unsqueeze(1)          &#47&#47 B x 1 x N x 2
        tgt_scores_dense = scores_dense[dense_inds]
        pseudo_scores = F.grid_sample(tgt_scores_dense, pseudo_norm, mode=&quotbilinear&quot)           &#47&#47 B x 1 x 1 x N
        pseudo_scores = pseudo_scores.reshape(B, 1, n_points)                          &#47&#47 B x 1 x N
        &#47&#47 GET DESCRIPTORS for pseudo point locations
        pseudo_desc = F.grid_sample(tgt_desc_dense, pseudo_norm, mode=&quotbilinear&quot)               &#47&#47 B x C x 1 x N
        pseudo_desc = pseudo_desc.reshape(B, encoder_dim, n_points)                    &#47&#47 B x C x N

        desc_match_score = torch.sum(src_desc * pseudo_desc, dim=1, keepdim=True) / float(encoder_dim)  &#47&#47 Bx1xN
        src_scores = keypoint_scores[kp_inds]
        if self.score_comp:
            match_weights = 0.5 * (desc_match_score + 1) * src_scores * pseudo_scores
        else:
            match_weights = pseudo_scores

        <a id="change">return </a>pseudo_coords<a id="change">, match_weights, kp_inds</a>

def normalize_coords(coords_2D, width, height):
    Normalizes coords_2D (B x N x 2) to be within [-1, 1] 
    batch_size = coords_2D.size(0)</code></pre>