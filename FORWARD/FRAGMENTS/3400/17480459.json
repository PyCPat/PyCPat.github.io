{"BEFORE":"        input = input.permute(0, 2, 3, 1) # [B x D x H x W] -> [B x H x W x D]\n        input_shape = input.shape\n        flat_input = input.contiguous().view(-1, self.D)    # [BHW x D]\n\n        # Compute L2 distance between input and embedding weights\n        dist = torch.sum(flat_input**2, dim = 1, keepdim=True) + \\\n               torch.sum(self.embedding.weight ** 2, dim = 1) - \\\n               2 * torch.matmul(flat_input, self.embedding.weight.t()) # [BHW x K]\n\n        # Get the encoding that has the min distance\n        encoding_inds = torch.argmin(dist, dim = 1).view(-1, 1) # [BHW, 1]\n\n        # Convert to one-hot encodings\n        device = input.device\n        encoding_one_hot = torch.zeros(encoding_inds.size(0), self.K, device=device)\n        encoding_one_hot.scatter_(1, encoding_inds, 1.) # [BHW x K]\n\n        # Quantize the input\n        quantized_input = torch.matmul(encoding_one_hot, self.embedding.weight) # [BHW, D]\n        quantized_input = quantized_input.view(input_shape) # [B x H x W x D]\n\n        return quantized_input.permute(0, 3, 1, 2) # [B x D x H x W]\n","AFTER":"        latents = latents.permute(0, 2, 3, 1).contiguous()  # [B x D x H x W] -> [B x H x W x D]\n        latents_shape = latents.shape\n        flat_latents = latents.view(-1, self.D)  # [BHW x D]\n\n        # Compute L2 distance between latents and embedding weights\n        dist = torch.sum(flat_latents ** 2, dim=1, keepdim=True) + \\\n               torch.sum(self.embedding.weight ** 2, dim=1) - \\\n               2 * torch.matmul(flat_latents, self.embedding.weight.t())  # [BHW x K]\n\n        # Get the encoding that has the min distance\n        encoding_inds = torch.argmin(dist, dim=1).unsqueeze(1)  # [BHW, 1]\n\n        # Convert to one-hot encodings\n        device = latents.device\n        encoding_one_hot = torch.zeros(encoding_inds.size(0), self.K, device=device)\n        encoding_one_hot.scatter_(1, encoding_inds, 1)  # [BHW x K]\n\n        # Quantize the latents\n        quantized_latents = torch.matmul(encoding_one_hot, self.embedding.weight)  # [BHW, D]\n        quantized_latents = quantized_latents.view(latents_shape)  # [B x H x W x D]\n\n        # Compute the VQ Losses\n        commitment_loss = F.mse_loss(quantized_latents.detach(), latents)\n        embedding_loss = F.mse_loss(quantized_latents, latents.detach())\n\n        vq_loss = commitment_loss * self.beta + embedding_loss\n\n        # Add the residue back to the latents\n        quantized_latents = latents + (quantized_latents - latents).detach()\n\n        return quantized_latents.permute(0, 3, 1, 2).contiguous(), vq_loss  # [B x D x H x W]\n"}