{"BEFORE":"        batch_size = V.size(0)\n        q_len = Q.size(1)\n        v_len = V.size(1)\n\n        residual = Q\n        U = torch.transpose(self.conv(last_align.unsqueeze(1)), 1, 2)\n\n        q_s = self.W_Q(Q).view(batch_size, q_len, self.num_heads * self.dim)\n        v_s = self.W_V(V).view(batch_size, v_len, self.num_heads * self.dim) + self.W_U(U) + self.bias\n\n        q_s = q_s.view(batch_size, q_len, self.num_heads, self.dim).permute(2, 0, 1, 3)\n        v_s = v_s.view(batch_size, v_len, self.num_heads, self.dim).permute(2, 0, 1, 3)\n\n        q_s = q_s.contiguous().view(-1, q_len, self.dim)  # (batch_size * num_heads, q_len, dim)\n        v_s = v_s.contiguous().view(-1, v_len, self.dim)  # (batch_size * num_heads, v_len, dim)\n\n        score = torch.bmm(q_s, v_s.transpose(1, 2)) \/ np.sqrt(self.dim)  # scaled dot-product\n\n        if self.smoothing:\n            score = torch.sigmoid(score)\n            align = torch.div(score, score.sum(dim=-1).unsqueeze(dim=-1))\n\n        else:\n            align = self.softmax(score)\n\n        context = torch.bmm(align, v_s).view(self.num_heads, batch_size, q_len, self.dim)\n        context = context.permute(1, 2, 0, 3).contiguous().view(batch_size, q_len, -1)\n\n        combined = torch.cat([context, residual], dim=2)\n        output = torch.tanh(self.fc(combined.view(-1, self.in_features << 1))).view(batch_size, -1, self.in_features)\n\n        return output, align.squeeze()\n","AFTER":"        batch_size = V.size(0)\n        q_len = Q.size(1)\n        v_len = V.size(1)\n\n        residual = Q\n\n        loc_energy = self.get_loc_energy(prev_align, batch_size, v_len)\n\n        q_s = self.W_Q(Q).view(batch_size, q_len, self.num_heads * self.dim)\n        v_s = self.W_V(V).view(batch_size, v_len, self.num_heads * self.dim) + loc_energy\n\n        q_s = q_s.view(batch_size, q_len, self.num_heads, self.dim).permute(2, 0, 1, 3)\n        v_s = v_s.view(batch_size, v_len, self.num_heads, self.dim).permute(2, 0, 1, 3)\n\n        q_s = q_s.contiguous().view(-1, q_len, self.dim)  # (batch_size * num_heads, q_len, dim)\n        v_s = v_s.contiguous().view(-1, v_len, self.dim)  # (batch_size * num_heads, v_len, dim)\n\n        context, align = self.scaled_dot(q_s, v_s)\n        context = context.view(self.num_heads, batch_size, q_len, self.dim)\n\n        context = context.permute(1, 2, 0, 3).contiguous().view(batch_size, q_len, -1)\n        align = align.squeeze()\n\n        combined = torch.cat([context, residual], dim=2)\n        output = self.norm(self.fc(combined.view(-1, self.in_features << 1))).view(batch_size, -1, self.in_features)\n\n        return output, align\n"}