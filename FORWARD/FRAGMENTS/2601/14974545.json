{"BEFORE":"        out, (hidden, cell) = self.lstm(packed_embedded)\n        \n        # hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n        # output = self.fc1(hidden)\n        # output = self.dropout(self.fc2(output))\n                \n        #hidden = [batch size, hid dim * num directions]\n\n        # # Each sequence \"x\" is passed through an embedding layer\n        # out = self.embedding(x)\n\n        # Feed LSTMs\n        # out, (hidden, cell) = self.lstm(out)\n        out = self.dropout(out)\n\n        # The last hidden state is taken\n        out = torch.relu_(self.fc1(out[:,-1,:]))\n        out = self.dropout(out)\n        out = torch.sigmoid(self.fc2(out))\n","AFTER":"        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n\n        #unpack sequence\n        out, out_lengths = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n\n        out = torch.relu_(out[:,-1,:])\n"}