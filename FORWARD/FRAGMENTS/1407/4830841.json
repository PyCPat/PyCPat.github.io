{"BEFORE":"        blocks = [\n            partial(\n                b,\n                msa_mask=msa_mask,\n                pair_mask=pair_mask,\n                chunk_size=chunk_size,\n                use_lma=use_lma,\n                _mask_trans=_mask_trans,\n            )\n            for b in self.blocks\n        ]\n\n        if(self.clear_cache_between_blocks):\n            def block_with_cache_clear(block, *args, **kwargs):\n                torch.cuda.empty_cache()\n                return block(*args, **kwargs)\n\n            blocks = [partial(block_with_cache_clear, b) for b in blocks]\n\n        if(chunk_size is not None and self.chunk_size_tuner is not None):\n            tuned_chunk_size = self.chunk_size_tuner.tune_chunk_size(\n                representative_fn=blocks[0],\n                args=(m,z),\n                min_chunk_size=chunk_size,\n            )\n            blocks = [\n                partial(b, \n                    chunk_size=tuned_chunk_size,\n                    # A temporary measure to address torch's occasional\n                    # inability to allocate large tensors\n                    _attn_chunk_size=max(chunk_size, tuned_chunk_size \/\/ 4),\n                ) for b in blocks\n            ]\n\n        blocks_per_ckpt = self.blocks_per_ckpt\n        if(not torch.is_grad_enabled()):\n            blocks_per_ckpt = None\n\n        m, z = checkpoint_blocks(\n            blocks,\n            args=(m, z),\n            blocks_per_ckpt=blocks_per_ckpt,\n        )\n\n        s = self.linear(m[..., 0, :, :])\n        \n        return m, z, s\n","AFTER":"        return self._forward_list(\n            [m, z],\n            msa_mask=msa_mask,\n            pair_mask=pair_mask,\n            chunk_size=chunk_size,\n            use_lma=use_lma,\n            _mask_trans=_mask_trans,\n        )\n"}