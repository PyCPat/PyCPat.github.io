{"BEFORE":"        pred = outputs[\"outputs\"]\n        target = move_to(batch[\"targets\"], device)\n\n        if self.weight is not None:\n            self.weight = move_to(self.weight, device)\n\n        if self.ignore_index is not None:\n            target = torch.argmax(target, dim=1)\n            loss = nn.functional.cross_entropy(pred, target, weight=self.weight, ignore_index=self.ignore_index)\n        else:\n            loss = nn.functional.cross_entropy(pred, target, weight=self.weight)\n            \n        loss_dict = {\"CE\": loss.item()}\n","AFTER":"        pred = outputs[\"outputs\"]\n        targets = move_to(batch[\"targets\"], device)\n        \n        batch_size, num_classes = pred.shape[:2]\n        y_hot = move_to(torch.zeros(pred.shape), device).scatter_(1, targets.unsqueeze(1) , 1.0)\n        y_smooth = (1 - self.alpha) * y_hot + self.alpha \/ num_classes\n        loss = torch.sum(- y_smooth * torch.nn.functional.log_softmax(pred, -1), -1).sum()\n\n        if self.reduction == \"mean\":\n            loss \/= batch_size\n\n        loss_dict = {\"CE\": loss.item()}\n"}