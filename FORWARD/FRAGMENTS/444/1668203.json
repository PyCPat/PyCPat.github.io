{"BEFORE":"            node_encodings = box_features[counter: counter+n]\n            # Duplicate human nodes\n            h_node_encodings = node_encodings[:n_h]\n            # Get the pairwise index between every human and object instance\n            x, y = torch.meshgrid(\n                torch.arange(n_h, device=device),\n                torch.arange(n, device=device)\n            )\n            # Remove pairs consisting of the same human instance\n            x_keep, y_keep = torch.nonzero(x != y).unbind(1)\n            if len(x_keep) == 0:\n                # Should never happen, just to be safe\n                continue\n\n            # Compute spatial encoding and edge features\n            spatial_encodings = self.get_spatial_encoding(x_keep, y_keep, coords)\n            edge_features = self.spatial_head(spatial_encodings)\n            # Run bipartite graph\n            h_node_encodings, node_encodings, adjacency_matrix = self.bipartite_graph(\n                h_node_encodings, node_encodings\n            )\n","AFTER":"            n = num_boxes[b_idx]\n            device = box_features.device\n\n            n_h = torch.sum(labels == self.human_idx).item()\n            # Skip image when there are no detected human or object instances\n            # and when there is only one detected instance\n            if n_h == 0 or n <= 1:\n                continue\n            if not torch.all(labels[:n_h]==self.human_idx):\n                raise AssertionError(\"Human detections are not permuted to the top\")\n\n            node_encodings = box_features[counter: counter+n]\n            # Duplicate human nodes\n            h_node_encodings = node_encodings[:n_h]\n            # Get the pairwise index between every human and object instance\n            x, y = torch.meshgrid(\n                torch.arange(n_h, device=device),\n                torch.arange(n, device=device)\n            )\n            # Remove pairs consisting of the same human instance\n            x_keep, y_keep = torch.nonzero(x != y).unbind(1)\n            if len(x_keep) == 0:\n                # Should never happen, just to be safe\n                continue\n            # Human nodes have been duplicated and will be treated independently\n            # of the humans included amongst object nodes\n            x = x.flatten(); y = y.flatten()\n\n            # Compute spatial encoding and edge features\n            spatial_encodings = self.get_spatial_encoding(x_keep, y_keep, coords)\n            edge_features = self.spatial_head(spatial_encodings)\n\n            adjacency_matrix = torch.ones(n_h, n, device=device)\n            for i in range(self.num_iter):\n                # Compute weights of each edge\n                weights = self.adjacency(torch.cat([\n                    h_node_encodings[x],\n                    node_encodings[y]\n                ], 1))\n                adjacency_matrix = weights.reshape(n_h, n)\n\n                # Update human nodes\n                h_node_encodings = self.sub_update(torch.cat([\n                    h_node_encodings,\n                    torch.mm(adjacency_matrix, self.obj_to_sub(node_encodings))\n                ], 1))\n\n                # Update object nodes (including human nodes)\n                node_encodings = self.obj_update(torch.cat([\n                    node_encodings,\n                    torch.mm(adjacency_matrix.t(), self.sub_to_obj(h_node_encodings))\n                ], 1))\n\n            if targets is not None:\n"}