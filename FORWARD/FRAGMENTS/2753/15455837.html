<link rel="stylesheet" href="../default.css">
<script src="../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 masked by the missing entries
        &#47&#47 note, different batch may contain different number of real entities
        tensor_list = <a id="change">[]</a>
        for i, batch in enumerate(out):
            mean_entity = 0.
            real_number = real_number_tensor[i]
            real_number = real_number if real_number != 0 else 1
            for j, entity in enumerate(batch):
                if j &gt;= real_number_tensor[i]:
                    break        
                mean_entity = mean_entity + entity
            mean_entity = mean_entity / (real_number)
            tensor_list.append(mean_entity.reshape(1, -1))
        tensor_mean<a id="change"> = </a><a id="change">torch.cat(</a>tensor_list<a id="change">, dim=0)</a>
        print(&quottensor_mean:&quot, tensor_mean) if debug else None

        &#47&#47 print(&quotout.shape:&quot, out.shape) if debug else None</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 AlphaStar: The mean of the transformer output across across the units (masked by the missing entries) 
        &#47&#47 is fed through a linear layer of size 256 and a ReLU to yield `embedded_entity`
        masked_out = out * <a id="change">mask.unsqueeze(2</a><a id="change">)</a>

        &#47&#47 sum over across the units
        &#47&#47 masked_out: [batch_seq_size x entities_size x embeding_size]</code></pre>