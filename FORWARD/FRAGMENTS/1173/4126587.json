{"BEFORE":"    def forward(self, input, return_only_mlm_loss = False):\n        b, t = input.shape\n\n        # do not mask [pad] tokens, or any other tokens in the tokens designated to be excluded ([cls], [sep])\n        # also do not include these special tokens in the tokens chosen at random\n        no_mask = mask_with_tokens(input, self.mask_ignore_token_ids)\n        mask = get_mask_subset_with_prob(~no_mask, self.mask_prob)\n\n        # get mask indices\n        mask_indices = torch.nonzero(mask, as_tuple=True)\n\n        # mask input with mask tokens with probability of `replace_prob` (keep tokens the same with probability 1 - replace_prob)\n        masked_input = input.clone().detach()\n\n        # if random token probability > 0 for mlm\n        if self.random_token_prob > 0:\n            random_token_prob = prob_mask_like(input, self.random_token_prob)\n            random_tokens = torch.randint(0, self.num_tokens, input.shape, device=input.device)\n            random_no_mask = mask_with_tokens(random_tokens, self.mask_ignore_token_ids)\n            random_token_prob &= ~random_no_mask\n            random_indices = torch.nonzero(random_token_prob, as_tuple=True)\n            masked_input[random_indices] = random_tokens[random_indices]\n\n        # [mask] input\n        replace_prob = prob_mask_like(input, self.replace_prob)\n        masked_input = masked_input.masked_fill(mask * replace_prob, self.mask_token_id)\n\n        # set inverse of mask to padding tokens for labels\n        gen_labels = input.masked_fill(~mask, self.pad_token_id)\n\n        # get generator output and get mlm loss\n        logits = self.generator(masked_input)\n\n        mlm_loss = F.cross_entropy(\n            logits.transpose(1, 2),\n            gen_labels,\n            ignore_index = self.pad_token_id\n        )\n\n        # return only mlm loss if flag set to true\n        if return_only_mlm_loss:\n            return mlm_loss\n\n        # use mask from before to select logits that need sampling\n        sample_logits = logits[mask_indices]\n\n        # sample\n        sampled = gumbel_sample(sample_logits, temperature = self.temperature)\n\n        # scatter the sampled values back to the input\n        disc_input = input.clone()\n        disc_input[mask_indices] = sampled.detach()\n\n        # generate discriminator labels, with replaced as True and original as False\n        disc_labels = (input != disc_input).float().detach()\n\n        # get discriminator predictions of replaced \/ original\n        non_padded_indices = torch.nonzero(input != self.pad_token_id, as_tuple=True)\n\n        disc_logits = self.discriminator(disc_input)\n        disc_probs = disc_logits.sigmoid().squeeze(-1)\n","AFTER":"        disc_logits = self.discriminator(disc_input)\n        disc_probs = disc_logits.squeeze(-1)\n"}