<link rel="stylesheet" href="../default.css">
<script src="../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        return loss

    def forward(self, image, text = None):
        b, device, img_size, = <a id="change">image.shape[0]</a>, image.device, self.image_size
        check_shape(image, &quotb c h w&quot, h = img_size, w = img_size, c = self.channels)

        times = torch.randint(0, self.num_timesteps, (b,), device = device, dtype = torch.long)</code></pre><h3>After Change</h3><pre><code class='java'>

    def forward(self, image, text = None, unet_number = None):
        assert not (len(self.unets) &gt; 1 and not exists(unet_number)), f&quotyou must specify which unet you want trained, from a range of 1 to {len(self.unets)}, if you are training cascading DDPM (multiple unets)&quot
        unet_number = <a id="change">default(</a>unet_number, 1<a id="change">)</a>
        assert 1 &lt;= unet_number &lt;= len(self.unets)

        index<a id="change"> = </a>unet_number - 1
        unet = self.unets[index]
        target_image_size = self.image_sizes[index]

        b, c, h, w, device, = *image.shape, image.device

        check_shape(image, &quotb c h w&quot, c = self.channels)
        assert h &gt;= target_image_size and w &gt;= target_image_size

        times = torch.randint(0, self.num_timesteps, (b,), device = device, dtype = torch.long)

        image_embed = self.get_image_embed(image)
        text_encodings = self.get_text_encodings(text) if exists(text) else None

        lowres_cond_img = image if index &gt; 0 else None
        ddpm_image = resize_image_to(image, target_image_size)
        <a id="change">return </a>self.p_losses(unet, ddpm_image, times, image_embed = image_embed, text_encodings = text_encodings, lowres_cond_img = lowres_cond_img)

&#47&#47 main class
</code></pre>