{"BEFORE":"        basis,\n        edges = None,\n        mask = None,\n        nbhd_indices = None\n    ):\n        b, n, d, h, fourier_features, device = *feats.shape, self.heads, self.fourier_features, feats.device\n\n        rel_coors = rearrange(coors, 'b i d -> b i () d') - rearrange(coors, 'b j d -> b () j d')\n        rel_dist = (rel_coors ** 2).sum(dim = -1, keepdim = True)\n\n        if fourier_features > 0:\n            rel_dist = fourier_encode_dist(rel_dist, num_encodings = fourier_features)\n            rel_dist = rearrange(rel_dist, 'b i j () d -> b i j d')\n\n        rel_dist = repeat(rel_dist, 'b i j d -> b h i j d', h = h)\n\n        # derive queries keys and values\n\n        q, k, v = self.to_qkv(feats).chunk(3, dim = -1)\n        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), (q, k, v))\n\n        # calculate nearest neighbors\n\n        i = j = n\n\n        if exists(nbhd_indices):\n            i, j = nbhd_indices.shape[-2:]\n            nbhd_indices_with_heads = repeat(nbhd_indices, 'b n d -> b h n d', h = h)\n            k        = batched_index_select(k, nbhd_indices_with_heads, dim = 2)\n            v        = batched_index_select(v, nbhd_indices_with_heads, dim = 2)\n            rel_dist = batched_index_select(rel_dist, nbhd_indices_with_heads, dim = 3)\n            basis    = batched_index_select(basis, nbhd_indices, dim = 2)\n        else:\n            k = repeat(k, 'b h j d -> b h n j d', n = n)\n\n        # prepare mask\n\n        if exists(mask):\n            q_mask = rearrange(mask, 'b i -> b () i ()')\n            k_mask = repeat(mask, 'b j -> b i j', i = n)\n\n            if exists(nbhd_indices):\n                k_mask = batched_index_select(k_mask, nbhd_indices, dim = 2)\n\n            k_mask = rearrange(k_mask, 'b i j -> b () i j')\n            mask = q_mask * k_mask\n\n        # expand queries and keys for concatting\n\n        q = repeat(q, 'b h i d -> b h i n d', n = j)\n\n        edge_input = torch.cat((q, k, rel_dist), dim = -1)\n\n        if exists(edges):\n            if exists(nbhd_indices):\n                edges = batched_index_select(edges, nbhd_indices, dim = 2)\n\n            edges = repeat(edges, 'b i j d -> b h i j d', h = h)\n            edge_input = torch.cat((edge_input, edges), dim = -1)\n\n        m_ij = self.edge_mlp(edge_input)\n\n        coor_weights = self.coors_mlp(m_ij)\n\n        if exists(mask):\n            coor_weights.masked_fill_(mask, 0.)\n\n        if self.norm_rel_coors:\n            basis = F.normalize(basis, dim = -1, p = 2)\n\n        coors_out = einsum('b h i j, b i j c -> b i c', coor_weights, basis)\n\n        # derive attention\n\n        sim = self.to_attn_mlp(m_ij)\n\n        if exists(mask):\n            max_neg_value = -torch.finfo(sim.dtype).max\n            sim.masked_fill_(mask, max_neg_value)\n","AFTER":"        b, n, d, h, fourier_features, num_nn, device = *feats.shape, self.heads, self.fourier_features, self.num_nearest_neighbors, feats.device\n\n        rel_coors = rearrange(coors, 'b i d -> b i () d') - rearrange(coors, 'b j d -> b () j d')\n        rel_dist = rel_coors.norm(dim = -1, p = 2)\n\n        nbhd_indices = None\n        if num_nn > 0:\n            rel_dist = rel_coors.norm(dim = -1, p = 2)\n            nbhd_indices = rel_dist.topk(num_nn, dim = -1, largest = False).indices\n\n        rel_dist = rearrange(rel_dist, 'b i j -> b i j ()')\n\n        if fourier_features > 0:\n            rel_dist = fourier_encode_dist(rel_dist, num_encodings = fourier_features)\n            rel_dist = rearrange(rel_dist, 'b i j () d -> b i j d')\n\n        rel_dist = repeat(rel_dist, 'b i j d -> b h i j d', h = h)\n\n        # derive queries keys and values\n\n        q, k, v = self.to_qkv(feats).chunk(3, dim = -1)\n        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), (q, k, v))\n\n        # calculate nearest neighbors\n\n        i = j = n\n\n        if exists(nbhd_indices):\n            i, j = nbhd_indices.shape[-2:]\n            nbhd_indices_with_heads = repeat(nbhd_indices, 'b n d -> b h n d', h = h)\n            k         = batched_index_select(k, nbhd_indices_with_heads, dim = 2)\n            v         = batched_index_select(v, nbhd_indices_with_heads, dim = 2)\n            rel_dist  = batched_index_select(rel_dist, nbhd_indices_with_heads, dim = 3)\n            rel_coors = batched_index_select(rel_coors, nbhd_indices, dim = 2)\n        else:\n            k = repeat(k, 'b h j d -> b h n j d', n = n)\n\n        # prepare mask\n\n        if exists(mask):\n            q_mask = rearrange(mask, 'b i -> b () i ()')\n            k_mask = repeat(mask, 'b j -> b i j', i = n)\n\n            if exists(nbhd_indices):\n                k_mask = batched_index_select(k_mask, nbhd_indices, dim = 2)\n\n            k_mask = rearrange(k_mask, 'b i j -> b () i j')\n            mask = q_mask * k_mask\n\n        # expand queries and keys for concatting\n\n        q = repeat(q, 'b h i d -> b h i n d', n = j)\n\n        edge_input = torch.cat((q, k, rel_dist), dim = -1)\n\n        if exists(edges):\n            if exists(nbhd_indices):\n                edges = batched_index_select(edges, nbhd_indices, dim = 2)\n\n            edges = repeat(edges, 'b i j d -> b h i j d', h = h)\n            edge_input = torch.cat((edge_input, edges), dim = -1)\n\n        m_ij = self.edge_mlp(edge_input)\n\n        coor_weights = self.coors_mlp(m_ij)\n\n        if exists(mask):\n            coor_weights.masked_fill_(mask, 0.)\n\n        if self.norm_rel_coors:\n            rel_coors = F.normalize(rel_coors, dim = -1, p = 2)\n\n        coors_out = einsum('b h i j, b i j c -> b i c', coor_weights, rel_coors)\n\n        # derive attention\n\n        sim = self.to_attn_mlp(m_ij)\n\n        if exists(mask):\n            max_neg_value = -torch.finfo(sim.dtype).max\n            sim.masked_fill_(~mask, max_neg_value)\n"}