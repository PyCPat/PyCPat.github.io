{"BEFORE":"\tdef forward(self, img_id, class_id, style_code):\n\t\tcontent_code = self.content_embedding(img_id)\n\n\t\tif self.training and self.config['content_std'] != 0:\n\t\t\tnoise = torch.zeros_like(content_code)\n\t\t\tnoise.normal_(mean=0, std=self.config['content_std'])\n\n\t\t\tregularized_content_code = content_code + noise\n\t\telse:\n\t\t\tregularized_content_code = content_code\n\n\t\tclass_code = self.class_embedding(class_id)\n\t\tclass_with_style_code = torch.cat((class_code, style_code), dim=1)\n\t\tclass_adain_params = self.modulation(class_with_style_code)\n\n\t\tgenerated_img = self.decoder(regularized_content_code, class_adain_params)\n\n\t\treturn {\n\t\t\t'img': generated_img,\n\t\t\t'content_code': content_code\n\t\t}\n","AFTER":"\tdef forward(self, content_img_id, style_img_id, class_id):\n\t\tbatch_size = content_img_id.shape[0]\n\n\t\tcontent_code = self.content_embedding(content_img_id)\n\t\tstyle_code = self.style_embedding(style_img_id)\n\t\tclass_code = self.class_embedding(class_id)\n\n\t\tif self.training and self.config['content_std'] != 0:\n\t\t\tnoise = torch.zeros_like(content_code)\n\t\t\tnoise.normal_(mean=0, std=self.config['content_std'])\n\n\t\t\tregularized_content_code = content_code + noise\n\t\telse:\n\t\t\tregularized_content_code = content_code\n\n\t\tif self.training and self.config['style_std'] != 0:\n\t\t\tnoise = torch.zeros_like(style_code)\n\t\t\tnoise.normal_(mean=0, std=self.config['style_std'])\n\n\t\t\tregularized_style_code = style_code + noise\n\t\telse:\n\t\t\tregularized_style_code = style_code\n\n\t\tclass_with_style_code = torch.cat((class_code, regularized_style_code), dim=1)\n\t\tclass_with_style_code = self.class_style_modulation(class_with_style_code)\n\n\t\tx = self.projection(regularized_content_code)\n\t\tx = x.view((batch_size, 256, 4, 4))\n\n\t\tfor block in self.decoder:\n\t\t\tx = block(x, class_with_style_code)\n\n\t\treturn {\n\t\t\t'img': self.to_rgb(x),\n\t\t\t'content_code': content_code,\n\t\t\t'style_code': style_code\n\t\t}\n"}