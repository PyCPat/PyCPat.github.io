{"BEFORE":"        enc = self.encoder(src, context = mems, src_mask = src_mask)\n\n        if exists(self.decoder):\n            assert exists(tgt), 'target sequence must be given if using full encoder \/ decoder memformer'\n            out = self.decoder(tgt, context = enc, src_mask = tgt_mask, tgt_mask = src_mask)\n        else:\n            out = enc\n\n        # update memory with attention\n        mem_mask = torch.eye(num_mem, num_mem, device = device).bool()\n        mem_mask = repeat(mem_mask, 'i j -> b i j', b = b)\n        mem_mask = F.pad(mem_mask, (0, n), value = True)\n\n        if exists(src_mask):\n            src_mask = rearrange(src_mask, 'b j -> b () j')\n            mem_enc_mask = F.pad(src_mask, (num_mem, 0), value = True)\n            mem_mask &= mem_enc_mask\n\n        for _ in range(self.num_mem_updates):\n            prev_mems = mems\n            updated_mems = self.mem_updater(mems, enc, mask = mem_mask, attend_self = True)\n\n            next_mems = self.gru(\n                rearrange(updated_mems, 'b n d -> (b n) d'),\n                rearrange(prev_mems, 'b n d -> (b n) d')\n            )\n\n            mems = rearrange(next_mems, '(b n) d -> b n d', b = b)\n            mems = self.mem_ff(mems)\n\n        return out, mems\n","AFTER":"        enc = self.encoder(src, context = mems, src_mask = src_mask)\n\n        if exists(self.decoder) and exists(tgt):\n            dec_out = self.decoder(tgt, context = enc, src_mask = tgt_mask, tgt_mask = src_mask, return_loss = True)\n        else:\n            dec_out = torch.tensor(0., requires_grad = True, device = device)\n\n        # update memory with attention\n        mem_mask = torch.eye(num_mem, num_mem, device = device).bool()\n        mem_mask = repeat(mem_mask, 'i j -> b i j', b = b)\n        mem_mask = F.pad(mem_mask, (0, n), value = True)\n\n        if exists(src_mask):\n            src_mask = rearrange(src_mask, 'b j -> b () j')\n            mem_enc_mask = F.pad(src_mask, (num_mem, 0), value = True)\n            mem_mask &= mem_enc_mask\n\n        for _ in range(self.num_mem_updates):\n            prev_mems = mems\n            updated_mems = self.mem_updater(mems, enc, mask = mem_mask, attend_self = True)\n\n            next_mems = self.gru(\n                rearrange(updated_mems, 'b n d -> (b n) d'),\n                rearrange(prev_mems, 'b n d -> (b n) d')\n            )\n\n            mems = rearrange(next_mems, '(b n) d -> b n d', b = b)\n            mems = self.mem_ff(mems)\n\n        if not exists(self.decoder):\n            return EncOnlyResults(enc, mems)\n\n        return Results(enc, mems, dec_out)\n"}