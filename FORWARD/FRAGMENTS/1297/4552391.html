<link rel="stylesheet" href="../default.css">
<script src="../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    def forward(self, pred, target):
        log_prob = F.log_softmax(pred, dim=-1)
        dist = torch.empty_like(pred).fill_(self.smoothing / (pred.size(-1)<a id="change"> - </a>1))
        <a id="change">dist.scatter_(dim=-1, index=target[..., None], value=(1 - self.smoothing))</a>
        loss = F.kl_div(log_prob, dist)
        <a id="change">return </a>loss
</code></pre><h3>After Change</h3><pre><code class='java'>
        self.vocab = vocab

    def forward(self, pred: torch.Tensor, target: torch.Tensor, mask: torch.Tensor):
        pred<a id="change"> = </a>pred.flatten(0, 1)
        target = target.flatten(0, 1)
        mask<a id="change"> = </a>mask.flatten(0, 1).float()
        chunked_pred = torch.chunk(pred, chunks=self.chunk, dim=0)
        chunked_target = torch.chunk(target, chunks=self.chunk, dim=0)
        chunked_mask<a id="change"> = </a>torch.chunk(mask, chunks=self.chunk, dim=0)
        log_prob = [F.log_softmax(p, dim=-1) for p in chunked_pred]
        loss = [self.smoothed_loss(p, t, m)[None]\
            for p, t, m in zip(log_prob, chunked_target, chunked_mask)]
        loss = torch.cat(loss, dim=0).sum()
        <a id="change">return </a>loss<a id="change"> / </a>mask.sum()

    def smoothed_loss(self, log_prob: torch.Tensor, target: torch.Tensor, mask: torch.Tensor) -&gt; torch.Tensor:
        dist = torch.full_like(log_prob, fill_value=self.smoothing / (self.vocab - 2))</code></pre>