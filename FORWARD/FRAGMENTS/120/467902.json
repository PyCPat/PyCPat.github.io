{"BEFORE":"        embed_x = self.embedding(x)\n        # print('[DEBUG] embed x',embed_x.size()) # [16384, 128]\n        # print('[DEBUG] linear',self.linear(x).squeeze(1).size())\n        # print('[DEBUG] fm',self.fm(embed_x).size())\n        # print('[DEBUG] mlp',self.mlp(embed_x).squeeze(-1).size())\n        x = self.linear(x).squeeze(1) + self.fm(embed_x) + self.mlp(embed_x).squeeze(-1)\n","AFTER":"    def forward(self, sparse_feats, dense_feats):\n        \"\"\"\n        :param x: Long tensor of size ``(batch_size, num_fields)``\n        \"\"\"\n        embed_x = self.embedding(sparse_feats)\n        linear_x = self.linear(dense_feats)\n        combined_x = torch.cat([embed_x, linear_x], dim=1)\n        # print('[DEBUG] embed x',embed_x.size()) # [16384, 128]\n        # print('[DEBUG] linear',self.linear(x).squeeze(1).size())\n        # print('[DEBUG] fm',self.fm(embed_x).size())\n        # print('[DEBUG] mlp',self.mlp(embed_x).squeeze(-1).size())\n        x = self.fm(embed_x) + self.mlp(combined_x).squeeze(-1)\n"}