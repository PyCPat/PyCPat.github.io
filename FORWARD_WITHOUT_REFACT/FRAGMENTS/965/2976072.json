{"BEFORE":"\tdef forward(self, input_ids=None, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, inputs_embeds=None, labels=None):\n\t\toutputs = self.bert(\n\t\t\tinput_ids \t= input_ids,\n\t\t\tattention_mask\t= attention_mask,\n\t\t\ttoken_type_ids\t= token_type_ids,\n\t\t\tposition_ids\t= position_ids,\n\t\t\thead_mask\t= head_mask,\n\t\t\tinputs_embeds\t= inputs_embeds\n\t\t)\n\n\t\tpooled_output\t= outputs[1]\n\t\tpooled_output\t= self.dropout(pooled_output)\n\t\tlogits\t\t= self.classifier(pooled_output)\n\n\t\tif labels is None:\n\t\t\treturn logits\n\t\telse:\n\t\t\tloss = F.binary_cross_entropy_with_logits(logits, labels.float())\n\t\t\treturn loss, logits\n\nclass BertCombined(nn.Module):\n","AFTER":"\tdef forward(self, input_ids, attention_mask, mention_pos_idx, labels=None):\n\t\toutputs = self.bert(\n\t\t\tinput_ids \t= input_ids,\n\t\t\tattention_mask\t= attention_mask\n\t\t)\n\n\t\ttok_embed\t= outputs[0]\n\t\tbsz, mtok, dim  = tok_embed.shape\n\t\ttok_embed_flat\t= tok_embed.reshape(-1, dim)\n\t\tmen_idx \t= torch.arange(bsz).to(tok_embed.device) * mtok + mention_pos_idx\n\t\tmen_embed \t= tok_embed_flat[men_idx]\n\n\t\tpooled_output\t= self.dropout(men_embed)\n\t\tlogits\t\t= self.classifier(pooled_output)\n\t\tloss \t\t= F.binary_cross_entropy_with_logits(logits, labels.float())\n\n\t\tloss = F.binary_cross_entropy_with_logits(logits, labels.float())\n\t\treturn loss, logits\n"}