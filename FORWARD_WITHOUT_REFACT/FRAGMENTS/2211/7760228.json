{"BEFORE":"        losses = list()\n        k = logits[0].shape[1]\n        for logit, target in zip(logits, targets):\n            if step % 2 == 0:\n                # Discriminator step: find context relations\n                # logit: [n, k, h*w]\n                # target: [n, h*w]\n                loss = self._ceLoss(logit, target)\n            else:\n                # Generator step: corrupt context relations\n                logit = logit.permute(0, 2, 1).reshape(-1, k)\n                p = Categorical(logits=logit)\n                q = Categorical(logits=torch.zeros_like(logit))\n                loss = kl_divergence(p, q).mean()\n            losses.append(loss)\n        return sum(losses)\n","AFTER":"        losses = list()\n        k = logits[0].shape[1]\n        for logit, target in zip(logits, targets):\n            if step % 2 == 0:\n                # Discriminator step: find context relations\n                # logit: [n, k, h*w]\n                # target: [n, h*w]\n                loss = torch.maximum(self._ceLoss(logit, target), torch.ones_like(target, dtype=torch.float32) * 0.02).mean()\n            else:\n                # Generator step: corrupt context relations\n                # logit = logit.permute(0, 2, 1).reshape(-1, k)\n                # p = Categorical(logits=logit)\n                # q = Categorical(logits=torch.zeros_like(logit))\n                # loss = kl_divergence(p, q).mean()\n                loss = -torch.minimum(self._ceLoss(logit, target), -torch.log(torch.ones_like(target, dtype=torch.float32) \/ k)).mean()\n            losses.append(loss)\n        return sum(losses) \/ len(losses)\n"}