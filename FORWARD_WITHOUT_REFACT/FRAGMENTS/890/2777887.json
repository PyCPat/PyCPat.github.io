{"BEFORE":"            num_step = X.shape[1]\r\n            num_nodes = X.shape[2]\r\n            mask = torch.ones(num_step, num_step)\r\n            mask = torch.tril(mask)\r\n            mask = torch.unsqueeze(torch.unsqueeze(mask, dim=0), dim=0)\r\n            mask = mask.repeat(self._K * batch_size, num_nodes, 1, 1)\r\n            mask = mask.to(torch.bool)\r\n            condition = torch.FloatTensor([-2 ** 15 + 1])\r\n","AFTER":"        X = torch.cat((X, STE), dim=-1)\r\n        query = self._fully_connected_q(X)\r\n        key = self._fully_connected_k(X)\r\n        value = self._fully_connected_v(X)\r\n        query = torch.cat(torch.split(query, self._K, dim=-1), dim=0)\r\n        key = torch.cat(torch.split(key, self._K, dim=-1), dim=0)\r\n        value = torch.cat(torch.split(value, self._K, dim=-1), dim=0)\r\n        query = query.permute(0, 2, 1, 3)\r\n        key = key.permute(0, 2, 3, 1)\r\n        value = value.permute(0, 2, 1, 3)\r\n        attention = torch.matmul(query, key)\r\n        attention \/= (self._d ** 0.5)\r\n        if self._mask:\r\n            batch_size = X.shape[0]\r\n            num_step = X.shape[1]\r\n            num_nodes = X.shape[2]\r\n            mask = torch.ones(num_step, num_step).to(X.device)\r\n            mask = torch.tril(mask)\r\n            mask = torch.unsqueeze(torch.unsqueeze(mask, dim=0), dim=0)\r\n            mask = mask.repeat(self._K * batch_size, num_nodes, 1, 1)\r\n            mask = mask.to(torch.bool)\r\n            condition = torch.FloatTensor([-2 ** 15 + 1]).to(X.device)\r\n"}