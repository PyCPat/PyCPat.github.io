{"BEFORE":"        self.gat_layers = nn.ModuleList()\n        for i in range(num_meta_paths):\n            self.gat_layers.append(GATConv(\n                in_size, out_size, layer_num_heads, dropout, dropout, activation=F.elu\n            ))\n        self.semantic_attention = SemanticAttention(in_size=out_size * layer_num_heads)\n        self.num_meta_paths = num_meta_paths\n","AFTER":"        self.gats = nn.ModuleList([\n            GATConv(in_dim, out_dim, num_heads, dropout, dropout, activation=F.elu)\n            for _ in range(num_metapaths)\n        ])\n"}