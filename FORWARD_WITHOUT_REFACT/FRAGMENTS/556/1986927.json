{"BEFORE":"        M_space = M_space.view(M_space.size(0),M_space.size(1),-1) # N, (H*W), (H*W)\n        M_channel = self.Conv4Channel(channelF_cat) # N, C, C\n\n        input_flatten = input.view(input.size(0),input.size(1),-1) # N, C, H*W\n        feat_space = torch.matmul(input_flatten, M_space) # N, C, H*W\n        feat_channel = torch.matmul(M_channel, input_flatten) # N, C, H*W\n\n        feat_space = feat_space.view(feat_space.size(0),feat_space.size(1),self.shape,-1)\n        feat_channel = feat_channel.view(feat_channel.size(0),feat_channel.size(1),self.shape,-1)\n\n        feat_cat = torch.cat((feat_space,feat_channel),1) # N, 2*C, H, W\n        feat_new = self.Conv4Merge(feat_cat)\n\n        feat_new_v = self.pool5_7x7(feat_new).view(feat_new.size(0), -1)\n        feat_space_v = self.pool5_7x7(feat_space).view(feat_space.size(0), -1)\n        feat_channel_v = self.pool5_7x7(feat_channel).view(feat_channel.size(0), -1)\n\n        pred_label = self.classifier(feat_new_v)\n        return feat_new_v, feat_space_v, feat_channel_v, feat_new, feat_space, feat_channel, M_space, M_channel, pred_label\n","AFTER":"    def forward(self, input, label=None):\n        ss_space, ss_channel = selfSimilarity(input)\n\n        spaceF_cat = torch.cat((input, ss_space), 1) # N, (H*W+C), 7, 7\n        channelF_cat = torch.cat((input.view(input.size(0),input.size(1),-1), ss_channel),2) \n\n        M_space = self.Conv4Space(spaceF_cat) # N, (H*W), H, W\n        M_space = M_space.view(M_space.size(0),M_space.size(1),-1) # N, (H*W), (H*W)\n        M_channel = self.Conv4Channel(channelF_cat) # N, C, C\n\n        input_flatten = input.view(input.size(0),input.size(1),-1) # N, C, H*W\n        feat_space = torch.matmul(input_flatten, M_space) # N, C, H*W\n        feat_channel = torch.matmul(M_channel, input_flatten) # N, C, H*W\n\n        feat_space = feat_space.view(feat_space.size(0),feat_space.size(1),self.shape,-1)\n        feat_channel = feat_channel.view(feat_channel.size(0),feat_channel.size(1),self.shape,-1)\n\n        # ----------- Flip -------------\n        feat_channel_flip = torch.flip(feat_channel,[3])\n        feat_channel_cat = torch.cat((feat_channel_flip, feat_channel),1)\n        feat_channel = self.ChannelFlipMerge(feat_channel_cat)\n\n        feat_cat = torch.cat((feat_space, feat_channel, input),1) # N, 3*C, H, W\n        feat_new = self.Conv4Merge(feat_cat)\n\n        feat_new_v = self.pool5_7x7(feat_new).view(feat_new.size(0), -1)\n        # feat_space_v = self.pool5_7x7(feat_space).view(feat_space.size(0), -1)\n        # feat_channel_v = self.pool5_7x7(feat_channel).view(feat_channel.size(0), -1)\n\n        if label is None:\n            return feat_new_v, feat_new\n        else:\n            pred_loss, pred_label = self.classifier(feat_new_v,label)\n            return feat_new_v, pred_loss, pred_label, M_space, M_channel, feat_space, feat_channel\n\n# class RecNet_chn(nn.Module):\n#     r\"\"\"Implement of large margin cosine distance: :\n#     Args:\n#         in_features: size of each input sample\n#         out_features: size of each output sample\n#         s: norm of input feature\n#         m: margin\n#         our FINAL model.\n#     \"\"\"\n#     def __init__(self, channel=512, shape=7, norm_type='bn', relu_type='prelu'):\n#         super(RecNet_chn, self).__init__()\n#         self.channel = channel\n#         self.shape = shape\n\n#         conv_args = {'norm_type': norm_type, 'relu_type': relu_type}\n#         self.Conv4Channel = nn.Sequential(\n#             nn.Linear(self.channel + self.shape**2, 32),\n#             ReluLayer(512, 'prelu'),\n#             nn.Linear(32, self.channel),\n\n#             nn.Linear(self.channel, 32),\n#             ReluLayer(512, 'prelu'),\n#             nn.Linear(32, self.channel),\n\n#             nn.Linear(self.channel, 32),\n#             ReluLayer(512, 'prelu'),\n#             nn.Linear(32, self.channel),\n\n#             nn.Sigmoid(),\n#         )\n#         self.ChannelFlipMerge = nn.Sequential(\n#             ConvLayer(self.channel*2,self.channel, **conv_args),\n#             ResidualBlock(self.channel, self.channel, **conv_args),\n#         )\n#         self.Conv4Merge = nn.Sequential(\n#                 ConvLayer(self.channel*2, self.channel, **conv_args),\n#                 ResidualBlock(self.channel, self.channel, **conv_args),\n#         )\n#         self.pool5_7x7 = nn.AvgPool2d(kernel_size=[7, 7], stride=[1, 1], padding=0)\n#         self.classifier = AddMarginProduct(self.channel)\n\n#     def forward(self, input, label=None):\n#         _, ss_channel = selfSimilarity(input)\n\n#         channelF_cat = torch.cat((input.view(input.size(0),input.size(1),-1), ss_channel),2) \n#         M_channel = self.Conv4Channel(channelF_cat) # N, C, C\n\n#         input_flatten = input.view(input.size(0),input.size(1),-1) # N, C, H*W\n#         feat_channel = torch.matmul(M_channel, input_flatten) # N, C, H*W\n\n#         feat_channel = feat_channel.view(feat_channel.size(0),feat_channel.size(1),self.shape,-1)\n\n#         # ----------- Flip -------------\n#         feat_channel_flip = torch.flip(feat_channel,[3])\n#         feat_channel_cat = torch.cat((feat_channel_flip, feat_channel),1)\n#         feat_channel = self.ChannelFlipMerge(feat_channel_cat)\n    \n#         feat_cat = torch.cat((feat_channel, input),1) # N, 2*C, H, W\n#         feat_new = self.Conv4Merge(feat_cat)\n\n#         feat_new_v = self.pool5_7x7(feat_new).view(feat_new.size(0), -1)\n#         # feat_space_v = self.pool5_7x7(feat_space).view(feat_space.size(0), -1)\n#         # feat_channel_v = self.pool5_7x7(feat_channel).view(feat_channel.size(0), -1)\n\n#         if label is None:\n#             return feat_new_v, feat_new\n#         else:\n#             pred_loss, pred_label = self.classifier(feat_new_v,label)\n#             return feat_new_v, pred_loss, pred_label\n\n# class RecNet_spc(nn.Module):\n#     r\"\"\"Implement of large margin cosine distance: :\n#     Args:\n#         in_features: size of each input sample\n#         out_features: size of each output sample\n#         s: norm of input feature\n#         m: margin\n#         our FINAL model.\n#     \"\"\"\n#     def __init__(self, channel=512, shape=7, norm_type='bn', relu_type='prelu'):\n#         super(RecNet_spc, self).__init__()\n#         self.channel = channel\n#         self.shape = shape\n\n#         conv_args = {'norm_type': norm_type, 'relu_type': relu_type}\n#         self.Conv4Space = nn.Sequential(\n#             ConvLayer(self.channel + self.shape**2, 256, **conv_args),\n#             ResidualBlock(256, 256, **conv_args),\n#             ConvLayer(256, 128, **conv_args),\n#             ResidualBlock(128, 128, **conv_args),\n#             ConvLayer(128, self.shape**2, **conv_args),\n#             ResidualBlock(self.shape**2, self.shape**2, **conv_args),\n\n#             nn.Sigmoid(),\n#         )\n\n#         self.Conv4Merge = nn.Sequential(\n#                 ConvLayer(self.channel*2, self.channel, **conv_args),\n#                 ResidualBlock(self.channel, self.channel, **conv_args),\n#         )\n#         self.pool5_7x7 = nn.AvgPool2d(kernel_size=[7, 7], stride=[1, 1], padding=0)\n#         self.classifier = AddMarginProduct(self.channel)\n\n#     def forward(self, input, label=None):\n#         ss_space, _ = selfSimilarity(input)\n\n#         spaceF_cat = torch.cat((input, ss_space), 1) # N, (H*W+C), 7, 7\n        \n#         M_space = self.Conv4Space(spaceF_cat) # N, (H*W), H, W\n#         M_space = M_space.view(M_space.size(0),M_space.size(1),-1) # N, (H*W), (H*W)\n        \n\n#         input_flatten = input.view(input.size(0),input.size(1),-1) # N, C, H*W\n#         feat_space = torch.matmul(input_flatten, M_space) # N, C, H*W\n#         feat_space = feat_space.view(feat_space.size(0),feat_space.size(1),self.shape,-1)\n    \n#         feat_cat = torch.cat((feat_space,input),1) # N, 2*C, H, W\n#         feat_new = self.Conv4Merge(feat_cat)\n\n#         feat_new_v = self.pool5_7x7(feat_new).view(feat_new.size(0), -1)\n#         # feat_space_v = self.pool5_7x7(feat_space).view(feat_space.size(0), -1)\n#         # feat_channel_v = self.pool5_7x7(feat_channel).view(feat_channel.size(0), -1)\n\n#         if label is None:\n#             return feat_new_v, feat_new\n#         else:\n#             pred_loss, pred_label = self.classifier(feat_new_v,label)\n#             return feat_new_v, pred_loss, pred_label\n\n# class RecNet(nn.Module):\n#     def __init__(self, channel=512, shape=7, norm_type='bn', relu_type='prelu'):\n#         super(RecNet, self).__init__()\n#         self.channel = channel\n#         self.shape = shape\n\n#         self.rec_chn = RecNet_chn()\n#         self.rec_spc = RecNet_spc()\n#         weight_spc = load('\/app\/Occluded-Face-RecNet\/pretrained_weight\/spc_weight.pth.gzip')\n#         weight_chn = load('\/app\/Occluded-Face-RecNet\/pretrained_weight\/chn_weight.pth.gzip')\n#         self.rec_spc.load_state_dict(weight_spc['RecNet'], strict=False)\n#         self.rec_chn.load_state_dict(weight_chn['RecNet'], strict=False)\n#         for p in self.rec_spc.parameters():\n#             p.requires_grad = False\n#         for p in self.rec_chn.parameters():\n#             p.requires_grad = False\n    \n#     def forward(self, input, label=None):\n#         f_chn, _ = self.rec_chn(input)\n#         f_spc, _ = self.rec_spc(input)\n        \n#         f_new = f_spc*0.8 + f_chn*0.2\n\n#         if label is None:\n#             return f_new\n#         else:\n#             pred_loss, pred_label = self.classifier(f_new,label)\n#             return f_new, pred_loss, pred_label\n\n\n# class RecNet(nn.Module):\n#     r\"\"\"Implement of large margin cosine distance: :\n#     Args:\n#         in_features: size of each input sample\n#         out_features: size of each output sample\n#         s: norm of input feature\n#         m: margin\n#         our FINAL model.\n#     \"\"\"\n#     def __init__(self, channel=512, shape=7, norm_type='bn', relu_type='prelu'):\n#         super(RecNet, self).__init__()\n#         self.channel = channel\n#         self.shape = shape\n\n#         conv_args = {'norm_type': norm_type, 'relu_type': relu_type}\n#         self.Conv4Space = nn.Sequential(\n#             ConvLayer(self.channel + self.shape**2, 256, **conv_args),\n#             ResidualBlock(256, 256, **conv_args),\n#             ConvLayer(256, 128, **conv_args),\n#             ResidualBlock(128, 128, **conv_args),\n#             ConvLayer(128, self.shape**2, **conv_args),\n#             ResidualBlock(self.shape**2, self.shape**2, **conv_args),\n\n#             nn.Sigmoid(),\n#         )\n#         self.Conv4Channel = nn.Sequential(\n#             nn.Linear(self.channel + self.shape**2, 32),\n#             ReluLayer(512, 'prelu'),\n#             nn.Linear(32, self.channel),\n\n#             nn.Linear(self.channel, 32),\n#             ReluLayer(512, 'prelu'),\n#             nn.Linear(32, self.channel),\n\n#             nn.Linear(self.channel, 32),\n#             ReluLayer(512, 'prelu'),\n#             nn.Linear(32, self.channel),\n\n#             nn.Sigmoid(),\n#         )\n#         self.ChannelFlipMerge = nn.Sequential(\n#             ConvLayer(self.channel*2,self.channel, **conv_args),\n#             ResidualBlock(self.channel, self.channel, **conv_args),\n#         )\n#         self.Conv4Merge = nn.Sequential(\n#                 ConvLayer(self.channel*2, self.channel, **conv_args),\n#                 ResidualBlock(self.channel, self.channel, **conv_args),\n#         )\n#         self.pool5_7x7 = nn.AvgPool2d(kernel_size=[7, 7], stride=[1, 1], padding=0)\n#         self.classifier = AddMarginProduct(self.channel)\n\n#     def forward(self, input, label=None):\n#         ss_space, ss_channel = selfSimilarity(input)\n\n#         spaceF_cat = torch.cat((input, ss_space), 1) # N, (H*W+C), 7, 7\n#         channelF_cat = torch.cat((input.view(input.size(0),input.size(1),-1), ss_channel),2) \n\n#         M_space = self.Conv4Space(spaceF_cat) # N, (H*W), H, W\n#         M_space = M_space.view(M_space.size(0),M_space.size(1),-1) # N, (H*W), (H*W)\n#         M_channel = self.Conv4Channel(channelF_cat) # N, C, C\n\n#         input_flatten = input.view(input.size(0),input.size(1),-1) # N, C, H*W\n#         feat_space = torch.matmul(input_flatten, M_space) # N, C, H*W\n#         feat_channel = torch.matmul(M_channel, input_flatten) # N, C, H*W\n\n#         feat_space = feat_space.view(feat_space.size(0),feat_space.size(1),self.shape,-1)\n#         feat_channel = feat_channel.view(feat_channel.size(0),feat_channel.size(1),self.shape,-1)\n\n#         # # ----------- Flip -------------\n#         # feat_channel_flip = torch.flip(feat_channel,[3])\n#         # feat_channel_cat = torch.cat((feat_channel_flip, feat_channel),1)\n#         # feat_channel = self.ChannelFlipMerge(feat_channel_cat)\n\n#         feat_cat = torch.cat((feat_space,feat_channel),1) # N, 2*C, H, W\n#         feat_new = self.Conv4Merge(feat_cat)\n\n#         feat_new_v = self.pool5_7x7(feat_new).view(feat_new.size(0), -1)\n#         # feat_space_v = self.pool5_7x7(feat_space).view(feat_space.size(0), -1)\n#         # feat_channel_v = self.pool5_7x7(feat_channel).view(feat_channel.size(0), -1)\n\n#         if label is None:\n#             return feat_new_v, M_space, M_channel\n#         else:\n#             pred_loss, pred_label = self.classifier(feat_new_v,label)\n#             return feat_new_v, pred_loss, pred_label\n\n\n# class RecNet(nn.Module):\n#     r\"\"\"Implement of large margin cosine distance: :\n#     Args:\n#         in_features: size of each input sample\n#         out_features: size of each output sample\n#         s: norm of input feature\n#         m: margin\n#     \"\"\"\n#     def __init__(self, channel=512, shape=7, norm_type='bn', relu_type='prelu'):\n#         super(RecNet, self).__init__()\n#         self.channel = channel\n#         self.shape = shape\n#         self.N_head = 8\n#         conv_args = {'norm_type': norm_type, 'relu_type': relu_type}\n#         self.Conv4Space = nn.Sequential(\n#             ConvLayer(self.channel + self.shape**2, 256, **conv_args),\n#             ResidualBlock(256, 256, **conv_args),\n#             ConvLayer(256, 128, **conv_args),\n#             ResidualBlock(128, 128, **conv_args),\n#             ConvLayer(128, self.shape**2, **conv_args),\n#             ResidualBlock(self.shape**2, self.shape**2, **conv_args),\n\n#             nn.Sigmoid(),\n#         )\n#         self.Conv4Channel = nn.Sequential(\n#             nn.Linear(self.channel + self.shape**2, 32),\n#             ReluLayer(512, 'prelu'),\n#             nn.Linear(32, self.channel),\n\n#             nn.Linear(self.channel, 32),\n#             ReluLayer(512, 'prelu'),\n#             nn.Linear(32, self.channel),\n\n#             nn.Linear(self.channel, 32),\n#             ReluLayer(512, 'prelu'),\n#             nn.Linear(32, self.channel),\n\n#             nn.Sigmoid(),\n#         )\n#         self.ChannelFlipMerge = nn.Sequential(\n#             ConvLayer(self.channel*2,self.channel, **conv_args),\n#             ResidualBlock(self.channel, self.channel, **conv_args),\n#         )\n#         self.Conv4Merge = nn.Sequential(\n#                 ConvLayer(self.channel*2, self.channel, **conv_args),\n#                 ResidualBlock(self.channel, self.channel, **conv_args),\n#                 )\n#         self.pool5_7x7 = nn.AvgPool2d(kernel_size=[7, 7], stride=[1, 1], padding=0)\n#         self.classifier = AddMarginProduct(self.channel)\n\n#         # self.layer_stack = nn.ModuleList([\n#         #     RecMatrix_Block(self.channel, self.shape, **conv_args)\n#         #     for _ in range(self.N_head)])\n\n#         # self.Linear = nn.Linear(self.N_head, 1)\n\n#     def forward(self, input, label=None):\n#         # feat_lst = [] \n#         # for rec_layer in self.layer_stack:\n#         #     f = rec_layer(input)\n#         #     feat_lst.append(f.view(f.size(0),f.size(1), -1))\n        \n#         # feat_cat = torch.cat(feat_lst, 2) # N, C, N_head\n#         # feat_new = self.Linear(feat_cat).view(feat_cat.size(0), -1)\n#         # if label is None:\n#         #     return l2_norm(feat_new), feat_lst\n#         # else:\n#         #     pred_loss, pred_label = self.classifier(feat_new, label)\n#         #     return l2_norm(feat_new), feat_lst, pred_loss, pred_label\n\n#         # feat_new_v = self.pool5_7x7(feat_new).view(feat_new.size(0), -1)\n\n#         # feat_space_v = self.pool5_7x7(feat_space).view(feat_space.size(0), -1)\n#         # feat_channel_v = self.pool5_7x7(feat_channel).view(feat_channel.size(0), -1)\n        \n#         # --------- seblock -----------\n#         b, c, _, _ = input.size()\n#         y = self.avg_pool(input).view(b, c)\n#         y = self.seblock(y).view(b, c, 1, 1)\n#         output = input + input * y.expand_as(input)\n#         feat_out_v = self.pool5_7x7(output).view(output.size(0),-1)\n#         feat_new = output\n#         feat_new_v = feat_out_v\n\n#         # space feat\n#         feat_new = feat_space\n#         feat_new_v = feat_space_v\n\n#         # channel feat\n#         feat_new = feat_channel\n#         feat_new_v = feat_channel_v\n        \n#         if label is None:\n#             return feat_new_v, feat_space_v, feat_channel_v, feat_new, feat_space, feat_channel, M_space, M_channel\n#         else:\n#             pred_loss, pred_label = self.classifier(feat_new_v,label)\n#             return feat_new_v, feat_space_v, feat_channel_v, feat_new, feat_space, feat_channel, M_space, M_channel, pred_loss, pred_label\n\nif __name__ == '__main__':\n"}