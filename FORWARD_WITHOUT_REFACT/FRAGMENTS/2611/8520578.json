{"BEFORE":"            s = [0.83, 0.67]  # scales\n            y = []\n            for i, xi in enumerate((x,\n                                    torch_utils.scale_img(x.flip(3), s[0]),  # flip-lr and scale\n                                    torch_utils.scale_img(x, s[1]),  # scale\n                                    )):\n                # cv2.imwrite('img%g.jpg' % i, 255 * xi[0].numpy().transpose((1, 2, 0))[:, :, ::-1])\n                y.append(self.forward_once(xi)[0])\n\n            y[1][..., :4] \/= s[0]  # scale\n            y[1][..., 0] = img_size[1] - y[1][..., 0]  # flip lr\n            y[2][..., :4] \/= s[1]  # scale\n","AFTER":"            img_size = x.shape[-2:]  # height, width\n            s = [1, 0.83, 0.67]  # scales\n            f = [None, 3, None]  # flips (2-ud, 3-lr)\n            y = []  # outputs\n            for si, fi in zip(s, f):\n                xi = torch_utils.scale_img(x.flip(fi) if fi else x, si)\n                yi = self.forward_once(xi)[0]  # forward\n                # cv2.imwrite('img%g.jpg' % s, 255 * xi[0].numpy().transpose((1, 2, 0))[:, :, ::-1])  # save\n                yi[..., :4] \/= si  # de-scale\n                if fi is 2:\n                    yi[..., 1] = img_size[0] - yi[..., 1]  # de-flip ud\n                elif fi is 3:\n                    yi[..., 0] = img_size[1] - yi[..., 0]  # de-flip lr\n                y.append(yi)\n            return torch.cat(y, 1), None  # augmented inference, train\n"}