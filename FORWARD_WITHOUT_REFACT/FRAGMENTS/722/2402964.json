{"BEFORE":"        d = self.res\/2\n        x = x.clamp(self.lo-d, self.hi+d)[...,None]\n        x_ = (x - loc) * s\n\n        # numerical crimes follow\n        # q = b ** -x_\n        q = x_.exp()\n        sd = s*d\n        # bdp, bdm = b**d, b**-d\n        sdm, sdp = (-sd).exp(), sd.exp()\n        # # censoring\n        lo_cens = x <= self.lo\n        hi_cens = x >= self.hi\n        ones = torch.ones_like(q)\n        zeros = torch.zeros_like(q)\n\n        diff_term = torch.where(\n            lo_cens | hi_cens, ones, sdp - sdm).log()\n        # sdm_term = torch.where(\n        #     hi_cens, ones, (q + sdm)).log()\n        sdm_term = torch.where(hi_cens, zeros, x_ + F.softplus(-sd-x_))\n        # sdp_term = torch.where(\n        #     lo_cens, ones, (q + sdp)).log()\n        sdp_term = torch.where(lo_cens, zeros, x_ + F.softplus(sd-x_))\n        x_or_sd = torch.where(hi_cens, sd, x_)\n\n        log_delta_cdf = (\n            x_or_sd + diff_term - sdm_term - sdp_term\n        )\n    \n        # log prob\n        r = {\n            'log_prob': (log_pi + log_delta_cdf).logsumexp(-1)\n        }\n        # diagnostics\n        with torch.no_grad():\n            ent = D.Categorical(logits=log_pi).entropy()\n            # s = -b.log()\n            r |= {\n                'min_sharpness': s.min(),\n                'max_sharpness': s.max(),\n                'min_entropy': ent.min(),\n                'max_entropy': ent.max(),\n                'marginal_entropy': D.Categorical(\n                    log_pi.exp().mean(list(range(log_pi.ndim-1)))).entropy(),\n                'min_loc': loc.min(),\n                'max_loc': loc.max()\n","AFTER":"        d = self.res\/2\n        x = x.clamp(self.lo, self.hi)[...,None]\n        x_ = (x - loc) * s\n        sd = s*d\n\n        # # censoring\n        lo_cens = x <= self.lo+d\n        hi_cens = x >= self.hi-d\n        ones = torch.ones_like(x_)\n        zeros = torch.zeros_like(x_)\n\n        diff_term = torch.where(lo_cens | hi_cens, \n            ones, sd.exp() - (-sd).exp()\n            ).log()\n        minus_sp_term = torch.where(hi_cens, -sd, F.softplus(-sd-x_))\n        plus_sp_term = torch.where(lo_cens, zeros, x_ + F.softplus(sd-x_))\n\n        log_delta_cdf = diff_term - minus_sp_term - plus_sp_term\n    \n        # log prob\n        r = {\n            'log_prob': (log_pi + log_delta_cdf).logsumexp(-1)\n        }\n        # diagnostics\n        with torch.no_grad():\n            ent = D.Categorical(logits=log_pi).entropy()\n            r |= {\n                # 'min_sharpness': s.min(),\n                'max_sharpness': s.max(),\n                'mean_sharpness': (s*log_pi.exp()).sum(-1).mean(),\n                # 'min_entropy': ent.min(),\n                # 'max_entropy': ent.max(),\n                'mean_cmp_entropy': ent.mean(),\n"}