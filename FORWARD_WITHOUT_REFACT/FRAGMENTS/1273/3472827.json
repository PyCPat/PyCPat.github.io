{"BEFORE":"    def __init__(self, in_dim, action_dim, hidden_dim, device, num_layers_linear_hidden,\n             log_std_min=-20, log_std_max=2, init_w=3e-3):\n\n        assert len(in_dim) == 1\n        assert len(action_dim) == 1\n\n        in_dim = np.product(in_dim)\n        action_dim = np.product(action_dim)\n\n        super(PolicyNet, self).__init__()\n        # device is initialized by agents Class\n\n        self.device = device\n\n        self.log_std_min = log_std_min\n        self.log_std_max = log_std_max\n\n        layers = [nn.Linear(in_dim, hidden_dim)]\n\n        for l in range(num_layers_linear_hidden):\n            layers.append(nn.ReLU())\n            layers.append(nn.Linear(hidden_dim, hidden_dim))\n        layers.append(nn.ReLU())\n\n        self.net = nn.Sequential(*layers)\n\n        self.mean_linear = nn.Linear(hidden_dim, action_dim)\n        self.mean_linear.weight.data.uniform_(-init_w, init_w)\n        self.mean_linear.bias.data.uniform_(-init_w, init_w)\n\n        self.log_std_linear = nn.Linear(hidden_dim, action_dim)\n        self.log_std_linear.weight.data.uniform_(-init_w, init_w)\n        self.log_std_linear.bias.data.uniform_(-init_w, init_w)\n","AFTER":"        super(Policy, self).__init__()\n\n        assert len(in_dim) == 1\n        assert len(action_dim) == 1\n\n        in_dim = np.product(in_dim)\n        action_dim = np.product(action_dim)\n\n        # device is initialized by agents Class\n        self.operators = nn.ModuleList([\n            Flatten(),\n            nn.Linear(in_dim, hidden_dim),\n        ])\n\n        for l in range(num_layers_linear_hidden):\n            self.operators.append(nn.ReLU())\n            self.operators.append(nn.Linear(hidden_dim, hidden_dim))\n\n        self.operators.append(nn.Linear(hidden_dim, 2 * action_dim))\n\n        self.operators.apply(init_xavier_uniform)\n\n        self.std_clamp = Clamp(log_std_min, log_std_max)\n"}