{"BEFORE":"        h = x\n        for index, blocklist in enumerate(self.blocks):\n            for block in blocklist:\n                h = block(h)\n        h = self.conv1(h)\n        if not self.apply_d_sn:\n            h = self.bn1(h)\n        h = self.activation(h)\n        h = torch.sum(h, dim=[2, 3])\n\n        # adversarial training\n        adv_output = torch.squeeze(self.linear1(h))\n\n        # add num_classes for discrminating fake images using ADC\n        if adc_fake:\n            label = label + self.num_classes\n\n        # class conditioning\n        if self.d_cond_mtd == \"AC\":\n            if self.normalize_d_embed:\n                for W in self.linear2.parameters():\n                    W = F.normalize(W, dim=1)\n                h = F.normalize(h, dim=1)\n            cls_output = self.linear2(h)\n        elif self.d_cond_mtd == \"PD\":\n            adv_output = adv_output + torch.sum(torch.mul(self.embedding(label), h), 1)\n        elif self.d_cond_mtd in [\"2C\", \"D2DCE\"]:\n            embed = self.linear2(h)\n            proxy = self.embedding(label)\n            if self.normalize_d_embed:\n                embed = F.normalize(embed, dim=1)\n                proxy = F.normalize(proxy, dim=1)\n        elif self.d_cond_mtd == \"MD\":\n            idx = torch.LongTensor(range(label.size(0))).to(label.device)\n            adv_output = adv_output[idx, label]\n        elif self.d_cond_mtd in [\"W\/O\", \"MH\"]:\n            pass\n        else:\n            raise NotImplementedError\n\n        # extra conditioning for TACGAN and ADCGAN\n        if self.aux_cls_type == \"TAC\":\n            if self.d_cond_mtd == \"AC\":\n                if self.normalize_d_embed:\n                    for W in self.linear_mi.parameters():\n                        W = F.normalize(W, dim=1)\n                mi_cls_output = self.linear_mi(h)\n            elif self.d_cond_mtd in [\"2C\", \"D2DCE\"]:\n                mi_embed = self.linear_mi(h)\n                mi_proxy = self.embedding_mi(label)\n                if self.normalize_d_embed:\n                    mi_embed = F.normalize(mi_embed, dim=1)\n                    mi_proxy = F.normalize(mi_proxy, dim=1)\n        return {\n","AFTER":"    def forward(self, x, label, eval=False, adc_fake=False):\n        with torch.cuda.amp.autocast() if self.mixed_precision and not eval else misc.dummy_context_mgr() as mp:\n            embed, proxy, cls_output = None, None, None\n            mi_embed, mi_proxy, mi_cls_output = None, None, None\n            h = x\n            for index, blocklist in enumerate(self.blocks):\n                for block in blocklist:\n                    h = block(h)\n            h = self.conv1(h)\n            if not self.apply_d_sn:\n                h = self.bn1(h)\n            h = self.activation(h)\n            h = torch.sum(h, dim=[2, 3])\n\n            # adversarial training\n            adv_output = torch.squeeze(self.linear1(h))\n\n            # add num_classes for discrminating fake images using ADC\n            if adc_fake:\n                label = label + self.num_classes\n\n            # class conditioning\n            if self.d_cond_mtd == \"AC\":\n                if self.normalize_d_embed:\n                    for W in self.linear2.parameters():\n                        W = F.normalize(W, dim=1)\n                    h = F.normalize(h, dim=1)\n                cls_output = self.linear2(h)\n            elif self.d_cond_mtd == \"PD\":\n                adv_output = adv_output + torch.sum(torch.mul(self.embedding(label), h), 1)\n            elif self.d_cond_mtd in [\"2C\", \"D2DCE\"]:\n                embed = self.linear2(h)\n                proxy = self.embedding(label)\n                if self.normalize_d_embed:\n                    embed = F.normalize(embed, dim=1)\n                    proxy = F.normalize(proxy, dim=1)\n            elif self.d_cond_mtd == \"MD\":\n                idx = torch.LongTensor(range(label.size(0))).to(label.device)\n                adv_output = adv_output[idx, label]\n            elif self.d_cond_mtd in [\"W\/O\", \"MH\"]:\n                pass\n            else:\n                raise NotImplementedError\n\n            # extra conditioning for TACGAN and ADCGAN\n            if self.aux_cls_type == \"TAC\":\n                if self.d_cond_mtd == \"AC\":\n                    if self.normalize_d_embed:\n                        for W in self.linear_mi.parameters():\n                            W = F.normalize(W, dim=1)\n                    mi_cls_output = self.linear_mi(h)\n                elif self.d_cond_mtd in [\"2C\", \"D2DCE\"]:\n                    mi_embed = self.linear_mi(h)\n                    mi_proxy = self.embedding_mi(label)\n                    if self.normalize_d_embed:\n                        mi_embed = F.normalize(mi_embed, dim=1)\n                        mi_proxy = F.normalize(mi_proxy, dim=1)\n        return {\n"}