{"BEFORE":"        initial_input = Variable(\n            encoder_outputs.data.new(B, self.in_dim * self.r).zero_())\n\n        # Init decoder states\n        attention_rnn_hidden = Variable(\n            encoder_outputs.data.new(B, 256).zero_())\n        decoder_rnn_hiddens = [Variable(\n            encoder_outputs.data.new(B, 256).zero_())\n            for _ in range(len(self.decoder_rnns))]\n        current_attention = Variable(\n            encoder_outputs.data.new(B, 256).zero_())\n\n        # Time first (T_decoder, B, in_dim)\n        if inputs is not None:\n            inputs = inputs.transpose(0, 1)\n\n        outputs = []\n        alignments = []\n\n        t = 0\n        current_input = initial_input\n        while True:\n            if t > 0:\n                current_input = outputs[-1] if greedy else inputs[t - 1]\n            # Prenet\n            current_input = self.prenet(current_input)\n\n            # Attention RNN\n            attention_rnn_hidden, current_attention, alignment = self.attention_rnn(\n                current_input, current_attention, attention_rnn_hidden,\n                encoder_outputs, processed_memory=processed_memory, mask=mask)\n\n            # Concat RNN output and attention context vector\n            decoder_input = self.project_to_decoder_in(\n                torch.cat((attention_rnn_hidden, current_attention), -1))\n\n            # Pass through the decoder RNNs\n            for idx in range(len(self.decoder_rnns)):\n                decoder_rnn_hiddens[idx] = self.decoder_rnns[idx](\n                    decoder_input, decoder_rnn_hiddens[idx])\n                # Residual connectinon\n                decoder_input = decoder_rnn_hiddens[idx] + decoder_input\n\n            output = decoder_input\n            output = self.proj_to_mel(output)\n\n            outputs += [output]\n            alignments += [alignment]\n\n            t += 1\n\n            if greedy:\n                if t > 1 and is_end_of_frames(output):\n                    break\n                elif t > self.max_decoder_steps:\n                    print(\"Warning! doesn't seems to be converged\")\n                    break\n            else:\n                if t >= T_decoder:\n                    break\n\n        assert greedy or len(outputs) == T_decoder\n\n        # Back to batch first\n        alignments = torch.stack(alignments).transpose(0, 1)\n        outputs = torch.stack(outputs).transpose(0, 1).contiguous()\n\n        return outputs, alignments\n","AFTER":"        initial_input = encoder_outputs.data.new(B, self.mel_dim * self.r).zero_()\n\n        # Init decoder states\n        attention_rnn_hidden = encoder_outputs.data.new(B, self.attention_rnn_units).zero_()\n        decoder_rnn_hiddens = [encoder_outputs.data.new(B, self.decoder_rnn_units).zero_()\n                               for _ in range(len(self.decoder_rnns))]\n        attention_context = encoder_outputs.data.new(B, self.attention_rnn_units).zero_()\n\n        # Time first (T', B, mel_dim*4)\n        if inputs is not None:\n            inputs = inputs.transpose(0, 1)\n\n        mel_outputs, attn_scores = [], []\n\n        # Run the decoder loop\n        t = 0\n        current_input = initial_input\n        while True:\n            if t > 0:\n                current_input = outputs[-1] if greedy else inputs[t - 1]\n            t += 1\n\n            # Prenet\n            current_input = self.prenet(current_input)\n\n            # Attention RNN\n            attention_rnn_hidden, attention_context, attention_score = self.attention_rnn(\n                current_input, attention_context, attention_rnn_hidden,\n                encoder_outputs, processed_memory=processed_memory, mask=mask)\n\n            # Concat RNN output and attention context vector\n            decoder_input = self.project_to_decoder_in(\n                torch.cat((attention_rnn_hidden, attention_context), -1))\n\n            # Pass through the decoder RNNs\n            for idx in range(len(self.decoder_rnns)):\n                decoder_rnn_hiddens[idx] = self.decoder_rnns[idx](\n                    decoder_input, decoder_rnn_hiddens[idx])\n                # Residual connectinon\n                decoder_input = decoder_rnn_hiddens[idx] + decoder_input\n\n            # Project to mel\n            output = decoder_input\n            output = self.proj_to_mel(output)\n\n            # Store predictions\n            mel_outputs += [output]\n            attn_scores += [attention_score]\n\n            if greedy:\n                if t > 1 and is_end_of_frames(output):\n                    break\n                elif t > self.max_decoder_steps:\n                    print(\"Warning! doesn't seems to be converged\")\n                    break\n            else:\n                if t >= T_decoder:\n                    break\n\n        # Validation check\n        assert greedy or len(mel_outputs) == T_decoder\n\n        # Back to batch first\n        attn_scores = torch.stack(attn_scores).transpose(0, 1)\n        mel_outputs = torch.stack(mel_outputs).transpose(0, 1).contiguous()\n\n        return mel_outputs, attn_scores\n"}