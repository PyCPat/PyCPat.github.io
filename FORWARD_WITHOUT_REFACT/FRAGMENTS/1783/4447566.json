{"BEFORE":"        self.representation_dim = representation_dim\n        shared_network_layers = []\n\n        # figure out how big the convolution output will be\n        conv_arch = DEFAULT_CNN_ARCHITECTURE['CONV']\n        dense_arch = DEFAULT_CNN_ARCHITECTURE['DENSE'].copy()  # copy to mutate\n        dense_in_dim = np.prod(sb_conv_arch_output_size(obs_space.shape[1:],\n                                                        conv_arch))\n        dense_arch[0]['in_dim'] = dense_in_dim\n\n        for layer_spec in conv_arch:\n            shared_network_layers.append(nn.Conv2d(self.input_channel, layer_spec['out_dim'],\n                                                   kernel_size=layer_spec['kernel_size'], stride=layer_spec['stride']))\n            shared_network_layers.append(nn.ReLU())\n            self.input_channel = layer_spec['out_dim']\n\n        shared_network_layers.append(nn.Flatten())\n        for ind, layer_spec in enumerate(dense_arch[:-1]):\n            in_dim, out_dim = layer_spec.get('in_dim'), layer_spec.get('out_dim')\n            shared_network_layers.append(nn.Linear(in_dim, out_dim))\n            shared_network_layers.append(nn.ReLU())\n\n        self.shared_network = nn.Sequential(*shared_network_layers)\n        self.mean_layer = nn.Linear(dense_arch[-1]['in_dim'], self.representation_dim)\n        self.scale_layer = nn.Linear(dense_arch[-1]['in_dim'], self.representation_dim)\n","AFTER":"        shared_network_layers = []\n\n        # first apply convolution layers + flattening\n        conv_arch = [\n            {'out_dim': 32, 'kernel_size': 8, 'stride': 4},\n            {'out_dim': 64, 'kernel_size': 4, 'stride': 2},\n            {'out_dim': 64, 'kernel_size': 3, 'stride': 1},\n        ]\n        for layer_spec in conv_arch:\n            shared_network_layers.append(nn.Conv2d(self.input_channel, layer_spec['out_dim'],\n                                                   kernel_size=layer_spec['kernel_size'], stride=layer_spec['stride']))\n            shared_network_layers.append(nn.ReLU())\n            self.input_channel = layer_spec['out_dim']\n        shared_network_layers.append(nn.Flatten())\n\n        # now customise the dense layers to handle an appropriate-sized conv output\n        dense_in_dim, = compute_output_shape(observation_space, shared_network_layers)\n        dense_arch = [\n            # this input size is accurate for Atari, but will be ovewritten for other envs\n            {'in_dim': 64*7*7},\n        ]\n        dense_arch[0]['in_dim'] = dense_in_dim\n        dense_arch[-1]['out_dim'] = representation_dim\n\n        # apply the dense layers\n        for ind, layer_spec in enumerate(dense_arch[:-1]):\n            shared_network_layers.append(nn.Linear(layer_spec['in_dim'], layer_spec['out_dim']))\n            shared_network_layers.append(nn.ReLU())\n        # no ReLU after last layer\n        last_layer_spec = dense_arch[-1]\n        shared_network_layers.append(\n            nn.Linear(last_layer_spec['in_dim'], last_layer_spec['out_dim']))\n"}