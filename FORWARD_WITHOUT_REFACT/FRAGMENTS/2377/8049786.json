{"BEFORE":"        pass\n","AFTER":"        num_batches = encoded.shape[0]\n        num_series = encoded.shape[1]\n        num_timesteps = encoded.shape[2]\n\n        data = encoded\n\n        for i in range(self.attention_layers):\n            # Treat the various series as a batch dimension\n            mod_timesteps = self.layer_timesteps[i]\n            # [batch, series, time steps, embedding]\n            data = data.flatten(start_dim=0, end_dim=1)\n            # [batch * series, time steps, embedding]\n            data = data.transpose(0, 1)\n            # [time steps, batch * series, embedding] Correct order for PyTorch module\n            data = mod_timesteps(data)\n            data = data.transpose(0, 1)\n            # [batch * series, time steps, embedding]\n            data = data.unflatten(dim=0, sizes=(num_batches, num_series))\n            # [batch, series, time steps, embedding]\n\n            # Treat the various time steps as a batch dimension\n            mod_series = self.layer_series[i]\n            data = data.transpose(0, 1)\n            # [series, batch, time steps, embedding]\n            data = data.flatten(start_dim=1, end_dim=2)\n            # [series, batch * time steps, embedding] Correct order for PyTorch module\n            data = mod_series(data)\n            data = data.unflatten(dim=1, sizes=(num_batches, num_timesteps))\n            # [series, batch, time steps, embedding]\n            data = data.transpose(0, 1)\n            # [batch, series, time steps, embedding]\n\n        # The resulting tensor may not be contiguous, which can cause problems further down the line.\n        output = data.contiguous()\n\n        return output\n"}