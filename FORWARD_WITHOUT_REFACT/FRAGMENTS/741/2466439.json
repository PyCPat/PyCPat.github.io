{"BEFORE":"        pool=\"mean\",\n        dropout=0.0,\n        emb_dropout=0.0,\n        num_classes=64,\n    ):\n        super(ViT, self).__init__()\n\n        image_height, image_width = image_size, image_size\n        patch_height, patch_width = patch_size, patch_size\n\n        assert (\n            image_height % patch_height == 0 and image_width % patch_width == 0\n        ), \"Image dimensions must be divisible by the patch size.\"\n\n        num_patches = (image_height \/\/ patch_height) * (image_width \/\/ patch_width)\n        patch_dim = channels * patch_height * patch_width\n\n        self.to_patch_embedding = nn.Sequential(\n            # Rearrange(patch_height, patch_width),\n            Rearrange(\n                \"b c (h p1) (w p2) -> b (h w) (p1 p2 c)\",\n                p1=patch_height,\n                p2=patch_width,\n            ),\n            nn.Linear(patch_dim, dim),\n        )\n\n        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n        self.dropout = nn.Dropout(emb_dropout)\n\n        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n\n        self.pool = pool\n        self.to_latent = nn.Identity()\n\n        self.mlp_head = nn.Sequential(nn.LayerNorm(dim), nn.Linear(dim, num_classes))\n","AFTER":"        super().__init__()\n        image_height, image_width = pair(image_size)\n        patch_height, patch_width = pair(patch_size)\n\n        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n\n        num_patches = (image_height \/\/ patch_height) * (image_width \/\/ patch_width)\n        patch_dim = channels * patch_height * patch_width\n        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n"}