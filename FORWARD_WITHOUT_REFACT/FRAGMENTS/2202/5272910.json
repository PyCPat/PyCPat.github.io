{"BEFORE":"            self.season_params = nn.ParameterDict({})\n            for name, dim in self.season_dims.items():\n                self.season_params[name] = new_param(dims=[dim])\n            # self.season_params_vec = torch.cat([self.season_params[name] for name in self.season_params.keys()])\n\n        ## Autoregression\n        self.n_lags = n_lags\n","AFTER":"                 covar_config=None,\n                 ):\n        \"\"\"\n        Args:\n            n_forecasts (int): number of steps to forecast. Aka number of model outputs.\n            n_lags (int): number of previous steps of time series used as input. Aka AR-order.\n                0 (default): no auto-regression\n            n_changepoints (int): number of trend changepoints.\n                0 (default): no changepoints\n            trend_smoothness (int\/float): how much to regularize the trend changepoints\n                0 (default): segmentwise trend with continuity (individual k for each segment)\n                -1: discontinuous segmentwise trend (individual k, m for each segment)\n            num_hidden_layers (int): number of hidden layers (for AR-Net)\n                0 (default): no hidden layers, corresponds to classic Auto-Regression\n            d_hidden (int): dimensionality of hidden layers  (for AR-Net). ignored if no hidden layers.\n                None (default): sets to n_lags + n_forecasts\n            season_dims (OrderedDict(int)): ordered Dict with entries: <seasonality name>: vector dimension\n                None (default): No seasonality\n            season_mode (str): 'additive', 'multiplicative', how seasonality term is accounted for in forecast.\n                'additive' (default): add seasonality component to outputs of other model components\n            covar_config (list): Names of covariate variables.\n        \"\"\"\n        super(TimeNet, self).__init__()\n        ## General\n        self.n_forecasts = n_forecasts\n\n        ## Bias\n        self.forecast_bias = new_param(dims=[self.n_forecasts])\n\n        ## Trend\n        self.n_changepoints = n_changepoints\n        self.continuous_trend = True\n        self.segmentwise_trend = True\n        if trend_smoothness < 0:\n            self.continuous_trend = False\n        elif trend_smoothness > 0:\n            # compute trend delta-wise to allow for stable regularization.\n            # has issues with gradient bleedover to past.\n            self.segmentwise_trend = False\n        # changepoint times, including zero.\n        linear_t = np.arange(self.n_changepoints + 1).astype(float) \/ (self.n_changepoints + 1)\n        self.trend_changepoints_t = torch.tensor(linear_t, requires_grad=False, dtype=torch.float)\n        self.trend_k0 = new_param(dims=[1])\n        self.trend_m0 = new_param(dims=[1])\n        if self.n_changepoints > 0:\n            self.trend_deltas = new_param(dims=[self.n_changepoints + 1]) # including first segment\n            if not self.continuous_trend:\n                self.trend_m = new_param(dims=[self.n_changepoints + 1]) # including first segment\n\n        ## Seasonalities\n        self.season_dims = season_dims\n        self.season_mode = season_mode\n        if self.season_dims is not None:\n            if self.season_mode not in ['additive', 'multiplicative']:\n                raise NotImplementedError(\"Seasonality Mode {} not implemented\".format(self.season_mode))\n            self.season_params = nn.ParameterDict({\n                name: new_param(dims=[dim]) for name, dim in self.season_dims.items()\n            })\n            # self.season_params_vec = torch.cat([self.season_params[name] for name in self.season_params.keys()])\n\n        ## Autoregression\n        self.n_lags = n_lags\n        self.num_hidden_layers = num_hidden_layers\n        self.d_hidden = n_lags + n_forecasts if d_hidden is None else d_hidden\n        if self.n_lags > 0:\n            self.ar_net = nn.ModuleList()\n            d_inputs = self.n_lags\n            for i in range(self.num_hidden_layers):\n                self.ar_net.append(nn.Linear(d_inputs, self.d_hidden, bias=True))\n                d_inputs = d_hidden\n            self.ar_net.append(nn.Linear(d_inputs, self.n_forecasts, bias=False))\n            for lay in self.ar_net:\n                nn.init.kaiming_normal_(lay.weight, mode='fan_in')\n\n        ## Covariates\n        self.covariate_names = list(covar_config.keys())\n        if self.covariate_names is not None:\n            assert self.n_lags > 0\n            self.covar_nets = nn.ModuleDict({})\n            for covar in self.covariate_names:\n                # self.covariate_nets[covar] = new_param(dims=[self.n_forecasts, self.n_lags])\n                # self.covariate_nets[covar] = nn.Linear(self.n_lags, self.n_forecasts, bias=False)\n                covar_net = nn.ModuleList()\n                d_inputs = self.n_lags\n                for i in range(self.num_hidden_layers):\n                    covar_net.append(nn.Linear(d_inputs, self.d_hidden, bias=True))\n                    d_inputs = d_hidden\n                covar_net.append(nn.Linear(d_inputs, self.n_forecasts, bias=False))\n                for lay in covar_net:\n                    nn.init.kaiming_normal_(lay.weight, mode='fan_in')\n                self.covar_nets[covar] = covar_net\n\n    @property\n"}