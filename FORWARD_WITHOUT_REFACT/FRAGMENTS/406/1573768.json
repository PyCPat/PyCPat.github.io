{"BEFORE":"        batch_size = values.size(0)\n        query_length = queries.size(1)\n        value_length = values.size(1)\n\n        preserved = queries\n\n        queries = self.W(queries).view(batch_size, query_length, self.n_head, self.dim)\n        values = self.V(values).view(batch_size, value_length, self.n_head, self.dim)\n\n        queries = queries.permute(2, 0, 1, 3).contiguous().view(-1, query_length, self.dim)\n        values = values.permute(2, 0, 1, 3).contiguous().view(-1, value_length, self.dim)\n\n        attn_score = torch.bmm(queries, values.transpose(1, 2))\n        alignment = F.softmax(attn_score, dim=2)\n\n        attn_val = torch.bmm(alignment, values).view(self.n_head, batch_size, query_length, self.dim)\n        attn_val = attn_val.permute(1, 2, 0, 3).contiguous().view(batch_size, query_length, -1)\n\n        combined = torch.cat([attn_val, preserved], dim=2)\n        context = torch.tanh(self.fc(combined.view(-1, 2 * self.in_features))).view(batch_size, -1, self.in_features)\n","AFTER":"        batch_size = V.size(0)\n        residual = Q\n\n        q_s = self.W_Q(Q).view(batch_size, -1, self.num_head, self.dim)\n        v_s = self.W_V(V).view(batch_size, -1, self.num_head, self.dim)\n\n        q_s = q_s.permute(2, 0, 1, 3).contiguous().view(batch_size * self.num_head, -1, self.dim)\n        v_s = v_s.permute(2, 0, 1, 3).contiguous().view(batch_size * self.num_head, -1, self.dim)\n\n        attn_score = torch.bmm(q_s, v_s.transpose(1, 2))\n        align = F.softmax(attn_score, dim=2)\n\n        attn_val = torch.bmm(align, v_s).view(self.num_head, batch_size, -1, self.dim)\n        attn_val = attn_val.permute(1, 2, 0, 3).contiguous().view(batch_size, -1, self.num_head * self.dim)\n        combined = torch.cat([attn_val, residual], dim=2)\n\n        context = torch.tanh(self.fc(combined.view(-1, self.in_features + self.dim * self.num_head)))\n        context = context.view(batch_size, -1, self.in_features)\n"}