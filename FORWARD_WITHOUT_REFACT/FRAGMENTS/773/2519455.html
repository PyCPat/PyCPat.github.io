<link rel="stylesheet" href="../default.css">
<script src="../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        batch_size, seq_len, vocab_size = logits.shape
        loss = self.loss_fct(logits.view(-1, logits.size(-1)), labels.view(-1))
        loss = loss.view(batch_size, -1).sum(dim=-1) &#47&#47TODO support more objectives
        loss = <a id="change">loss.mean()</a>
        <a id="change">return </a>loss
    
    
    def generate(self, batch: Union[Dict, InputFeatures], **generation_kwargs):</code></pre><h3>After Change</h3><pre><code class='java'>
        if self.in_generation_function:
            return self.prompt_model.model.forward(*args, **kwargs)
        else:
            <a id="change">return </a><a id="change">self._forward(</a>*<a id="change">args, **kwargs)</a>

    def _forward(self, batch: Union[Dict, InputFeatures]) -&gt; torch.Tensor:
        r 
        This is the forward method of the training of generation in prompt-learning framework. </code></pre>