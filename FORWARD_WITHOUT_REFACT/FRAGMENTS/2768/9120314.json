{"BEFORE":"        pooled_out = self.pooler(out, attn_mask)\n\n        return self.proj(pooled_out)\n","AFTER":"        out = self.transformer(input_ids=x, attention_mask=attn_mask)\n        pooled_out = self.pooler(out, attn_mask)\n        projected = self.proj(pooled_out)\n\n        seq_len = out.last_hidden_state.shape[1]\n        tokens = (\n            out.last_hidden_state[:, torch.arange(seq_len) != self.pooler.cls_token_position, :] \n            if type(self.pooler) == ClsPooler \n            else out.last_hidden_state\n        )\n        \n        if self.output_tokens:\n            return projected, tokens\n        return projected\n"}