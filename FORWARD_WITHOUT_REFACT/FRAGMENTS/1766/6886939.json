{"BEFORE":"        ord_num = C \/\/ 2\n\n        A = x[:, ::2, :, :]\n        B = x[:, 1::2, :, :]\n\n        A = A.view(N, 1, ord_num * H * W)\n        B = B.view(N, 1, ord_num * H * W)\n        concat_feats = torch.cat((A, B), dim=1).contiguous()\n\n        if self.training:\n            ord_prob = F.log_softmax(concat_feats, dim=1)\n            return ord_prob.view(-1, ord_num, H, W)\n\n        ord_prob = F.softmax(C, dim=1)[:, 1, ::]\n        ord_prob = ord_prob.view(-1, ord_num, H, W)\n        ord_label = torch.sum((ord_prob > 0.5), dim=1).view(-1, 1, H, W)\n","AFTER":"        A = x[:, ::2, :, :]\n        B = x[:, 1::2, :, :]\n\n        # A = A.reshape(N, 1, ord_num * H * W)\n        # B = B.reshape(N, 1, ord_num * H * W)\n        A = A.unsqueeze(dim=1)\n        B = B.unsqueeze(dim=1)\n        concat_feats = torch.cat((A, B), dim=1)\n\n        if self.training:\n            prob = F.log_softmax(concat_feats, dim=1)\n            ord_prob = x.clone()\n            ord_prob[:, 0::2, :, :] = prob[:, 0, :, :, :]\n            ord_prob[:, 1::2, :, :] = prob[:, 1, :, :, :]\n            return ord_prob\n\n        ord_prob = F.softmax(concat_feats, dim=1)[:, 0, ::]\n        ord_label = torch.sum((ord_prob > 0.5), dim=1).reshape((N, 1, H, W))\n"}