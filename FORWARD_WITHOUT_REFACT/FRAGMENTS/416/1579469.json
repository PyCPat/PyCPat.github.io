{"BEFORE":"        unet_number = default(unet_number, 1)\n        assert 1 <= unet_number <= len(self.unets)\n\n        index = unet_number - 1\n        unet = self.unets[index]\n        target_image_size = self.image_sizes[index]\n\n        b, c, h, w, device, = *image.shape, image.device\n\n        check_shape(image, 'b c h w', c = self.channels)\n        assert h >= target_image_size and w >= target_image_size\n\n        times = torch.randint(0, self.num_timesteps, (b,), device = device, dtype = torch.long)\n\n        if not exists(image_embed):\n            image_embed = self.get_image_embed(image)\n\n        text_encodings = self.get_text_encodings(text) if exists(text) and not exists(text_encodings) else None\n\n        lowres_cond_img = image if index > 0 else None\n","AFTER":"        unet_number = default(unet_number, 1)\n\n        unet = self.get_unet(unet_number)\n\n        target_image_size = self.image_sizes[unet_number - 1]\n\n        b, c, h, w, device, = *image.shape, image.device\n\n        check_shape(image, 'b c h w', c = self.channels)\n        assert h >= target_image_size and w >= target_image_size\n\n        times = torch.randint(0, self.num_timesteps, (b,), device = device, dtype = torch.long)\n\n        if not exists(image_embed):\n            image_embed = self.get_image_embed(image)\n\n        text_encodings = self.get_text_encodings(text) if exists(text) and not exists(text_encodings) else None\n\n        lowres_cond_img = image if unet_number > 1 else None\n"}