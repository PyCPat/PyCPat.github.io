{"BEFORE":"        box_features = self.box_head(box_features)\n\n        num_boxes = [len(boxes_per_image) for boxes_per_image in box_coords]\n        \n        counter = 0\n        all_boxes_h = []; all_boxes_o = []; all_object_class = []\n        all_labels = []; all_prior = []\n        all_box_pair_features = []\n        for b_idx, (coords, labels, scores) in enumerate(zip(box_coords, box_labels, box_scores)):\n            n = num_boxes[b_idx]\n            device = box_features.device\n\n            human_box_idx = torch.nonzero(labels == self.human_idx).squeeze(1).tolist()\n            n_h = len(human_box_idx)\n            # Skip image when there are no detected human or object instances\n            if n_h == 0 or n == 0:\n                continue\n            if n_h == n:\n                node_encodings = box_features[counter: counter+n]\n            else:\n                # Permute the boxes so that humans are on the top\n                permutation = torch.cat([\n                    torch.as_tensor(human_box_idx, device=device),\n                    torch.as_tensor([i for i in range(n) if i not in human_box_idx], device=device)\n                ])\n                coords = coords[permutation]\n                labels = labels[permutation]\n                scores = scores[permutation]\n                node_encodings = box_features[counter: counter+n][permutation]\n\n            # Duplicate human nodes\n            h_node_encodings = node_encodings[:n_h]\n","AFTER":"            n_h = torch.sum(labels == self.human_idx).item()\n            # Skip image when there are no detected human or object instances\n            if n_h == 0 or n == 0:\n                continue\n            if not torch.all(labels[:n_h]==self.human_idx):\n                raise AssertionError(\"Human detections are not permuted to the top\")\n\n            node_encodings = box_features[counter: counter+n]\n"}