{"BEFORE":"        mask = self.create_padding_mask(X_time)\n\n        # apply dropout for output from positional encoding\n        x = self.pos_enc_dropout(X_features)\n\n        # embed 36 features into 64 to be consistent with other baselines\n        x = self.linear_embedding(x)\n\n        # pass through transformer encoder layer\n        x = self.encoder_layer(x, src_key_padding_mask=mask)\n\n        # concatenate static features to the matrix (add additional row with the size 64)\n        static_x = self.static_feed_forward(X_static).unsqueeze(1)\n        x = torch.cat((x, static_x), dim=1)\n\n        # take the mean of all time steps (rows) with additional row for static features; output size = (batch_size, 64)\n        x = torch.mean(x, 1)\n","AFTER":"        mask, time_length = self.create_padding_mask(X_time)\n\n        # apply dropout for output from positional encoding\n        x = self.pos_enc_dropout(X_features)\n\n        # embed 36 features into 64 to be consistent with other baselines\n        x = self.linear_embedding(x)\n\n        # pass through transformer encoder layer\n        x = self.encoder_layer(x, src_key_padding_mask=mask)\n\n        # concatenate static features to the matrix (add additional row with the size 64)\n        static_x = self.static_feed_forward(X_static).unsqueeze(1)\n        x = torch.cat((x, static_x), dim=1)\n\n        # # take the mean of all time steps (rows) with additional row for static features; output size = (batch_size, 64)\n        # x = torch.mean(x, 1)\n\n        # take the masked mean of all time steps (rows) with additional row for static features; output size = (batch_size, 64)\n        mask = torch.cat((mask, torch.ones((x.size()[0], 1), dtype=torch.bool)), dim=1).unsqueeze(2).long()\n        time_length = torch.FloatTensor(time_length).unsqueeze(1)\n        x = torch.sum(x * (1 - mask), dim=1) \/ (time_length + 1)    # masked aggregation\n"}