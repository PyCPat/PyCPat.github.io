{"BEFORE":"        weakDiversityLoss = list()\n        weakFeatureLoss = list()\n\n        for features, quantizeds, codebooks in zip(allFeatures, allQuantizeds, allCodebooks):\n            for codebook in codebooks:\n                # [k, k] := [k, c] @ [c, k]\n                innerProduct = codebook @ codebook.T\n                # orthogonal regularization\n                weakCodebookLoss.append(self._auxLoss(innerProduct, torch.eye(innerProduct.shape[0], device=innerProduct.device, dtype=innerProduct.dtype)))\n            m = len(features)\n            for i in range(m):\n                for j in range(i + 1, m):\n                    # [n, h, w] := ([n, h, w, c] * [n, h, w, c]).sum(-1)\n                    interProduct = (features[i] * features[j]).sum(-1)\n                    # feature from different group should be orthogonal\n                    weakFeatureLoss.append(2 * self._auxLoss(interProduct, torch.zeros_like(interProduct)))\n                intraProduct = (features[i] * features[i]).sum(1)\n                # weakDiversityLoss.append(F.mse_loss(quantizeds[i], features[i].detach()))\n                weakFeatureLoss.append(self._auxLoss(intraProduct, torch.ones_like(intraProduct)))\n\n        # self._movingMean -= 0.9 * (self._movingMean - ssimLoss.mean())\n        # pLoss = self._pLoss(image, restored)\n        return dLoss, (sum(weakCodebookLoss), sum(weakFeatureLoss), 0.0), (restored, allTrues, allLogits)\n","AFTER":"        for raws, codes, codebooks, k, logits, spread in zip(allFeatures, allCodes, allCodebooks, self._k, allLogits, self._spreadLoss):\n            for raw, code, codebook, logit in zip(raws, codes, codebooks, logits):\n                # weakFeatureLoss.append(self._alignLoss(raw, F.one_hot(code, k).float(), codebook))\n                weakCodebookLoss.append(spread(codebook))\n                # weakCodebookLoss.append(self._l2Reg(raw, -1))\n\n        return dLoss, (sum(weakCodebookLoss), 0.0, 0.0), (restored, allTrues, allLogits)\n"}