{"BEFORE":"            ngu = self.ng.repeat((1, self.na * self.nx * self.ny, 1))\n            grid_xy = self.grid_xy.repeat((1, self.na, 1, 1, 1)).view((1, -1, 2))\n            anchor_wh = self.anchor_wh.repeat((1, 1, self.nx, self.ny, 1)).view((1, -1, 2)) \/ ngu\n\n            # p = p.view(-1, 5 + self.nc)\n            # xy = torch.sigmoid(p[..., 0:2]) + grid_xy[0]  # x, y\n            # wh = torch.exp(p[..., 2:4]) * anchor_wh[0]  # width, height\n            # p_conf = torch.sigmoid(p[:, 4:5])  # Conf\n            # p_cls = F.softmax(p[:, 5:85], 1) * p_conf  # SSD-like conf\n            # return torch.cat((xy \/ ngu[0], wh, p_conf, p_cls), 1).t()\n\n            p = p.view(1, -1, 5 + self.nc)\n            xy = torch.sigmoid(p[..., 0:2]) + grid_xy  # x, y\n            wh = torch.exp(p[..., 2:4]) * anchor_wh  # width, height\n            p_conf = torch.sigmoid(p[..., 4:5])  # Conf\n            p_cls = p[..., 5:5 + self.nc]\n            # Broadcasting only supported on first dimension in CoreML. See onnx-coreml\/_operators.py\n            # p_cls = F.softmax(p_cls, 2) * p_conf  # SSD-like conf\n            p_cls = torch.exp(p_cls).permute((2, 1, 0))\n            p_cls = p_cls \/ p_cls.sum(0).unsqueeze(0) * p_conf.permute((2, 1, 0))  # F.softmax() equivalent\n            p_cls = p_cls.permute(2, 1, 0)\n            return torch.cat((xy \/ ngu, wh, p_conf, p_cls), 2).squeeze().t()\n","AFTER":"            ngu = self.ng.repeat((1, self.na * self.nx * self.ny, 1))\n            grid_xy = self.grid_xy.repeat((1, self.na, 1, 1, 1)).view((1, -1, 2))\n            anchor_wh = self.anchor_wh.repeat((1, 1, self.nx, self.ny, 1)).view((1, -1, 2)) \/ ngu\n\n            p = p.view(-1, 5 + self.nc)\n            xy = torch.sigmoid(p[..., 0:2]) + grid_xy[0]  # x, y\n            wh = torch.exp(p[..., 2:4]) * anchor_wh[0]  # width, height\n            p_conf = torch.sigmoid(p[:, 4:5])  # Conf\n            p_cls = F.softmax(p[:, 5:85], 1) * p_conf  # SSD-like conf\n            return torch.cat((xy \/ ngu[0], wh, p_conf, p_cls), 1).t()\n"}