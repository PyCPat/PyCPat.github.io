{"BEFORE":"    def forward(self, x, edge_index):\n        \"\"\"\n        Making a forward pass. This is one ASTGCN block.\n        B is the batch size. N_nodes is the number of nodes in the graph. F_in is the dimension of input features. \n        T_in is the length of input sequence in time. T_out is the length of output sequence in time.\n        nb_time_filter is the number of time filters used.\n        Arg types:\n            * x (PyTorch Float Tensor) - Node features for T time periods, with shape (B, N_nodes, F_in, T_in).\n            * edge_index (Tensor): Edge indices, can be an array of a list of Tensor arrays, depending on whether edges change over time.\n\n        Return types:\n            * output (PyTorch Float Tensor) - Hidden state tensor for all nodes, with shape (B, N_nodes, nb_time_filter, T_out).\n        \"\"\"\n        batch_size, num_of_vertices, num_of_features, num_of_timesteps = x.shape\n\n        # TAt\n        temporal_At = self._temporal_attention(x)  # (b, T, T)\n\n        x_TAt = torch.matmul(x.reshape(batch_size, -1, num_of_timesteps), temporal_At).reshape(batch_size, num_of_vertices, num_of_features, num_of_timesteps)\n\n        # SAt\n        spatial_At = self._spatial_attention(x_TAt)\n\n        # cheb gcn\n        if not isinstance(edge_index, list):\n            data = Data(edge_index=edge_index, edge_attr=None, num_nodes=num_of_vertices)\n            lambda_max = LaplacianLambdaMax()(data).lambda_max\n            outputs = []\n            for time_step in range(num_of_timesteps):\n                outputs.append(torch.unsqueeze(self._chebconv_attention(x[:,:,:,time_step], edge_index, spatial_At, lambda_max = lambda_max), -1))\n    \n            spatial_gcn = F.relu(torch.cat(outputs, dim=-1)) # (b,N,F,T) # (b,N,F,T)        \n        else: # edge_index changes over time\n            outputs = []\n            for time_step in range(num_of_timesteps):\n                data = Data(edge_index=edge_index[time_step], edge_attr=None, num_nodes=num_of_vertices)\n                lambda_max = LaplacianLambdaMax()(data).lambda_max\n                outputs.append(torch.unsqueeze(self._chebconv_attention(x=x[:,:,:,time_step], edge_index=edge_index[time_step],\n                    spatial_attention=spatial_At,lambda_max=lambda_max), -1))\n            spatial_gcn = F.relu(torch.cat(outputs, dim=-1)) # (b,N,F,T)\n            \n        # convolution along the time axis\n        time_conv_output = self.time_conv(spatial_gcn.permute(0, 2, 1, 3))  # (b,N,F,T)->(b,F,N,T) use kernel size (1,3)->(b,F,N,T)\n\n        # residual shortcut\n        x_residual = self.residual_conv(x.permute(0, 2, 1, 3))  # (b,N,F,T)->(b,F,N,T) use kernel size (1,1)->(b,F,N,T)\n\n        x_residual = self.ln(F.relu(x_residual + time_conv_output).permute(0, 3, 2, 1)).permute(0, 2, 3, 1)\n        # (b,F,N,T)->(b,T,N,F) -ln-> (b,T,N,F)->(b,N,F,T)\n\n        return x_residual\n","AFTER":"    def forward(self, X: torch.FloatTensor, edge_index: torch.LongTensor):\n        \"\"\"\n        Making a forward pass. This is one ASTGCN block.\n        B is the batch size. N_nodes is the number of nodes in the graph. F_in is the dimension of input features. \n        T_in is the length of input sequence in time. T_out is the length of output sequence in time.\n        nb_time_filter is the number of time filters used.\n        Arg types:\n            * x (PyTorch Float Tensor) - Node features for T time periods, with shape (B, N_nodes, F_in, T_in).\n            * edge_index (LongTensor): Edge indices, can be an array of a list of Tensor arrays, depending on whether edges change over time.\n\n        Return types:\n            * output (PyTorch Float Tensor) - Hidden state tensor for all nodes, with shape (B, N_nodes, nb_time_filter, T_out).\n        \"\"\"\n        batch_size, num_of_vertices, num_of_features, num_of_timesteps = X.shape\n\n        X_tilde = self._temporal_attention(X)\n        X_tilde = torch.matmul(X.reshape(batch_size, -1, num_of_timesteps), X_tilde)\n        X_tilde = X_tilde.reshape(batch_size, num_of_vertices, num_of_features, num_of_timesteps)\n        X_tilde = self._spatial_attention(X_tilde)\n\n        if not isinstance(edge_index, list):\n            data = Data(edge_index=edge_index, edge_attr=None, num_nodes=num_of_vertices)\n            lambda_max = LaplacianLambdaMax()(data).lambda_max\n            X_hat = []\n            for t in range(num_of_timesteps):\n                X_hat.append(torch.unsqueeze(self._chebconv_attention(X[:,:,:,t], edge_index, X_tilde, lambda_max=lambda_max), -1))\n    \n            X_hat = F.relu(torch.cat(X_hat, dim=-1))       \n        else:\n            X_hat = []\n            for t in range(num_of_timesteps):\n                data = Data(edge_index=edge_index[t], edge_attr=None, num_nodes=num_of_vertices)\n                lambda_max = LaplacianLambdaMax()(data).lambda_max\n                X_hat.append(torch.unsqueeze(self._chebconv_attention(x=x[:,:,:,t], edge_index=edge_index[t], patial_attention=X_tilde,lambda_max=lambda_max), -1))\n            X_hat = F.relu(torch.cat(X_hat, dim=-1))\n\n        X_hat = self._time_convolution(X_hat.permute(0, 2, 1, 3))\n        X = self._residual_convolution(X.permute(0, 2, 1, 3))\n        X = self._layer_norm(F.relu(X + X_hat).permute(0, 3, 2, 1))\n        X = X.permute(0, 2, 3, 1)\n        return X\n"}