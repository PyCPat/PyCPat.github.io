{"BEFORE":"    def forward(self, x, lengths):\n        x, lengths = self.conv_subsampling(x, lengths)\n        x = self.input_projection(x)\n        x = self.layers(x)\n        return x, lengths\n","AFTER":"    def forward(self, inputs: Tensor, input_lengths: Tensor) -> Tuple[Tensor, Tensor]:\n        \"\"\"\n        Forward propagate a `inputs` for  encoder training.\n        Args:\n            inputs (torch.FloatTensor): A input sequence passed to encoder. Typically for inputs this will be a padded\n                `FloatTensor` of size ``(batch, seq_length, dimension)``.\n            input_lengths (torch.LongTensor): The length of input tensor. ``(batch)``\n        Returns:\n            (Tensor, Tensor)\n            * outputs (torch.FloatTensor): A output sequence of encoder. `FloatTensor` of size\n                ``(batch, seq_length, dimension)``\n            * output_lengths (torch.LongTensor): The length of output tensor. ``(batch)``\n        \"\"\"\n        outputs, output_lengths = self.conv_subsample(inputs, input_lengths)\n        outputs = self.input_dropout(outputs)\n\n        for layer in self.layers:\n            outputs = layer(outputs)\n\n        return outputs, output_lengths\n"}