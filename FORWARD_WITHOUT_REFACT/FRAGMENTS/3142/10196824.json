{"BEFORE":"        x = self._randomize(x)\n\n        # Apply leaf distributions (replace marginalization indicators with 0.0 first)\n        x = self._leaf(x)\n\n        # Pass through intermediate layers\n        x = self._forward_layers(x)\n\n        # Merge results from the different repetitions into the channel dimension\n        batch_size, features, channels, repetitions = x.size()\n        assert features == 1  # number of features should be 1 at this point\n        assert channels == 1  # number of channels should be 1 at this point\n        x = x.view(batch_size, 1, repetitions, 1)\n","AFTER":"    def forward(self, x: torch.Tensor, marginalization_mask: torch.Tensor = None) -> torch.Tensor:\n        \"\"\"\n        Forward pass through RatSpn. Computes the conditional log-likelihood P(X | C).\n\n        Args:\n            x: Input.\n            marginalization_mask: Leaf marginalization mask. True indicates, that the specific scope\n                is missing.\n\n        Returns:\n            Log-likelihood tensor of the input: p(X) or p(X | C) if number of classes > 1.\n        \"\"\"\n        # Apply leaf distributions (replace marginalization indicators with 0.0 first)\n        x = self._leaf(x, marginalization_mask)\n\n        # Pass through intermediate layers\n        x = self._forward_layers(x)\n\n        # Merge results from the different repetitions into the channel dimension\n        batch_size, features, channels, repetitions = x.size()\n        assert features == 1  # number of features should be 1 at this point\n        assert channels == self.config.C\n\n        # Treat repetitions as additional channels at this point\n        x = x.reshape(batch_size, 1, channels * repetitions, 1)\n"}