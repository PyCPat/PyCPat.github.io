{"BEFORE":"        ner_score = self.get_ner_score(output_lstm)\n        # print(\"hello0\")\n        # 下面是使用CFR\n        crf_model = CRF(self.num_token_type, batch_first=True)\n        if USE_CUDA:\n            crf_model = crf_model.cuda()\n        if not is_test:\n            log_likelihood = crf_model(ner_score, data_item['token_type_list'].to(torch.int64),\n                                       mask=data_item['mask_tokens'])\n            loss_ner = -log_likelihood\n            \n        pred_ner = crf_model.decode(ner_score)  # , mask=data_item['mask_tokens']\n","AFTER":"        ner_score = self.get_ner_score(output_lstm)\n        # print(\"hello0\")\n        # 下面是使用CFR\n        \n        if USE_CUDA:\n            self.crf_model = self.crf_model.cuda()\n        if not is_test:\n            log_likelihood = self.crf_model(ner_score, data_item['token_type_list'].to(torch.int64),\n                                       mask=data_item['mask_tokens'])\n            loss_ner = -log_likelihood\n            \n        pred_ner = self.crf_model.decode(ner_score)  # , mask=data_item['mask_tokens']\n        \n        # 下面使用的是Softmax\n        # loss_ner = F.softmax(ner_score, data_item['ner_type'])\n        # pred_ner = torch.argmax(ner_score, 2)\n        \n        #--------------------------Relation\n        if not is_test and torch.rand(1) > self.config.teach_rate:\n            labels = data_item['token_type_list']\n        else:\n            if USE_CUDA:\n                labels = torch.Tensor(pred_ner).cuda()\n            else:\n                labels = torch.Tensor(pred_ner)\n        # print(\"hello1\")\n        label_embeddings = self.token_type_embedding(labels.to(torch.int64))\n        rel_input = torch.cat((output_lstm, label_embeddings), 2)\n        rel_score_matrix = self.getHeadSelectionScores(rel_input)  # [batch, seq_len, seq_len, num_relation]\n        rel_score_prob = torch.sigmoid(rel_score_matrix)\n        #gold_predicate_matrix_one_hot = F.one_hot(data_item['pred_rel_matrix'], len(self.config.relations))\n        if not is_test:\n            # 这样计算交叉熵有问题吗\n            # 交叉熵计算不适用 rel_score_prob， 应该是rel_score_matrix\n            loss_rel = F.cross_entropy(rel_score_prob.permute(0, 3, 1, 2), data_item['pred_rel_matrix'], self.weights_rel)  # 要把分类放在第二维度\n            loss_rel *= rel_score_prob.shape[1]\n"}