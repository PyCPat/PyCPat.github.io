{"BEFORE":"\t\tembed_enc_inputs = self.Embedding(x)\n\t\tembed = embed_enc_inputs.size(2)\n\t\talready_played_action_mask = torch.zeros(batch, city_t).to(device)\n\t\tenc_h, (dec_h0, dec_c0) = self.Encoder(embed_enc_inputs, None)\n\t\tdec_state = (dec_h0, dec_c0)\n\t\tpred_tour_list, neg_log = [], 0\n\t\tdec_i1 = torch.rand(batch, 1, embed).to(device)\n\t\tfor i in range(city_t):\n\t\t\tdec_h, dec_state = self.Decoder(dec_i1, dec_state)\n\t\t\tlogits, probs, dec_i1 = self.pointing_mechanism(\n\t\t\t\t\t\t\t\tenc_h, dec_h, embed_enc_inputs, already_played_action_mask)\n\t\t\tnext_city_index = torch.argmax(logits, dim=1)\n\t\t\tpred_tour_list.append(next_city_index)\n\t\t\tneg_log += self.CEL(input = logits, target = next_city_index)\n\t\t\t'''\n\t\t\tinput(batch, class), target(batch);target value:0 ~ class-1)\n\t\t\tlogits(batch,city_t) -> next_city_index(batch);value:0 ~ 20\n\t\t\tneg_log is for calculating log part of gradient policy equation \n\t\t\t'''\n\t\t\talready_played_action_mask += torch.zeros(batch,city_t).to(device).scatter_(\n\t\t\t\t\t\t\tdim = 1, index = torch.unsqueeze(next_city_index, dim = 1),value = 1)\n\t\t\n\t\tpred_tour = torch.stack(pred_tour_list, dim = 1)\n\t\t'''\n\t\ta list of tensors -> pred_tour;tensor(batch,city_t)\n\t\t# ~ pred_tour = torch.LongTensor(pred_tour_list)#pred_tour = torch.tensor(pred_tour_list)\n\t\t# ~ for i in range(city_t):\n\t\t\t# ~ neg_log += self.CEL(input = logits, target = pred_tour[:,i])\n\t\t'''\n\t\treturn pred_tour, neg_log \n","AFTER":"\t\tmask = torch.zeros(batch, city_t).to(device)\n\t\tenc_h, (h, c) = self.Encoder(embed_enc_inputs, None)\n\t\tpi_list, log_ps = [], []\n\t\tdec_input = self.dec_input.unsqueeze(0).repeat(batch,1).unsqueeze(1).to(device)\n\t\tfor i in range(city_t):\n\t\t\t_, (h, c) = self.Decoder(dec_input, (h, c))\n\t\t\tquery, ref = h.squeeze(0), enc_h\n\t\t\tfor i in range(self.n_glimpse):\n\t\t\t\tquery = self.glimpse(query, ref, mask)\n\t\t\tlogits, dec_input = self.pointer(query, ref, mask)\t\n\t\t\tlog_p = torch.log_softmax(logits, dim = -1)\n\t\t\t# next_node = torch.argmax(log_p, dim = 1).type(torch.long)\n\t\t\tnext_node = torch.multinomial(log_p.exp(), 1).type(torch.long).squeeze(1)\n\t\t\t\n\t\t\tpi_list.append(next_node)\n\t\t\tlog_ps.append(log_p)\n\t\t\tmask += torch.zeros(batch,city_t).to(device).scatter_(dim = 1, index = next_node.unsqueeze(1), value = 1)\n\t\t\t\n\t\tpi = torch.stack(pi_list, dim = 1)\n\t\tll = self.get_log_likelihood(torch.stack(log_ps, 1), pi)\n\t\treturn pi, ll \n"}