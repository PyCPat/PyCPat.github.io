{"BEFORE":"        self.hidden_units = [400, 300, 200, 100, 50]\n        if trial is not None:\n            for i in range(0, 5):\n                self.hidden_units[i] = trial.suggest_int(\n                    f\"fc{i+2}_input_dim\", self.min_dim, self.max_dim\n                )\n\n        print(f\"input dimentsions: {self.hidden_units}\")\n        self.fc1 = nn.Linear(self.pose, self.hidden_units[0])\n        self.fc2 = nn.Linear(self.hidden_units[0], self.hidden_units[1])\n        self.fc3 = nn.Linear(self.hidden_units[1], self.hidden_units[2])\n        self.fc4 = nn.Linear(self.hidden_units[2], self.hidden_units[3])\n        self.fc5 = nn.Linear(self.hidden_units[3], self.hidden_units[4])\n        self.fc6 = nn.Linear(self.hidden_units[4], self.dof)\n","AFTER":"        self.hidden_units = [400, 300, 200, 100, 50]\n        self.dropout_ratios = [0.0] * 5\n        if trial is not None:\n            for i in range(0, 5):\n                self.hidden_units[i] = trial.suggest_int(\n                    f\"fc{i+2}_input_dim\", self.min_dim, self.max_dim\n                )\n\n        print(f\"input dimentsions: {self.hidden_units}\")\n        layers = []\n        input_dim = self.pose\n        for output_dim in self.hidden_units:\n            layers.append(nn.Linear(input_dim, output_dim))\n            layers.append(nn.ReLU())\n            input_dim = output_dim\n        layers.append(nn.Linear(input_dim, self.dof))\n        self.layers = nn.Sequential(*layers)\n"}