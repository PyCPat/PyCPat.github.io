<link rel="stylesheet" href="../default.css">
<script src="../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        return self
    
    def forward(self, sample):
        <a id="change">if type(sample) == dict</a><a id="change">:
            </a>x = sample[&quotimage&quot]
            dh = sample[&quotdepth&quot]
        else:
            x<a id="change">, dh = sample</a>

        B, _, H, W = x.shape
            
        x = torch.cat([x, dh], dim=1)
        x = self.reduce(x)
        
        dh1 = self.pyr.down(dh)
        dh2 = self.pyr.down(dh1)
        dh3 = self.pyr.down(dh2)
            
        B, _, H, W = x.shape
        x1, x2, x3, x4, x5 = self.backbone(x)
        
        x1 = self.context1(x1) &#47&#474
        x2 = self.context2(x2) &#47&#474
        x3 = self.context3(x3) &#47&#478
        x4 = self.context4(x4) &#47&#4716
        x5 = self.context5(x5) &#47&#4732

        f3, d3 = self.decoder(x5, x4, x3) &#47&#4716

        f3 = self.res(f3, (H // 4,  W // 4 ))
        f2, _ = self.attention2_1(torch.cat([x2, f3], dim=1), d3.detach())
        f2, p2 = self.attention2_2(torch.cat([f2, f3], dim=1), dh3)
        d2 = self.pyr.rec(d3.detach(), p2) &#47&#474

        x1 = self.res(x1, (H // 2, W // 2))
        f2 = self.res(f2, (H // 2, W // 2))
        f1, _ = self.attention1_1(torch.cat([x1, f2], dim=1), d2.detach()) &#47&#472
        f1, p1 = self.attention1_2(torch.cat([f1, f2], dim=1), dh2) &#47&#472
        d1 = self.pyr.rec(d2.detach(), p1) &#47&#472
        
        f1 = self.res(f1, (H, W))
        f1, _ = self.attention0_1(f1, d1.detach()) &#47&#472
        f1, p0 = self.attention0_2(f1, dh1) &#47&#472
        d0 = self.pyr.rec(d1.detach(), p0) &#47&#472
        
        if type(sample) == dict and &quotgt&quot in sample.keys() and sample[&quotgt&quot] is not None:
            y = sample[&quotgt&quot]
            
            y1 = self.pyr.down(y)
            y2 = self.pyr.down(y1)
            y3 = self.pyr.down(y2)

            ploss =  self.pyramidal_consistency_loss_fn(self.des(d3, (H, W)), self.des(self.pyr.down(d2), (H, W)).detach()) * 0.0001
            ploss += self.pyramidal_consistency_loss_fn(self.des(d2, (H, W)), self.des(self.pyr.down(d1), (H, W)).detach()) * 0.0001
            ploss += self.pyramidal_consistency_loss_fn(self.des(d1, (H, W)), self.des(self.pyr.down(d0), (H, W)).detach()) * 0.0001
            
            closs =  self.loss_fn(self.des(d3, (H, W)), self.des(y3, (H, W)))
            closs += self.loss_fn(self.des(d2, (H, W)), self.des(y2, (H, W)))
            closs += self.loss_fn(self.des(d1, (H, W)), self.des(y1, (H, W)))
            closs += self.loss_fn(self.des(d0, (H, W)), self.des(y, (H, W)))
            
            loss = ploss + closs

        else:
            loss = 0

        <a id="change">if type(sample) == dict</a><a id="change">:
            return </a><a id="change">{</a>&quotpred&quot: d0, 
                    &quotloss&quot: loss, 
                    &quotgaussian&quot: <a id="change">[</a>d3, d2, d1, <a id="change">d0</a>], 
                    &quotlaplacian&quot: <a id="change">[</a>p2, p1, p0<a id="change"></a>]<a id="change">}</a>
        
        else:
            <a id="change">return d0</a>
    
    
def InSPyReNetV4_Res2Net50(depth, pretrained, base_size, **kwargs):
    return InSPyReNetV4(res2net50_v1b_26w_4s(pretrained=pretrained), [64, 256, 512, 1024, 2048], depth, base_size, **kwargs)</code></pre><h3>After Change</h3><pre><code class='java'>
        f1 = self.res(f1, (H, W))
        f1, _ = self.attention0_1(f1, d1.detach()) &#47&#472
        f1, p0 = self.attention0_2(f1, dh1) &#47&#472
        <a id="change">d0</a> = self.pyr.rec(d1.detach(), p0) &#47&#472
        
        if type(sample) == dict and &quotgt&quot in sample.keys() and sample[&quotgt&quot] is not None:
            y = sample[&quotgt&quot]
            
            y1 = self.pyr.down(y)
            y2 = self.pyr.down(y1)
            y3 = self.pyr.down(y2)

            ploss =  self.pyramidal_consistency_loss_fn(self.des(d3, (H, W)), self.des(self.pyr.down(d2), (H, W)).detach()) * 0.0001
            ploss += self.pyramidal_consistency_loss_fn(self.des(d2, (H, W)), self.des(self.pyr.down(d1), (H, W)).detach()) * 0.0001
            ploss += self.pyramidal_consistency_loss_fn(self.des(d1, (H, W)), self.des(self.pyr.down(d0), (H, W)).detach()) * 0.0001
            
            closs =  self.loss_fn(self.des(d3, (H, W)), self.des(y3, (H, W)))
            closs += self.loss_fn(self.des(d2, (H, W)), self.des(y2, (H, W)))
            closs += self.loss_fn(self.des(d1, (H, W)), self.des(y1, (H, W)))
            closs += self.loss_fn(self.des(d0, (H, W)), self.des(y, (H, W)))
            
            loss = ploss + closs

        else:
            loss = 0

        <a id="change">sample[&quotpred&quot] = d0</a>
        <a id="change">sample[&quotloss&quot] = </a>loss
        <a id="change">sample[&quotgaussian&quot] = </a><a id="change">[</a>d3, d2, d1, <a id="change">d0</a>]
        <a id="change">sample[&quotlaplacian&quot] = </a><a id="change">[</a>p2, p1, p0<a id="change"></a>]
        <a id="change">return sample</a>

    
    
def InSPyReNetV4_Res2Net50(depth, pretrained, base_size, **kwargs):</code></pre>