<link rel="stylesheet" href="../default.css">
<script src="../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        nn.init.constant_(self.bias, val=0)
        
    def forward(self, x, node_embeddings):
        <a id="change">if len(node_embeddings.shape)==2</a><a id="change">:
            </a>node_num = node_embeddings.shape[0]
            supports<a id="change"> = </a>F.softmax(F.relu(torch.mm(node_embeddings, node_embeddings.transpose(0, 1))), dim=1)
        else:
            node_num = node_embeddings.shape[1]
            supports = F.softmax(F.relu(torch.einsum(&quotbnc,bmc-&gt;nm&quot, node_embeddings, node_embeddings)), dim=1)            </code></pre><h3>After Change</h3><pre><code class='java'>
            support_ks = [torch.eye(support.shape[0]).to(support.device), support]
            for k in range(2, self.cheb_k):
                support_ks.append(torch.matmul(2 * support, support_ks[-1]) - support_ks[-2]) 
            <a id="change">support_set.extend(</a>support_ks<a id="change">)</a>
        for support in support_set:
            x_g.append(torch.einsum("nm,bmc-&gt;bnc", support, x))
        x_g = torch.cat(x_g, dim=-1) &#47&#47 B, N, 2 * cheb_k * dim_in
        x_gconv = torch.einsum(&quotbni,io-&gt;bno&quot, x_g, self.weights) + self.bias  &#47&#47 b, N, dim_out</code></pre>