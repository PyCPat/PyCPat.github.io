{"BEFORE":"                 num_heads=0, mlp_ratios=[0, 0, 0, 0], qkv_bias=True, qk_scale=None, drop_rate=0., attn_drop_rate=0.,\n                 drop_path_rate=0., norm_layer=partial(nn.LayerNorm, eps=1e-6),\n                 return_interm_layers=False, out_features = None, crpe_window=None, **kwargs):\n        super().__init__()\n        crpe_window = crpe_window or {3: 2, 5: 3, 7: 3}\n        self.return_interm_layers = return_interm_layers\n        self.out_features = out_features\n        self.num_classes = num_classes\n\n        # Patch embeddings.\n        self.patch_embed1 = PatchEmbed(\n            img_size=img_size, patch_size=patch_size, in_chans=in_chans,\n            embed_dim=embed_dims[0], norm_layer=nn.LayerNorm)\n        self.patch_embed2 = PatchEmbed(\n            img_size=img_size \/\/ 4, patch_size=2, in_chans=embed_dims[0],\n            embed_dim=embed_dims[1], norm_layer=nn.LayerNorm)\n        self.patch_embed3 = PatchEmbed(\n            img_size=img_size \/\/ 8, patch_size=2, in_chans=embed_dims[1],\n            embed_dim=embed_dims[2], norm_layer=nn.LayerNorm)\n        self.patch_embed4 = PatchEmbed(\n            img_size=img_size \/\/ 16, patch_size=2, in_chans=embed_dims[2],\n            embed_dim=embed_dims[3], norm_layer=nn.LayerNorm)\n\n        # Class tokens.\n        self.cls_token1 = nn.Parameter(torch.zeros(1, 1, embed_dims[0]))\n        self.cls_token2 = nn.Parameter(torch.zeros(1, 1, embed_dims[1]))\n        self.cls_token3 = nn.Parameter(torch.zeros(1, 1, embed_dims[2]))\n        self.cls_token4 = nn.Parameter(torch.zeros(1, 1, embed_dims[3]))\n\n        # Convolutional position encodings.\n        self.cpe1 = ConvPosEnc(dim=embed_dims[0], k=3)\n        self.cpe2 = ConvPosEnc(dim=embed_dims[1], k=3)\n        self.cpe3 = ConvPosEnc(dim=embed_dims[2], k=3)\n        self.cpe4 = ConvPosEnc(dim=embed_dims[3], k=3)\n\n        # Convolutional relative position encodings.\n        self.crpe1 = ConvRelPosEnc(Ch=embed_dims[0] \/\/ num_heads, h=num_heads, window=crpe_window)\n        self.crpe2 = ConvRelPosEnc(Ch=embed_dims[1] \/\/ num_heads, h=num_heads, window=crpe_window)\n        self.crpe3 = ConvRelPosEnc(Ch=embed_dims[2] \/\/ num_heads, h=num_heads, window=crpe_window)\n        self.crpe4 = ConvRelPosEnc(Ch=embed_dims[3] \/\/ num_heads, h=num_heads, window=crpe_window)\n\n        # Disable stochastic depth.\n        dpr = drop_path_rate\n        assert dpr == 0.0\n        \n        # Serial blocks 1.\n        self.serial_blocks1 = nn.ModuleList([\n            SerialBlock(\n                dim=embed_dims[0], num_heads=num_heads, mlp_ratio=mlp_ratios[0], qkv_bias=qkv_bias, qk_scale=qk_scale,\n                drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr, norm_layer=norm_layer, \n                shared_cpe=self.cpe1, shared_crpe=self.crpe1\n            )\n            for _ in range(serial_depths[0])]\n        )\n\n        # Serial blocks 2.\n        self.serial_blocks2 = nn.ModuleList([\n            SerialBlock(\n                dim=embed_dims[1], num_heads=num_heads, mlp_ratio=mlp_ratios[1], qkv_bias=qkv_bias, qk_scale=qk_scale,\n                drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr, norm_layer=norm_layer, \n                shared_cpe=self.cpe2, shared_crpe=self.crpe2\n            )\n            for _ in range(serial_depths[1])]\n        )\n\n        # Serial blocks 3.\n        self.serial_blocks3 = nn.ModuleList([\n            SerialBlock(\n                dim=embed_dims[2], num_heads=num_heads, mlp_ratio=mlp_ratios[2], qkv_bias=qkv_bias, qk_scale=qk_scale,\n                drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr, norm_layer=norm_layer, \n                shared_cpe=self.cpe3, shared_crpe=self.crpe3\n            )\n            for _ in range(serial_depths[2])]\n        )\n\n        # Serial blocks 4.\n        self.serial_blocks4 = nn.ModuleList([\n            SerialBlock(\n                dim=embed_dims[3], num_heads=num_heads, mlp_ratio=mlp_ratios[3], qkv_bias=qkv_bias, qk_scale=qk_scale,\n                drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr, norm_layer=norm_layer, \n                shared_cpe=self.cpe4, shared_crpe=self.crpe4\n            )\n            for _ in range(serial_depths[3])]\n        )\n\n        # Parallel blocks.\n        self.parallel_depth = parallel_depth\n        if self.parallel_depth > 0:\n            self.parallel_blocks = nn.ModuleList([\n                ParallelBlock(\n                    dims=embed_dims, num_heads=num_heads, mlp_ratios=mlp_ratios, qkv_bias=qkv_bias, qk_scale=qk_scale,\n                    drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr, norm_layer=norm_layer, \n                    shared_cpes=[self.cpe1, self.cpe2, self.cpe3, self.cpe4],\n                    shared_crpes=[self.crpe1, self.crpe2, self.crpe3, self.crpe4]\n                )\n                for _ in range(parallel_depth)]\n            )\n        else:\n            self.parallel_blocks = None\n\n        # Classification head(s).\n        if not self.return_interm_layers:\n            self.norm1 = norm_layer(embed_dims[0])\n            self.norm2 = norm_layer(embed_dims[1])\n            self.norm3 = norm_layer(embed_dims[2])\n","AFTER":"        img_size = to_2tuple(img_size)\n        self.patch_embed1 = PatchEmbed(\n            img_size=img_size, patch_size=patch_size, in_chans=in_chans,\n            embed_dim=embed_dims[0], norm_layer=nn.LayerNorm)\n        self.patch_embed2 = PatchEmbed(\n            img_size=[x \/\/ 4 for x in img_size], patch_size=2, in_chans=embed_dims[0],\n            embed_dim=embed_dims[1], norm_layer=nn.LayerNorm)\n        self.patch_embed3 = PatchEmbed(\n            img_size=[x \/\/ 8 for x in img_size], patch_size=2, in_chans=embed_dims[1],\n            embed_dim=embed_dims[2], norm_layer=nn.LayerNorm)\n        self.patch_embed4 = PatchEmbed(\n            img_size=[x \/\/ 16 for x in img_size], patch_size=2, in_chans=embed_dims[2],\n            embed_dim=embed_dims[3], norm_layer=nn.LayerNorm)\n\n        # Class tokens.\n        self.cls_token1 = nn.Parameter(torch.zeros(1, 1, embed_dims[0]))\n        self.cls_token2 = nn.Parameter(torch.zeros(1, 1, embed_dims[1]))\n        self.cls_token3 = nn.Parameter(torch.zeros(1, 1, embed_dims[2]))\n        self.cls_token4 = nn.Parameter(torch.zeros(1, 1, embed_dims[3]))\n\n        # Convolutional position encodings.\n        self.cpe1 = ConvPosEnc(dim=embed_dims[0], k=3)\n        self.cpe2 = ConvPosEnc(dim=embed_dims[1], k=3)\n        self.cpe3 = ConvPosEnc(dim=embed_dims[2], k=3)\n        self.cpe4 = ConvPosEnc(dim=embed_dims[3], k=3)\n\n        # Convolutional relative position encodings.\n        self.crpe1 = ConvRelPosEnc(Ch=embed_dims[0] \/\/ num_heads, h=num_heads, window=crpe_window)\n        self.crpe2 = ConvRelPosEnc(Ch=embed_dims[1] \/\/ num_heads, h=num_heads, window=crpe_window)\n        self.crpe3 = ConvRelPosEnc(Ch=embed_dims[2] \/\/ num_heads, h=num_heads, window=crpe_window)\n        self.crpe4 = ConvRelPosEnc(Ch=embed_dims[3] \/\/ num_heads, h=num_heads, window=crpe_window)\n\n        # Disable stochastic depth.\n        dpr = drop_path_rate\n        assert dpr == 0.0\n        \n        # Serial blocks 1.\n        self.serial_blocks1 = nn.ModuleList([\n            SerialBlock(\n                dim=embed_dims[0], num_heads=num_heads, mlp_ratio=mlp_ratios[0], qkv_bias=qkv_bias,\n                drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr, norm_layer=norm_layer, \n                shared_cpe=self.cpe1, shared_crpe=self.crpe1\n            )\n            for _ in range(serial_depths[0])]\n        )\n\n        # Serial blocks 2.\n        self.serial_blocks2 = nn.ModuleList([\n            SerialBlock(\n                dim=embed_dims[1], num_heads=num_heads, mlp_ratio=mlp_ratios[1], qkv_bias=qkv_bias,\n                drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr, norm_layer=norm_layer, \n                shared_cpe=self.cpe2, shared_crpe=self.crpe2\n            )\n            for _ in range(serial_depths[1])]\n        )\n\n        # Serial blocks 3.\n        self.serial_blocks3 = nn.ModuleList([\n            SerialBlock(\n                dim=embed_dims[2], num_heads=num_heads, mlp_ratio=mlp_ratios[2], qkv_bias=qkv_bias,\n                drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr, norm_layer=norm_layer, \n                shared_cpe=self.cpe3, shared_crpe=self.crpe3\n            )\n            for _ in range(serial_depths[2])]\n        )\n\n        # Serial blocks 4.\n        self.serial_blocks4 = nn.ModuleList([\n            SerialBlock(\n                dim=embed_dims[3], num_heads=num_heads, mlp_ratio=mlp_ratios[3], qkv_bias=qkv_bias,\n                drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr, norm_layer=norm_layer, \n                shared_cpe=self.cpe4, shared_crpe=self.crpe4\n            )\n            for _ in range(serial_depths[3])]\n        )\n\n        # Parallel blocks.\n        self.parallel_depth = parallel_depth\n        if self.parallel_depth > 0:\n            self.parallel_blocks = nn.ModuleList([\n                ParallelBlock(\n                    dims=embed_dims, num_heads=num_heads, mlp_ratios=mlp_ratios, qkv_bias=qkv_bias,\n                    drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr, norm_layer=norm_layer,\n                    shared_crpes=(self.crpe1, self.crpe2, self.crpe3, self.crpe4)\n                )\n                for _ in range(parallel_depth)]\n            )\n        else:\n            self.parallel_blocks = None\n\n        # Classification head(s).\n        if not self.return_interm_layers:\n            if self.parallel_blocks is not None:\n                self.norm2 = norm_layer(embed_dims[1])\n                self.norm3 = norm_layer(embed_dims[2])\n            else:\n                self.norm2 = self.norm3 = None\n            self.norm4 = norm_layer(embed_dims[3])\n"}