{"BEFORE":"    self.embed_dim = embed_dim\n\n    self.seq_len = seq_len\n    self.vocab_dim = hyper_parameters['vocab_dim']\n    self.layer_num = hyper_parameters['layer_num']\n    self.block_num = hyper_parameters['block_num']\n    self.tokenizer = hyper_parameters['tokenizer']\n\n    self.__cnn__ = cnn.features\n    self.__img2embed_conv__ = nn.Conv2d(self.features_dim, int(self.embed_dim * 0.5), kernel_size = 1, stride = 1)\n    self.__content_embed__ = gpt2_model.wte\n","AFTER":"    self.embed_dim = embed_dim\n\n    self.seq_len = seq_len\n    self.vocab_dim = hyper_parameters['vocab_dim']\n    self.layer_num = hyper_parameters['layer_num']\n    self.block_num = hyper_parameters['block_num']\n    self.clip_dim = hyper_parameters['clip_dim']\n    self.tags_num = 0#hyper_parameters['tags_num']\n    self.tokenizer = hyper_parameters['tokenizer']\n    self.start_token = hyper_parameters['start_token']\n    self.end_token = hyper_parameters['end_token']\n    \n    self.__clip__ = clip_model\n    self.__cnn__ = cnn.features\n    self.__img2embed__ = nn.Linear(self.clip_dim, self.embed_dim)\n    #self.__text2embed__ = nn.Linear(self.clip_dim, self.embed_dim)\n    self.__content_embed__ = nn.Embedding.from_pretrained(pretrained_embedding)\n    self.__position_embed__ = gpt2_model.wpe\n    self.__hidden_layers__ = gpt2_model.h\n    self.__layer_norm__ = gpt2_model.ln_f\n    self.__fc_layer__ = nn.Linear(self.embed_dim, self.vocab_dim)\n    self.__clip_drop__ = nn.Dropout(p = 0.1)\n    self.__embed_drop__ = nn.Dropout(p = dropout)\n    self.tokenizer = SimpleTokenizer()\n"}