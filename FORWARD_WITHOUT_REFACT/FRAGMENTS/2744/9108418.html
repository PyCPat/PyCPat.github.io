<link rel="stylesheet" href="../default.css">
<script src="../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        If ``cache`` is set to True, ``feat`` and ``graph`` should not change during
        training, or you will get wrong results.
        
        <a id="change">with </a><a id="change">graph.local_scope():

            </a>if self._cached and self._cached_h is not None:
                feat = self._cached_h
            else:
                &#47&#47 compute normalization
                degs = graph.in_degrees().float().clamp(min=1)
                norm = th.pow(degs, -0.5).to(feat.device).unsqueeze(1)

                &#47&#47 compute (D^-0.5 * A * D^-0.5)^k X
                for _ in range(self._k):
                    feat = feat * norm
                    graph.ndata[&quoth&quot] = feat
                    graph.update_all(fn.copy_src(&quoth&quot, &quotm&quot),
                                     fn.sum(&quotm&quot, &quoth&quot))
                    feat = graph.ndata.pop(&quoth&quot)
                    feat = feat * norm

                &#47&#47 cache feature
                if self._cached:
                    self._cached_h = feat

            if weight is not None:
                if self.weight is not None:
                    raise DGLError(&quotExternal weight is provided while at the same time the&quot
                                   &quot module has defined its own weight parameter. Please&quot
                                   &quot create the module with flag weight=False.&quot)
            else:
                weight = self.weight

            if weight is not None:
                feat = th.matmul(feat, weight)

            if self.bias is not None:
                feat = feat + self.bias
            <a id="change">return </a>feat
</code></pre><h3>After Change</h3><pre><code class='java'>
        else:
            assert edge_weight is None or edge_weight.size(0) == graph.num_edges()

            <a id="change">if self._add_self_loop</a><a id="change">:
                </a>graph = graph.add_self_loop()
                if edge_weight is not None:
                    size = (graph.num_nodes(),) + edge_weight.size()[1:]
                    self_loop<a id="change"> = </a>edge_weight.new_ones(size)
                    edge_weight = torch.cat([edge_weight, self_loop])
            else:
                graph = graph.local_var()

            edge_weight = dgl_normalize(graph, self._norm, edge_weight)
            <a id="change">graph.edata[&quot_edge_weight&quot]</a> = edge_weight

            for _ in range(self._k):
                graph.ndata[&quoth&quot] = feat</code></pre>