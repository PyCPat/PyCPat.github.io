{"BEFORE":"        _, prediction_s = y_s.max(dim=1)\n        _, prediction_t = y_t.max(dim=1)\n        return self.margin * F.cross_entropy(y_s_adv, prediction_s, reduction=self.reduction) \\\n               + F.nll_loss(shift_log(1. - F.softmax(y_t_adv, dim=1)), prediction_t, reduction=self.reduction)\n","AFTER":"        loss = -self.margin * self.source_disparity(y_s, y_s_adv) + self.target_disparity(y_t, y_t_adv)\n        if self.reduction == 'mean':\n            loss = loss.mean()\n        elif self.reduction == 'sum':\n            loss = loss.sum()\n        return loss\n"}