<link rel="stylesheet" href="../default.css">
<script src="../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                &#47&#47 diversity = torch.minimum(var, torch.ones_like(var))
                &#47&#47 reg -= diversity

                diversity = <a id="change">batchWiseLogit.std(1).mean(</a>-1<a id="change">)</a>.sigmoid()

                &#47&#47 summedProb = batchWiseLogit.sum(1)
                &#47&#47 posterior = OneHotCategorical(logits=summedProb)
                &#47&#47 prior = OneHotCategorical(probs=torch.ones_like(summedProb) / summedProb.shape[-1])
                &#47&#47 reg = torch.distributions.kl_divergence(posterior, prior) / diversity
                reg = compute_penalties(batchWiseLogit, allowed_entropy=0.1, individual_entropy_coeff=cv, allowed_js=4.0, js_coeff=cv, cv_coeff=cv, eps=Consts.Eps)
                reg<a id="change"> = </a>reg / diversity
                regs.append(reg)
            regs = sum(regs)
        return ssimLoss, l1Loss + l2Loss, l1QLoss + l2QLoss, regs &#47&#47 + 10 * stdReg</code></pre><h3>After Change</h3><pre><code class='java'>
        l2QLoss = list()
        l1QLoss = list()
        if not e2e:
            for latent, <a id="change">q</a> in zip(latents, quantizeds):
                l2QLoss.append(F.mse_loss(latent.detach(), q, reduction=&quotnone&quot).mean(axis=(1, 2, 3)))
                l1QLoss.append(F.l1_loss(latent.detach(), q, reduction=&quotnone&quot).mean(axis=(1, 2, 3)))
                l2QLoss.append(<a id="change">0.00001</a><a id="change"> * </a>F.mse_loss(latent, q.detach(), reduction=&quotnone&quot).mean(axis=(1, 2, 3)))
                l1QLoss.append(<a id="change">0.00001</a><a id="change"> * </a><a id="change">F.l1_loss(latent, q.detach(), reduction=&quotnone&quot).mean(axis=(1, 2, 3))</a>)

        l1QLoss = sum(l1QLoss)
        l2QLoss = sum(l2QLoss)</code></pre>