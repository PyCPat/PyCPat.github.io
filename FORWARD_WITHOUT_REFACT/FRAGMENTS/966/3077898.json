{"BEFORE":"    def __init__(self, inplanes, outplanes, stride=1, t=6, activation=nn.ReLU6):\n        super(LinearBottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, inplanes * t, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(inplanes * t)\n        self.conv2 = nn.Conv2d(inplanes * t, inplanes * t, kernel_size=3, stride=stride, padding=1, bias=False,\n                               groups=inplanes * t)\n        self.bn2 = nn.BatchNorm2d(inplanes * t)\n        self.conv3 = nn.Conv2d(inplanes * t, outplanes, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(outplanes)\n        self.activation = activation(inplace=True)\n        self.stride = stride\n        self.t = t\n        self.inplanes = inplanes\n        self.outplanes = outplanes\n","AFTER":"    def __init__(self, input_channel, output_channel, t=6, downsample=False):\n        \"\"\"\n            t:  expansion factor, t*input_channel is channel of expansion layer\n            alpha:  width multiplier, to get thinner models\n            rho:    resolution multiplier, to get reduced representation\n        \"\"\"\n        super(BaseBlock, self).__init__()\n        self.stride = 2 if downsample else 1\n        self.downsample = downsample\n        self.shortcut = (not downsample) and (input_channel == output_channel)\n\n        # apply alpha\n        input_channel = int(self.alpha * input_channel)\n        output_channel = int(self.alpha * output_channel)\n\n        # for main path:\n        c = t * input_channel\n        # 1x1   point wise conv\n        self.conv1 = nn.Conv2d(input_channel, c, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(c)\n        # 3x3   depth wise conv\n        self.conv2 = nn.Conv2d(c, c, kernel_size=3, stride=self.stride, padding=1, groups=c, bias=False)\n        self.bn2 = nn.BatchNorm2d(c)\n        # 1x1   point wise conv\n        self.conv3 = nn.Conv2d(c, output_channel, kernel_size=1, bias=False)\n"}