{"BEFORE":"        in_out = list(zip(dims[:-1], dims[1:]))\n\n        # time, image embeddings, and optional text encoding\n\n        cond_dim = default(cond_dim, dim)\n        time_cond_dim = dim * 4\n\n        self.to_time_hiddens = nn.Sequential(\n            SinusoidalPosEmb(dim),\n            nn.Linear(dim, time_cond_dim),\n            nn.SiLU()\n        )\n\n        self.to_lowres_time_hiddens = None\n        if lowres_cond:\n            self.to_lowres_time_hiddens = nn.Sequential(\n                SinusoidalPosEmb(dim),\n                nn.Linear(dim, time_cond_dim),\n                nn.SiLU()\n            )\n            time_cond_dim *= 2\n\n        # project to time tokens as well as time hiddens\n\n        self.to_time_tokens = nn.Sequential(\n            nn.Linear(time_cond_dim, cond_dim * num_time_tokens),\n            Rearrange('b (r d) -> b r d', r = num_time_tokens)\n        )\n\n        self.to_time_cond = nn.Sequential(\n            nn.Linear(time_cond_dim, time_cond_dim)\n        )\n\n        self.norm_cond = nn.LayerNorm(cond_dim)\n        self.norm_mid_cond = nn.LayerNorm(cond_dim)\n\n        # text encoding conditioning (optional)\n\n        self.text_to_cond = None\n\n        if cond_on_text:\n            assert exists(text_embed_dim), 'text_embed_dim must be given to the unet if cond_on_text is True'\n            self.text_to_cond = nn.Linear(text_embed_dim, cond_dim)\n\n        # finer control over whether to condition on text encodings\n\n        self.cond_on_text = cond_on_text\n\n        # for classifier free guidance\n\n        self.null_image_embed = nn.Parameter(torch.randn(1, num_image_tokens, cond_dim))\n\n        self.max_text_len = max_text_len\n        self.null_text_embed = nn.Parameter(torch.randn(1, max_text_len, cond_dim))\n\n        # attention related params\n\n        attn_kwargs = dict(heads = attn_heads, dim_head = attn_dim_head)\n\n        num_layers = len(in_out)\n\n        # resnet block klass\n\n        num_resnet_blocks = cast_tuple(num_resnet_blocks, num_layers)\n        resnet_groups = cast_tuple(resnet_groups, num_layers)\n\n        layer_attns = cast_tuple(layer_attns, num_layers)\n        layer_cross_attns = cast_tuple(layer_cross_attns, num_layers)\n\n        assert all([layers == num_layers for layers in list(map(len, (resnet_groups, layer_attns, layer_cross_attns)))])\n\n        # downsample klass\n\n        downsample_klass = Downsample\n        if cross_embed_downsample:\n            downsample_klass = partial(CrossEmbedLayer, kernel_sizes = cross_embed_downsample_kernel_sizes)\n\n        # layers\n\n        self.downs = nn.ModuleList([])\n        self.ups = nn.ModuleList([])\n        num_resolutions = len(in_out)\n\n        for ind, ((dim_in, dim_out), layer_num_resnet_blocks, groups, layer_attn, layer_cross_attn) in enumerate(zip(in_out, num_resnet_blocks, resnet_groups, layer_attns, layer_cross_attns)):\n            is_first = ind == 0\n            is_last = ind >= (num_resolutions - 1)\n            layer_cond_dim = cond_dim if layer_cross_attn else None\n\n            self.downs.append(nn.ModuleList([\n                ResnetBlock(dim_in, dim_out, cond_dim = layer_cond_dim, time_cond_dim = time_cond_dim, groups = groups),\n                nn.ModuleList([ResnetBlock(dim_out, dim_out, groups = groups) for _ in range(layer_num_resnet_blocks)]),\n                TransformerBlock(dim = dim_out, heads = attn_heads, dim_head = attn_dim_head, ff_mult = ff_mult) if layer_attn else nn.Identity(),\n                downsample_klass(dim_out) if not is_last else nn.Identity()\n            ]))\n\n        mid_dim = dims[-1]\n\n        self.mid_block1 = ResnetBlock(mid_dim, mid_dim, cond_dim = cond_dim, time_cond_dim = time_cond_dim, groups = resnet_groups[-1])\n        self.mid_attn = EinopsToAndFrom('b c h w', 'b (h w) c', Residual(Attention(mid_dim, **attn_kwargs))) if attend_at_middle else None\n        self.mid_block2 = ResnetBlock(mid_dim, mid_dim, cond_dim = cond_dim, time_cond_dim = time_cond_dim, groups = resnet_groups[-1])\n\n        for ind, ((dim_in, dim_out), layer_num_resnet_blocks, groups, layer_attn, layer_cross_attn) in enumerate(zip(reversed(in_out[1:]), reversed(num_resnet_blocks), reversed(resnet_groups), reversed(layer_attns), reversed(layer_cross_attns))):\n            is_last = ind >= (num_resolutions - 2)\n","AFTER":"        in_out = list(zip(dims[:-1], dims[1:]))\n\n        # time, image embeddings, and optional text encoding\n\n        cond_dim = default(cond_dim, dim)\n        time_cond_dim = dim * 4\n\n        self.to_time_hiddens = nn.Sequential(\n            SinusoidalPosEmb(dim),\n            nn.Linear(dim, time_cond_dim),\n            nn.SiLU()\n        )\n\n        self.to_lowres_time_hiddens = None\n        if lowres_cond:\n            self.to_lowres_time_hiddens = nn.Sequential(\n                SinusoidalPosEmb(dim),\n                nn.Linear(dim, time_cond_dim),\n                nn.SiLU()\n            )\n            time_cond_dim *= 2\n\n        # project to time tokens as well as time hiddens\n\n        self.to_time_tokens = nn.Sequential(\n            nn.Linear(time_cond_dim, cond_dim * num_time_tokens),\n            Rearrange('b (r d) -> b r d', r = num_time_tokens)\n        )\n\n        self.to_time_cond = nn.Sequential(\n            nn.Linear(time_cond_dim, time_cond_dim)\n        )\n\n        self.norm_cond = nn.LayerNorm(cond_dim)\n        self.norm_mid_cond = nn.LayerNorm(cond_dim)\n\n        # text encoding conditioning (optional)\n\n        self.text_to_cond = None\n\n        if cond_on_text:\n            assert exists(text_embed_dim), 'text_embed_dim must be given to the unet if cond_on_text is True'\n            self.text_to_cond = nn.Linear(text_embed_dim, cond_dim)\n\n        # finer control over whether to condition on text encodings\n\n        self.cond_on_text = cond_on_text\n\n        # for classifier free guidance\n\n        self.null_image_embed = nn.Parameter(torch.randn(1, num_image_tokens, cond_dim))\n\n        self.max_text_len = max_text_len\n        self.null_text_embed = nn.Parameter(torch.randn(1, max_text_len, cond_dim))\n\n        # attention related params\n\n        attn_kwargs = dict(heads = attn_heads, dim_head = attn_dim_head)\n\n        num_layers = len(in_out)\n\n        # resnet block klass\n\n        num_resnet_blocks = cast_tuple(num_resnet_blocks, num_layers)\n        resnet_groups = cast_tuple(resnet_groups, num_layers)\n\n        layer_attns = cast_tuple(layer_attns, num_layers)\n        layer_cross_attns = cast_tuple(layer_cross_attns, num_layers)\n\n        assert all([layers == num_layers for layers in list(map(len, (resnet_groups, layer_attns, layer_cross_attns)))])\n\n        # downsample klass\n\n        downsample_klass = Downsample\n        if cross_embed_downsample:\n            downsample_klass = partial(CrossEmbedLayer, kernel_sizes = cross_embed_downsample_kernel_sizes)\n\n        # layers\n\n        self.downs = nn.ModuleList([])\n        self.ups = nn.ModuleList([])\n        num_resolutions = len(in_out)\n\n        layer_params = [num_resnet_blocks, resnet_groups, layer_attns, layer_cross_attns]\n        reversed_layer_params = list(map(reversed, layer_params))\n\n        for ind, ((dim_in, dim_out), layer_num_resnet_blocks, groups, layer_attn, layer_cross_attn) in enumerate(zip(in_out, *layer_params)):\n            is_last = ind >= (num_resolutions - 1)\n            layer_cond_dim = cond_dim if layer_cross_attn else None\n\n            self.downs.append(nn.ModuleList([\n                ResnetBlock(dim_in, dim_out, cond_dim = layer_cond_dim, time_cond_dim = time_cond_dim, groups = groups),\n                nn.ModuleList([ResnetBlock(dim_out, dim_out, groups = groups) for _ in range(layer_num_resnet_blocks)]),\n                TransformerBlock(dim = dim_out, heads = attn_heads, dim_head = attn_dim_head, ff_mult = ff_mult) if layer_attn else nn.Identity(),\n                downsample_klass(dim_out) if not is_last else nn.Identity()\n            ]))\n\n        mid_dim = dims[-1]\n\n        self.mid_block1 = ResnetBlock(mid_dim, mid_dim, cond_dim = cond_dim, time_cond_dim = time_cond_dim, groups = resnet_groups[-1])\n        self.mid_attn = EinopsToAndFrom('b c h w', 'b (h w) c', Residual(Attention(mid_dim, **attn_kwargs))) if attend_at_middle else None\n        self.mid_block2 = ResnetBlock(mid_dim, mid_dim, cond_dim = cond_dim, time_cond_dim = time_cond_dim, groups = resnet_groups[-1])\n\n        for ind, ((dim_in, dim_out), layer_num_resnet_blocks, groups, layer_attn, layer_cross_attn) in enumerate(zip(reversed(in_out[1:]), *reversed_layer_params)):\n"}