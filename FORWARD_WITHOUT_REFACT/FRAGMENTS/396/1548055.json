{"BEFORE":"        mleLoss = list()\n\n        for logits, codes in zip(allLogits, allTrues):\n            # rand = torch.randint_like(codes, logits.shape[-1])\n            # regLoss.append(self._auxLoss(logits.permute(0, 4, 1, 2, 3), rand))\n            mleLoss.append(self._auxLoss(logits.permute(0, 4, 1, 2, 3), codes))\n\n        # self._movingMean -= 0.9 * (self._movingMean - ssimLoss.mean())\n        # pLoss = self._pLoss(image, restored)\n        return dLoss, sum(mleLoss), (restored, allTrues, allLogits)\n","AFTER":"        restored, allHards, latent, allCodes, allTrues, allLogits, allFeatures, allCodebooks = self._compressor(image, temp, True)\n\n        dLoss = self._cLoss(image, restored)\n\n        # regLoss = list()\n        weakCodebookLoss = list()\n        weakFeatureLoss = list()\n\n        for features, codebooks in zip(allFeatures, allCodebooks):\n            for codebook in codebooks:\n                # [k, k] := [k, c] @ [c, k]\n                innerProduct = codebook @ codebook.T\n                # orthogonal regularization\n                weakCodebookLoss.append(self._auxLoss(innerProduct, torch.eye(innerProduct.shape[0], device=innerProduct.device, dtype=innerProduct.dtype)))\n            m = len(features)\n            for i in range(m):\n                for j in range(i + 1, m):\n                    # [n, h, w] := ([n, c, h, w] * [n, c, h, w]).sum(1)\n                    interProduct = (features[i] * features[j]).sum(1)\n                    # feature from different group should be orthogonal\n                    weakFeatureLoss.append(2 * self._auxLoss(interProduct, torch.zeros_like(interProduct)))\n                intraProduct = (features[i] * features[i]).sum(1)\n                weakFeatureLoss.append(self._auxLoss(intraProduct, torch.ones_like(intraProduct)))\n\n        # self._movingMean -= 0.9 * (self._movingMean - ssimLoss.mean())\n        # pLoss = self._pLoss(image, restored)\n        return dLoss, (sum(weakCodebookLoss), sum(weakFeatureLoss)), (restored, allTrues, allLogits)\n"}