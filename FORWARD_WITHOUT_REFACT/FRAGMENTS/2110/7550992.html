<link rel="stylesheet" href="../default.css">
<script src="../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        first_h_b = self.initHidden_beta(x.shape[1])

        self.emb = self.embedding(x)
        <a id="change">if </a>self.drop &lt; 1<a id="change">:
            </a>self.emb<a id="change"> = </a>self.dropout(self.emb)

        count = np.arange(x.shape[0]) + 1
        <a id="change">self.c_t</a> = torch.zeros_like(self.emb)  &#47&#47 shape=(seq_len, batch_size, day_dim)
        <a id="change">for </a>i, att_timesteps in enumerate(count)<a id="change">:
            &#47&#47 按时间步迭代，计算每个时间步的经attention的gru输出
            self.c_t[i]</a><a id="change"> = </a>self.attentionStep(first_h_a, first_h_b, att_timesteps)

        if self.drop &lt; 1.0:
            self.c_t = self.dropout(self.c_t)</code></pre><h3>After Change</h3><pre><code class='java'>

        for cur_time in range(time_steps):
            cur_x = x[:, : cur_time + 1, :]
            <a id="change">out[:, cur_time, :]</a> = self.retain_encoder(cur_x)
        return out
</code></pre>