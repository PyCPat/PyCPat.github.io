{"BEFORE":"        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = self.pool(F.relu(self.conv3(x)))\n        x = x.view(-1, 64 * 4 * 4)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        output = self.fc3(x)\n        if last:\n          return output, x\n        else:\n          return output\n    def get_embedding_dim(self):\n","AFTER":"    def forward(self, x, last=False, freeze=False):\n        if freeze:\n            with torch.no_grad():\n                out = self.pool(F.relu(self.conv1(x)))\n                out = self.pool(F.relu(self.conv2(out)))\n                out = self.pool(F.relu(self.conv3(out)))\n                out = out.view(-1, 64 * 4 * 4)\n                out = F.relu(self.fc1(out))\n                e = F.relu(self.fc2(out))\n        else:\n            out = self.pool(F.relu(self.conv1(x)))\n            out = self.pool(F.relu(self.conv2(out)))\n            out = self.pool(F.relu(self.conv3(out)))\n            out = out.view(-1, 64 * 4 * 4)\n            out = F.relu(self.fc1(out))\n            e = F.relu(self.fc2(out))\n        out = self.fc3(e)\n        if last:\n            return out, e\n        else:\n            return out\n\n\n    def get_embedding_dim(self):\n"}