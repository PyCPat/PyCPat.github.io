{"BEFORE":"        pos_relations = pos_exmpls[:, 1:2]\n        pos_tails = pos_exmpls[:, 2:3]\n\n        neg_heads = neg_exmpls[:, 0:1]\n        neg_relations = neg_exmpls[:, 1:2]\n        neg_tails = neg_exmpls[:, 2:3]\n\n        pos_h_embs = self.entities_embeddings(pos_heads)\n        pos_r_embs = self.relation_embeddings(pos_relations)\n        pos_t_embs = self.entities_embeddings(pos_tails)\n\n        neg_h_embs = self.entities_embeddings(neg_heads)\n        neg_r_embs = self.relation_embeddings(neg_relations)\n        neg_t_embs = self.entities_embeddings(neg_tails)\n\n        # L2 normalization of the vectors\n        pos_h_embs = torch.nn.functional.normalize(pos_h_embs, p=self.l_p_norm, dim=1)\n        pos_t_embs = torch.nn.functional.normalize(pos_t_embs, p=self.l_p_norm, dim=1)\n        neg_h_embs = torch.nn.functional.normalize(neg_h_embs, p=self.l_p_norm, dim=1)\n        neg_t_embs = torch.nn.functional.normalize(neg_t_embs, p=self.l_p_norm, dim=1)\n","AFTER":"        pos_relations = pos_exmpls[:, 1:2]\n        pos_tails = pos_exmpls[:, 2:3]\n\n        neg_heads = neg_exmpls[:, 0:1]\n        neg_relations = neg_exmpls[:, 1:2]\n        neg_tails = neg_exmpls[:, 2:3]\n\n        pos_h_embs = self.entities_embeddings(pos_heads)\n        pos_r_embs = self.relation_embeddings(pos_relations).view(-1, self.embedding_dim)\n        pos_t_embs = self.entities_embeddings(pos_tails)\n\n        neg_h_embs = self.entities_embeddings(neg_heads)\n        neg_r_embs = self.relation_embeddings(neg_relations).view(-1, self.embedding_dim)\n        neg_t_embs = self.entities_embeddings(neg_tails)\n\n        # L-P normalization of the vectors\n        pos_h_embs = torch.nn.functional.normalize(pos_h_embs, p=self.l_p_norm, dim=1).view(-1, self.embedding_dim)\n        pos_t_embs = torch.nn.functional.normalize(pos_t_embs, p=self.l_p_norm, dim=1).view(-1, self.embedding_dim)\n        neg_h_embs = torch.nn.functional.normalize(neg_h_embs, p=self.l_p_norm, dim=1).view(-1, self.embedding_dim)\n        neg_t_embs = torch.nn.functional.normalize(neg_t_embs, p=self.l_p_norm, dim=1).view(-1, self.embedding_dim)\n"}