{"BEFORE":"        image_tokens: List[LongTensor] = []\n        attention_state = torch.zeros(self.attention_state_shape)\n        if torch.cuda.is_available(): \n            attention_state = attention_state.cuda()\n        image_token = self.start_token\n\n        for i in range(self.sample_token_count):\n            probs, attention_state = self.decode_step(\n                text_tokens = text_tokens,\n                encoder_state = encoder_state,\n                attention_state = attention_state,\n                prev_token = image_token,\n                token_index = self.token_indices[[i]]\n            )\n\n            image_token = torch.multinomial(probs, 1)\n            image_tokens += [image_token]\n            \n        return torch.cat(image_tokens)\n","AFTER":"        image_count: int,\n        text_tokens: LongTensor,\n        encoder_state: FloatTensor\n    ) -> LongTensor:\n        expanded_indices = [0] * image_count + [1] * image_count\n        text_tokens = text_tokens[expanded_indices]\n        encoder_state = encoder_state[expanded_indices]\n        attention_mask = text_tokens.not_equal(1)\n\n        attention_state_shape = (\n            self.layer_count,\n            image_count * 4,\n            self.image_token_count,\n            self.embed_count\n        )\n        attention_state = torch.zeros(attention_state_shape)\n        if torch.cuda.is_available(): attention_state = attention_state.cuda()\n        \n        image_tokens = self.start_token[[0] * image_count]\n        image_tokens_sequence: list[LongTensor] = []\n        for i in range(self.sample_token_count):\n            probs, attention_state = self.decode_step(\n                attention_mask = attention_mask,\n                encoder_state = encoder_state,\n                attention_state = attention_state,\n                prev_tokens = image_tokens,\n                token_index = self.token_indices[[i]]\n            )\n\n            image_tokens = torch.multinomial(probs, 1)[:, 0]\n            image_tokens_sequence += [image_tokens]\n        \n        return torch.stack(image_tokens_sequence).T\n"}