{"BEFORE":"        torch_mask_time_indices = torch.tensor(\n            mask_time_indices, device=wav.device, dtype=torch.long,\n        )\n\n        # 2. Sample the negative samples from the masked indices.\n        # The number of negative must be < 50% of the number of masked indices\n        # this is critical for short sentences that may always selected all\n        # the masked indices as negatives (hence reducing variability)\n        # Hence, if the number of required samples is higher than half of the\n        # total number of masked indices, we enforce it to become 50% of this\n        # value.\n        max_number_negative = (\n            torch_mask_time_indices.sum(dim=-1).min() \/\/ self.negative_threshold\n        )\n        if self.config.num_negatives > max_number_negative:\n            dynamic_num_negatives = max_number_negative\n        else:\n            dynamic_num_negatives = torch.tensor(\n                self.config.num_negatives,\n                device=max_number_negative.device,\n                dtype=torch.int,\n            )\n\n        # print(np.sum(mask_time_indices, axis=1))\n        negative_sample_indices = torch.tensor(\n            transformers.models.wav2vec2.modeling_wav2vec2._sample_negative_indices(\n                (batch_size, sequence_length),\n                num_negatives=dynamic_num_negatives,\n                mask_time_indices=mask_time_indices,\n            ),\n            device=wav.device,\n            dtype=torch.long,\n        )\n        factor = int(self.config.num_negatives \/\/ dynamic_num_negatives.item())\n        negative_sample_indices = torch.cat(\n            [negative_sample_indices] * factor, dim=-1\n        )\n","AFTER":"        sequence_length = self.model._get_feat_extract_output_lengths(\n            raw_sequence_length\n        )\n\n        # 1. Compute the indices that will be masked\n        mask_time_indices = _compute_mask_indices(\n            (batch_size, sequence_length),\n            mask_prob=self.mask_prob,\n            mask_length=self.mask_length,\n        )\n        torch_mask_time_indices = torch.tensor(\n            mask_time_indices, device=wav.device, dtype=torch.long,\n        )\n\n        # 2. Sample the negative samples from the entire sequence.\n        # Fairseq does it only on the masked indices, but this only work if you\n        # have long sentences. For more versatily, we sample on the entire sequence.\n        # value.\n        full_sentence_indices = np.ones((batch_size, sequence_length))\n"}