{"BEFORE":"    def forward(self, x, input_lengths):\n        for conv in self.convolutions:\n            x = F.dropout(F.relu(conv(x)), 0.5, self.training)\n\n        x = x.transpose(1, 2)\n        total_length = x.size(1)\n\n        # pytorch tensor are not reversible, hence the conversion\n        input_lengths = input_lengths.cpu().numpy()\n        x = nn.utils.rnn.pack_padded_sequence(\n            x, input_lengths, batch_first=True)\n\n        self.lstm.flatten_parameters()\n        outputs, _ = self.lstm(x)\n\n        # use total_length of a batch for data parallelism\n        # https:\/\/pytorch.org\/docs\/stable\/notes\/faq.html#pack-rnn-unpack-with-data-parallelism\n        outputs, _ = nn.utils.rnn.pad_packed_sequence(\n            outputs, batch_first=True, total_length=total_length)\n","AFTER":"        x = self.conv1ds(x.transpose(1, 2)).transpose(1, 2)\n"}