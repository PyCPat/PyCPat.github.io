{"BEFORE":"            attn_weights = attn_weights.view(bsz, self.num_heads, tgt_len, src_len)\n            if self.onnx_trace:\n                attn_weights = torch.where(\n                    key_padding_mask.unsqueeze(1).unsqueeze(2),\n                    torch.Tensor([float(\"-Inf\")]),\n                    attn_weights.float()\n                ).type_as(attn_weights)\n            else:\n                attn_weights = attn_weights.float().masked_fill(\n                    key_padding_mask.unsqueeze(1).unsqueeze(2),\n                    float('-inf'),\n                ).type_as(attn_weights)  # FP16 support: cast to float and back\n","AFTER":"            attn_weights = attn_weights.view(bsz, self.num_heads, tgt_len, src_len)\n            if self.onnx_trace:\n                attn_weights = torch.where(\n                    key_padding_mask.unsqueeze(1).unsqueeze(2),\n                    torch.Tensor([float(\"-Inf\")]),\n                    attn_weights.float()\n                ).type_as(attn_weights)\n            else:\n                attn_weights = attn_weights.masked_fill(\n                    key_padding_mask.unsqueeze(1).unsqueeze(2),\n                    float('-inf'),\n                )\n"}