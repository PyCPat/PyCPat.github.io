{"BEFORE":"        dim_batch = past.size()[0]\n        zero_padding = torch.zeros(1, dim_batch, self.dim_embedding_key * 2).cuda()\n        prediction = torch.Tensor().cuda()\n        present_temp = past[:, -1].unsqueeze(1)\n\n        # past temporal encoding\n        past = torch.transpose(past, 1, 2)\n        story_embed = self.relu(self.conv_past(past))\n        story_embed = torch.transpose(story_embed, 1, 2)\n        output_past, state_past = self.encoder_past(story_embed)\n\n        # Cosine similarity and memory read\n        past_normalized = F.normalize(self.memory_past, p=2, dim=1)\n        state_normalized = F.normalize(state_past.squeeze(), p=2, dim=1)\n        self.weight_read = torch.matmul(past_normalized, state_normalized.transpose(0, 1)).transpose(0, 1)\n        self.index_max = torch.sort(self.weight_read, descending=True)[1].cpu()\n\n        for i_track in range(self.num_prediction):\n            present = present_temp\n            prediction_single = torch.Tensor().cuda()\n            ind = self.index_max [:, i_track]\n\n            #ablation study\n            # prediction_single = self.memory_count[ind]\n            # prediction = torch.cat((prediction, prediction_single.unsqueeze(1)), 1)\n\n            info_future = self.memory_fut[ind]\n            info_total = torch.cat((state_past, info_future.unsqueeze(0)), 2)\n            input_dec = info_total\n            state_dec = zero_padding\n            for i in range(self.future_len):\n                output_decoder, state_dec = self.decoder(input_dec, state_dec)\n                displacement_next = self.FC_output(output_decoder)\n                coords_next = present + displacement_next.squeeze(0).unsqueeze(1)\n                prediction_single = torch.cat((prediction_single, coords_next), 1)\n                present = coords_next\n                input_dec = zero_padding\n            prediction = torch.cat((prediction, prediction_single.unsqueeze(1)), 1)\n        return prediction\n","AFTER":"        dim_batch = past.size()[0]\n        zero_padding = torch.zeros(1, dim_batch*self.num_prediction, self.dim_embedding_key * 2).cuda()\n        prediction = torch.Tensor().cuda()\n        present_temp = past[:, -1].unsqueeze(1)\n\n        # past temporal encoding\n        past = torch.transpose(past, 1, 2)\n        story_embed = self.relu(self.conv_past(past))\n        story_embed = torch.transpose(story_embed, 1, 2)\n        output_past, state_past = self.encoder_past(story_embed)\n\n        # Cosine similarity and memory read\n        past_normalized = F.normalize(self.memory_past, p=2, dim=1)\n        state_normalized = F.normalize(state_past.squeeze(), p=2, dim=1)\n        self.weight_read = torch.matmul(past_normalized, state_normalized.transpose(0, 1)).transpose(0, 1)\n        self.index_max = torch.sort(self.weight_read, descending=True)[1].cpu()[:,:self.num_prediction]\n        present = present_temp.repeat_interleave(self.num_prediction, dim=0)\n        state_past = state_past.repeat_interleave(self.num_prediction, dim=1)\n        ind = self.index_max.flatten()\n\n        #ablation study\n        #pdb.set_trace()\n        # temp = self.memory_count[ind]\n        # prediction = temp.view(dim_batch, self.num_prediction, self.future_len, 2)\n\n\n        info_future = self.memory_fut[ind]\n        info_total = torch.cat((state_past, info_future.unsqueeze(0)), 2)\n        input_dec = info_total\n        state_dec = zero_padding\n        for i in range(self.future_len):\n            output_decoder, state_dec = self.decoder(input_dec, state_dec)\n            displacement_next = self.FC_output(output_decoder)\n            coords_next = present + displacement_next.squeeze(0).unsqueeze(1)\n            prediction = torch.cat((prediction, coords_next), 1)\n            present = coords_next\n            input_dec = zero_padding\n        prediction = prediction.view(dim_batch, self.num_prediction, self.future_len, 2)\n"}