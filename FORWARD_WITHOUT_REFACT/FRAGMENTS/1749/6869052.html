<link rel="stylesheet" href="../default.css">
<script src="../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        :return: attention result of shape (B, N, F) where B is the batch size, N the query sequence length
            and F the number of output channels (= `num_output_channels`)
        
        <a id="change">if attn_mask is not None</a><a id="change">:
            </a>raise NotImplementedError("attention masks not supported yet")

        q = self.q_proj(x_q)
        k = self.k_proj(x_kv)</code></pre><h3>After Change</h3><pre><code class='java'>
        attn = attn.softmax(dim=-1)
        attn = self.dropout(attn)

        o = <a id="change">torch.einsum("b h i j, b h j c -&gt; b h i c"</a>, attn, v<a id="change">)</a>
        o = rearrange(o, "b h n c -&gt; b n (h c)", h=self.num_heads)

        return self.o_proj(o)
</code></pre>