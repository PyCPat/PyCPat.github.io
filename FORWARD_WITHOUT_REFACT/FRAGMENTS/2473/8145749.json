{"BEFORE":"        dtype = paddle.float32\n        # memory_format = torch.contiguous_format\n\n        # FromRGB.\n        # x = x.to(dtype=dtype, memory_format=memory_format)\n        x = paddle.cast(x, dtype=dtype)\n        if self.architecture == 'skip':\n            # img = img.to(dtype=dtype, memory_format=memory_format)\n            img = paddle.cast(img, dtype=dtype)\n            x = x + self.fromrgb(img)\n\n        # Main layers.\n        if self.mbstd is not None:\n            x = self.mbstd(x)\n        x = self.conv(x)\n        # flatten_x = x.flatten(1)   # 因为flatten()没有实现二阶梯度，所以用其它等价实现。\n        batch_size = x.shape[0]\n        flatten_x = x.reshape((batch_size, -1))\n        x = self.fc(flatten_x)\n","AFTER":"        dtype = torch.float32\n        memory_format = torch.contiguous_format\n\n        # FromRGB.\n        x = x.to(dtype=dtype, memory_format=memory_format)\n        if self.architecture == 'skip':\n            img = img.to(dtype=dtype, memory_format=memory_format)\n            x = x + self.fromrgb(img)\n\n        # Main layers.\n        if self.mbstd is not None:\n            x = self.mbstd(x)\n        x = self.conv(x)\n        x = self.fc(x.flatten(1))\n"}