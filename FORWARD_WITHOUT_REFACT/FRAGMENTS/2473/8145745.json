{"BEFORE":"        batch_size, channels, height, width = input.shape  # type: int, int, int, int\n        # Reshape input to [batch size, in channels, height, width]\n        input: torch.Tensor = bchw_to_bhwc(input)\n        # Unfold input\n        input: torch.Tensor = input.unfold(dimension=1, size=2, step=2).unfold(dimension=2, size=2, step=2)\n        input: torch.Tensor = input.reshape(batch_size, input.shape[1], input.shape[2], -1)\n        # Normalize input\n        input: torch.Tensor = self.normalization(input)\n        # Perform linear mapping\n        output: torch.Tensor = bhwc_to_bchw(self.linear_mapping(input))\n        return output\n","AFTER":"        x = bchw_to_bhwc(x).unfold(dimension=1, size=2, step=2).unfold(dimension=2, size=2, step=2)\n        x = x.permute(0, 1, 2, 5, 4, 3).flatten(3)  # permute maintains compat with ch order in official swin impl\n        x = self.norm(x)\n        x = bhwc_to_bchw(self.reduction(x))\n        return x\n"}