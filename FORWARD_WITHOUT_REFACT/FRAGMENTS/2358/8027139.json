{"BEFORE":"        src_emb = self.embedding(src_input)  # (B, L, d_model)\n        src_emb = self.positional_embedding(src_emb, cal='add')  # (B, L, d_model)\n        trg_emb = self.embedding(trg_input)  # (B, L, d_model)\n        trg_emb = self.positional_embedding(trg_emb, cal='add')  # (B, L, d_model)\n        \n        # Encoding phase\n        e_output = self.encoder(src_emb, e_mask)  # (B, L, d_model)\n        \n        # Encoded input & context combination\n        e_output = torch.cat((e_output, context.unsqueeze(1).repeat(1,self.config['max_len'],1)), dim=-1)  # (B, L, d_model+d_h)\n        e_output = self.linear1(e_output)  # (B, L, d_mid)\n        e_output = self.linear2(e_output)  # (B, L, d_model)\n        \n        # Decoding phase\n        d_output = self.decoder(trg_emb, e_output, e_mask, d_mask)  # (B, L, d_model)\n        \n        output = self.softmax(self.output_linear(d_output))  # (B, L, vocab_size)\n        \n        # Context update\n        next_context = self.context_update(context, e_output)  # (B, d_model)\n","AFTER":"        trg_emb = self.embed(trg_input)  # (B, L, d_model)\n        e_mask = self.make_encoder_mask(src_input)  # (B, 1, L)\n        d_mask = self.make_encoder_mask(trg_input)  # (B, L, L)\n        \n        # Encoding phase\n        e_output = self.encoder(src_emb, e_mask)  # (B, L, d_model)\n        \n        # Context update\n        next_context = self.context_update(context, e_output)  # (B, d_model)\n        \n        # Decoding phase\n        e_output = self.combine_context(e_output, context)  # (B, L, d_model)\n        d_output = self.decoder(trg_emb, e_output, e_mask, d_mask)  # (B, L, d_model)\n        \n        output = self.softmax(self.output_linear(d_output))  # (B, L, vocab_size)\n        \n        del e_mask, d_mask\n"}