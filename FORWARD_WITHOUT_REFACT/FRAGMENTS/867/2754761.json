{"BEFORE":"            loc_t = torch.zeros(num, num_priors, 4, device='cuda:0')\n            conf_t = torch.zeros(num, num_priors, device='cuda:0').long()\n            overlap_t = torch.zeros(num, num_priors, device='cuda:0')\n            pred_t = torch.zeros(num, num_priors, device='cuda:0')\n            for idx in range(num):\n                truths = targets[idx][:, :-1]\n                labels = targets[idx][:, -1].long()\n                regress = loc_data[idx, :, :]\n                classif = conf_data[idx, :, :]\n                mutual_match(truths, priors, regress, classif, labels, loc_t, conf_t, overlap_t, pred_t, idx)\n            loc_t = Variable(loc_t, requires_grad=False)\n            conf_t = Variable(conf_t, requires_grad=False)\n            overlap_t = Variable(overlap_t, requires_grad=False)\n            pred_t = Variable(pred_t, requires_grad=False)\n\n            # Localization Loss (Smooth L1)\n            pos = pred_t == 3.0\n            priors = priors.unsqueeze(0).expand_as(loc_data)\n            mask = pos.unsqueeze(-1).expand_as(loc_data)\n            loc_p = loc_data[mask].view(-1, 4)\n            loc_t = loc_t[mask].view(-1, 4)\n            priors = priors[mask].view(-1, 4)\n            loc_t = encode(loc_t, priors)\n            loss_l = self.reg_loss(loc_p, loc_t, reduction='mean')\n\n            # Classification Loss\n            pos = overlap_t == 3.0\n            ign = overlap_t == 2.0\n            neg = overlap_t <= 1.0\n            conf_t[neg] = 0\n            with torch.no_grad():\n                batch_label = torch.zeros(num * num_priors, num_classes + 1, device='cuda:0').scatter_(1, conf_t.view(-1, 1), 1)\n                batch_label = batch_label[:, 1:].view(num, num_priors, num_classes)  # shape: (batch_size, num_priors, num_classes)\n                ign = ign.unsqueeze(-1).expand_as(batch_label)  # shape: (batch_size, num_priors, num_classes)\n                batch_label[ign] *= -1\n                mask = batch_label >= 0\n            loss_c = self.focal_loss(conf_data[mask], batch_label[mask], reduction='mean')\n\n            return (loss_l, loss_c)\n\n        else:\n\n            # match priors (default boxes) and ground truth boxes\n            overlap_t = torch.zeros(num, num_priors, device='cuda:0')\n            loc_t = torch.zeros(num, num_priors, 4, device='cuda:0')\n            conf_t = torch.zeros(num, num_priors, device='cuda:0').long()\n            for idx in range(num):\n                truths = targets[idx][:, :-1]\n                labels = targets[idx][:, -1].long()\n                match(truths, priors, labels, loc_t, conf_t, overlap_t, idx)\n            overlap_t = Variable(overlap_t, requires_grad=False)\n            loc_t = Variable(loc_t, requires_grad=False)\n            conf_t = Variable(conf_t, requires_grad=False)\n\n            pos = overlap_t >= 0.5\n            ign = (overlap_t < 0.5) * (overlap_t >= 0.4)\n            neg = overlap_t < 0.4\n\n            # Localization Loss (Smooth L1)\n            priors = priors.unsqueeze(0).expand_as(loc_data)\n            mask = pos.unsqueeze(-1).expand_as(loc_data)\n            loc_p = loc_data[mask].view(-1, 4)\n            loc_t = loc_t[mask].view(-1, 4)\n            priors = priors[mask].view(-1, 4)\n            loc_t = encode(loc_t, priors)\n            loss_l = self.reg_loss(loc_p, loc_t, reduction='mean')\n\n            # Classification Loss\n            conf_t[neg] = 0\n            with torch.no_grad():\n                batch_label = torch.zeros(num * num_priors, num_classes + 1, device='cuda:0').scatter_(1, conf_t.view(-1, 1), 1)\n                batch_label = batch_label[:, 1:].view(num, num_priors, num_classes)  # shape: (batch_size, num_priors, num_classes)\n                ign = ign.unsqueeze(-1).expand_as(batch_label)  # shape: (batch_size, num_priors, num_classes)\n                batch_label[ign] *= -1\n                mask = batch_label >= 0\n            loss_c = self.focal_loss(conf_data[mask], batch_label[mask], reduction='mean')\n","AFTER":"            with torch.no_grad():\n                loc_t = torch.zeros(num, num_priors, 4).cuda()\n                conf_t = torch.zeros(num, num_priors).cuda().long()\n                overlap_t = torch.zeros(num, num_priors).cuda()\n                pred_t = torch.zeros(num, num_priors).cuda()\n                for idx in range(num):\n                    truths = targets[idx][:, :-1]\n                    labels = targets[idx][:, -1].long()\n                    regress = loc_data[idx, :, :]\n                    classif = conf_data[idx, :, :]\n                    mutual_match(truths, priors, regress, classif, labels, loc_t, conf_t, overlap_t, pred_t, idx, self.multi_anchor)\n                loc_t = Variable(loc_t, requires_grad=False)\n                conf_t = Variable(conf_t, requires_grad=False)\n                overlap_t = Variable(overlap_t, requires_grad=False)\n                pred_t = Variable(pred_t, requires_grad=False)\n\n            # Localization Loss (Smooth L1)\n            pos = pred_t >= 3.0\n            priors = priors.unsqueeze(0).expand_as(loc_data)\n            mask = pos.unsqueeze(-1).expand_as(loc_data)\n            loc_p = loc_data[mask].view(-1, 4)\n            loc_t = loc_t[mask].view(-1, 4)\n            priors = priors[mask].view(-1, 4)\n            loss_l = self.l1_loss(loc_p, encode(loc_t, priors))\n\n            # Classification Loss\n            neg = overlap_t <= 1.0\n            conf_t[neg] = 0\n            with torch.no_grad():\n                batch_label = torch.zeros(num * num_priors, num_classes + 1).cuda().scatter_(1, conf_t.view(-1, 1), 1)\n                batch_label = batch_label[:, 1:].view(num, num_priors, num_classes)  # shape: (batch_size, num_priors, num_classes)\n                score = (overlap_t-3.0).relu().unsqueeze(-1).expand_as(batch_label)\n                batch_label = batch_label * score\n                mask = batch_label >= 0\n            loss_c = self.gfocal_loss(conf_data, batch_label, mask)\n            return (loss_l, loss_c)\n\n        else:\n\n            # match priors (default boxes) and ground truth boxes\n            overlap_t = torch.zeros(num, num_priors).cuda()\n            loc_t = torch.zeros(num, num_priors, 4).cuda()\n            conf_t = torch.zeros(num, num_priors).cuda().long()\n            for idx in range(num):\n                truths = targets[idx][:, :-1]\n                labels = targets[idx][:, -1].long()\n                match(truths, priors, labels, loc_t, conf_t, overlap_t, idx, self.multi_anchor)\n            overlap_t = Variable(overlap_t, requires_grad=False)\n            loc_t = Variable(loc_t, requires_grad=False)\n            conf_t = Variable(conf_t, requires_grad=False)\n\n            pos = overlap_t >= 0.5\n            ign = (overlap_t < 0.5) * (overlap_t >= 0.4)\n            neg = overlap_t < 0.4\n\n            # Localization Loss (Smooth L1)\n            priors = priors.unsqueeze(0).expand_as(loc_data)\n            mask = pos.unsqueeze(-1).expand_as(loc_data)\n            loc_p = loc_data[mask].view(-1, 4)\n            loc_t = loc_t[mask].view(-1, 4)\n            priors = priors[mask].view(-1, 4)\n            loss_l = self.l1_loss(loc_p, encode(loc_t, priors))\n\n            # Classification Loss\n            conf_t[neg] = 0\n            with torch.no_grad():\n                batch_label = torch.zeros(num * num_priors, num_classes + 1).cuda().scatter_(1, conf_t.view(-1, 1), 1)\n                batch_label = batch_label[:, 1:].view(num, num_priors, num_classes)  # shape: (batch_size, num_priors, num_classes)\n                ign = ign.unsqueeze(-1).expand_as(batch_label)  # shape: (batch_size, num_priors, num_classes)\n                batch_label[ign] *= -1\n                mask = batch_label >= 0\n            loss_c = self.focal_loss(conf_data, batch_label, mask)\n"}