{"BEFORE":"\t\tbatch_size = content_code.shape[0]\n\n\t\tcontent_code = content_code.view((batch_size, -1, 4, 4))\n\t\tif self.training and self.config['content_std'] != 0:\n\t\t\tnoise = torch.zeros_like(content_code)\n\t\t\tnoise.normal_(mean=0, std=self.config['content_std'])\n\n\t\t\tout = content_code + noise\n\t\telse:\n\t\t\tout = content_code\n\n\t\tfor layer in self.layers:\n\t\t\tout = layer(out, class_code, None)\n\n\t\tout = self.to_rgb(out)\n\t\treturn out\n","AFTER":"\t\tstyles = torch.cat((content_codes, class_codes), dim=1)\n\t\tlatent = styles.unsqueeze(dim=1).repeat(1, self.n_latent, 1)\n\t\t# latent = styles.view((-1, self.n_latent, 512))\n\n\t\tout = self.input(latent)\n\t\tout = self.conv1(out, latent[:, 0])\n\n\t\tskip = self.to_rgb1(out, latent[:, 1])\n\n\t\ti = 1\n\t\tfor conv1, conv2, to_rgb in zip(self.convs[::2], self.convs[1::2], self.to_rgbs):\n\t\t\tout = conv1(out, latent[:, i])\n\t\t\tout = conv2(out, latent[:, i + 1])\n\t\t\tskip = to_rgb(out, latent[:, i + 2], skip)\n\n\t\t\ti += 2\n\n\t\timage = skip\n\t\treturn image\n"}