<link rel="stylesheet" href="../default.css">
<script src="../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                batchWiseLogit = logit.reshape(len(logit), -1, logit.shape[-1])

                &#47&#47 [n, k]
                summedProb = <a id="change">batchWiseLogit.mean(</a>1<a id="change">)</a>.sigmoid()

                target = torch.ones_like(summedProb)<a id="change"> / 2.0</a>
                &#47&#47 [n, ]
                reg = F.binary_cross_entropy(summedProb, target, reduction=&quotnone&quot).sum(-1)

                &#47&#47 [n, k] -&gt; [n, ]</code></pre><h3>After Change</h3><pre><code class='java'>
                diversity = batchWiseLogit.var(1).sum(-1).sigmoid()

                summedProb = batchWiseLogit.sum(1)
                posterior = <a id="change">OneHotCategorical(logits=summedProb)</a>
                prior = <a id="change">OneHotCategorical(probs=torch.ones_like(summedProb) / summedProb.shape[-1])</a>
                reg<a id="change"> = </a><a id="change">torch.distributions.kl_divergence(</a>posterior, prior<a id="change">)</a> / diversity
                &#47&#47 reg += compute_penalties(unNormlogit, allowed_entropy=0.1, individual_entropy_coeff=cv, allowed_js=4.0, js_coeff=cv, cv_coeff=cv, eps=Consts.Eps)
                regs.append(reg)
            regs = sum(regs)</code></pre>