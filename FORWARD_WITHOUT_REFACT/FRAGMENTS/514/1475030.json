{"BEFORE":"                 reduce_dim=768,\n                 use_gem_pool=False,\n                 stage_with_gcb_str='0,1,2,3'):\n        super(Baseline, self).__init__()\n        stage_with_gcb = [False, False, False, False]\n        if gcb and stage_with_gcb_str:\n            stage_with_gcb_list = map(int, stage_with_gcb_str.split(','))\n            for n in stage_with_gcb_list:\n                stage_with_gcb[n] = True\n        if num_layers in [50, 101, '101_32x8d']:\n            if num_layers == 50:\n                resnet_fn = resnet50\n            elif num_layers == 101:\n                resnet_fn = resnet101\n            elif num_layers == '101_32x8d':\n                resnet_fn = resnext101_32x8d\n            self.resnet = resnet_fn(pretrained=True,\n                                    gcb=gcb,\n                                    with_ibn=with_ibn,\n                                    stage_with_gcb=stage_with_gcb)\n        elif num_layers in ['resnest50', 'resnest101', 'resnest200', 'resnest269']:\n            self.resnet = resnest_zoo[num_layers](pretrained=True,\n                                                  with_top=False,\n                                                  last_stride=1,\n                                                  )\n        elif num_layers == '101_ibn':\n            self.resnet = resnet101_ibn_a(pretrained=True, last_stride=1)\n\n        self.use_gem_pool = use_gem_pool\n        if not self.use_gem_pool:\n            self.gap = nn.AdaptiveAvgPool2d(1)\n            self.gmp = nn.AdaptiveMaxPool2d(1)\n            input_dim = 4096\n        else:\n            print('use use_gem_pool')\n            self.gemp = GeneralizedMeanPoolingP()\n            input_dim = 2048\n\n        self.embedding_layer = nn.Conv2d(input_dim, reduce_dim, kernel_size=1, stride=1, bias=False)\n        nn.init.kaiming_normal_(self.embedding_layer.weight, mode='fan_out')\n        self.bn = nn.Sequential(nn.BatchNorm2d(reduce_dim))\n        self._init_bn(self.bn)\n\n        self.fc_layer = nn.Sequential(nn.Dropout(), nn.Linear(reduce_dim, num_classes))\n        self._init_fc(self.fc_layer)\n","AFTER":"                 reduce_dim=768,\n                 pool_type='baseline',\n                 loss_type=['softmax, triplet'],\n                 margin=0.5,\n                 use_non_local=False\n                 ):\n        super(Baseline, self).__init__()\n        kwargs = {\n            'use_non_local': use_non_local\n        }\n        self.resnet = model_zoo[num_layers](\n            pretrained=True, last_stride=last_stride,\n            **kwargs\n        )\n\n        self.pool_type = pool_type\n        if self.pool_type == 'baseline':\n            self.gap = nn.AdaptiveAvgPool2d(1)\n            self.gmp = nn.AdaptiveMaxPool2d(1)\n            input_dim = 4096\n        elif self.pool_type == 'gemm':\n            print('use use_gem_pool')\n            self.gemp = GeneralizedMeanPoolingP()\n            input_dim = 2048\n        elif self.pool_type == 'norm':\n            input_dim = 2048\n\n        self.embedding_layer = nn.Conv2d(input_dim, reduce_dim,\n                                         kernel_size=1, stride=1, bias=False\n                                         )\n        nn.init.kaiming_normal_(self.embedding_layer.weight, mode='fan_out')\n        self.bn = nn.Sequential(nn.BatchNorm2d(reduce_dim))\n        self._init_bn(self.bn)\n\n        self.loss_type = loss_type\n        if 'softmax' in self.loss_type:\n            self.fc_layer = nn.Sequential(nn.Dropout(), nn.Linear(reduce_dim, num_classes))\n            self._init_fc(self.fc_layer)\n            if 'labelsmooth' in self.loss_type:\n                self.ce_loss = CrossEntropyLabelSmooth(num_classes)\n            else:\n                self.ce_loss = nn.CrossEntropyLoss()  # .cuda()\n        elif 'arcface' in self.loss_type:\n            pass\n        elif 'circle' in self.loss_type:\n            self.fc_layer = Circle(num_classes, reduce_dim)\n\n        if 'triplet' in self.loss_type:\n            self.tri_loss = TripletLoss(margin, normalize_feature=not 'circle' in self.loss_type) #.cuda()\n\n    @staticmethod\n"}