{"BEFORE":"        self.block = nn.Sequential(\n            MBConv(\n                stage_dim_in,\n                layer_dim,\n                kernel,\n                dilation,\n                padding,\n                downsample=is_first,\n                expansion_rate=mbconv_expansion_rate,\n                shrinkage_rate=mbconv_shrinkage_rate\n            ),\n            Rearrange('b d (x w1) (y w2) -> b x y w1 w2 d', w1=w, w2=w),  # block-like attention\n            PreNormResidual(layer_dim, Attention(dim=layer_dim, dim_head=dim_head, dropout=dropout, window_size=w)),\n            PreNormResidual(layer_dim, FeedForward(dim=layer_dim, dropout=dropout)),\n            Rearrange('b x y w1 w2 d -> b d (x w1) (y w2)'),\n\n            Rearrange('b d (w1 x) (w2 y) -> b x y w1 w2 d', w1=w, w2=w),  # grid-like attention\n            PreNormResidual(layer_dim, Attention(dim=layer_dim, dim_head=dim_head, dropout=dropout, window_size=w)),\n            PreNormResidual(layer_dim, FeedForward(dim=layer_dim, dropout=dropout)),\n            Rearrange('b x y w1 w2 d -> b d (w1 x) (w2 y)'),\n        )\n","AFTER":"        self.l0 = nn.Sequential(\n            nn.Conv2d(stage_dim_in, layer_dim, 1),\n            nn.BatchNorm2d(layer_dim),\n            nn.SiLU(),\n\n        )\n        self.l1 = nn.Sequential(\n            nn.Conv2d(layer_dim, layer_dim, kernel_size=kernel, stride=1, padding='same', dilation=dilation,groups=layer_dim),\n            SqueezeExcitation(layer_dim, shrinkage_rate=mbconv_shrinkage_rate),\n            nn.Conv2d(layer_dim, layer_dim, 1),\n            nn.BatchNorm2d(layer_dim)\n        )\n        self.l2 = Rearrange('b d (x w1) (y w2) -> b x y w1 w2 d', w1=w, w2=w)  # block-like attention\n        self.l3 = PreNormResidual(layer_dim, Attention(dim=layer_dim, dim_head=dim_head, dropout=dropout, window_size=w))\n        self.l4 = PreNormResidual(layer_dim, FeedForward(dim=layer_dim, dropout=dropout))\n        self.l5 = Rearrange('b x y w1 w2 d -> b d (x w1) (y w2)')\n\n        self.l6 = Rearrange('b d (w1 x) (w2 y) -> b x y w1 w2 d', w1=w, w2=w)  # grid-like attention\n        self.l7 = PreNormResidual(layer_dim, Attention(dim=layer_dim, dim_head=dim_head, dropout=dropout, window_size=w))\n        self.l8 = PreNormResidual(layer_dim, FeedForward(dim=layer_dim, dropout=dropout))\n        self.l9 = Rearrange('b x y w1 w2 d -> b d (w1 x) (w2 y)')\n"}