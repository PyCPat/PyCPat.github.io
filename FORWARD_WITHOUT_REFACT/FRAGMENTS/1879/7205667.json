{"BEFORE":"        emb = torch.einsum('bhid,jhd->bhij', q, self.weights.type(q.dtype)) * self.scale\n","AFTER":"    def forward(self, q, mem_len = 0):\n        seq_len = q.shape[2] + mem_len\n        weights = self.weights[:seq_len].type(q.dtype)\n        emb = torch.einsum('bhid,jhd->bhij', q, weights) * self.scale\n"}