{"BEFORE":"        x = self._randomize(x)\n\n        log_p = self.leaf(x)\n\n        # Forward through all layers, bottom up\n        for layer in self.layers:\n            log_p = layer(log_p)\n\n        # Root layer merges all scopes that are left\n        log_p = self.prod(log_p)\n\n        # Shift repetition dimension to build sum over repetitions\n        log_p = log_p.permute(0, 1, 3, 2)\n        log_p = self.root(log_p)\n        log_p = log_p.view(x.shape[0])\n\n        return log_p\n","AFTER":"        x = self._randomize(x)\n\n        # Apply leaf distributions (replace marginalization indicators with 0.0 first)\n        x = self._leaf(x)\n\n        # Pass through intermediate layers\n        x = self._forward_layers(x)\n\n        # Merge results from the different repetitions into the channel dimension\n        batch_size, features, channels, repetitions = x.size()\n        assert features == 1  # number of features should be 1 at this point\n        assert channels == 1  # number of channels should be 1 at this point\n        x = x.view(batch_size, 1, repetitions, 1)\n\n        # Apply C sum node outputs\n        x = self.root(x)\n\n        # Remove repetition dimension\n        x = x.squeeze(3)\n\n        # Remove in_features dimension\n        x = x.squeeze(1)\n\n        return x\n"}