{"BEFORE":"        quantizeds = list()\n        codes = list()\n        logits = list()\n        xs = list()\n        for xRaw in latents:\n            n, c, h, w = xRaw.shape\n            # [1, k, c]\n            codebook = getattr(self, \"codebook\")[None, ...]\n            # [n, c, h, w] -> [n, h, w, c]\n            encoderIn = xRaw.permute(0, 2, 3, 1)\n            # [n, h, w, c] -> [n, h*w, c]\n            encoderIn = self._position(encoderIn).reshape(n, -1, c)\n            # [1, k, c]\n            codebookQ = self._codebookQuery(codebook)\n            # [n, h*w, c]\n            x = self._encoder(encoderIn, codebookQ)\n            xs.append(x)\n            # [n, h*w, k]\n            logit = self._select(x)\n\n            # [k]\n            bernoulli = Bernoulli(probs=maskProb)\n            # [n, h*w, k] (0 or 1 -> choose or not choose)\n            randomFalseMask = bernoulli.sample((n, h*w, )).bool()\n\n            maskedLogit = logit.masked_fill(randomFalseMask, -1e9)\n\n            # randomFalseMask *= -1e9\n            # maskedLogit = logit + randomFalseMask # + randomTrueMask\n\n            sample = F.gumbel_softmax(maskedLogit, 1.0, True)\n            # [1, k, c]\n            codewords = self._codebookEncoder(codebook)\n            # [n, h*w, c]\n            quantized = sample @ codewords[0, ...]\n            # [n, h*w, c]\n            posistedQuantized = self._position(quantized.reshape(n, h, w, c)).reshape(n, -1, c)\n            # [1, k, c]\n            decodedCodes = self._codebookDecoder(codebook)\n            # [n, c, h, w]\n            deTransformed = self._decoder(posistedQuantized, decodedCodes).reshape(n, h, w, c).permute(0, 3, 1, 2)\n\n            # [n, c, h, w]\n            quantizeds.append(deTransformed)\n            codes.append(sample.argmax(-1).reshape(n, h, w))\n            logits.append(logit.reshape(n, h, w, -1))\n        return quantizeds, codes, logits, xs\n","AFTER":"    def forward(self, latents, maskProb, temperature, *_):\n        quantizeds = list()\n        codes = list()\n        logits = list()\n        xs = list()\n        transformedCodewords = list()\n        for xRaw in latents:\n            n, c, h, w = xRaw.shape\n            # [1, k, c]\n            codebook = getattr(self, \"codebook\")[None, ...]\n            # [n, c, h, w] -> [n, h, w, c]\n            encoderIn = xRaw.permute(0, 2, 3, 1)\n            # [n, h, w, c] -> [n, h*w, c]\n            encoderIn = self._position(encoderIn).reshape(n, -1, c)\n            # [1, k, c]\n            codebookQ = self._codebookQuery(codebook)\n            transformedCodewords.append(codebookQ)\n            # [n, h*w, c]\n            x = self._encoder(encoderIn, codebookQ)\n            xs.append(x)\n            # [n, h*w, k]\n            logit = self._select(x)\n\n            # [k]\n            bernoulli = Bernoulli(probs=maskProb)\n            # [n, h*w, k] (0 or 1 -> choose or not choose)\n            randomFalseMask = bernoulli.sample((n, h*w, )).bool()\n\n            maskedLogit = logit.masked_fill(randomFalseMask, -1e9)\n\n            # randomFalseMask *= -1e9\n            # maskedLogit = logit + randomFalseMask # + randomTrueMask\n\n            sample = F.gumbel_softmax(maskedLogit, temperature, True)\n            # [1, k, c]\n            codewords = self._codebookEncoder(codebook)\n            transformedCodewords.append(codewords)\n            # [n, h*w, c]\n            quantized = sample @ codewords[0, ...]\n            # [n, h*w, c]\n            posistedQuantized = self._position(quantized.reshape(n, h, w, c)).reshape(n, -1, c)\n            # [1, k, c]\n            decodedCodes = self._codebookDecoder(codebook)\n            # [n, c, h, w]\n            deTransformed = self._decoder(posistedQuantized, decodedCodes).reshape(n, h, w, c).permute(0, 3, 1, 2)\n\n            # [n, c, h, w]\n            quantizeds.append(deTransformed)\n            codes.append(sample.argmax(-1).reshape(n, h, w))\n            logits.append(logit.reshape(n, h, w, -1))\n        return quantizeds, codes, logits, (xs, transformedCodewords)\n"}