{"BEFORE":"        semantic_embeddings = []\n        h = self.hidden(h)\n        if self._cached_graph is None or self._cached_graph is not g:\n            self._cached_graph = g\n            self._cached_coalesced_graph.clear()\n            for meta_path in self.meta_paths:\n                self._cached_coalesced_graph[meta_path] = dgl.metapath_reachable_graph(\n                        g, meta_path)\n\n        for i, meta_path in enumerate(self.meta_paths):\n\n            new_g = self._cached_coalesced_graph[meta_path]\n            semantic_embeddings.append(self.propagation_layers[i](new_g, h).flatten(1))\n        semantic_embeddings = torch.stack(semantic_embeddings, dim=1)\n\n        return self.semantic_fusion(semantic_embeddings)\n","AFTER":"        h = self.hidden(h)\n        if self._cached_graph is None or self._cached_graph is not g:\n            self._cached_graph = g\n            self._cached_coalesced_graph.clear()\n            for meta_path in self.meta_paths:\n                self._cached_coalesced_graph[meta_path] = dgl.metapath_reachable_graph(\n                        g, meta_path)\n\n        h = self.model(self._cached_coalesced_graph, h)\n        return h\n"}