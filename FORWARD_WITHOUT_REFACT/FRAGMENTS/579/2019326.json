{"BEFORE":"            n = num_boxes[b_idx]\n            device = box_features.device\n\n            human_box_idx = torch.nonzero(labels == self.human_idx).squeeze(1).tolist()\n            # Skip image when there are no detected human or object instances\n            if n == 0 or len(human_box_idx) == 0:\n                continue\n            # Permute the boxes so that humans are on the top\n            permutation = torch.cat([\n                torch.as_tensor(human_box_idx, device=device),\n                torch.as_tensor([i for i in range(n) if i not in human_box_idx], device=device)\n            ])\n            coords = coords[permutation]\n            labels = labels[permutation]\n            scores = scores[permutation]\n            node_encodings = box_features[counter: counter+n][permutation]\n\n            n_h = len(human_box_idx)\n            # Get the pairwise index between every human and object instance\n            x, y = torch.meshgrid(\n                torch.arange(n_h, device=device),\n                torch.arange(n, device=device)\n            )\n            x, y = torch.nonzero(x != y).unbind(1)\n\n            for i in range(self.num_iter):\n                # Compute weights of each edge\n                weights = self.adjacency(torch.cat([\n                    node_encodings[x],\n                    node_encodings[y]\n                ], 1))\n                # Construct adjacency matrix\n                # Diagonal entries are set to zero\n                adjacency_matrix = torch.zeros([n_h, n], device=device)\n                adjacency_matrix[x, y] = torch.sigmoid(weights)\n\n                # Update human nodes\n                node_encodings[:n_h] = self.sub_update(torch.cat([\n                    node_encodings[:n_h],\n                    torch.mm(adjacency_matrix, self.obj_to_sub(node_encodings))\n                ], 1))\n\n                # Update object nodes (including human nodes)\n                node_encodings = self.obj_update(torch.cat([\n                    node_encodings,\n                    torch.mm(adjacency_matrix.t(), self.sub_to_obj(node_encodings[:n_h]))\n                ], 1))\n\n            if self.training:\n                all_labels.append(self.associate_with_ground_truth(\n                    coords[x], coords[y], targets[b_idx])\n                )\n                \n            all_box_pair_features.append(torch.cat([\n                node_encodings[x], node_encodings[y]\n            ], 1))\n            all_boxes_h.append(coords[x])\n            all_boxes_o.append(coords[y])\n            # The prior score is the product between edge weights and the\n            # pre-computed object detection scores with LIS\n            all_prior.append(\n                adjacency_matrix[x, y, None] *\n                self.compute_prior_scores(x, y, scores, labels)\n","AFTER":"            n = num_boxes[b_idx]\n            device = box_features.device\n\n            human_box_idx = torch.nonzero(labels == self.human_idx).squeeze(1).tolist()\n            # Skip image when there are no detected human or object instances\n            if n == 0 or len(human_box_idx) == 0:\n                continue\n            # Permute the boxes so that humans are on the top\n            permutation = torch.cat([\n                torch.as_tensor(human_box_idx, device=device),\n                torch.as_tensor([i for i in range(n) if i not in human_box_idx], device=device)\n            ])\n            coords = coords[permutation]\n            labels = labels[permutation]\n            scores = scores[permutation]\n            node_encodings = box_features[counter: counter+n][permutation]\n\n            n_h = len(human_box_idx)\n            # Duplicate human nodes\n            h_node_encodings = node_encodings[:n_h]\n            # Get the pairwise index between every human and object instance\n            x, y = torch.meshgrid(\n                torch.arange(n_h, device=device),\n                torch.arange(n, device=device)\n            )\n            # Remove pairs consisting of the same human instance\n            x_keep, y_keep = torch.nonzero(x != y).unbind(1)\n            # Human nodes have been duplicated and will be treated independently\n            # of the humans included amongst object nodes\n            x = x.flatten(); y = y.flatten()\n\n            for i in range(self.num_iter):\n                # Compute weights of each edge\n                weights = self.adjacency(torch.cat([\n                    h_node_encodings[x],\n                    node_encodings[y]\n                ], 1))\n                adjacency_matrix = weights.reshape(n_h, n)\n\n                # Update human nodes\n                h_node_encodings = self.sub_update(torch.cat([\n                    h_node_encodings,\n                    torch.mm(adjacency_matrix, self.obj_to_sub(node_encodings))\n                ], 1))\n\n                # Update object nodes (including human nodes)\n                node_encodings = self.obj_update(torch.cat([\n                    node_encodings,\n                    torch.mm(adjacency_matrix.t(), self.sub_to_obj(h_node_encodings))\n                ], 1))\n\n            if self.training:\n                all_labels.append(self.associate_with_ground_truth(\n                    coords[x_keep], coords[y_keep], targets[b_idx])\n                )\n                \n            all_box_pair_features.append(torch.cat([\n                h_node_encodings[x_keep], node_encodings[y_keep]\n            ], 1))\n            all_boxes_h.append(coords[x_keep])\n            all_boxes_o.append(coords[y_keep])\n            # The prior score is the product between edge weights and the\n            # pre-computed object detection scores with LIS\n            all_prior.append(\n                adjacency_matrix[x_keep, y_keep, None] *\n                self.compute_prior_scores(x_keep, y_keep, scores, labels)\n"}