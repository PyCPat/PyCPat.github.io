{"BEFORE":"            x = self.transformer(x_categ)\n\n            flat_categ = x.flatten(1)\n            xs.append(flat_categ)\n\n        assert x_cont.shape[1] == self.num_continuous, f'you must pass in {self.num_continuous} values for your continuous input'\n\n        if self.num_continuous > 0:\n            if exists(self.continuous_mean_std):\n                mean, std = self.continuous_mean_std.unbind(dim = -1)\n                x_cont = (x_cont - mean) \/ std\n\n            normed_cont = self.norm(x_cont)\n            xs.append(normed_cont)\n\n        x = torch.cat(xs, dim = -1)\n        return self.mlp(x)\n","AFTER":"    def forward(self, x_categ, x_cont, return_attn = False):\n        xs = []\n\n        assert x_categ.shape[-1] == self.num_categories, f'you must pass in {self.num_categories} values for your categories input'\n\n        if self.num_unique_categories > 0:\n            x_categ += self.categories_offset\n\n            x, attns = self.transformer(x_categ, return_attn = True)\n\n            flat_categ = x.flatten(1)\n            xs.append(flat_categ)\n\n        assert x_cont.shape[1] == self.num_continuous, f'you must pass in {self.num_continuous} values for your continuous input'\n\n        if self.num_continuous > 0:\n            if exists(self.continuous_mean_std):\n                mean, std = self.continuous_mean_std.unbind(dim = -1)\n                x_cont = (x_cont - mean) \/ std\n\n            normed_cont = self.norm(x_cont)\n            xs.append(normed_cont)\n\n        x = torch.cat(xs, dim = -1)\n        logits =self.mlp(x)\n\n        if not return_attn:\n            return logits\n\n        return logits, attns\n"}