{"BEFORE":"        sequence_length = self.model._get_feat_extract_output_lengths(\n            raw_sequence_length\n        )\n\n        # 1. Compute the indices that will be masked\n        mask_time_indices = _compute_mask_indices(\n            (batch_size, sequence_length),\n            mask_prob=self.mask_prob,\n            mask_length=self.mask_length,\n        )\n        torch_mask_time_indices = torch.tensor(\n            mask_time_indices, device=wav.device, dtype=torch.long,\n        )\n\n        # 2. Sample the negative samples from the masked indices.\n        # The number of negative must be < 50% of the number of masked indices\n        # this is critical for short sentences that may always selected all\n        # the masked indices as negatives (hence reducing variability)\n        # Hence, if the number of required samples is higher than half of the\n        # total number of masked indices, we enforce it to become 50% of this\n        # value.\n        # max_number_negative = (\n        #    torch_mask_time_indices.sum(dim=-1).min() \/\/ self.negative_threshold\n        # )\n        # if self.config.num_negatives > max_number_negative:\n        #    dynamic_num_negatives = max_number_negative\n        # else:\n        dynamic_num_negatives = self.config.num_negatives\n        # print(dynamic_num_negatives)\n        # print(np.sum(mask_time_indices, axis=1))\n        negative_sample_indices = torch.tensor(\n            transformers.models.wav2vec2.modeling_wav2vec2._sample_negative_indices(\n                (batch_size, sequence_length),\n                num_negatives=dynamic_num_negatives,\n                mask_time_indices=mask_time_indices,\n            ),\n            device=wav.device,\n            dtype=torch.long,\n        )\n        print(sequence_length)\n        print(torch_mask_time_indices.shape)\n        print(negative_sample_indices.shape)\n","AFTER":"        torch_mask_time_indices = torch.tensor(\n            mask_time_indices, device=wav.device, dtype=torch.long,\n        )\n\n        # 2. Sample the negative samples from the masked indices.\n        # The number of negative must be < 50% of the number of masked indices\n        # this is critical for short sentences that may always selected all\n        # the masked indices as negatives (hence reducing variability)\n        # Hence, if the number of required samples is higher than half of the\n        # total number of masked indices, we enforce it to become 50% of this\n        # value.\n        max_number_negative = (\n            torch_mask_time_indices.sum(dim=-1).min() \/\/ self.negative_threshold\n        )\n        if self.config.num_negatives > max_number_negative:\n            dynamic_num_negatives = max_number_negative\n        else:\n            dynamic_num_negatives = self.config.num_negatives\n\n        # print(np.sum(mask_time_indices, axis=1))\n        negative_sample_indices = torch.tensor(\n"}