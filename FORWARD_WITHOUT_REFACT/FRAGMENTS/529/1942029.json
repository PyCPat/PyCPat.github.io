{"BEFORE":"\tdef forward(self, content_img_id, style_img_id, class_id):\n\t\tbatch_size = content_img_id.shape[0]\n\n\t\tcontent_code = self.content_embedding(content_img_id)\n\t\tstyle_code = self.style_embedding(style_img_id)\n\t\tclass_code = self.class_embedding(class_id)\n\n\t\tif self.training and self.config['content_std'] != 0:\n\t\t\tnoise = torch.zeros_like(content_code)\n\t\t\tnoise.normal_(mean=0, std=self.config['content_std'])\n\n\t\t\tregularized_content_code = content_code + noise\n\t\telse:\n\t\t\tregularized_content_code = content_code\n\n\t\tif self.training and self.config['style_std'] != 0:\n\t\t\tnoise = torch.zeros_like(style_code)\n\t\t\tnoise.normal_(mean=0, std=self.config['style_std'])\n\n\t\t\tregularized_style_code = style_code + noise\n\t\telse:\n\t\t\tregularized_style_code = style_code\n\n\t\tclass_with_style_code = torch.cat((class_code, regularized_style_code), dim=1)\n\t\tclass_with_style_code = self.class_style_modulation(class_with_style_code)\n\n\t\tadain_params = self.modulation(class_with_style_code)\n\t\tgenerated_img = self.decoder(regularized_content_code, adain_params)\n\n\t\treturn {\n\t\t\t'img': generated_img,\n\t\t\t'content_code': content_code,\n\t\t\t'style_code': style_code\n\t\t}\n","AFTER":"\t\tx = self.from_rgb(content_img)\n\n\t\tfor block in self.encoder:\n\t\t\tx = block(x)\n\n\t\tcontent_code = x\n\t\tif self.training and self.config['content_std'] != 0:\n\t\t\tnoise = torch.zeros_like(x)\n\t\t\tnoise.normal_(mean=0, std=self.config['content_std'])\n\n\t\t\tx = x + noise\n\n\t\tif self.training and self.config['style_std'] != 0:\n\t\t\tnoise = torch.zeros_like(style_code)\n\t\t\tnoise.normal_(mean=0, std=self.config['style_std'])\n\n\t\t\tstyle_code = style_code + noise\n\n\t\tfor block in self.decoder:\n\t\t\tx = block(x, style_code)\n\n\t\treturn {\n\t\t\t'img': self.to_rgb(x),\n\t\t\t'content_code': content_code.reshape(x.shape[0], -1)\n\t\t}\n"}