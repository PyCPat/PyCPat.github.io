{"BEFORE":"        fea = src[:, :, :36]  # [128, 215, 36]\n        # mask = src[:, :, 36:]\n\n        output = torch.zeros((batch_size, self.d_K)).cuda()  # 68 = 2*(32+1+1)\n        for i in range(batch_size):\n            nonzero_index = fea[i].nonzero(as_tuple=False)\n            values = fea[i][nonzero_index[:,0], nonzero_index[:,1]] # v in SEFT paper\n            time_index = nonzero_index[:,0]\n            time_sequence = times[:, i]\n            time_points = time_sequence[time_index]  # t in SEFT paper\n            pe_ = self.pos_encoder(time_points.unsqueeze(1)).squeeze(1)\n            variable = nonzero_index[:,1] # the dimensions of variables. The m value in SEFT paper.\n\n            unit = torch.cat([pe_, values.unsqueeze(1), variable.unsqueeze(1)], dim=1)\n\n            # # \"\"\"positional encoding\"\"\"  AUROC ~0.86 Why positional encoding works?\n            # # values_ = self.pos_encoder_value(values.unsqueeze(1)).squeeze(1)\n            # variable_ = self.pos_encoder_sensor(variable.unsqueeze(1)).squeeze(1)\n            #\n            # \"\"\"linear mapping\"\"\" # AUROC~0.8\n            # # values_ =  self.linear_value(values.float().unsqueeze(1)).squeeze(1)\n            # # variable_ = self.linear_sensor(variable.float().unsqueeze(1)).squeeze(1)\n            #\n            # \"\"\"Nonlinear transformation\"\"\" # AUROC ~0.8\n            # values_ =  F.relu(self.linear_value(values.float().unsqueeze(1))).squeeze(1)\n            # # variable_ =  F.relu(self.linear_sensor(variable.float().unsqueeze(1))).squeeze(1)\n            #\n            # unit = torch.cat([pe_, values_, variable_], dim=1)\n            # \"\"\"Add Normalization across samples here, to make all 48-dimensions are in similar scale\"\"\"\n            # unit = F.normalize(unit, dim=1)\n\n            # \"\"\"use 2-layer transformer to get f'\"\"\"\n            # trans_unit = self.transformer_encoder_f_prime(unit.unsqueeze(1))\n            # f_prime = torch.mean(trans_unit, dim=0) # [435, 34] --> [1,34]\n\n            f_prime = torch.mean(unit, dim=0)\n\n            x = torch.cat([f_prime.repeat(unit.shape[0], 1), unit], dim=1)\n            x = x.unsqueeze(1) #.repeat(1,2,1)  # shape[469, 2, 68]\n            output_unit = self.transformer_encoder(x)\n            output_unit = torch.mean(output_unit, dim=0)\n            output[i,:] = output_unit\n        # print(output.shape)\n        output = output.matmul(self.proj_weight)  # dimension: 68-->32\n\n        if static is not None:\n            emb = self.emb(static)  # emb.shape = [128, 64]. Linear layer: 9--> 64\n\n        # feed through MLP\n        output = torch.cat([emb, output], dim=1)  # x.shape: [216, 128, 64]\n","AFTER":"        src = src.permute(1, 0,2) # shape [128, 215, 36+36]\n        # fea = src[:, :, :36]  # [128, 215, 36]\n        fea = src[:, :, :int(src.shape[2]\/2)]\n        # mask = src[:, :, 36:]\n\n        output = torch.zeros((batch_size, self.d_K)).cuda()  # 68 = 2*(32+1+1)\n        # output = torch.ones((batch_size, 4)).cuda()\n        for i in range(batch_size):\n            nonzero_index = fea[i].nonzero(as_tuple=False)\n            if nonzero_index.shape[0]==0:\n                continue\n            values = fea[i][nonzero_index[:,0], nonzero_index[:,1]] # v in SEFT paper\n            time_index = nonzero_index[:,0]\n            time_sequence = times[:, i]\n            time_points = time_sequence[time_index]  # t in SEFT paper\n            pe_ = self.pos_encoder(time_points.unsqueeze(1)).squeeze(1)\n            # pe_ = torch.zeros(pe_.shape).cuda()\n\n            variable = nonzero_index[:,1] # the dimensions of variables. The m value in SEFT paper.\n\n            unit = torch.cat([pe_, values.unsqueeze(1), variable.unsqueeze(1)], dim=1)\n\n            # \"\"\"positional encoding\"\"\"  AUROC ~0.86 Why positional encoding works?\n            # values_ = self.pos_encoder_value(values.unsqueeze(1)).squeeze(1)\n            variable_ = self.pos_encoder_sensor(variable.unsqueeze(1)).squeeze(1)\n\n            \"\"\"linear mapping\"\"\" # AUROC~0.8\n            values_ =  self.linear_value(values.float().unsqueeze(1)).squeeze(1)\n            # variable_ = self.linear_sensor(variable.float().unsqueeze(1)).squeeze(1)\n\n            \"\"\"Nonlinear transformation\"\"\" # AUROC ~0.8\n            # values_ =  F.relu(self.linear_value(values.float().unsqueeze(1))).squeeze(1)\n            # variable_ =  F.relu(self.linear_sensor(variable.float().unsqueeze(1))).squeeze(1)\n\n            unit = torch.cat([pe_, values_, variable_], dim=1)\n            # \"\"\"Add Normalization across samples here, to make all 48-dimensions are in similar scale\"\"\"\n            # unit = F.normalize(unit, dim=1)\n\n            # \"\"\"use 2-layer transformer to get f'\"\"\"\n            # trans_unit = self.transformer_encoder_f_prime(unit.unsqueeze(1))\n            # f_prime = torch.mean(trans_unit, dim=0) # [435, 34] --> [1,34]\n\n            f_prime = torch.mean(unit, dim=0)\n\n            x = torch.cat([f_prime.repeat(unit.shape[0], 1), unit], dim=1)\n            # x = torch.cat([unit, unit], dim=1)\n\n            x = x.unsqueeze(1) #.repeat(1,2,1)  # shape[469, 2, 68]\n            # output_unit = self.transformer_encoder(x)\n\n            output_unit = x\n\n            output_unit = torch.mean(output_unit, dim=0)\n            output[i,:] = output_unit\n\n        output = self.lin_map(output) # dimension: 68-->32\n\n        # emb = self.emb(static)  # Linear layer: 9--> 16\n        if static is not None:\n            emb = self.emb(static)  # emb.shape = [128, 64]. Linear layer: 9--> 64\n\n\n        # feed through MLP\n        # output = torch.cat([ output, emb], dim=1)  # x.shape: [216, 128, 64]\n        if static is not None:\n            output = torch.cat([output, emb], dim=1) # [128, 36*5+9] # emb with dim: d_model\n        # output = torch.mean(fea, dim=1)\n        output = self.mlp(output)  # two linears: 64-->64-->2\n"}