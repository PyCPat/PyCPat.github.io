{"BEFORE":"        point_features_list = []\n        if 'bev' in self.model_cfg['features_source']:\n            point_bev_features = self.interpolate_from_bev_features(\n                keypoints[..., :3], batch_dict['spatial_features'], batch_dict['batch_size'],\n                bev_stride=batch_dict['spatial_features_stride']\n            )\n            point_features_list.append(point_bev_features[kpt_mask])\n\n        batch_size, num_keypoints, _ = keypoints.shape\n        # new_xyz = keypoints.view(-1, 3)\n        # new_xyz_batch_cnt = new_xyz.new_zeros(batch_size).int().fill_(num_keypoints)\n        new_xyz = keypoints[kpt_mask]\n        new_xyz_batch_cnt = torch.tensor([(mask).sum() for mask in kpt_mask], device=new_xyz.device).int()\n\n        if 'raw_points' in self.model_cfg['features_source']:\n            raw_points = batch_dict['points']\n            xyz = raw_points[:, 1:4]\n            xyz_batch_cnt = xyz.new_zeros(batch_size).int()\n            for bs_idx in range(batch_size):\n                xyz_batch_cnt[bs_idx] = (raw_points[:, 0] == bs_idx).sum()\n            # point_features = raw_points[:, 4:].contiguous() if raw_points.shape[1] > 4 else None\n            point_features =  None\n\n            pooled_points, pooled_features = self.SA_rawpoints(\n                xyz=xyz.contiguous(),\n                xyz_batch_cnt=xyz_batch_cnt,\n                new_xyz=new_xyz[:, :3].contiguous(),\n                new_xyz_batch_cnt=new_xyz_batch_cnt,\n                features=point_features,\n            )\n            # point_features_list.append(pooled_features.view(batch_size, num_keypoints, -1))\n            point_features_list.append(pooled_features)\n\n        for k, src_name in enumerate(self.SA_layer_names):\n            cur_coords = batch_dict['multi_scale_3d_features'][src_name].indices\n            xyz = common_utils.get_voxel_centers(\n                cur_coords[:, 1:4],\n                downsample_times=self.downsample_times_map[src_name],\n                voxel_size=self.voxel_size,\n                point_cloud_range=self.point_cloud_range\n            )\n            xyz_batch_cnt = xyz.new_zeros(batch_size).int()\n            for bs_idx in range(batch_size):\n                xyz_batch_cnt[bs_idx] = (cur_coords[:, 0] == bs_idx).sum()\n\n            pooled_points, pooled_features = self.SA_layers[k](\n                xyz=xyz.contiguous(),\n                xyz_batch_cnt=xyz_batch_cnt,\n                new_xyz=new_xyz[:, :3].contiguous(),\n                new_xyz_batch_cnt=new_xyz_batch_cnt,\n                features=batch_dict['multi_scale_3d_features'][src_name].features.contiguous(),\n            )\n            # point_features_list.append(pooled_features.view(batch_size, num_keypoints, -1))\n            point_features_list.append(pooled_features)\n        if self.model_cfg['add_ego_mask_feature']:\n            ego_mask = torch.ones((len(new_xyz), 1), device=point_features_list[0].device)\n            ego_mask[new_xyz_batch_cnt[0]:] = 0\n            point_features_list.append(ego_mask)\n\n        point_features = torch.cat(point_features_list, dim=1)\n\n        # batch_idx = torch.arange(batch_size, device=keypoints.device).view(-1, 1).repeat(1, keypoints.shape[1]).view(-1)\n        # point_coords = torch.cat((batch_idx.view(-1, 1).float(), keypoints.view(-1, 3)), dim=1)\n\n        batch_dict['point_features_before_fusion'] = point_features.view(-1, point_features.shape[-1])\n        point_features = self.vsa_point_feature_fusion(point_features.view(-1, point_features.shape[-1]))\n\n        cur_idx = 0\n        batch_dict['point_features'] = []\n        batch_dict['point_coords'] = []\n        for num in new_xyz_batch_cnt:\n            batch_dict['point_features'].append(point_features[cur_idx:cur_idx + num])\n            batch_dict['point_coords'].append(new_xyz[cur_idx:cur_idx + num])\n","AFTER":"            for i, dets in enumerate(dets_list):\n                if len(dets)==0:\n                    continue\n                cur_dets = dets.clone()\n                if self.model_cfg['enlarge_selection_boxes']:\n                    cur_dets[:, 3:6] += 0.5\n                boxes[i, :len(dets)] = cur_dets\n            #### mask out some keypoints to spare the GPU storage\n            kpt_mask2 = points_in_boxes_gpu(keypoints[..., :3], boxes) >= 0\n            # kpt_mask = (keypoints[:,:,3:]== torch.tensor(labels_used, device=keypoints.device).view(1, 1, -1)).sum(dim=2).bool()\n            # kpt_mask = torch.ones(keypoints.shape[:2], device=keypoints.device).bool()\n        kpt_mask = torch.logical_and(kpt_mask1, kpt_mask2) if kpt_mask2 is not None else kpt_mask1\n        # Ensure there are more than 2 points are selected to satisfy the condition of batch norm in\n        # the FC layers of feature fusion module\n        if (kpt_mask).sum()<2:\n            kpt_mask[0, random.randint(0, 1024)] = True\n            kpt_mask[1, random.randint(0, 1024)] = True\n\n        # import matplotlib.pyplot as plt\n        # from vlib.point import draw_box_plt\n        # fig = plt.figure(figsize=(20, 20))\n        # ax = fig.add_subplot(111)\n        # pcd = keypoints[0].cpu().numpy()\n        # ax.plot(pcd[:, 0], pcd[:, 1], '.', markersize=5)\n        # boxes_vis = dets_list[0].detach().cpu().numpy()\n        # draw_box_plt(boxes_vis, ax)\n        # plt.savefig('\/media\/hdd\/ophelia\/tmp\/tmp.png')\n        # plt.close()\n\n        point_features_list = []\n        if 'bev' in self.model_cfg['features_source']:\n            point_bev_features = self.interpolate_from_bev_features(\n                keypoints[..., :3], batch_dict['processed_lidar']['spatial_features'], batch_dict['batch_size'],\n                bev_stride=batch_dict['processed_lidar']['spatial_features_stride']\n            )\n            point_features_list.append(point_bev_features[kpt_mask])\n\n        batch_size, num_keypoints, _ = keypoints.shape\n        # new_xyz = keypoints.view(-1, 3)\n        # new_xyz_batch_cnt = new_xyz.new_zeros(batch_size).int().fill_(num_keypoints)\n        new_xyz = keypoints[kpt_mask]\n        new_xyz_batch_cnt = torch.tensor([(mask).sum() for mask in kpt_mask], device=new_xyz.device).int()\n\n        if 'raw_points' in self.model_cfg['features_source']:\n            raw_points = batch_dict['origin_lidar']\n            xyz = raw_points[:, 1:4]\n            xyz_batch_cnt = xyz.new_zeros(batch_size).int()\n            for bs_idx in range(batch_size):\n                xyz_batch_cnt[bs_idx] = (raw_points[:, 0] == bs_idx).sum()\n            # point_features = raw_points[:, 4:].contiguous() if raw_points.shape[1] > 4 else None\n            point_features =  None\n\n            pooled_points, pooled_features = self.SA_rawpoints(\n                xyz=xyz.contiguous(),\n                xyz_batch_cnt=xyz_batch_cnt,\n                new_xyz=new_xyz[:, :3].contiguous(),\n                new_xyz_batch_cnt=new_xyz_batch_cnt,\n                features=point_features,\n            )\n            # point_features_list.append(pooled_features.view(batch_size, num_keypoints, -1))\n            point_features_list.append(pooled_features)\n\n        for k, src_name in enumerate(self.SA_layer_names):\n            cur_coords = batch_dict['processed_lidar']['multi_scale_3d_features'][src_name].indices\n            xyz = common_utils.get_voxel_centers(\n                cur_coords[:, 1:4],\n                downsample_times=self.downsample_times_map[src_name],\n                voxel_size=self.voxel_size,\n                point_cloud_range=self.point_cloud_range\n            )\n            xyz_batch_cnt = xyz.new_zeros(batch_size).int()\n            for bs_idx in range(batch_size):\n                xyz_batch_cnt[bs_idx] = (cur_coords[:, 0] == bs_idx).sum()\n\n            pooled_points, pooled_features = self.SA_layers[k](\n                xyz=xyz.contiguous(),\n                xyz_batch_cnt=xyz_batch_cnt,\n                new_xyz=new_xyz[:, :3].contiguous(),\n                new_xyz_batch_cnt=new_xyz_batch_cnt,\n                features=batch_dict['processed_lidar']['multi_scale_3d_features'][src_name].features.contiguous(),\n            )\n            # point_features_list.append(pooled_features.view(batch_size, num_keypoints, -1))\n            point_features_list.append(pooled_features)\n\n        point_features = torch.cat(point_features_list, dim=1)\n\n        # batch_idx = torch.arange(batch_size, device=keypoints.device).view(-1, 1).repeat(1, keypoints.shape[1]).view(-1)\n        # point_coords = torch.cat((batch_idx.view(-1, 1).float(), keypoints.view(-1, 3)), dim=1)\n\n        batch_dict['processed_lidar']['point_features_before_fusion'] = point_features.view(-1, point_features.shape[-1])\n        point_features = self.vsa_point_feature_fusion(point_features.view(-1, point_features.shape[-1]))\n\n        cur_idx = 0\n        batch_dict['processed_lidar']['point_features'] = []\n        batch_dict['processed_lidar']['point_coords'] = []\n        for num in new_xyz_batch_cnt:\n            batch_dict['processed_lidar']['point_features'].append(point_features[cur_idx:cur_idx + num])\n            batch_dict['processed_lidar']['point_coords'].append(new_xyz[cur_idx:cur_idx + num])\n"}