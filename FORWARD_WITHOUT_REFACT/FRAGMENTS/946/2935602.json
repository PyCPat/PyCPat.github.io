{"BEFORE":"        z = rearrange(z, 'b c h w -> b h w c').contiguous()\n        z_flattened = z.view(-1, self.e_dim)\n        # distances from z to embeddings e_j (z - e)^2 = z^2 + e^2 - 2 e * z\n\n        d = torch.sum(z_flattened ** 2, dim=1, keepdim=True) + \\\n            torch.sum(self.embedding.weight**2, dim=1) - 2 * \\\n            torch.einsum('bd,dn->bn', z_flattened, rearrange(self.embedding.weight, 'n d -> d n'))\n\n        min_encoding_indices = torch.argmin(d, dim=1)\n        z_q = self.embedding(min_encoding_indices).view(z.shape)\n        perplexity = None\n        min_encodings = None\n\n        # compute loss for embedding\n\n        loss = torch.mean((z_q.detach()-z)**2) + self.beta * \\\n                   torch.mean((z_q - z.detach()) ** 2)\n\n        # preserve gradients\n        z_q = z + (z_q - z).detach()\n\n        # reshape back to match original input shape\n        z_q = rearrange(z_q, 'b h w c -> b c h w').contiguous()\n","AFTER":"        z = z.permute(0, 2, 3, 1).contiguous()\n        z_flattened = z.view(-1, self.e_dim)\n        # distances from z to embeddings e_j (z - e)^2 = z^2 + e^2 - 2 e * z\n\n        d = torch.sum(z_flattened ** 2, dim=1, keepdim=True) + \\\n            torch.sum(self.embedding.weight**2, dim=1) - 2 * \\\n            torch.einsum('bd,dn->bn', z_flattened, self.embedding.weight.permute(1,0).continuous()) # 'n d -> d n'\n\n        min_encoding_indices = torch.argmin(d, dim=1)\n        z_q = self.embedding(min_encoding_indices).view(z.shape)\n        perplexity = None\n        min_encodings = None\n\n        # compute loss for embedding\n\n        loss = torch.mean((z_q.detach()-z)**2) + self.beta * \\\n                   torch.mean((z_q - z.detach()) ** 2)\n\n        # preserve gradients\n        z_q = z + (z_q - z).detach()\n\n        # reshape back to match original input shape\n        #z_q, 'b h w c -> b c h w'\n        z_q = z_q.permute(0, 3, 1, 2).contiguous()\n"}