{"BEFORE":"                x = layer(x)\n            else:\n                x = layer(x, adj)\n\n        x = F.relu(self.linear1(x))\n        if self.dropout is not None:\n            x = self.dropout(x)\n        x = self.linear2(x)\n","AFTER":"                x = layer(x)\n            else:\n                x = layer(x, adj)\n\n        for i, layer in enumerate(self.mlp_layers):\n            x = layer(x)\n            if i != len(self.mlp_layers) - 1:\n                x = self.activation(x)\n                if self.dropout is not None:\n                    x = self.dropout(x)\n\n        return x\n"}