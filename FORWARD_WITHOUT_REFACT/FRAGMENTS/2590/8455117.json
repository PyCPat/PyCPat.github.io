{"BEFORE":"    def forward(self, x, mask=None):\n        b, n, _ = x.shape\n\n        q = self.query(x).view(b, -1, self.heads, self.head_dim)\n        k = self.key(x).view(b, -1, self.heads, self.head_dim)\n        v = self.value(x).view(b, -1, self.heads, self.head_dim)\n\n        scores = torch.matmul(q, k.transpose(-2, -1)) \/ self.scale\n        if mask is not None:\n            scores = scores.masked_fill(mask == 0, -1e9)\n\n        attn_scores = F.softmax(scores, dim=-1)\n\n        out = torch.matmul(attn_scores, v)\n        out = out.transpose(1, 2).contiguous().view(b, -1, self.heads * self.head_dim)\n","AFTER":"        q = self.query(x, dims=([2], [0]))\n        k = self.key(x, dims=([2], [0]))\n        v = self.value(x, dims=([2], [0]))\n\n        q = q.permute(0, 2, 1, 3)\n        k = k.permute(0, 2, 1, 3)\n        v = v.permute(0, 2, 1, 3)\n\n        attn_weights = torch.matmul(q, k.transpose(-2, -1)) \/ self.scale\n        attn_weights = F.softmax(attn_weights, dim=-1)\n        out = torch.matmul(attn_weights, v)\n        out = out.permute(0, 2, 1, 3)\n"}