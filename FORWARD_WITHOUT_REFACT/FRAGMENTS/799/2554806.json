{"BEFORE":"        src = self.encoder(src) * math.sqrt(self.d_model)  # linear layer: 72 --> 32\n\n        pe = self.pos_encoder(times)  # times.shape = [215, 128], the values are hours.\n        # pe.shape = [215, 128, 32]\n\n        \"\"\"Here are two options: plus or concat\"\"\"\n        #         src = src + pe\n        src = torch.cat([pe, src], axis=2)  # shape: [215, 128, 64]\n\n\n        src = self.dropout(src)\n\n        emb = self.emb(static)  # emb.shape = [128, 64]. Linear layer: 9--> 64\n\n        # append context on front\n        # \"\"\"215-D for time series and 1-D for static info\"\"\"\n        x = src\n\n        \"\"\"mask out the all-zero rows. \"\"\"\n        # mask = torch.arange(maxlen + 1)[None, :] >= (lengths.cpu()[:, None] + 1)\n        mask = torch.arange(maxlen)[None, :] >= (lengths.cpu()[:, None])\n        mask = mask.squeeze(1).cuda()  # shape: [128, 216]\n\n        output = self.transformer_encoder(x, src_key_padding_mask=mask) # output.shape: [216, 128, 64]\n\n        # masked aggregation\n        mask2 = mask.permute(1, 0).unsqueeze(2).long()  # [216, 128, 1]\n        if self.aggreg == 'mean':\n            lengths2 = lengths.unsqueeze(1)\n            output = torch.sum(output * (1 - mask2), dim=0) \/ (lengths2 + 1)\n        elif self.aggreg == 'max':\n            output, _ = torch.max(output * ((mask2 == 0) * 1.0 + (mask2 == 1) * -10.0), dim=0)\n\n        # feed through MLP\n        output = torch.cat([emb, output], dim=1)  # x.shape: [216, 128, 64]\n        output = self.mlp(output)  # two linears: 64-->64-->2\n        return output\n","AFTER":"        src = src[:, :, :int(src.shape[2]\/2)] # remove the mask info\n\n        \"\"\"Question: why 72 features (36 feature + 36 mask)?\"\"\"\n        src = self.encoder(src) #* math.sqrt(self.d_model)  # linear layer: 72 --> 32\n        pe = self.pos_encoder(times)  # times.shape = [215, 128], the values are hours.\n        # pe.shape = [215, 128, 32]\n\n        \"\"\"Here are two options: plus or concat\"\"\"\n        #         src = src + pe\n        src = torch.cat([pe, src], axis=2)  # shape: [215, 128, 64]\n\n\n        src = self.dropout(src)\n\n        emb = self.emb(static)  # emb.shape = [128, 64]. Linear layer: 9--> 64\n\n        # append context on front\n        # \"\"\"215-D for time series and 1-D for static info\"\"\"\n        x = src\n\n        \"\"\"mask out the all-zero rows. \"\"\"\n        # mask = torch.arange(maxlen + 1)[None, :] >= (lengths.cpu()[:, None] + 1)\n        mask = torch.arange(maxlen)[None, :] >= (lengths.cpu()[:, None])\n        mask = mask.squeeze(1).cuda()  # shape: [128, 216]\n\n        output = self.transformer_encoder(x, src_key_padding_mask=mask) # output.shape: [216, 128, 64]\n\n        \"\"\"What if no transformer? just MLP, the performance is still good!!!\"\"\"\n        # output = x\n\n        # masked aggregation: this really matters.\n        mask2 = mask.permute(1, 0).unsqueeze(2).long()  # [216, 128, 1]\n        if self.aggreg == 'mean':\n            lengths2 = lengths.unsqueeze(1)\n            output = torch.sum(output * (1 - mask2), dim=0) \/ (lengths2 + 1)\n        elif self.aggreg == 'max':\n            output, _ = torch.max(output * ((mask2 == 0) * 1.0 + (mask2 == 1) * -10.0), dim=0)\n\n        # output = torch.sum(output , dim=0) \/ (lengths.unsqueeze(1) + 1)\n\n        # feed through MLP\n        output = torch.cat([output, emb], dim=1)  # x.shape: [216, 128, 64]\n        output = self.mlp(output)  # two linears: 64-->64-->2\n        return output, 0, 0\n"}