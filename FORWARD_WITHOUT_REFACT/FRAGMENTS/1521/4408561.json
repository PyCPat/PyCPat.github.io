{"BEFORE":"                d_weight = torch.tensor(self.adversarial_weight)\n                \n                if self.use_adaptive_adv:\n                    d_weight *= self.calculate_adaptive_factor(nll_loss, g_loss, last_layer=last_layer)\n            except RuntimeError:\n                assert not self.training\n                d_weight = torch.tensor(0.0)\n\n            disc_factor = 1 if global_step >= self.discriminator_iter_start else 0\n            loss = nll_loss + disc_factor * d_weight * g_loss + self.codebook_weight * codebook_loss\n\n            log = {\"{}\/total_loss\".format(split): loss.clone().detach(),\n                   \"{}\/quant_loss\".format(split): codebook_loss.detach(),\n                   \"{}\/rec_loss\".format(split): nll_loss.detach(),\n                   \"{}\/loglaplace_loss\".format(split): loglaplace_loss.detach(),\n                   \"{}\/loggaussian_loss\".format(split): loggaussian_loss.detach(),\n                   \"{}\/perceptual_loss\".format(split): perceptual_loss.detach(),\n                   \"{}\/d_weight\".format(split): d_weight.detach(),\n","AFTER":"                d_weight = self.adversarial_weight\n                \n                if self.use_adaptive_adv:\n                    d_weight *= self.calculate_adaptive_factor(nll_loss, g_loss, last_layer=last_layer)\n            except RuntimeError:\n                assert not self.training\n                d_weight = torch.tensor(0.0)\n\n            disc_factor = 1 if global_step >= self.discriminator_iter_start else 0\n            loss = nll_loss + disc_factor * d_weight * g_loss + self.codebook_weight * codebook_loss\n\n            log = {\"{}\/total_loss\".format(split): loss.clone().detach(),\n                   \"{}\/quant_loss\".format(split): codebook_loss.detach(),\n                   \"{}\/rec_loss\".format(split): nll_loss.detach(),\n                   \"{}\/loglaplace_loss\".format(split): loglaplace_loss.detach(),\n                   \"{}\/loggaussian_loss\".format(split): loggaussian_loss.detach(),\n                   \"{}\/perceptual_loss\".format(split): perceptual_loss.detach(),\n                   \"{}\/g_loss\".format(split): g_loss.detach(),\n                   }\n\n            if self.use_adaptive_adv:\n                log[\"{}\/d_weight\".format(split)] =  d_weight.detach()\n            \n            return loss, log\n"}