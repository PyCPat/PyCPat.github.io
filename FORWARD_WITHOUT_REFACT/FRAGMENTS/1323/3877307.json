{"BEFORE":"        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n        phi = cosine * self.cos_m - sine * self.sin_m\n        if self.easy_margin:\n            phi = torch.where(cosine > 0, phi, cosine)\n        else:\n            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n        # --------------------------- convert label to one-hot ---------------------------\n        # one_hot = torch.zeros(cosine.size(), requires_grad=True, device='cuda')\n        one_hot = torch.zeros(cosine.size(), device = 'cuda')\n        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)  # you can use torch.where if your torch.__version__ is 0.4\n        output *= self.s\n","AFTER":"        embbedings = l2_norm(embbedings, axis = 1)\n        kernel_norm = l2_norm(self.kernel, axis = 0)\n        cos_theta = torch.mm(embbedings, kernel_norm)\n        cos_theta = cos_theta.clamp(-1, 1)  # for numerical stability\n        with torch.no_grad():\n            origin_cos = cos_theta.clone()\n        target_logit = cos_theta[torch.arange(0, embbedings.size(0)), label].view(-1, 1)\n\n        sin_theta = torch.sqrt(1.0 - torch.pow(target_logit, 2))\n        cos_theta_m = target_logit * self.cos_m - sin_theta * self.sin_m #cos(target+margin)\n        if self.easy_margin:\n            final_target_logit = torch.where(target_logit > 0, cos_theta_m, target_loit)\n        else:\n            final_target_logit = torch.where(target_logit > self.th, cos_theta_m, target_logit - self.mm)\n\n        cos_theta.scatter_(1, label.view(-1, 1).long(), final_target_logit)\n        output = cos_theta * self.s\n"}