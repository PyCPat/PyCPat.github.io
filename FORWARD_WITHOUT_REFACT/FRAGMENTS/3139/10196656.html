<link rel="stylesheet" href="../default.css">
<script src="../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        encoded: torch.Tensor [batch, series, time steps, output embedding dimension]
            The encoded embedding for each series and time step.
        
        <a id="change">pass</a>


class TemporalEncoder(nn.Module):
    </code></pre><h3>After Change</h3><pre><code class='java'>
        encoded = encoded.view(num_batches, num_series * num_timesteps, self.embedding_dim)

        &#47&#47 The PyTorch implementation wants the following order: [tokens, batch, embedding]
        encoded<a id="change"> = </a><a id="change">encoded.transpose(0</a>, <a id="change">1</a><a id="change">)</a>

        output = self.transformer_encoder(
            encoded, mask=torch.zeros(encoded.shape[0], encoded.shape[0], device=encoded.device)
        )

        &#47&#47 Reset to the original shape
        output<a id="change"> = </a>output.transpose(0, 1)
        output<a id="change"> = </a>output.view(num_batches, num_series, num_timesteps, self.embedding_dim)

        <a id="change">return </a>output


class TemporalEncoder(nn.Module):</code></pre>