{"BEFORE":"        attention_state: FloatTensor,\n        prev_tokens: LongTensor,\n        token_index: LongTensor\n    ) -> Tuple[LongTensor, FloatTensor]:\n        image_count = encoder_state.shape[0] \/\/ 2\n        token_index_batched = token_index[[0] * image_count * 2]\n        prev_tokens = prev_tokens[list(range(image_count)) * 2]\n        prev_tokens.clamp_(0, self.image_vocab_count)\n        decoder_state = self.embed_tokens.forward(prev_tokens)\n        decoder_state += self.embed_positions.forward(token_index_batched)\n        decoder_state = self.layernorm_embedding.forward(decoder_state)\n        decoder_state = decoder_state[:, None]\n","AFTER":"        attention_state: Optional[FloatTensor],\n        prev_tokens: LongTensor,\n        token_index: LongTensor,\n        return_logits: bool = False\n    ) -> Union[Tuple[LongTensor, FloatTensor], FloatTensor]:\n        image_count = encoder_state.shape[0] \/\/ 2\n        token_index_batched = token_index[None, :][list(range(image_count)) * 2]\n        if prev_tokens.ndim == 1:\n            prev_tokens = prev_tokens.unsqueeze(0)\n        prev_tokens = prev_tokens.T[list(range(image_count)) * 2]\n        prev_tokens.clamp_(0, self.image_vocab_count)\n        decoder_state = self.embed_tokens.forward(prev_tokens)\n        decoder_state += self.embed_positions.forward(token_index_batched)\n        decoder_state = self.layernorm_embedding.forward(decoder_state)\n        if decoder_state.ndim < 3:\n            decoder_state = decoder_state[:, None]\n        if attention_state is None:\n            attention_state = [None] * self.layer_count\n        for i in range(self.layer_count):\n            decoder_state, attention_state[i] = self.layers[i].forward(\n                decoder_state,\n                encoder_state,\n                attention_state[i],\n                attention_mask,\n                token_index\n            )\n        decoder_state = self.final_ln(decoder_state)\n        logits = self.lm_head(decoder_state)\n        temperature = settings[[0]]\n        top_k = settings[[1]].to(torch.long)\n        supercondition_factor = settings[[2]]\n        logits = logits[:, -1, : 2 ** 14]\n        logits: FloatTensor = (\n            logits[:image_count] * (1 - supercondition_factor) + \n            logits[image_count:] * supercondition_factor\n        )\n        if return_logits:\n            return logits\n        logits_sorted, _ = logits.sort(descending=True)\n"}