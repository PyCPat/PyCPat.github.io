{"BEFORE":"        print(self.transformer(seq, seq).shape)\n","AFTER":"        pos = torch.arange(0, seq[1]).unsqueeze(0).repeat(seq[0], 1)\n        seq = self.dropout((self.tok_embed(seq) * self.scale) + self.pos_encoding(pos))\n        return self.transformer(seq, seq)\n"}