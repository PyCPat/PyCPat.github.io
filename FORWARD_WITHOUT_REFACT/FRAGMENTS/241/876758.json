{"BEFORE":"        x, valid_len, time_step_len = global_data.x, global_data.valid_lens, global_data.time_step_len\n\n        for name, layer in self.layers.named_modules():\n            if isinstance(layer, SelfAttentionLayer):\n                x = layer(x, valid_len, time_step_len)\n\n        return x\n","AFTER":"        x, edge_index = global_data.x, global_data.edge_index\n        valid_lens, time_step_len = global_data.valid_lens, int(global_data.time_step_len[0])\n\n        # print(\"x size:\", x.size())\n        x = x.view(-1, time_step_len, self.in_channels)\n        # randomly mask out node features when training\n        if self.training:\n            batch_size = x.size()[0]\n            aux_mask_tensor_idx = [random.randint(0, time_step_len-1) for _ in range(batch_size)]\n            for i in range(batch_size):\n                x[i, aux_mask_tensor_idx, :] = 0.0\n\n        for name, layer in self.layers.named_modules():\n            if isinstance(layer, SelfAttentionLayer):\n                x = layer(x, edge_index, valid_lens)\n\n        if self.training:\n            return x, aux_mask_tensor_idx\n        else:\n            return x, None\n\n\nclass SelfAttentionLayer(MessagePassing):\n"}