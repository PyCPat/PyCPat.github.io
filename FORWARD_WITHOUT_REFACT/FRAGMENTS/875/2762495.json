{"BEFORE":"        feat_outputs = list()\n        stop_outputs = list()\n        alignment_energies = list()\n\n        inputs, max_length, train = self.validate_args(inputs, encoder_outputs)\n        self._init_decoder_states(encoder_outputs)\n\n        if train:\n            inputs = self.prenet(inputs)  # B x T x 256\n\n            for di in range(max_length):\n                feat_output, stop_output, alignment_energy = self.forward_step(inputs[:, di, :].unsqueeze(1), encoder_outputs)\n                feat_outputs.append(feat_output)\n                stop_outputs.append(stop_output)\n                alignment_energies.append(alignment_energy)\n\n        else:\n            input_var = inputs\n\n            for di in range(max_length):\n                input_var = self.prenet(input_var)\n                feat_output, stop_output, alignment_energy = self.forward_step(input_var, encoder_outputs)\n                feat_outputs.append(feat_output)\n                stop_outputs.append(stop_output)\n                alignment_energies.append(alignment_energy)\n\n                if torch.sigmoid(stop_output.item()) > self.stop_threshold:\n                    break\n\n                input_var = feat_output\n\n        output = self.parse_decoder_outputs(feat_outputs, stop_outputs, alignment_energies)\n\n        return output\n","AFTER":"            teacher_forcing_ratio: float = 1.0\n    ) -> Dict[str, Tensor]:\n        feat_outputs, stop_outputs, alignments = list(), list(), list()\n        use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n\n        inputs, max_decoding_step = self.validate_args(encoder_outputs, inputs, teacher_forcing_ratio)\n        decoder_states = self._init_decoder_states(encoder_outputs)\n\n        if use_teacher_forcing:\n            inputs = self.prenet(inputs)\n\n            for di in range(max_decoding_step):\n                input_var = inputs[:, di, :].unsqueeze(1)\n                decoder_states = self.forward_step(\n                    input_var=input_var,\n                    encoder_outputs=encoder_outputs,\n                    o_list=decoder_states[\"o_list\"],\n                    h_list=decoder_states[\"h_list\"],\n                    alignment=decoder_states[\"alignment\"],\n                    alignment_cum=decoder_states[\"alignment_cum\"],\n                    context=decoder_states[\"context\"]\n                )\n\n                feat_outputs.append(decoder_states[\"feat_output\"])\n                stop_outputs.append(decoder_states[\"stop_output\"])\n                alignments.append(decoder_states[\"alignment\"])\n\n        else:\n            input_var = inputs\n\n            for di in range(max_decoding_step):\n                input_var = self.prenet(input_var)\n                decoder_states = self.forward_step(\n                    input_var=input_var,\n                    encoder_outputs=encoder_outputs,\n                    o_list=decoder_states[\"o_list\"],\n                    h_list=decoder_states[\"h_list\"],\n                    alignment=decoder_states[\"alignment\"],\n                    alignment_cum=decoder_states[\"alignment_cum\"],\n                    context=decoder_states[\"context\"]\n                )\n\n                feat_outputs.append(decoder_states[\"feat_output\"])\n                stop_outputs.append(decoder_states[\"stop_output\"])\n                alignments.append(decoder_states[\"alignment\"])\n\n                if torch.sigmoid(decoder_states[\"stop_output\"]).item() > self.stop_threshold:\n                    break\n\n                input_var = decoder_states[\"feat_output\"]\n\n        return self.parse_decoder_outputs(feat_outputs, stop_outputs, alignments)\n"}