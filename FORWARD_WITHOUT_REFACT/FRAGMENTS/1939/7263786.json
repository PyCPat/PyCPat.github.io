{"BEFORE":"        cond_prob_mask = prob_mask_like((batch_size,), cond_drop_prob, device = device)\n\n        # mask out image embedding depending on condition dropout\n        # for classifier free guidance\n\n        image_tokens = self.image_to_cond(image_embed)\n\n        image_tokens = torch.where(\n            rearrange(cond_prob_mask, 'b -> b 1 1'),\n            image_tokens,\n            self.null_image_embed\n        )\n\n        c = torch.cat((time_tokens, image_tokens), dim = -2) # c for condition\n\n        hiddens = []\n\n        for convnext, convnext2, downsample in self.downs:\n            x = convnext(x, c)\n            x = convnext2(x, c)\n            hiddens.append(x)\n            x = downsample(x)\n\n        x = self.mid_block1(x, c)\n        x = self.mid_attn(x)\n        x = self.mid_block2(x, c)\n","AFTER":"        cond_prob_mask = prob_mask_like((batch_size,), cond_drop_prob, device = device)\n        cond_prob_mask = rearrange(cond_prob_mask, 'b -> b 1 1')\n\n        # mask out image embedding depending on condition dropout\n        # for classifier free guidance\n\n        image_tokens = self.image_to_cond(image_embed)\n\n        image_tokens = torch.where(\n            cond_prob_mask,\n            image_tokens,\n            self.null_image_embed\n        )\n\n        # take care of text encodings (optional)\n\n        if exists(text_encodings):\n            text_tokens = self.text_to_cond(text_encodings)\n            text_tokens = torch.where(\n                cond_prob_mask,\n                text_tokens,\n                self.null_text_embed\n            )\n\n        # main conditioning tokens (c)\n\n        c = torch.cat((time_tokens, image_tokens), dim = -2)\n\n        # text and image conditioning tokens (mid_c)\n        # to save on compute, only do cross attention based conditioning on the inner most layers of the Unet\n\n        mid_c = c if not exists(text_encodings) else torch.cat((c, text_tokens), dim = -2)\n\n        # go through the layers of the unet, down and up\n\n        hiddens = []\n\n        for convnext, convnext2, downsample in self.downs:\n            x = convnext(x, c)\n            x = convnext2(x, c)\n            hiddens.append(x)\n            x = downsample(x)\n\n        x = self.mid_block1(x, mid_c)\n        x = self.mid_attn(x)\n        x = self.mid_block2(x, mid_c)\n"}