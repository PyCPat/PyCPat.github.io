{"BEFORE":"        q, k, v = self.to_qkv(x).chunk(3, dim = -1)\n\n        # pre layernorm\n\n        x = self.norm(x)\n\n        # split heads\n\n        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))\n\n        # rotary embeddings\n\n        positions = self.rotary_emb(n, device = device)\n        q, k = map(lambda t: apply_rotary_pos_emb(positions, t), (q, k))\n\n        # scale\n\n        q = q * self.scale\n\n        # similarity\n\n        sim = einsum('b i d, b j d -> b i j', q, k)\n\n        # causal mask\n\n        causal_mask = torch.ones((n, n), device = device, dtype = torch.bool).triu(1)\n        sim = sim.masked_fill(causal_mask, -torch.finfo(sim.dtype).max)\n\n        # attention\n\n        attn = sim.softmax(dim = -1)\n\n        # aggregate values\n\n        out = einsum('b i j, b j d -> b i d', attn, v)\n\n        # merge heads\n\n        out = rearrange(out, '(b h) n d -> b n (h d)', h = h)\n","AFTER":"        q, k, v = (self.to_q(x), *self.to_kv(x).chunk(2, dim = -1))\n\n        # pre layernorm\n\n        x = self.norm(x)\n\n        # split heads\n        # they use multi-query attention, yet another Noam Shazeer paper\n        # they found no performance loss past a certain scale, and more efficient decoding obviously\n        # https:\/\/arxiv.org\/abs\/1911.02150\n\n        q = rearrange(q, 'b n (h d) -> b h n d', h = h)\n\n        # rotary embeddings\n\n        positions = self.rotary_emb(n, device = device)\n        q, k = map(lambda t: apply_rotary_pos_emb(positions, t), (q, k))\n\n        # scale\n\n        q = q * self.scale\n\n        # similarity\n\n        sim = einsum('b h i d, b j d -> b h i j', q, k)\n\n        # causal mask\n\n        causal_mask = torch.ones((n, n), device = device, dtype = torch.bool).triu(1)\n        sim = sim.masked_fill(causal_mask, -torch.finfo(sim.dtype).max)\n\n        # attention\n\n        attn = sim.softmax(dim = -1)\n\n        # aggregate values\n\n        out = einsum('b h i j, b j d -> b h i d', attn, v)\n\n        # merge heads\n\n        out = rearrange(out, 'b h n d -> b n (h d)')\n"}