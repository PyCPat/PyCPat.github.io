{"BEFORE":"        total_loss = torch.tensor(0., **to(x)).requires_grad_()\n\n        if has_local:\n            local_out = self.local_attn(lqk, lqk, lv, input_mask = input_mask)\n            out.append(local_out)\n\n        if has_global:\n            global_out, loss = self.global_attn(q, k, v, query_mask = input_mask, key_mask = context_mask)\n            total_loss = total_loss + loss\n\n            if self.receives_context:\n                full_out = self.full_attn(q[:, :, 0:self.window_size], k, v)\n                global_out = torch.cat((full_out, global_out[:, :, self.window_size:]), dim=2)\n\n            out.append(global_out)\n","AFTER":"        total_loss = torch.tensor(0., requires_grad=True, **to(x))\n"}