{"BEFORE":"    def forward(self, latents, codebooks, logits, codes):\n        loss = 0.0\n        for z, c, l, b in zip(latents, codebooks, logits, codes):\n            z = z.detach().permute(0, 2, 3, 1)\n            k = l.shape[-1]\n            soft = l @ c\n            softQE = F.mse_loss(soft, z)\n            oneHot = F.one_hot(b, k).float()\n            hard = oneHot @ c\n            hardQE = F.mse_loss(hard, z)\n            loss += (softQE + hardQE + 0.1 * F.mse_loss(hard, soft)).mean()\n","AFTER":"        loss = 0.0\n        for z, zq, soft in zip(latents, zqs, softs):\n            qe = F.mse_loss(z.detach(), zq, reduction='none').mean(axis=(0, 2))\n            commit = F.mse_loss(z, zq.detach(), reduction='none').mean(axis=(0, 2))\n            softQE = F.mse_loss(z.detach(), soft, reduction='none').mean(axis=(0, 2))\n            softCommit = F.mse_loss(z, soft.detach(), reduction='none').mean(axis=(0, 2))\n            # joint = F.mse_loss(soft, zq, reduction='none').mean(axis=(0, 2))\n            loss += qe + 0.01 * commit + 0.1 * (softQE + 0.01 * softCommit)\n"}