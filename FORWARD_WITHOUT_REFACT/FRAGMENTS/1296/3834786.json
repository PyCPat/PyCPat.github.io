{"BEFORE":"        conv5_maxpool = self.embed(x)\n        if embed:\n            return conv5_maxpool\n        \n        conv5_dropout   = F.dropout(input = conv5_maxpool, p = 0.25, training = self.training, inplace = True)\n        conv6_pad       = F.pad(conv5_dropout, (0, 0, 31, 32))\n        conv6           = self.conv6(conv6_pad)\n        conv6_activation = F.relu(conv6)\n        conv6_BN        = self.conv6_BN(conv6_activation)\n        conv6_maxpool, conv6_maxpool_idx = F.max_pool2d(conv6_BN, kernel_size=(2, 1), stride=(2, 1), padding=0, ceil_mode=False, return_indices=True)\n        conv6_dropout   = F.dropout(input = conv6_maxpool, p = 0.25, training = self.training, inplace = True)\n        flatten         = conv6_dropout.reshape(-1, 256)\n        classifier      = self.classifier(flatten)\n        classifier_activation = F.sigmoid(classifier)\n        return classifier_activation\n","AFTER":"        x = self.embed(x)\n        \n        if embed:\n            return x\n        \n        # Finish layer five\n        x = F.dropout(x, p=0.25, training=self.training, inplace=True)\n        \n        # Forward pass through layer six\n        x = self.layer(x, self.conv6, self.conv6_BN)\n        \n        # Compute logits\n        return self.classifier(x.reshape(-1, 256))\n"}