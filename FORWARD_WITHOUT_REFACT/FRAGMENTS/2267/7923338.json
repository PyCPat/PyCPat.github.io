{"BEFORE":"        x = x.permute(0, 3, 1, 2).view(x.size(0), x.size(3), x.size(1), self.size,\r\n                                       self.size)  # B x T x (H x W) x C -> B x C x T x H x W\r\n        x = self.unpatch_emb(x)\r\n        x = x.permute(0, 2, 1, 3, 4)  # B x C x T x H x W -> B x T x C x H x W\r\n","AFTER":"        x = x.permute(0, 3, 1, 2).view(x.size(0), x.size(3), x.size(1), self.size, self.size)  # B x T x (H x W) x C -> B x C x T x H x W\r\n        if x.shape[2] > 1:  # not only image training\r\n            image, video = x[:, :, 0], x[:, :, 1:]\r\n            video = self.video_unpatch_emb(video)\r\n            image = self.image_unpatch_emb(image)\r\n            x = torch.cat([image.unsqueeze(2), video], dim=2).permute(0, 2, 1, 3, 4)  # B x C x T x H x W -> B x T x C x H x W\r\n        else:\r\n            image = x[:, :, 0]\r\n            image = self.image_unpatch_emb(image)\r\n            x = image.unsqueeze(2).permute(0, 2, 1, 3, 4)\r\n        return x\r\n"}