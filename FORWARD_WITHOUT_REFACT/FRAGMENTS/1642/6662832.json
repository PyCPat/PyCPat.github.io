{"BEFORE":"        if self.is_rl_training and random.random() < 0.5:\r\n            action_type_logits[:] = 0.\r\n\r\n        action_type_probs = self.softmax(action_type_logits)\r\n","AFTER":"        action_type_logits = action_type_logits \/ self.temperature\r\n        print('action_type_logits after temperature:', action_type_logits) if debug else None\r\n\r\n        if self.is_rl_training:\r\n            if random.random() < 0.8:\r\n                if random.random() < 0.8:\r\n                    action_type_logits[:, 0] = 1e5\r\n                else:\r\n                    action_type_logits[:] = 0.\r\n\r\n        action_type_probs = self.softmax(action_type_logits)\r\n        print('action_type_probs:', action_type_probs) if debug else None\r\n        print('action_type_probs.shape:', action_type_probs.shape) if debug else None\r\n\r\n        device = next(self.parameters()).device\r\n        print('ActionTypeHead device:', device) if debug else None\r\n        print('self.max_action_num:', self.max_action_num) if debug else None\r\n\r\n        if self.is_rl_training or self.use_action_type_mask:\r\n            action_type_mask = torch.zeros(self.max_action_num, device=device)\r\n            print('action_type_mask:', action_type_mask) if debug else None\r\n            print('action_type_mask.shape:', action_type_mask.shape) if debug else None\r\n\r\n            # action_type_mask[RAMP.SMALL_LIST] = 1.\r\n\r\n            action_type_mask[RAW_FUNCTIONS.no_op.id.value] = 1.\r\n            action_type_mask[RAW_FUNCTIONS.Build_Pylon_pt.id.value] = 1.\r\n            action_type_mask[RAW_FUNCTIONS.Train_Probe_quick.id.value] = 1.\r\n            action_type_mask[RAW_FUNCTIONS.Build_Gateway_pt.id.value] = 1.\r\n            action_type_mask[RAW_FUNCTIONS.Train_Zealot_quick.id.value] = 1.\r\n            action_type_mask[RAW_FUNCTIONS.Harvest_Gather_unit.id.value] = 1.\r\n            action_type_mask[RAW_FUNCTIONS.Attack_pt.id.value] = 1.\r\n"}