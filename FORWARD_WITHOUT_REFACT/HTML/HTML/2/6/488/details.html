<html><h3>Pattern ID :488
</h3><img src='1754490.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    def forward(self, x, action, with_variance=False):
        mu, logstd = self.compute_stats(x, action)
        dist = Normal(mu, <a id="change">logstd.exp()</a>)
        pred = dist.rsample()
        &#47&#47 residual prediction
        next_x<a id="change"> = </a>x<a id="change"> + </a>pred[:, :-1]
        next_reward = pred[:, -1].view(-1, 1)
        if with_variance:
            return next_x, next_reward, dist.variance.sum(dim=1, keepdims=True)
        <a id="change">return </a>next_x<a id="change">, next_reward</a>

    def compute_error(self, obs_t, act_t, rew_tp1, obs_tp1):
        mu, logstd = self.compute_stats(obs_t, act_t)
</code></pre><h3>After Change</h3><pre><code class='java'>
    def forward(
        self, x: torch.Tensor, action: torch.Tensor
    ) -&gt; Tuple[torch.Tensor, torch.Tensor]:
        <a id="change">return </a>self.predict_with_variance(x, action)[:2]

    def predict_with_variance(
        self, x: torch.Tensor, action: torch.Tensor</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/takuseno/d3rlpy/commit/9ccb6121c0baead0ffb85b64207c4fe6dc5fd5b5#diff-22be37d65fb97670d99ea5447aff62b9de05268ce0473195fea101ecff947388L94' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 1754490</div><div id='project'> Project Name: takuseno/d3rlpy</div><div id='commit'> Commit Name: 9ccb6121c0baead0ffb85b64207c4fe6dc5fd5b5</div><div id='time'> Time: 2021-01-01</div><div id='author'> Author: takuma.seno@gmail.com</div><div id='file'> File Name: d3rlpy/models/torch/dynamics.py</div><div id='m_class'> M Class Name: ProbablisticDynamics</div><div id='n_method'> N Class Name: ProbablisticDynamics</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: d3rlpy/models/torch/dynamics.py</div><div id='n_file'> N File Name: d3rlpy/models/torch/dynamics.py</div><div id='m_start'> M Start Line: 137</div><div id='m_end'> M End Line: 146</div><div id='n_start'> N Start Line: 94</div><div id='n_end'> N End Line: 96</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        mu = torch.clip(mu, MEAN_MIN, MEAN_MAX)
        log_sigma = self.sigma_head(a)
        log_sigma = torch.clip(log_sigma, LOG_STD_MIN, LOG_STD_MAX)
        sigma = <a id="change">torch.exp(</a>log_sigma<a id="change">)</a>

        a_distribution = Normal(mu, sigma)
        action = a_distribution.rsample()

        logp_pi = a_distribution.log_prob(action).sum(axis=-1)
        logp_pi -= (2 * (np.log(2) - action - F.softplus(-2 * action))).sum(axis=1)
        logp_pi = torch.unsqueeze(logp_pi, dim=1)

        action<a id="change"> = </a>self.max_action<a id="change"> * </a>torch.tanh(action)
        mu = torch.tanh(mu) * self.max_action
        <a id="change">return </a>action<a id="change">, logp_pi, mu</a>

    def get_log_density(self, state, action):
        a = F.relu(self.fc1(state))
        a = F.relu(self.fc2(a))</code></pre><h3>After Change</h3><pre><code class='java'>
        a_dist, a_tanh_mode = self._get_outputs(state)
        action = a_dist.rsample()
        logp_pi = a_dist.log_prob(action).sum(axis=-1)
        <a id="change">return </a>action, logp_pi, a_tanh_mode

    def get_log_density(self, state, action):
        a_dist, _ = self._get_outputs(state)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ryanxhr/dwbc/commit/b3791e408af7125fde12cda1cdeaefbaa400aacc#diff-75aa8d0a222c16ec3e4bb78749eef436b3d51c25ea931fe019fed10965e94549L34' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 1754506</div><div id='project'> Project Name: ryanxhr/dwbc</div><div id='commit'> Commit Name: b3791e408af7125fde12cda1cdeaefbaa400aacc</div><div id='time'> Time: 2022-06-30</div><div id='author'> Author: xuhaoran8@jd.com</div><div id='file'> File Name: algos/DWBC.py</div><div id='m_class'> M Class Name: Actor</div><div id='n_method'> N Class Name: Actor</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: algos/DWBC.py</div><div id='n_file'> N File Name: algos/DWBC.py</div><div id='m_start'> M Start Line: 35</div><div id='m_end'> M End Line: 52</div><div id='n_start'> N Start Line: 51</div><div id='n_end'> N End Line: 54</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 w_1 = torch.exp(-0.1*(range_param.unsqueeze(-1) ** -2) * (t - c) ** 2)  &#47&#47 [B, L, T]
        &#47&#47 w_2 = torch.sum(torch.exp(-0.1*(range_param.unsqueeze(-1) ** -2) * (t - c) ** 2), dim=1, keepdim=True)  &#47&#47 [B, 1, T]
        w_1 = torch.exp(-0.1 * (t - c) ** 2)  &#47&#47 [B, L, T]
        w_2 = torch.sum(<a id="change">torch.exp(</a>-0.1 * (t - c) ** 2<a id="change">)</a>, dim=1, keepdim=True)  &#47&#47 [B, 1, T]
        w_2[w_2==0.] = 1.

        &#47&#47 w_1 = self.normpdf(t, c, range_param.unsqueeze(-1))  &#47&#47 [B, L, T]
        &#47&#47 w_1 = torch.distributions.normal.Normal(c, 0.1).log_prob(t)  &#47&#47 [B, L, T]
        &#47&#47 w_2 = torch.sum(w_1, dim=1, keepdim=True)  &#47&#47 [B, 1, T]
        &#47&#47 w_2[w_2==0.] = 1.

        w<a id="change"> = </a>w_1<a id="change"> / </a>w_2

        out = torch.matmul(w.transpose(1, 2), encoder_outputs)

        <a id="change">return </a>out<a id="change">, w</a>


class DurationPredictor(nn.Module):
     Duration Parameter Predictor </code></pre><h3>After Change</h3><pre><code class='java'>
        attn = w / (torch.sum(w, dim=1).unsqueeze(1) + 1e-8)  &#47&#47 [B, L, T]
        out = torch.bmm(attn.transpose(1, 2), encoder_outputs)

        <a id="change">return </a>out, attn


class DurationPredictor(nn.Module):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/keonlee9420/wavegrad2/commit/523ec241c64ab635218f32d071fd85fbc469e178#diff-44dac3f4f06b62a8129520d279f589b0b2144de4f2a7720992f263c496651b43L105' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 1754504</div><div id='project'> Project Name: keonlee9420/wavegrad2</div><div id='commit'> Commit Name: 523ec241c64ab635218f32d071fd85fbc469e178</div><div id='time'> Time: 2021-07-13</div><div id='author'> Author: keonlee9420@gmail.com</div><div id='file'> File Name: model/modules.py</div><div id='m_class'> M Class Name: GaussianUpsampling</div><div id='n_method'> N Class Name: GaussianUpsampling</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: model/modules.py</div><div id='n_file'> N File Name: model/modules.py</div><div id='m_start'> M Start Line: 115</div><div id='m_end'> M End Line: 135</div><div id='n_start'> N Start Line: 120</div><div id='n_end'> N End Line: 134</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 attention GMM parameters
        g_t = torch.softmax(g_t, dim=-1) + self.epsilon  &#47&#47 distribution weight
        sig_t = torch.exp(b_t) + self.epsilon  &#47&#47 variance
        mu_t<a id="change"> = </a>self.mu_tm1 + self.attention_alignment<a id="change"> * </a><a id="change">torch.exp(</a>k_t<a id="change">)</a>  &#47&#47 mean

        g_t = g_t.unsqueeze(2).expand(g_t.size(0),
                                      g_t.size(1),
                                      inputs.size(1))
        sig_t = sig_t.unsqueeze(2).expand_as(g_t)
        mu_t_ = mu_t.unsqueeze(2).expand_as(g_t)
        j = self.J[:g_t.size(0), :, :inputs.size(1)]

        &#47&#47 attention weights
        phi_t = g_t * torch.exp(-0.5 * sig_t * (mu_t_ - j)**2)
        alpha_t = self.COEF * torch.sum(phi_t, 1)

        &#47&#47 apply masking
        &#47&#47 if mask is not None:
        &#47&#47     alpha_t.data.masked_fill_(~mask, self._mask_value)
        
        breakpoint()

        c_t = torch.bmm(alpha_t.unsqueeze(1), inputs).squeeze(1)
        self.mu_tm1 = mu_t
        <a id="change">return </a>c_t<a id="change">, mu_t, alpha_t</a>


class Attention(nn.Module):
    &#47&#47 Pylint gets confused by PyTorch conventions here</code></pre><h3>After Change</h3><pre><code class='java'>
        self.attention_weights = alpha_t
        self.mu_prev = mu_t
        breakpoint()
        <a id="change">return </a>context


class OriginalAttention(nn.Module):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/coqui-ai/tts/commit/adf9ebd629abc21e0969db2a1c29f389b5301c9d#diff-1ca76b8dab5cda419aaf68884653245f0428af8e57cdb707fc538936bb59af29L129' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 1754496</div><div id='project'> Project Name: coqui-ai/tts</div><div id='commit'> Commit Name: adf9ebd629abc21e0969db2a1c29f389b5301c9d</div><div id='time'> Time: 2019-11-12</div><div id='author'> Author: egolge@mozilla.com</div><div id='file'> File Name: layers/common_layers.py</div><div id='m_class'> M Class Name: GravesAttention</div><div id='n_method'> N Class Name: GravesAttention</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: layers/common_layers.py</div><div id='n_file'> N File Name: layers/common_layers.py</div><div id='m_start'> M Start Line: 141</div><div id='m_end'> M End Line: 169</div><div id='n_start'> N Start Line: 149</div><div id='n_end'> N End Line: 180</div><BR>