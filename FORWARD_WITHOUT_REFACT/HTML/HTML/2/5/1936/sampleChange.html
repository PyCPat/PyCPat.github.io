<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    def forward(self, input, demo):
        batch_size = input.size(0)
        time_step = <a id="change">input.size(1</a><a id="change">)</a>
        feature_dim = input.size(2)
        assert feature_dim == self.n_input

        self.agent1_action = []
        self.agent1_prob = []
        self.agent1_entropy = []
        self.agent1_baseline = []
        self.agent2_action = []
        self.agent2_prob = []
        self.agent2_entropy = []
        self.agent2_baseline = []

        cur_h = self.init_h(demo)
        if self.cell == "lstm":
            cur_c = self.init_c(demo)

        for cur_time in range(time_step):
            cur_input = input[:, cur_time, :]

            if cur_time == 0:
                obs_1 = cur_h
                obs_2 = cur_input
                obs_1 = torch.cat((obs_1, demo), dim=1)
                obs_2 = torch.cat((obs_2, demo), dim=1)
                self.choose_action(obs_1, 1).long()
                self.choose_action(obs_2, 2).long()

                observed_h = (
                    torch.zeros_like(cur_h, dtype=torch.float32)
                    .view(-1)
                    .repeat(self.n_actions)
                    .view(self.n_actions, batch_size, self.n_hidden)
                )
                action_h = cur_h
                if self.cell == "lstm":
                    observed_c = (
                        torch.zeros_like(cur_c, dtype=torch.float32)
                        .view(-1)
                        .repeat(self.n_actions)
                        .view(self.n_actions, batch_size, self.n_hidden)
                    )
                    action_c = cur_c

            else:
                observed_h = torch.cat((observed_h[1:], cur_h.unsqueeze(0)), 0)

                obs_1 = observed_h.mean(dim=0)
                obs_2 = cur_input
                obs_1 = torch.cat((obs_1, demo), dim=1)
                obs_2 = torch.cat((obs_2, demo), dim=1)
                act_idx1 = self.choose_action(obs_1, 1).long()
                act_idx2 = self.choose_action(obs_2, 2).long()
                batch_idx = (
                    torch.arange(batch_size, dtype=torch.long)
                    .unsqueeze(-1)
                    .to(self.device)
                )
                action_h1 = observed_h[act_idx1, batch_idx, :].squeeze(1)
                action_h2 = observed_h[act_idx2, batch_idx, :].squeeze(1)
                action_h = (action_h1 + action_h2) / 2
                if self.cell == "lstm":
                    observed_c = torch.cat((observed_c[1:], cur_c.unsqueeze(0)), 0)
                    action_c1 = observed_c[act_idx1, batch_idx, :].squeeze(1)
                    action_c2 = observed_c[act_idx2, batch_idx, :].squeeze(1)
                    action_c = (action_c1 + action_c2) / 2

            if self.cell == "lstm":
                weighted_h = self.lamda * action_h + (1 - self.lamda) * cur_h
                weighted_c = self.lamda * action_c + (1 - self.lamda) * cur_c
                rnn_state = (weighted_h, weighted_c)
                cur_h, cur_c = self.rnn(cur_input, rnn_state)
            else:
                weighted_h = self.lamda * action_h + (1 - self.lamda) * cur_h
                cur_h = self.rnn(cur_input, weighted_h)

        if self.dropout &gt; 0.0:
            cur_h = self.nn_dropout(cur_h)
        cur_h = torch.cat((cur_h, demo), dim=1)
        cur_h = self.fusion(cur_h)
        cur_h = self.relu(cur_h)
        output<a id="change"> = </a>self.output(cur_h)
        output<a id="change"> = </a>self.sigmoid(output)

        return output
</code></pre><h3>After Change</h3><pre><code class='java'>
        batch_size = labtest.size(0)
        time_step = labtest.size(1)
        feature_dim = labtest.size(2)
        <a id="change">assert </a>feature_dim == self.lab_dim

        self.agent1_action = []
        self.agent1_prob = []</code></pre>