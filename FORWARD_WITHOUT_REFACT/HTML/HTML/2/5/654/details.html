<html><h3>Pattern ID :654
</h3><img src='2286115.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        tokens = tokens + rearrange(pos_emb, &quotn d -&gt; 1 n d&quot)

        text_embeds = self.text_transformer(tokens, mask = text_mask)
        <a id="change">return </a>text_embeds
</code></pre><h3>After Change</h3><pre><code class='java'>
        frame_indices = rearrange(frame_indices, &quotb ... -&gt; b (...)&quot)
        frame_indices_input = frame_indices[:, :-1] if return_loss else frame_indices

        frame_embeddings<a id="change"> = </a>self.image_embedding(frame_indices_input)
        frame_embeddings = self.video_pos_emb(frame_embeddings) + frame_embeddings

        bos = repeat(self.video_bos, &quotd -&gt; b 1 d&quot, b = batch)
        frame_embeddings = torch.cat((bos, frame_embeddings), dim = 1)
        frame_embeddings = self.video_transformer(frame_embeddings)

        logits = self.to_logits(frame_embeddings)

        if not return_loss:
            <a id="change">return </a>logits

        loss<a id="change"> = </a><a id="change">F.cross_entropy(</a>rearrange(logits, &quotb n c -&gt; b c n&quot), frame_indices<a id="change">)</a>
        return loss
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lucidrains/nuwa-pytorch/commit/daeefa2be5de809f9003a5333dad62183cf819f7#diff-47b637f0a46bb7e4f245f382a9b47f0351b6a5fda8ab6476a0476b4677441eddL219' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2286115</div><div id='project'> Project Name: lucidrains/nuwa-pytorch</div><div id='commit'> Commit Name: daeefa2be5de809f9003a5333dad62183cf819f7</div><div id='time'> Time: 2021-12-28</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: nuwa_pytorch/nuwa_pytorch.py</div><div id='m_class'> M Class Name: NUWA</div><div id='n_method'> N Class Name: NUWA</div><div id='m_method'> M Method Name: forward(1)</div><div id='n_method'> N Method Name: forward(1)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: nuwa_pytorch/nuwa_pytorch.py</div><div id='n_file'> N File Name: nuwa_pytorch/nuwa_pytorch.py</div><div id='m_start'> M Start Line: 219</div><div id='m_end'> M End Line: 227</div><div id='n_start'> N Start Line: 270</div><div id='n_end'> N End Line: 296</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        super().__init__()

    def forward(self, x):
        <a id="change">return </a>x
</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 get positional embedding

        pos_emb<a id="change"> = </a>self.pos_emb(torch.arange(n, device = device))
        pos_emb = rearrange(pos_emb, &quotn d -&gt; 1 n d&quot)
        embed = embed + pos_emb

        logits = self.to_logits(embed)

        if not return_loss:
            <a id="change">return </a>logits

        loss<a id="change"> = </a><a id="change">F.cross_entropy(</a>rearrange(logits, &quotb n c -&gt; b c n&quot), labels<a id="change">)</a>
        return loss
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/retro-pytorch/commit/e737b0c407799969e66abe02d9071e6459c629a0#diff-fedd9cc24fef747e4ffbe9ce88b42fa6cdd64bd399aeb8589d4b304931bfcc64L15' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2286113</div><div id='project'> Project Name: lucidrains/retro-pytorch</div><div id='commit'> Commit Name: e737b0c407799969e66abe02d9071e6459c629a0</div><div id='time'> Time: 2022-01-17</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: retro_pytorch/retro_pytorch.py</div><div id='m_class'> M Class Name: RETRO</div><div id='n_method'> N Class Name: RETRO</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: retro_pytorch/retro_pytorch.py</div><div id='n_file'> N File Name: retro_pytorch/retro_pytorch.py</div><div id='m_start'> M Start Line: 15</div><div id='m_end'> M End Line: 16</div><div id='n_start'> N Start Line: 66</div><div id='n_end'> N End Line: 101</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        position_logits = self.to_position_logits(embed)
        value_logits = self.to_value_logits(embed)

        <a id="change">return </a>channel_logits
</code></pre><h3>After Change</h3><pre><code class='java'>
        embed = torch.cat((start_token, embed), dim = 1)

        if return_loss:
            embed<a id="change"> = </a>embed[:, :-1]

        embed = self.postemb_norm(embed)

        &#47&#47 layers of attention + cross attention

        for attn, cross_attn, ff in self.layers:
            embed = attn(embed) + embed
            embed = cross_attn(embed, encoded) + embed
            embed = ff(embed) + embed

        &#47&#47 to logits

        embed = self.final_norm(embed)

        channel_logits = self.to_channel_logits(embed)
        position_logits = self.to_position_logits(embed)
        value_logits = self.to_value_logits(embed)

        if not return_loss:
            <a id="change">return </a>channel_logits, position_logits, value_logits

        channel_logits, position_logits, value_logits = map(lambda t: rearrange(t, &quotb n c -&gt; b c n&quot), (channel_logits, position_logits, value_logits))

        channel_loss = F.cross_entropy(channel_logits, channels)
        position_loss<a id="change"> = </a><a id="change">F.cross_entropy(</a>channel_logits, channels<a id="change">)</a>
        value_loss = F.cross_entropy(channel_logits, channels)

        return (channel_loss + position_loss + value_loss) / 3
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/transframer-pytorch/commit/0ccad402b8e5bb5e46393b16e72048567d983ed3#diff-8297de4bcdca0c16a036a8cea9b0742314816cee6103a4872f00abb1bf4234f4L150' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2286119</div><div id='project'> Project Name: lucidrains/transframer-pytorch</div><div id='commit'> Commit Name: 0ccad402b8e5bb5e46393b16e72048567d983ed3</div><div id='time'> Time: 2022-08-20</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: transframer_pytorch/transframer_pytorch.py</div><div id='m_class'> M Class Name: Transframer</div><div id='n_method'> N Class Name: Transframer</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: transframer_pytorch/transframer_pytorch.py</div><div id='n_file'> N File Name: transframer_pytorch/transframer_pytorch.py</div><div id='m_start'> M Start Line: 179</div><div id='m_end'> M End Line: 183</div><div id='n_start'> N Start Line: 154</div><div id='n_end'> N End Line: 200</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            mask = F.pad(mask, (0, self.image_seq_len), value = True)

        out = self.transformer(tokens, mask = mask)
        <a id="change">return </a>self.to_logits(out)
</code></pre><h3>After Change</h3><pre><code class='java'>
            mask = F.pad(mask, (0, self.image_seq_len), value = True)

        out = self.transformer(tokens, mask = mask)
        out<a id="change"> = </a>self.to_logits(out)

        if not return_loss:
            <a id="change">return </a>out

        offsetted_image = image + self.num_text_tokens
        labels = torch.cat((text, offsetted_image), dim = 1)
        labels = F.pad(labels, (0, 1), value = (self.total_tokens - 1)) &#47&#47 last token predicts EOS
        loss<a id="change"> = </a><a id="change">F.cross_entropy(</a>out.transpose(1, 2), labels[:, 1:]<a id="change">)</a>
        return loss
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/dalle-pytorch/commit/fa7ab5506002acc0704b3ea6e85fdfc2d5f9a2d4#diff-7fee3463af42e34e03d754e24fa9b24e3cde98aae198d2cb45f200d6da301016L158' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2286132</div><div id='project'> Project Name: lucidrains/dalle-pytorch</div><div id='commit'> Commit Name: fa7ab5506002acc0704b3ea6e85fdfc2d5f9a2d4</div><div id='time'> Time: 2021-01-06</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: dalle_pytorch/dalle_pytorch.py</div><div id='m_class'> M Class Name: DALLE</div><div id='n_method'> N Class Name: DALLE</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: dalle_pytorch/dalle_pytorch.py</div><div id='n_file'> N File Name: dalle_pytorch/dalle_pytorch.py</div><div id='m_start'> M Start Line: 172</div><div id='m_end'> M End Line: 173</div><div id='n_start'> N Start Line: 163</div><div id='n_end'> N End Line: 188</div><BR>