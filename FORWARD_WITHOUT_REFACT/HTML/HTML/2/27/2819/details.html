<html><h3>Pattern ID :2819
</h3><img src='9344606.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        hidden = context
        
        &#47&#47first input to the decoder is the &lt;sos&gt; tokens
        input, input_mark = <a id="change">x_dec[:, 0, :].unsqueeze(dim=1)</a><a id="change">, x_mark_dec[:, 0, :].unsqueeze(dim=1)</a>
        
        for t in range(1, x_dec_len):
            
            &#47&#47insert input token embedding, previous hidden state and the context state</code></pre><h3>After Change</h3><pre><code class='java'>
        hidden = context
        
        &#47&#47first input to the decoder is the &lt;sos&gt; tokens
        <a id="change">if isinstance(x_dec</a>, <a id="change">list</a><a id="change">)</a><a id="change">:
            </a>input<a id="change"> = </a><a id="change">[i[:, 0, :].unsqueeze(dim=1) for i in x_dec]</a>
        else:
            input<a id="change"> = x_dec[:, 0, :].unsqueeze(dim=1)</a>
        for t in range(1, x_dec_len):
            
            &#47&#47insert input token embedding, previous hidden state and the context state
            &#47&#47receive output tensor (predictions) and new hidden state
            output, hidden = self.decoder(input, hidden, context)
            
            &#47&#47place predictions in a tensor holding predictions for each token
            outputs[:, t-1, :] = output.squeeze(dim=1)
            
            &#47&#47decide if we are going to use teacher forcing or not
            teacher_force = random.random() &lt; teacher_forcing_ratio
            
            &#47&#47if teacher forcing, use actual next token as next input
            &#47&#47if not, use predicted token
            <a id="change">if </a><a id="change">isinstance(x_dec</a>, <a id="change">list</a><a id="change">):
                </a>input0 = <a id="change">x_dec[0]</a>[:, t, :].unsqueeze(dim=1)<a id="change"> if </a>teacher_force<a id="change"> else </a>output
                input<a id="change"> = </a><a id="change">[</a>input0, <a id="change">x_dec[1][:, t, :].unsqueeze(dim=1)</a>]
            else:
                input = x_dec[:, t, :].unsqueeze(dim=1) if teacher_force else output
        return outputs[:, :, -self.out_size:]</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 21</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/hyliush/deep-time-series/commit/986ccffa04ba3e38cf0c5caaab3f510ce28a740b#diff-aa3bf41a5074643d226ac3c1b45d1df6319ba06c4a8e8991bf2302b16261ca57L93' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9344606</div><div id='project'> Project Name: hyliush/deep-time-series</div><div id='commit'> Commit Name: 986ccffa04ba3e38cf0c5caaab3f510ce28a740b</div><div id='time'> Time: 2022-03-21</div><div id='author'> Author: 49185490+hyliush@users.noreply.github.com</div><div id='file'> File Name: models/seq2seq/EDGru.py</div><div id='m_class'> M Class Name: Gru</div><div id='n_method'> N Class Name: Gru</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/seq2seq/EDGru.py</div><div id='n_file'> N File Name: models/seq2seq/EDGru.py</div><div id='m_start'> M Start Line: 93</div><div id='m_end'> M End Line: 132</div><div id='n_start'> N Start Line: 115</div><div id='n_end'> N End Line: 138</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        hidden = context
        
        &#47&#47first input to the decoder is the &lt;sos&gt; tokens
        input, input_mark = <a id="change">x_dec[:, 0, :].unsqueeze(dim=1)</a><a id="change">, x_mark_dec[:, 0, :].unsqueeze(dim=1)</a>
        
        for t in range(1, x_dec_len):
            
            &#47&#47insert input token embedding, previous hidden state and the context state</code></pre><h3>After Change</h3><pre><code class='java'>
        hidden = context
        
        &#47&#47first input to the decoder is the &lt;sos&gt; tokens
        <a id="change">if isinstance(</a>x_dec, list<a id="change">)</a><a id="change">:
            </a>input<a id="change"> = </a><a id="change">[i[:, 0, :].unsqueeze(dim=1) for i in x_dec]</a>
        else:
            input<a id="change"> = x_dec[:, 0, :].unsqueeze(dim=1)</a>
        for <a id="change">t</a> in range(1, x_dec_len):
            
            &#47&#47insert input token embedding, previous hidden state and the context state
            &#47&#47receive output tensor (predictions) and new hidden state
            output, hidden = self.decoder(input, hidden, context)
            
            &#47&#47place predictions in a tensor holding predictions for each token
            outputs[:, t-1, :] = output.squeeze(dim=1)
            
            &#47&#47decide if we are going to use teacher forcing or not
            teacher_force = random.random() &lt; teacher_forcing_ratio
            
            &#47&#47if teacher forcing, use actual next token as next input
            &#47&#47if not, use predicted token
            <a id="change">if </a><a id="change">isinstance(</a>x_dec, list<a id="change">):
                </a>input0 = <a id="change">x_dec[0]</a>[:, t, :].unsqueeze(dim=1)<a id="change"> if </a>teacher_force<a id="change"> else </a>output
                input<a id="change"> = </a><a id="change">[</a>input0, <a id="change">x_dec[1][:, t, :].unsqueeze(dim=1)</a>]
            else:
                input = x_dec[:, t, :].unsqueeze(dim=1) if teacher_force else output
        return outputs[:, :, -self.out_size:]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/hyliush/deep-time-series/commit/986ccffa04ba3e38cf0c5caaab3f510ce28a740b#diff-aa3bf41a5074643d226ac3c1b45d1df6319ba06c4a8e8991bf2302b16261ca57L93' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9344607</div><div id='project'> Project Name: hyliush/deep-time-series</div><div id='commit'> Commit Name: 986ccffa04ba3e38cf0c5caaab3f510ce28a740b</div><div id='time'> Time: 2022-03-21</div><div id='author'> Author: 49185490+hyliush@users.noreply.github.com</div><div id='file'> File Name: models/seq2seq/EDGru.py</div><div id='m_class'> M Class Name: Gru</div><div id='n_method'> N Class Name: Gru</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/seq2seq/EDGru.py</div><div id='n_file'> N File Name: models/seq2seq/EDGru.py</div><div id='m_start'> M Start Line: 93</div><div id='m_end'> M End Line: 132</div><div id='n_start'> N Start Line: 115</div><div id='n_end'> N End Line: 138</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        encoder_outputs, hidden = self.encoder(x_enc, x_mark_enc)
        
        &#47&#47first input to the decoder is the &lt;sos&gt; tokens
        input, input_mark = <a id="change">x_dec[:, 0, :].unsqueeze(dim=1)</a><a id="change">, x_mark_dec[:, 0, :].unsqueeze(dim=1)</a>
        
        for t in range(1, x_dec_len):
            
            &#47&#47insert input token embedding, previous hidden state and the context state</code></pre><h3>After Change</h3><pre><code class='java'>
        encoder_outputs, hidden = self.encoder(x_enc)
        
        &#47&#47first input to the decoder is the &lt;sos&gt; tokens
        <a id="change">if isinstance(</a>x_dec, list<a id="change">)</a><a id="change">:
            </a>input<a id="change"> = </a><a id="change">[i[:, 0, :].unsqueeze(dim=1) for i in x_dec]</a>
        else:
            input<a id="change"> = x_dec[:, 0, :].unsqueeze(dim=1)</a>
        for <a id="change">t</a> in range(1, x_dec_len):
            
            &#47&#47insert input token embedding, previous hidden state and the context state
            &#47&#47receive output tensor (predictions) and new hidden state
            output, hidden = self.decoder(input, hidden, encoder_outputs)
            
            &#47&#47place predictions in a tensor holding predictions for each token
            outputs[:, t-1, :] = output.squeeze(dim=1)
            
            &#47&#47decide if we are going to use teacher forcing or not
            teacher_force = random.random() &lt; teacher_forcing_ratio
            
            &#47&#47if teacher forcing, use actual next token as next input
            &#47&#47if not, use predicted token
            <a id="change">if </a><a id="change">isinstance(</a>x_dec, list<a id="change">):
                </a>input0 = <a id="change">x_dec[0]</a>[:, t, :].unsqueeze(dim=1)<a id="change"> if </a>teacher_force<a id="change"> else </a>output
                input<a id="change"> = </a><a id="change">[</a>input0, <a id="change">x_dec[1][:, t, :].unsqueeze(dim=1)</a>]
            else:
                input = x_dec[:, t, :].unsqueeze(dim=1) if teacher_force else output
        return outputs[:, :, -self.out_size:]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/hyliush/deep-time-series/commit/986ccffa04ba3e38cf0c5caaab3f510ce28a740b#diff-35cbc17b3d598f3be3f2070f99d3489dccccc9245c00650ce2b2d457b8794b5fL143' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9344604</div><div id='project'> Project Name: hyliush/deep-time-series</div><div id='commit'> Commit Name: 986ccffa04ba3e38cf0c5caaab3f510ce28a740b</div><div id='time'> Time: 2022-03-21</div><div id='author'> Author: 49185490+hyliush@users.noreply.github.com</div><div id='file'> File Name: models/seq2seq/EDGruAttention.py</div><div id='m_class'> M Class Name: GruAttention</div><div id='n_method'> N Class Name: GruAttention</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/seq2seq/EDGruAttention.py</div><div id='n_file'> N File Name: models/seq2seq/EDGruAttention.py</div><div id='m_start'> M Start Line: 143</div><div id='m_end'> M End Line: 178</div><div id='n_start'> N Start Line: 161</div><div id='n_end'> N End Line: 184</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        hidden, cell = self.encoder(x_enc, x_mark_enc)
        
        &#47&#47first input to the decoder is the &lt;sos&gt; tokens
        input, input_mark = <a id="change">x_dec[:, 0, :].unsqueeze(dim=1)</a><a id="change">, x_mark_dec[:, 0, :].unsqueeze(dim=1)</a>

        for t in range(1, x_dec_len):
            
            &#47&#47insert input token embedding, previous hidden and previous cell states</code></pre><h3>After Change</h3><pre><code class='java'>
        hidden, cell = self.encoder(x_enc)
        
        &#47&#47first input to the decoder is the &lt;sos&gt; tokens
        <a id="change">if isinstance(</a>x_dec, list<a id="change">)</a><a id="change">:
            </a>input<a id="change"> = </a><a id="change">[i[:, 0, :].unsqueeze(dim=1) for i in x_dec]</a>
        else:
            input<a id="change"> = x_dec[:, 0, :].unsqueeze(dim=1)</a>
        for <a id="change">t</a> in range(1, x_dec_len):
            
            &#47&#47insert input token embedding, previous hidden and previous cell states
            &#47&#47receive output tensor (predictions) and new hidden and cell states
            output, hidden, cell = self.decoder(input, hidden, cell)
            
            &#47&#47place predictions in a tensor holding predictions for each token
            outputs[:, t-1, :] = output.squeeze(dim=1)
            
            &#47&#47decide if we are going to use teacher forcing or not
            teacher_force = random.random() &lt; teacher_forcing_ratio

            &#47&#47if teacher forcing, use actual next token as next input
            &#47&#47if not, use predicted token
            <a id="change">if </a><a id="change">isinstance(</a>x_dec, list<a id="change">):
                </a>input0 = <a id="change">x_dec[0]</a>[:, t, :].unsqueeze(dim=1)<a id="change"> if </a>teacher_force<a id="change"> else </a>output
                input<a id="change"> = </a><a id="change">[</a>input0, <a id="change">x_dec[1][:, t, :].unsqueeze(dim=1)</a>]
            else:
                input = x_dec[:, t, :].unsqueeze(dim=1) if teacher_force else output
        return outputs[:, :, -self.out_size:]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/hyliush/deep-time-series/commit/986ccffa04ba3e38cf0c5caaab3f510ce28a740b#diff-af805697d08a3808c558ad8e5080c824317b61e3aac22a68129bee6430c2b332L96' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9344603</div><div id='project'> Project Name: hyliush/deep-time-series</div><div id='commit'> Commit Name: 986ccffa04ba3e38cf0c5caaab3f510ce28a740b</div><div id='time'> Time: 2022-03-21</div><div id='author'> Author: 49185490+hyliush@users.noreply.github.com</div><div id='file'> File Name: models/seq2seq/EDLstm.py</div><div id='m_class'> M Class Name: Lstm</div><div id='n_method'> N Class Name: Lstm</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/seq2seq/EDLstm.py</div><div id='n_file'> N File Name: models/seq2seq/EDLstm.py</div><div id='m_start'> M Start Line: 96</div><div id='m_end'> M End Line: 131</div><div id='n_start'> N Start Line: 114</div><div id='n_end'> N End Line: 137</div><BR>