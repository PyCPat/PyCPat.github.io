<html><h3>Pattern ID :2201
</h3><img src='7748486.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            &#47&#47 按时间步迭代，计算每个时间步的经attention的gru输出
            self.c_t[i] = self.attentionStep(first_h_a, first_h_b, att_timesteps)

        <a id="change">if </a>self.drop &lt; 1.0<a id="change">:
            </a>self.c_t = self.dropout(self.c_t)

        &#47&#47 &#47&#47 output层
        &#47&#47 y_hat = self.out(self.c_t)</code></pre><h3>After Change</h3><pre><code class='java'>
        x = self.proj(x)
        x = self.dropout(x)

        out<a id="change"> = </a><a id="change">torch.zeros(</a>(batch_size<a id="change">, time_steps, self.hidden_dim</a>)<a id="change">)</a>

        for cur_time in range(time_steps):
            cur_x = x[:, : cur_time + 1, :]
            out[:, cur_time, :] = self.retain_encoder(cur_x)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/yhzhu99/covid-ehr-benchmarks/commit/b3d4ba85ad8e8cfeb3e45e07e5fadfa3fd4a25fa#diff-77d2a7ae5e3183c97c4a93ec2d675da0a9f18941a477d8d2a5d9e1d496f4b387L44' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 7748486</div><div id='project'> Project Name: yhzhu99/covid-ehr-benchmarks</div><div id='commit'> Commit Name: b3d4ba85ad8e8cfeb3e45e07e5fadfa3fd4a25fa</div><div id='time'> Time: 2022-06-25</div><div id='author'> Author: yhzhu99@gmail.com</div><div id='file'> File Name: app/models/backbones/retain.py</div><div id='m_class'> M Class Name: RETAIN</div><div id='n_method'> N Class Name: RETAIN</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: app/models/backbones/retain.py</div><div id='n_file'> N File Name: app/models/backbones/retain.py</div><div id='m_start'> M Start Line: 64</div><div id='m_end'> M End Line: 83</div><div id='n_start'> N Start Line: 44</div><div id='n_end'> N End Line: 53</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    def forward(self, x):
        remainder = x.shape[-1] % self.pool_size
        <a id="change">if </a>remainder &gt; 0<a id="change">:
            </a>x = F.pad(x, (0, remainder), value = 0)

        attn_logits = einsum(&quotb d n, d e -&gt; b e n&quot, x, self.to_attn_logits)
        x = self.pool_fn(x)</code></pre><h3>After Change</h3><pre><code class='java'>

        if needs_padding:
            x = F.pad(x, (0, remainder), value = 0)
            mask = <a id="change">torch.zeros(</a>(b<a id="change">, 1, n</a>)<a id="change">, dtype = torch.bool, device = x.device)</a>
            mask<a id="change"> = </a>F.pad(mask, (0, remainder), value = True)

        attn_logits = einsum(&quotb d n, d e -&gt; b e n&quot, x, self.to_attn_logits)
        x = self.pool_fn(x)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/enformer-pytorch/commit/d6c7c92831f85618e38d208d15a411e1259fa4b3#diff-d41824114176cf139e53af298fee855401c92b5fbb8c782f4eb1dd3fbf56fe10L121' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 7748484</div><div id='project'> Project Name: lucidrains/enformer-pytorch</div><div id='commit'> Commit Name: d6c7c92831f85618e38d208d15a411e1259fa4b3</div><div id='time'> Time: 2021-10-30</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: enformer_pytorch/enformer_pytorch.py</div><div id='m_class'> M Class Name: AttentionPool</div><div id='n_method'> N Class Name: AttentionPool</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: enformer_pytorch/enformer_pytorch.py</div><div id='n_file'> N File Name: enformer_pytorch/enformer_pytorch.py</div><div id='m_start'> M Start Line: 122</div><div id='m_end'> M End Line: 128</div><div id='n_start'> N Start Line: 122</div><div id='n_end'> N End Line: 139</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                uncertain_infos.append([uncertain, prob])

                &#47&#47 return early results
                <a id="change">if </a>uncertain &lt; inference_speed<a id="change">:
                    </a>return prob, i, uncertain_infos
            return prob, i, uncertain_infos

        &#47&#47 Training phase: the first phase corresponds to the backbone training</code></pre><h3>After Change</h3><pre><code class='java'>
        if inference:
            &#47&#47 positions will keep track of the original position of each element in the
            &#47&#47 batch when elements will be removed
            final_probs<a id="change"> = </a><a id="change">torch.zeros(</a>(hidden_states[0].shape[0]<a id="change">, 2</a>)<a id="change">, device=device)</a>
            positions = torch.arange(start=0, end=hidden_states[0].shape[0], device=device).long()

            for i, (layer_module, (k, layer_classifier_module)) in enumerate(
                    zip(self.layer, self.layer_classifiers.items())):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/julesbelveze/bert-squeeze/commit/3cb14b8f1e742b86fe609843f2779e3bb36de4aa#diff-aac748de92a29499c39463320f41c1eaeb283dae0ed8ead9584db8318265a4acL49' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 7748480</div><div id='project'> Project Name: julesbelveze/bert-squeeze</div><div id='commit'> Commit Name: 3cb14b8f1e742b86fe609843f2779e3bb36de4aa</div><div id='time'> Time: 2021-12-11</div><div id='author'> Author: 32683010+JulesBelveze@users.noreply.github.com</div><div id='file'> File Name: bert-squeeze/models/custom_transformers/fastbert.py</div><div id='m_class'> M Class Name: FastBertGraph</div><div id='n_method'> N Class Name: FastBertGraph</div><div id='m_method'> M Method Name: forward(7)</div><div id='n_method'> N Method Name: forward(6)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: bert-squeeze/models/custom_transformers/fastbert.py</div><div id='n_file'> N File Name: bert-squeeze/models/custom_transformers/fastbert.py</div><div id='m_start'> M Start Line: 57</div><div id='m_end'> M End Line: 70</div><div id='n_start'> N Start Line: 49</div><div id='n_end'> N End Line: 87</div><BR>