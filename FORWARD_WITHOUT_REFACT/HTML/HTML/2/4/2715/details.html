<html><h3>Pattern ID :2715
</h3><img src='9032969.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        )
        features = self.pe(features)
        print(f"Features dtype: {features.dtype}")
        <a id="change">print(f"Attention mask dtype: {attention_mask.dtype}"</a><a id="change">)</a>
        print(f"EncoderTransformer dtype: {self.transformer_encoder.dtype}")
        features = self.transformer_encoder(features, attention_mask)
        return features</code></pre><h3>After Change</h3><pre><code class='java'>
        features = self.pe(features)
        print(f"Features dtype: {features.dtype}")
        print(f"EncoderTransformer dtype: {self.transformer_encoder.dtype}")
        <a id="change">print(f"Attention mask: {attention_mask}"</a><a id="change">)</a>

        features = self.transformer_encoder(features, attention_mask)
        return features</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 6</div><BR><div id='size'>Non-data size: 2</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/ikergarcia1996/self-driving-car-in-video-games/commit/1ff5e70330b84d4200a0b261501c6ce5733ca2e1#diff-fada037ad086638e65c7ae77e3d223963e9afaa26326aab0ea718f4013176e43L493' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9032969</div><div id='project'> Project Name: ikergarcia1996/self-driving-car-in-video-games</div><div id='commit'> Commit Name: 1ff5e70330b84d4200a0b261501c6ce5733ca2e1</div><div id='time'> Time: 2022-05-06</div><div id='author'> Author: igarciaf896@gmail.com</div><div id='file'> File Name: model.py</div><div id='m_class'> M Class Name: EncoderTransformer</div><div id='n_method'> N Class Name: EncoderTransformer</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: model.py</div><div id='n_file'> N File Name: model.py</div><div id='m_start'> M Start Line: 493</div><div id='m_end'> M End Line: 493</div><div id='n_start'> N Start Line: 494</div><div id='n_end'> N End Line: 494</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        pos = torch.arange(0, seq.shape[1]).unsqueeze(0).repeat(seq.shape[0], 1).to(self.args.device)
        seq = self.dropout((self.tok_embed(seq) * self.scale) + self.pos_encoding(pos)).transpose(0, 1)
        out = self.transformer(seq, seq).transpose(0, 1)
        <a id="change">print(</a>pos, <a id="change">&quot\n&quot</a>, seq, &quot\n&quot, out<a id="change">)</a>
        return self.fc_out(out)</code></pre><h3>After Change</h3><pre><code class='java'>
        print(self.tok_embed(seq))
        seq = (self.dropout((self.tok_embed(seq) * self.scale) + self.pos_encoding(pos))).transpose(0, 1)
        out = self.transformer(seq, seq).transpose(0, 1)
        <a id="change">print(</a>seq, <a id="change">&quot\n&quot</a>, out<a id="change">)</a>
        return self.fc_out(out)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ammesatyajit/videobert/commit/eab8cbeeea6a73b3dee98baf5671017c995943b1#diff-bfbdfcab00b44379d0d84330903c598d633961fc4e68d6adc21c8b9cea49fc5aL154' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9032968</div><div id='project'> Project Name: ammesatyajit/videobert</div><div id='commit'> Commit Name: eab8cbeeea6a73b3dee98baf5671017c995943b1</div><div id='time'> Time: 2020-09-19</div><div id='author'> Author: ammesatyajit@gmail.com</div><div id='file'> File Name: VideoBERT/train/custom_vid_transformer.py</div><div id='m_class'> M Class Name: VideoTransformer</div><div id='n_method'> N Class Name: VideoTransformer</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: VideoBERT/train/custom_vid_transformer.py</div><div id='n_file'> N File Name: VideoBERT/train/custom_vid_transformer.py</div><div id='m_start'> M Start Line: 156</div><div id='m_end'> M End Line: 159</div><div id='n_start'> N Start Line: 157</div><div id='n_end'> N End Line: 160</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            self.rnn.flatten_parameters()
        observations = torch.swapaxes(observations, 0, 1)  &#47&#47 batch_first -&gt; seq_len_first
        summary, hidden = self.rnn(observations, hidden)
        <a id="change">print(&quot======&quot</a>, observations.shape<a id="change">)</a>
        print(hidden.shape)
        hidden = torch.swapaxes(observations, 0, 1)  &#47&#47 seq_len_first -&gt; batch_first
        if return_hidden:
            return summary, hidden</code></pre><h3>After Change</h3><pre><code class='java'>
        observations = torch.swapaxes(observations, 0, 1)  &#47&#47 batch_first -&gt; seq_len_first
        print(&quotIn&quot, hidden.shape)
        summary, hidden = self.rnn(observations, hidden)
        <a id="change">print(&quotOut&quot</a>, hidden.shape<a id="change">)</a>
        hidden = torch.swapaxes(observations, 0, 1)  &#47&#47 seq_len_first -&gt; batch_first
        if return_hidden:
            return summary, hidden
        else:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/zhihanyang2022/off-policy-continuous-control/commit/85073b334586f4e93dbbfe0a0b51fda1ed14316f#diff-e6ec9e4091b14be96acf6c262dd6a92ec681bc312d1b33f6ff4946f346aa4651L24' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9032984</div><div id='project'> Project Name: zhihanyang2022/off-policy-continuous-control</div><div id='commit'> Commit Name: 85073b334586f4e93dbbfe0a0b51fda1ed14316f</div><div id='time'> Time: 2021-06-18</div><div id='author'> Author: yangz2@carleton.edu</div><div id='file'> File Name: offpcc/basics/summarizer.py</div><div id='m_class'> M Class Name: Summarizer</div><div id='n_method'> N Class Name: Summarizer</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: offpcc/basics/summarizer.py</div><div id='n_file'> N File Name: offpcc/basics/summarizer.py</div><div id='m_start'> M Start Line: 27</div><div id='m_end'> M End Line: 30</div><div id='n_start'> N Start Line: 28</div><div id='n_end'> N End Line: 30</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 assert the input shape is : batch_seq_size x entities_size x embeding_size
        &#47&#47 note: because the feature size of entity is not equal to 256, so it can not fed into transformer directly.
        &#47&#47 thus, we add a embedding layer to transfer it to right size.
        <a id="change">print(&quotentity_input is nan:&quot</a>, torch.isnan(x).any()<a id="change">)</a> if debug else None

        &#47&#47 calculate there are how many real entities in each batch
        tmp_x = torch.mean(x, dim=2, keepdim=False)</code></pre><h3>After Change</h3><pre><code class='java'>
        mask = mask.repeat(batch_size, 1)
        mask = mask &lt; entity_num.unsqueeze(dim=1)

        <a id="change">print(&quotmask:&quot</a>, mask<a id="change">)</a> if debug else None
        print(&quotmask.shape:&quot, mask.shape) if debug else None

        &#47&#47 mask: [batch_size, max_entities]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/liuruoze/mini-alphastar/commit/612d42a7bf5ef827e1e919198d839fce106155cd#diff-71869e70f9cb835282d541d2d3529d25b6ed6795c79bc770e860e9318619f6b1L717' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9032970</div><div id='project'> Project Name: liuruoze/mini-alphastar</div><div id='commit'> Commit Name: 612d42a7bf5ef827e1e919198d839fce106155cd</div><div id='time'> Time: 2021-11-25</div><div id='author'> Author: liuruoze@163.com</div><div id='file'> File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='m_class'> M Class Name: EntityEncoder</div><div id='n_method'> N Class Name: EntityEncoder</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='n_file'> N File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='m_start'> M Start Line: 721</div><div id='m_end'> M End Line: 758</div><div id='n_start'> N Start Line: 716</div><div id='n_end'> N End Line: 778</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        return total_loss

    def forward(self):
        <a id="change">print(f&quotImagining "{self.text}" from the depths of my weights...&quot</a><a id="change">)</a>

        self.model(self.encoded_text) &#47&#47 one warmup step due to issue with CLIP and CUDA

        if self.open_folder:</code></pre><h3>After Change</h3><pre><code class='java'>
        penalizing = ""
        if len(self.text_min) &gt; 0:
            penalizing = f&quotpenalizing "{self.text_min}"&quot
        <a id="change">print(f&quotImagining "{self.text}" {penalizing}...&quot</a><a id="change">)</a>
        self.model(self.encoded_texts["max"][0]) &#47&#47 one warmup step due to issue with CLIP and CUDA

        if self.open_folder:
            open_folder(&quot./&quot)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/big-sleep/commit/4e40452960be080128e5cf7fc323d48635dc69b0#diff-a32d425a1d65b549cda9588699a004a9d283f46d0623256309606cc74f8d3dd8L351' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9032972</div><div id='project'> Project Name: lucidrains/big-sleep</div><div id='commit'> Commit Name: 4e40452960be080128e5cf7fc323d48635dc69b0</div><div id='time'> Time: 2021-02-28</div><div id='author'> Author: samsepi0l@fastmail.com</div><div id='file'> File Name: big_sleep/big_sleep.py</div><div id='m_class'> M Class Name: Imagine</div><div id='n_method'> N Class Name: Imagine</div><div id='m_method'> M Method Name: forward(1)</div><div id='n_method'> N Method Name: forward(1)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: big_sleep/big_sleep.py</div><div id='n_file'> N File Name: big_sleep/big_sleep.py</div><div id='m_start'> M Start Line: 352</div><div id='m_end'> M End Line: 354</div><div id='n_start'> N Start Line: 386</div><div id='n_end'> N End Line: 390</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if not self.use_sru:
            self.rnn.flatten_parameters()
        observations = torch.swapaxes(observations, 0, 1)  &#47&#47 batch_first -&gt; seq_len_first
        <a id="change">print(&quotIn&quot</a>, hidden.shape<a id="change">)</a>
        summary, hidden = self.rnn(observations, hidden)
        print(&quotOut&quot, hidden.shape)
        hidden = torch.swapaxes(observations, 0, 1)  &#47&#47 seq_len_first -&gt; batch_first
        if return_hidden:</code></pre><h3>After Change</h3><pre><code class='java'>
            self.rnn.flatten_parameters()
        observations = torch.swapaxes(observations, 0, 1)  &#47&#47 batch_first -&gt; seq_len_first
        summary, hidden = self.rnn(observations, hidden)
        <a id="change">print(&quot======&quot</a>, observations.shape<a id="change">)</a>
        print(hidden.shape)
        hidden = torch.swapaxes(observations, 0, 1)  &#47&#47 seq_len_first -&gt; batch_first
        if return_hidden:
            return summary, hidden</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/zhihanyang2022/off-policy-continuous-control/commit/c5ef390a7890573c99c45fa2a1c281813655c33a#diff-e6ec9e4091b14be96acf6c262dd6a92ec681bc312d1b33f6ff4946f346aa4651L24' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9032974</div><div id='project'> Project Name: zhihanyang2022/off-policy-continuous-control</div><div id='commit'> Commit Name: c5ef390a7890573c99c45fa2a1c281813655c33a</div><div id='time'> Time: 2021-06-19</div><div id='author'> Author: yangz2@carleton.edu</div><div id='file'> File Name: offpcc/basics/summarizer.py</div><div id='m_class'> M Class Name: Summarizer</div><div id='n_method'> N Class Name: Summarizer</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: offpcc/basics/summarizer.py</div><div id='n_file'> N File Name: offpcc/basics/summarizer.py</div><div id='m_start'> M Start Line: 28</div><div id='m_end'> M End Line: 30</div><div id='n_start'> N Start Line: 27</div><div id='n_end'> N End Line: 29</div><BR>