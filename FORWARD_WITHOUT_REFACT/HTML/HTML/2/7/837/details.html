<html><h3>Pattern ID :837
</h3><img src='2640457.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 masked by the missing entries
        &#47&#47 note, different batch may contain different number of real entities
        tensor_list = []
        <a id="change">for </a>i, batch in enumerate(out)<a id="change">:
            </a>mean_entity = 0.
            real_number = real_number_tensor[i]
            real_number = real_number if real_number != 0 else 1
            for j, entity in enumerate(batch):
                if j &gt;= real_number_tensor[i]:
                    break        
                mean_entity = mean_entity + entity
            mean_entity<a id="change"> = </a>mean_entity / (real_number)
            <a id="change">tensor_list.append(</a>mean_entity.reshape(1, -1)<a id="change">)</a>
        tensor_mean = torch.cat(tensor_list, dim=0)
        print(&quottensor_mean:&quot, tensor_mean) if debug else None
</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 mask for transformer need a special format
        mask_seq_len = mask.shape[-1]
        tran_mask<a id="change"> = </a><a id="change">mask.unsqueeze(1</a><a id="change">)</a>

        &#47&#47 tran_mask: [batch_seq_size x max_entities x max_entities]
        tran_mask = tran_mask.repeat(1, mask_seq_len, 1)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/liuruoze/mini-alphastar/commit/612d42a7bf5ef827e1e919198d839fce106155cd#diff-71869e70f9cb835282d541d2d3529d25b6ed6795c79bc770e860e9318619f6b1L716' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2640457</div><div id='project'> Project Name: liuruoze/mini-alphastar</div><div id='commit'> Commit Name: 612d42a7bf5ef827e1e919198d839fce106155cd</div><div id='time'> Time: 2021-11-25</div><div id='author'> Author: liuruoze@163.com</div><div id='file'> File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='m_class'> M Class Name: EntityEncoder</div><div id='n_method'> N Class Name: EntityEncoder</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='n_file'> N File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='m_start'> M Start Line: 721</div><div id='m_end'> M End Line: 758</div><div id='n_start'> N Start Line: 716</div><div id='n_end'> N End Line: 778</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 masked by the missing entries
        &#47&#47 note, different batch may contain different number of real entities
        tensor_list = []
        <a id="change">for </a>i, <a id="change">batch</a> in enumerate(out)<a id="change">:
            </a>mean_entity<a id="change"> = </a>0.
            real_number = real_number_tensor[i]
            real_number = real_number if real_number != 0 else 1
            for j, entity in enumerate(batch):
                if j &gt;= real_number_tensor[i]:
                    break        
                mean_entity = mean_entity + entity
            mean_entity = mean_entity / (real_number)
            <a id="change">tensor_list.append(</a>mean_entity.reshape(1, -1)<a id="change">)</a>
        tensor_mean = torch.cat(tensor_list, dim=0)
        print(&quottensor_mean:&quot, tensor_mean) if debug else None
</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 mask for transformer need a special format
        mask_seq_len = mask.shape[-1]
        tran_mask<a id="change"> = </a><a id="change">mask.unsqueeze(1</a><a id="change">)</a>

        &#47&#47 tran_mask: [batch_seq_size x max_entities x max_entities]
        tran_mask = tran_mask.repeat(1, mask_seq_len, 1)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/liuruoze/mini-alphastar/commit/612d42a7bf5ef827e1e919198d839fce106155cd#diff-71869e70f9cb835282d541d2d3529d25b6ed6795c79bc770e860e9318619f6b1L717' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2640426</div><div id='project'> Project Name: liuruoze/mini-alphastar</div><div id='commit'> Commit Name: 612d42a7bf5ef827e1e919198d839fce106155cd</div><div id='time'> Time: 2021-11-25</div><div id='author'> Author: liuruoze@163.com</div><div id='file'> File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='m_class'> M Class Name: EntityEncoder</div><div id='n_method'> N Class Name: EntityEncoder</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='n_file'> N File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='m_start'> M Start Line: 721</div><div id='m_end'> M End Line: 758</div><div id='n_start'> N Start Line: 716</div><div id='n_end'> N End Line: 778</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        output_seq = torch.stack(batched_output_per_clip, dim=0)
        gru_output, h_n = self.rnn(output_seq.unsqueeze(1))
        gru_output = gru_output.squeeze(1)
        <a id="change">for </a><a id="change">i</a> in range(gru_output.size(0))<a id="change">:
            </a>hr<a id="change"> = </a>self.fc_resnet(gru_output[i, :])
            &#47&#47 hr = hr * 25.0
            <a id="change">hr_per_clip.append(</a>hr<a id="change">)</a>

        output_seq = torch.stack(hr_per_clip, dim=0).permute(1,0)
        &#47&#47 return output_seq, gru_output.squeeze(0), fc_out
        return output_seq, output_seq.squeeze(0)[:6]</code></pre><h3>After Change</h3><pre><code class='java'>
            if t == 0:
                gru_output, h_n = self.rnn(x.unsqueeze(1))
            else:
                gru_output<a id="change">, h_n = </a>self.rnn(<a id="change">x.unsqueeze(1</a><a id="change">)</a>, h_n)
            &#47&#47 output dim: BSx1 and Squeeze sequence length after completing GRU step
            x = self.fc_resnet(gru_output.squeeze(1))
            &#47&#47 normalize by frame-rate: 25.0 for VIPL</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/anweshcr7/rhythmnet/commit/adec4d39977a38f9886da164d98a68aac1fcc004#diff-3fc5bf831ef8bd1cc5d50189ec691215fb3d3ae0cbb974e736200edc7f8c65cdL32' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2640475</div><div id='project'> Project Name: anweshcr7/rhythmnet</div><div id='commit'> Commit Name: adec4d39977a38f9886da164d98a68aac1fcc004</div><div id='time'> Time: 2021-03-13</div><div id='author'> Author: anwesh.marwade@beyondsports.nl</div><div id='file'> File Name: src/models/rhythmNet.py</div><div id='m_class'> M Class Name: RhythmNet</div><div id='n_method'> N Class Name: RhythmNet</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/models/rhythmNet.py</div><div id='n_file'> N File Name: src/models/rhythmNet.py</div><div id='m_start'> M Start Line: 33</div><div id='m_end'> M End Line: 64</div><div id='n_start'> N Start Line: 33</div><div id='n_end'> N End Line: 56</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        else:
            combined_embedding = []
            trial_counts = torch.zeros(batch, 1)
            <a id="change">for </a><a id="change">i</a> in range(batch)<a id="change">:
                &#47&#47 remove NaNs
                </a>valid_x<a id="change"> = </a>x[i, ~torch.isnan(x[i, :, 0]), :]
                trial_counts[i] = valid_x.shape[0]
                trial_embeddings = self.trial_net(valid_x)
                &#47&#47 apply combining operation over permutation dimension
                <a id="change">combined_embedding.append(
                    </a>self.combining_function(trial_embeddings, dim=0)<a id="change">
                )</a>

            combined_embedding = torch.stack(combined_embedding, dim=0)

        assert not torch.isnan(combined_embedding).any(), "NaNs in embedding."</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 Get number of trials from non-nan entries
        num_batch, max_num_trials = x.shape[0], x.shape[self.aggregation_dim]
        nan_counts = (
            <a id="change">torch.isnan(x)
            .sum(dim=self.aggregation_dim)  &#47&#47 count nans over trial dimension
            .reshape(-1)[:num_batch]  &#47&#47 counts are the same across data dims
            .unsqueeze(-1</a><a id="change">)  &#47&#47 make it (batch, 1) to match embeddings below
        )</a>
        &#47&#47 number of non-nan trials
        trial_counts = max_num_trials - nan_counts

        &#47&#47 get nan entries
        is_nan = torch.isnan(x)
        &#47&#47 apply trial net with nan entries replaced with 0
        masked_x = torch.nan_to_num(x, nan=0.0)
        trial_embeddings = self.trial_net(masked_x)
        &#47&#47 replace previous nan entries with zeros
        trial_embeddings = trial_embeddings * (~is_nan.all(-1, keepdim=True)).float()

        &#47&#47 Take mean over permutation dimension divide by number of trials
        &#47&#47 (instead of just taking torch.mean) to account for masking.
        if self.aggregation_fn == "mean":
            combined_embedding<a id="change"> = </a>(
                trial_embeddings.sum(dim=self.aggregation_dim) / trial_counts
            )
        else:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mackelab/sbi/commit/3831fd6d5fda0ca050db8c54868ed30558451042#diff-672ba10e6c3065a6f5554033b9b173c4fe88f4c05ffc31c70a9198691e6c6659L267' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2640460</div><div id='project'> Project Name: mackelab/sbi</div><div id='commit'> Commit Name: 3831fd6d5fda0ca050db8c54868ed30558451042</div><div id='time'> Time: 2023-03-01</div><div id='author'> Author: jan.boelts@tum.de</div><div id='file'> File Name: sbi/neural_nets/embedding_nets.py</div><div id='m_class'> M Class Name: PermutationInvariantEmbedding</div><div id='n_method'> N Class Name: PermutationInvariantEmbedding</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: sbi/neural_nets/embedding_nets.py</div><div id='n_file'> N File Name: sbi/neural_nets/embedding_nets.py</div><div id='m_start'> M Start Line: 274</div><div id='m_end'> M End Line: 300</div><div id='n_start'> N Start Line: 279</div><div id='n_end'> N End Line: 306</div><BR>