<html><h3>Pattern ID :831
</h3><img src='2638056.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        rel_embedded = self.relation_embeddings(relation_batch).view(-1, 1, self.img_height, self.img_width)

        &#47&#47 batch_size, num_input_channels, 2*height, width
        stacked_inputs = torch.cat(<a id="change">[</a>e1_embedded, rel_embedded<a id="change"></a>], 2)

        &#47&#47 batch_size, num_input_channels, 2*height, width
        stacked_inputs = self.bn0(stacked_inputs)

        &#47&#47 batch_size, num_input_channels, 2*height, width
        x = self.inp_drop(stacked_inputs)
        &#47&#47 (N,C_out,H_out,W_out)
        x = self.conv1(x)

        x = self.bn1(x)
        x = F.relu(x)
        x = self.feature_map_drop(x)
        &#47&#47 batch_size, num_output_channels * (2 * height - kernel_height + 1) * (width - kernel_width + 1)
        x = x.view(batch_size, -1)
        x = self.fc(x)
        x = self.hidden_drop(x)

        if batch_size &gt; 1:
            x = self.bn2(x)
        x = F.relu(x)

        x = torch.mm(x, self.entity_embeddings.weight.transpose(1, 0))

        &#47&#47 TODO: Why this?
        x<a id="change"> += </a>self.b.expand_as(x)
        pred = F.sigmoid(x)

        return pred</code></pre><h3>After Change</h3><pre><code class='java'>
    def forward(self, batch, labels):
        batch_size = batch.shape[0]

        heads<a id="change"> = </a>batch[:, 0:1]
        relations = <a id="change">batch[:, 1:2]</a>
        tails = batch[:, 2:3]

        &#47&#47 batch_size, num_input_channels, width, height
        heads_embs = self.entity_embeddings(heads).view(-1, 1, self.img_height, self.img_width)
        relation_embs = self.relation_embeddings(relations).view(-1, 1, self.img_height, self.img_width)
        tails_embs = self.entity_embeddings(tails).view(-1, self.embedding_dim)

        &#47&#47 batch_size, num_input_channels, 2*height, width
        stacked_inputs = torch.cat([heads_embs, relation_embs], 2)

        &#47&#47 batch_size, num_input_channels, 2*height, width
        stacked_inputs = self.bn0(stacked_inputs)

        &#47&#47 batch_size, num_input_channels, 2*height, width
        x = self.inp_drop(stacked_inputs)
        &#47&#47 (N,C_out,H_out,W_out)
        x = self.conv1(x)

        x = self.bn1(x)
        x = F.relu(x)
        x = self.feature_map_drop(x)
        &#47&#47 batch_size, num_output_channels * (2 * height - kernel_height + 1) * (width - kernel_width + 1)
        x = x.view(batch_size, -1)
        x = self.fc(x)
        x = self.hidden_drop(x)

        if batch_size &gt; 1:
            x = self.bn2(x)
        x = F.relu(x)

        scores = torch.sum(torch.mm(x, tails_embs.transpose(1, 0)), dim=1)

        predictions = F.sigmoid(scores)
        loss<a id="change"> = </a>self.compute_loss(predictions, labels)

        return loss
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/pykeen/pykeen/commit/e310dc04ccd0763bef25540fb0a19a7423a27a94#diff-ca7a8f13b7b28764529fdd6068fb9b1f73dab80a9636b4e70393393c8141e014L114' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2638056</div><div id='project'> Project Name: pykeen/pykeen</div><div id='commit'> Commit Name: e310dc04ccd0763bef25540fb0a19a7423a27a94</div><div id='time'> Time: 2018-09-19</div><div id='author'> Author: ali-mehdi@live.de</div><div id='file'> File Name: src/kg_embeddings_model/conv_e.py</div><div id='m_class'> M Class Name: ConvE</div><div id='n_method'> N Class Name: ConvE</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/kg_embeddings_model/conv_e.py</div><div id='n_file'> N File Name: src/kg_embeddings_model/conv_e.py</div><div id='m_start'> M Start Line: 116</div><div id='m_end'> M End Line: 151</div><div id='n_start'> N Start Line: 114</div><div id='n_end'> N End Line: 153</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        
        x = self.conv2d(input)

        skips = <a id="change">[]</a>
        skips.append(x)

        for idx in range(self.num_stacks):
            x = self.encoder[idx](x)
            skips.append(x)

        for idx in range(self.num_stacks - 1):
            skip_idx = self.num_stacks - idx - 1
            skip<a id="change"> = </a>skips[skip_idx]
            x = self.decoder[idx](x, skip=skip)

        output = self.bottleneck_conv2d(x)</code></pre><h3>After Change</h3><pre><code class='java'>
        Kh, Kw = self.kernel_size
        Ph, Pw = Kh - 1, Kw - 1
        padding_top = Ph // 2
        padding_bottom<a id="change"> = </a>Ph - padding_top
        padding_left = Pw // 2
        padding_right = Pw - padding_left

        input = F.pad(input, (padding_left, padding_right, padding_top, padding_bottom))

        x = self.conv2d(input)
        x, skip = self.encoder(x)
        x = self.bottleneck_conv2d(x)
        x = self.decoder(x, <a id="change">skip[::-1]</a>)

        if self.pointwise_conv2d:
            output<a id="change"> = </a>self.pointwise_conv2d(x)
        else:
            output = x
        </code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/tky823/dnn-based_source_separation/commit/8fb5cd5f4f8b4a435d058aef6204904f657abea0#diff-ead896e273fdbcf5c8f3a2cfbd8c95af50b268919d59e26568c480f7c48682c7L201' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2638073</div><div id='project'> Project Name: tky823/dnn-based_source_separation</div><div id='commit'> Commit Name: 8fb5cd5f4f8b4a435d058aef6204904f657abea0</div><div id='time'> Time: 2021-06-06</div><div id='author'> Author: 40362510+tky823@users.noreply.github.com</div><div id='file'> File Name: src/models/d3net.py</div><div id='m_class'> M Class Name: D3NetBackbone</div><div id='n_method'> N Class Name: D3NetBackbone</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/models/d3net.py</div><div id='n_file'> N File Name: src/models/d3net.py</div><div id='m_start'> M Start Line: 206</div><div id='m_end'> M End Line: 220</div><div id='n_start'> N Start Line: 207</div><div id='n_end'> N End Line: 226</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def forward(self, x):
        if self.training:
            total_blocks = sum([len(sx) for sx in x])
            mask_size = torch.Size(<a id="change">[</a>total_blocks<a id="change"></a>])
            binomial = torch.distributions.binomial.Binomial(probs=1 - self.p)
            mask = binomial.sample(mask_size) * (1.0 / (1 - self.p))
            mask_id = 0
            for mod in x:
                for x_mod in mod:
                    x_mod<a id="change"> *= </a>mask[mask_id]
                    mask_id += 1
            return x, mask
        return x, None</code></pre><h3>After Change</h3><pre><code class='java'>

    def forward(self, X):
        if self.training:
            blocks_per_mod<a id="change"> = </a>[sx.shape[1] for sx in X]
            mask_size = torch.Size([X[0].shape[0], sum(blocks_per_mod)])
            binomial = torch.distributions.binomial.Binomial(probs=1 - self.p)
            mask = binomial.sample(mask_size) * (1.0 / (1 - self.p))
            mask_shapes = [list(<a id="change">x.shape[:2]</a>) + [1] * (x.dim() - 2) for x in X]
            grouped_masks = torch.split(mask, blocks_per_mod, dim=1)
            grouped_masks = [m.reshape(s) for m, s in zip(grouped_masks, mask_shapes)]
            X<a id="change"> = </a>[x * m for x, m in zip(X, grouped_masks)]
            return X, grouped_masks
        return X, None
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/anita-hu/msaf/commit/a2c91bd6e186680ca2c41bbf22c9b57aff4654d2#diff-d68e3105d0084e846106ad79a39721b487918159e4343a84f4ae68b3d6eadc0cL38' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2638076</div><div id='project'> Project Name: anita-hu/msaf</div><div id='commit'> Commit Name: a2c91bd6e186680ca2c41bbf22c9b57aff4654d2</div><div id='time'> Time: 2020-12-30</div><div id='author'> Author: anitahu113@gmail.com</div><div id='file'> File Name: MSAF.py</div><div id='m_class'> M Class Name: BlockDropout</div><div id='n_method'> N Class Name: BlockDropout</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: MSAF.py</div><div id='n_file'> N File Name: MSAF.py</div><div id='m_start'> M Start Line: 40</div><div id='m_end'> M End Line: 49</div><div id='n_start'> N Start Line: 39</div><div id='n_end'> N End Line: 47</div><BR>