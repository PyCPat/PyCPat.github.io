<html><h3>Pattern ID :1534
</h3><img src='4426978.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 logits_flat: (batch * max_len, dim)
        input = input.view(-1, input.shape[-1])
        &#47&#47 target_flat: (batch * max_len, dim)
        target_flat = <a id="change">target.view(-1</a>, target.shape[-1]<a id="change">)</a>
        &#47&#47 losses_flat: (batch * max_len, dim)
        losses_flat = functional.l1_loss(
            input, target_flat, size_average=False, reduce=False)
        &#47&#47 losses: (batch, max_len, dim)
        losses<a id="change"> = losses_flat.view(</a>*<a id="change">target.size())</a>

        &#47&#47 mask: (batch, max_len, 1)
        mask = sequence_mask(
            sequence_length=length, max_len=target.size(1)).unsqueeze(2)</code></pre><h3>After Change</h3><pre><code class='java'>
            loss: An average loss value masked by the length.
        
        &#47&#47 mask: (batch, max_len, 1)
        mask = <a id="change">sequence_mask(
            sequence_length=length, max_len=target.size(1)).unsqueeze(2).float()</a>
        mask = mask.expand_as(input)
        loss = functional.l1_loss(
            input * mask, target * mask, reduction="sum")
        loss = loss<a id="change"> / </a><a id="change">mask.sum()</a>
        return loss


class MSELossMasked(nn.Module):</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/coqui-ai/tts/commit/a15b3ec9a18377bf67356a9b5c29f4b767001d05#diff-e2062370456db62dc9af5481873d2fcfe1d6e8a959459063dd6233f61d3f66d5L25' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4426978</div><div id='project'> Project Name: coqui-ai/tts</div><div id='commit'> Commit Name: a15b3ec9a18377bf67356a9b5c29f4b767001d05</div><div id='time'> Time: 2018-08-13</div><div id='author'> Author: erengolge@gmail.com</div><div id='file'> File Name: layers/losses.py</div><div id='m_class'> M Class Name: L1LossMasked</div><div id='n_method'> N Class Name: L1LossMasked</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: layers/losses.py</div><div id='n_file'> N File Name: layers/losses.py</div><div id='m_start'> M Start Line: 25</div><div id='m_end'> M End Line: 42</div><div id='n_start'> N Start Line: 26</div><div id='n_end'> N End Line: 31</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        target = target.contiguous()

        &#47&#47 logits_flat: (batch * max_len, dim)
        input = <a id="change">input.view(-1</a>, input.shape[-1]<a id="change">)</a>
        &#47&#47 target_flat: (batch * max_len, dim)
        target_flat = target.view(-1, target.shape[-1])
        &#47&#47 losses_flat: (batch * max_len, dim)
        losses_flat = functional.mse_loss(
            input, target_flat, size_average=False, reduce=False)
        &#47&#47 losses: (batch, max_len, dim)
        losses = <a id="change">losses_flat.view(</a>*<a id="change">target.size())</a>

        &#47&#47 mask: (batch, max_len, 1)
        mask = sequence_mask(
            sequence_length=length, max_len=target.size(1)).unsqueeze(2)
        losses = losses * mask.float()
        loss<a id="change"> = </a>losses.sum() / (length.float().sum() * float(target.shape[2]))
        return loss
</code></pre><h3>After Change</h3><pre><code class='java'>
            loss: An average loss value masked by the length.
        
        &#47&#47 mask: (batch, max_len, 1)
        mask = <a id="change">sequence_mask(
            sequence_length=length, max_len=target.size(1)).unsqueeze(2).float()</a>
        mask = mask.expand_as(input)
        loss = functional.mse_loss(
            input * mask, target * mask, reduction="sum")
        loss = loss<a id="change"> / </a><a id="change">mask.sum()</a>
        return loss

</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/coqui-ai/tts/commit/4326582bb1e68480ef79a02abbf4bfacc3aadede#diff-e2062370456db62dc9af5481873d2fcfe1d6e8a959459063dd6233f61d3f66d5L39' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4426977</div><div id='project'> Project Name: coqui-ai/tts</div><div id='commit'> Commit Name: 4326582bb1e68480ef79a02abbf4bfacc3aadede</div><div id='time'> Time: 2019-03-06</div><div id='author'> Author: egolge@mozilla.com</div><div id='file'> File Name: layers/losses.py</div><div id='m_class'> M Class Name: MSELossMasked</div><div id='n_method'> N Class Name: MSELossMasked</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: layers/losses.py</div><div id='n_file'> N File Name: layers/losses.py</div><div id='m_start'> M Start Line: 53</div><div id='m_end'> M End Line: 70</div><div id='n_start'> N Start Line: 54</div><div id='n_end'> N End Line: 59</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 if no NaNs for padding varying trial lengths we can batch the computation
        if not torch.isnan(x).any():
            trial_embeddings = <a id="change">self.trial_net(x.view(batch * permutation_dim, -1)).view(
                </a>batch, permutation_dim, -1<a id="change">
            )</a>
            combined_embedding<a id="change"> = </a>self.combining_function(trial_embeddings, dim=1)
            trial_counts = torch.ones(batch, 1, dtype=torch.float32) * permutation_dim

        &#47&#47 otherwise we need to loop over the batch to account for varying trial lengths</code></pre><h3>After Change</h3><pre><code class='java'>
        masked_x = torch.nan_to_num(x, nan=0.0)
        trial_embeddings = self.trial_net(masked_x)
        &#47&#47 replace previous nan entries with zeros
        trial_embeddings = trial_embeddings * <a id="change">(~is_nan.all(-1, keepdim=True)).float()</a>

        &#47&#47 Take mean over permutation dimension divide by number of trials
        &#47&#47 (instead of just taking torch.mean) to account for masking.
        if self.aggregation_fn == "mean":
            combined_embedding = (
                <a id="change">trial_embeddings.sum(dim=self.aggregation_dim) / </a>trial_counts
            )
        else:
            combined_embedding = trial_embeddings.sum(dim=self.aggregation_dim)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mackelab/sbi/commit/3831fd6d5fda0ca050db8c54868ed30558451042#diff-672ba10e6c3065a6f5554033b9b173c4fe88f4c05ffc31c70a9198691e6c6659L267' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4426973</div><div id='project'> Project Name: mackelab/sbi</div><div id='commit'> Commit Name: 3831fd6d5fda0ca050db8c54868ed30558451042</div><div id='time'> Time: 2023-03-01</div><div id='author'> Author: jan.boelts@tum.de</div><div id='file'> File Name: sbi/neural_nets/embedding_nets.py</div><div id='m_class'> M Class Name: PermutationInvariantEmbedding</div><div id='n_method'> N Class Name: PermutationInvariantEmbedding</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: sbi/neural_nets/embedding_nets.py</div><div id='n_file'> N File Name: sbi/neural_nets/embedding_nets.py</div><div id='m_start'> M Start Line: 274</div><div id='m_end'> M End Line: 300</div><div id='n_start'> N Start Line: 279</div><div id='n_end'> N End Line: 306</div><BR>