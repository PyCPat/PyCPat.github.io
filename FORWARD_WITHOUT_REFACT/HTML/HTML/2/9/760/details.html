<html><h3>Pattern ID :760
</h3><img src='2488757.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        
        nums_nodes, id = graph.batch_num_nodes(), 0
        items_embedding = self.item_embedding(torch.tensor([i for i in range(self.items_total)]).to(nodes.device))
        batch_embedding<a id="change"> = </a><a id="change">[]</a>
        <a id="change">for </a>num_nodes in nums_nodes<a id="change">:
            </a>output_node_features<a id="change"> = </a>nodes_output[id:id + num_nodes, :]
            output_nodes = nodes[id: id + num_nodes]
            beta = torch.zeros(self.items_total, 1).to(nodes.device)
            beta[output_nodes] = 1
            embed = (1 - beta * self.alpha) * items_embedding.clone()
            embed[output_nodes, :] = embed[output_nodes, :] + self.alpha[output_nodes] * output_node_features
            <a id="change">batch_embedding.append(</a>embed<a id="change">)</a>
            id += num_nodes
        batch_embedding = torch.stack(batch_embedding)
        <a id="change">return </a>batch_embedding


class AggregateTemporalNodeFeatures(nn.Module):</code></pre><h3>After Change</h3><pre><code class='java'>
        :return:
        
        items_embedding = self.item_embedding(torch.tensor([i for i in range(self.items_total)]).to(nodes.device))
        alpha<a id="change"> = </a>torch.sigmoid(self.alpha)
        embed = (1 - alpha) * items_embedding.clone() + alpha * nodes_output
        <a id="change">return </a>embed


class AggregateTemporalNodeFeatures(nn.Module):</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 8</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/benedekrozemberczki/pytorch_geometric_temporal/commit/c402d2a14167bceaa3c8d3845879f8056e8aead7#diff-781837fb12ee6ac1f0b89d83a2500544e486bd58832bd4e4a8d1a779b2a0950eL78' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2488757</div><div id='project'> Project Name: benedekrozemberczki/pytorch_geometric_temporal</div><div id='commit'> Commit Name: c402d2a14167bceaa3c8d3845879f8056e8aead7</div><div id='time'> Time: 2021-07-18</div><div id='author'> Author: benedek.rozemberczki@gmail.com</div><div id='file'> File Name: torch_geometric_temporal/nn/attention/dnntsp.py</div><div id='m_class'> M Class Name: GlobalGatedUpdater</div><div id='n_method'> N Class Name: GlobalGatedUpdater</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: torch_geometric_temporal/nn/attention/dnntsp.py</div><div id='n_file'> N File Name: torch_geometric_temporal/nn/attention/dnntsp.py</div><div id='m_start'> M Start Line: 78</div><div id='m_end'> M End Line: 98</div><div id='n_start'> N Start Line: 85</div><div id='n_end'> N End Line: 87</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        
        nums_nodes, id = graph.batch_num_nodes(), 0
        items_embedding = self.item_embedding(torch.tensor([i for i in range(self.items_total)]).to(nodes.device))
        batch_embedding<a id="change"> = </a><a id="change">[]</a>
        <a id="change">for </a><a id="change">num_nodes</a> in nums_nodes<a id="change">:
            </a>output_node_features = nodes_output[id:id + num_nodes, :]
            output_nodes = nodes[id: id + num_nodes]
            beta = torch.zeros(self.items_total, 1).to(nodes.device)
            beta[output_nodes] = 1
            embed = (1 - beta * self.alpha) * items_embedding.clone()
            embed[output_nodes, :]<a id="change"> = </a>embed[output_nodes, :] + self.alpha[output_nodes] * output_node_features
            <a id="change">batch_embedding.append(</a>embed<a id="change">)</a>
            id += num_nodes
        batch_embedding = torch.stack(batch_embedding)
        <a id="change">return </a>batch_embedding


class AggregateTemporalNodeFeatures(nn.Module):</code></pre><h3>After Change</h3><pre><code class='java'>
        :return:
        
        items_embedding = self.item_embedding(torch.tensor([i for i in range(self.items_total)]).to(nodes.device))
        alpha<a id="change"> = </a>torch.sigmoid(self.alpha)
        embed = (1 - alpha) * items_embedding.clone() + alpha * nodes_output
        <a id="change">return </a>embed


class AggregateTemporalNodeFeatures(nn.Module):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/benedekrozemberczki/pytorch_geometric_temporal/commit/c402d2a14167bceaa3c8d3845879f8056e8aead7#diff-781837fb12ee6ac1f0b89d83a2500544e486bd58832bd4e4a8d1a779b2a0950eL78' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2488756</div><div id='project'> Project Name: benedekrozemberczki/pytorch_geometric_temporal</div><div id='commit'> Commit Name: c402d2a14167bceaa3c8d3845879f8056e8aead7</div><div id='time'> Time: 2021-07-18</div><div id='author'> Author: benedek.rozemberczki@gmail.com</div><div id='file'> File Name: torch_geometric_temporal/nn/attention/dnntsp.py</div><div id='m_class'> M Class Name: GlobalGatedUpdater</div><div id='n_method'> N Class Name: GlobalGatedUpdater</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: torch_geometric_temporal/nn/attention/dnntsp.py</div><div id='n_file'> N File Name: torch_geometric_temporal/nn/attention/dnntsp.py</div><div id='m_start'> M Start Line: 78</div><div id='m_end'> M End Line: 98</div><div id='n_start'> N Start Line: 85</div><div id='n_end'> N End Line: 87</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        )

    def forward(self, input, hidden_state=None):
        output<a id="change"> = </a><a id="change">[]</a>
        <a id="change">for </a><a id="change">step</a> in range(input.size(1))<a id="change">:
            &#47&#47 Compute current time-step
            </a>hidden_state<a id="change"> = </a>self.rnn_cell(input[:, step, :, :, :], hidden_state)
            <a id="change">output.append(</a>hidden_state<a id="change">)</a>
        &#47&#47 Stack the list of output hidden states into a tensor
        output = torch.stack(output, 0)
        <a id="change">return </a>output


&#47&#47 --------------------------------------------------------------------------</code></pre><h3>After Change</h3><pre><code class='java'>
        seq_len = len(cur_layer_input)

        layer_output_list = []
        last_state_list<a id="change"> = </a>[]

        for l, (gru_cell, hid_dp) in enumerate(zip(self.cell_list, self.hidden_dps)):
            h = hidden_state[l]
            output_inner = []
            for t in range(seq_len):
                h = gru_cell(input=cur_layer_input[t], h_prev=h)
                output_inner.append(h)

            cur_layer_input = torch.stack(output_inner)  &#47&#47 list to array
            if l != self.n_layers:
                cur_layer_input = hid_dp(cur_layer_input)
            last_state_list.append(h)

        layer_output = torch.stack(output_inner, dim=int(self.batch_first))
        last_state_list = torch.stack(last_state_list, dim=0)
        <a id="change">return </a>layer_output, last_state_list

    def reset_parameters(self):
        for c in self.cell_list:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/openclimatefix/skillful_nowcasting/commit/02c5ceadd01484d6ac8bce848ff76446fe7a6917#diff-cee00a565d888c684ec40bd3eac27669aa3223b223a80ae9f871383a9fb64917L268' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2488753</div><div id='project'> Project Name: openclimatefix/skillful_nowcasting</div><div id='commit'> Commit Name: 02c5ceadd01484d6ac8bce848ff76446fe7a6917</div><div id='time'> Time: 2021-10-18</div><div id='author'> Author: jacob@bieker.tech</div><div id='file'> File Name: nowcasting_gan/layers/ConvGRU.py</div><div id='m_class'> M Class Name: ConvGRU</div><div id='n_method'> N Class Name: ConvGRU</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: nowcasting_gan/layers/ConvGRU.py</div><div id='n_file'> N File Name: nowcasting_gan/layers/ConvGRU.py</div><div id='m_start'> M Start Line: 269</div><div id='m_end'> M End Line: 276</div><div id='n_start'> N Start Line: 196</div><div id='n_end'> N End Line: 221</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        x = self.embedding(x)
        x = x.unsqueeze(dim=1)

        out_tensors<a id="change"> = </a><a id="change">[]</a>
        <a id="change">for </a>conv, <a id="change">pool</a> in zip(self.convs, self.pools)<a id="change">:
            </a>activation<a id="change"> = </a>pool(F.relu(conv(x)))
            <a id="change">out_tensors.append(</a>activation<a id="change">)</a>

        x = torch.cat(out_tensors, dim=1)

        batch_size = x.size(0)
        x = x.view(batch_size, -1)
        x = self.dropout(x)

        <a id="change">return </a>self.fc(x)
</code></pre><h3>After Change</h3><pre><code class='java'>
        x : torch.LongTensor or torch.cuda.LongTensor
            input tensor (batch_size, max_sequence_length) with padded sequences of word ids
        
        x<a id="change"> = </a>self._forward_pooled(x)
        <a id="change">return </a>self._dropout_and_fc(x)

    def _forward_pooled(self, x):
        assert x.size(1) == self.max_seq_length</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/webis-de/small-text/commit/88b16119a287d9e3aa15fdb74f67fad2456b5227#diff-03d250cd754127f674be2e5803e6078b86189341ed94643e6cb75bc6a958bd31L109' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2488751</div><div id='project'> Project Name: webis-de/small-text</div><div id='commit'> Commit Name: 88b16119a287d9e3aa15fdb74f67fad2456b5227</div><div id='time'> Time: 2021-12-19</div><div id='author'> Author: chschroeder@users.noreply.github.com</div><div id='file'> File Name: small_text/integrations/pytorch/models/kimcnn.py</div><div id='m_class'> M Class Name: KimCNN</div><div id='n_method'> N Class Name: KimCNN</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: small_text/integrations/pytorch/models/kimcnn.py</div><div id='n_file'> N File Name: small_text/integrations/pytorch/models/kimcnn.py</div><div id='m_start'> M Start Line: 116</div><div id='m_end'> M End Line: 132</div><div id='n_start'> N Start Line: 116</div><div id='n_end'> N End Line: 117</div><BR>