<html><h3>Pattern ID :1613
</h3><img src='6541891.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        for n in range(1, self.impulse_response_length):
            s = n - self.cep_order
            h[..., n] = (
                <a id="change">torch.einsum(
                    "...d,...d-&gt;..."</a>,
                    h[..., max(0, s) : n].clone(),
                    c1[..., max(0, -s) :]<a id="change">,
                )</a>
                / n
            )
        return h
</code></pre><h3>After Change</h3><pre><code class='java'>
        h[..., 0] = torch.exp(c0)
        for n in range(1, self.impulse_response_length):
            s = n - self.cep_order
            h[..., n] = <a id="change">(h[..., max(0, s) : n].clone() * c1[..., max(0, -s) :]).sum(
                </a>-1<a id="change">
            )</a> / n
        return h
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 2</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/sp-nitech/diffsptk/commit/29f817e959598e410ea695820338b357fa21fff2#diff-4d81b8d69c76a585e1c8e484ab2b41b62492adc9794a8285eb760fb4f4907ff7L69' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6541891</div><div id='project'> Project Name: sp-nitech/diffsptk</div><div id='commit'> Commit Name: 29f817e959598e410ea695820338b357fa21fff2</div><div id='time'> Time: 2022-04-08</div><div id='author'> Author: takenori.yoshimura24@gmail.com</div><div id='file'> File Name: diffsptk/core/c2mpir.py</div><div id='m_class'> M Class Name: CepstrumToImpulseResponse</div><div id='n_method'> N Class Name: CepstrumToImpulseResponse</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: diffsptk/core/c2mpir.py</div><div id='n_file'> N File Name: diffsptk/core/c2mpir.py</div><div id='m_start'> M Start Line: 69</div><div id='m_end'> M End Line: 83</div><div id='n_start'> N Start Line: 69</div><div id='n_end'> N End Line: 79</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            &#47&#47 c: (batch_size, num_capsules, num_route_nodes)
            &#47&#47 u_hat: (batch_size, num_capsules, num_route_nodes, out_channels)
            &#47&#47 s: (batch_size, num_capsules, out_channels)
            s = <a id="change">torch.einsum(&quotijk, ijkl -&gt; ijl&quot</a>, c, u_hat_temp<a id="change">)</a>
            v = squash(s)

            &#47&#47 Update b
            &#47&#47 u_hat: (batch_size, num_capsules, num_route_nodes, out_channels)</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 (batch_size, num_caps, in_caps, 1) * (batch_size, in_caps, num_caps, dim_caps) -&gt;
            &#47&#47 (batch_size, num_caps, in_caps, dim_caps) sum across in_caps -&gt;
            &#47&#47 (batch_size, num_caps, dim_caps)
            s = <a id="change">(c * temp_u_hat).sum(dim=2)</a>
            &#47&#47 apply "squashing" non-linearity along dim_caps
            v = squash(s)
            &#47&#47 dot product agreement between the current output vj and the prediction uj|i
            &#47&#47 (batch_size, num_caps, in_caps, dim_caps) @ (batch_size, num_caps, dim_caps, 1)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/riroaki/capsnet/commit/e62f83faad1731befd8a1e434aaf902e2140aecb#diff-903964c7bdce50a4b995b4520374f243c677f45b2f8c7ed7b15abeeb6f26af12L49' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6541890</div><div id='project'> Project Name: riroaki/capsnet</div><div id='commit'> Commit Name: e62f83faad1731befd8a1e434aaf902e2140aecb</div><div id='time'> Time: 2020-03-08</div><div id='author'> Author: aki@akideMacBook-Pro.local</div><div id='file'> File Name: capsnet.py</div><div id='m_class'> M Class Name: DigitCaps</div><div id='n_method'> N Class Name: DigitCaps</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: capsnet.py</div><div id='n_file'> N File Name: capsnet.py</div><div id='m_start'> M Start Line: 50</div><div id='m_end'> M End Line: 79</div><div id='n_start'> N Start Line: 59</div><div id='n_end'> N End Line: 93</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        d = torch.sum(z_flattened.pow(2), dim=1, keepdim=True) + \
            torch.sum(self.embedding.weight.pow(2), dim=1) - 2 * \
            <a id="change">torch.einsum(&quotbd,dn-&gt;bn&quot</a>, z_flattened, self.embedding.weight.permute(1,0)<a id="change">)</a> &#47&#47 &quotn d -&gt; d n&quot

        encoding_indices = torch.argmin(d, dim=1)
        z_q = self.embedding(encoding_indices).view(z.shape)</code></pre><h3>After Change</h3><pre><code class='java'>
            self.embedding.embed_avg.data.mul_(self.decay).add_(embed_sum, alpha=1 - self.decay)

            &#47&#47cluster size Laplace smoothing 
            n = <a id="change">self.embedding.cluster_size.sum()</a>
            cluster_size = (
                (self.embedding.cluster_size + self.eps) / (n + self.num_tokens * self.eps) * n
            )
            &#47&#47normalize embedding average with smoothed cluster size</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/tgisaturday/dalle-lightning/commit/e387b61c8c640b56c7cbd241d8ec60ab1f022611#diff-5cc0cb1395e7634e216d321d933d7868cc1ee34fa25763750d65126b9ad1ea15L82' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6541889</div><div id='project'> Project Name: tgisaturday/dalle-lightning</div><div id='commit'> Commit Name: e387b61c8c640b56c7cbd241d8ec60ab1f022611</div><div id='time'> Time: 2021-08-12</div><div id='author'> Author: jamesk1228@gmail.com</div><div id='file'> File Name: pl_dalle/modules/vqvae/quantize.py</div><div id='m_class'> M Class Name: EMAVectorQuantizer</div><div id='n_method'> N Class Name: EMAVectorQuantizer</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: pl_dalle/modules/vqvae/quantize.py</div><div id='n_file'> N File Name: pl_dalle/modules/vqvae/quantize.py</div><div id='m_start'> M Start Line: 85</div><div id='m_end'> M End Line: 118</div><div id='n_start'> N Start Line: 184</div><div id='n_end'> N End Line: 215</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        x = x.view(new_shape)
        &#47&#47 The better way, but not supported by torchscript
        &#47&#47 x = x.unflatten(-1, (self.groups, self.ws))  &#47&#47 [..., G, I/G]
        x = <a id="change">torch.einsum("...gi,...gih-&gt;...gh"</a>, x, self.weight<a id="change">)</a>  &#47&#47 [..., G, H/G]
        x = x.flatten(2, 3)  &#47&#47 [B, T, H]
        return x
</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 This is also not supported by tract:
        &#47&#47     x = torch.einsum("btgi,gih-&gt;btgh", x, self.weight)  &#47&#47 [..., G, H/G]
        &#47&#47 Thus, lets to some manual reshaping and multiplication:
        x = <a id="change">x.unsqueeze(-1).mul(self.weight.unsqueeze(0).unsqueeze(0)).sum(</a>-2<a id="change">)</a>
        x = x.flatten(2, 3)  &#47&#47 [B, T, H]
        return x

</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/rikorose/deepfilternet/commit/e52e8a423d869b5882f9b86aaa8a8d7e8a07edf2#diff-569ca7fdf94305f7a2fca088c4421d6a6d7147f193f64bb99c3653029cc16004L724' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6541885</div><div id='project'> Project Name: rikorose/deepfilternet</div><div id='commit'> Commit Name: e52e8a423d869b5882f9b86aaa8a8d7e8a07edf2</div><div id='time'> Time: 2022-10-20</div><div id='author'> Author: Rikorose@users.noreply.github.com</div><div id='file'> File Name: DeepFilterNet/df/modules.py</div><div id='m_class'> M Class Name: GroupedLinearEinsum</div><div id='n_method'> N Class Name: GroupedLinearEinsum</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: DeepFilterNet/df/modules.py</div><div id='n_file'> N File Name: DeepFilterNet/df/modules.py</div><div id='m_start'> M Start Line: 727</div><div id='m_end'> M End Line: 730</div><div id='n_start'> N Start Line: 727</div><div id='n_end'> N End Line: 733</div><BR>