<html><h3>Pattern ID :1828
</h3><img src='7088812.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        B, L, C = x.shape
        if L != H * W:
            raise ValueError(f&quotPatchMerging module. Input features L={L} doesn`t match with image size H*W={H*W}.&quot)
        <a id="change">if H % 2 != 0</a><a id="change">:
            </a>raise ValueError(f&quotPatchMerging module. Input height {H} is not even number&quot)
        <a id="change">if W % 2 != 0</a><a id="change">:
            raise </a><a id="change">ValueError(f&quotPatchMerging module. Input weight {W} is not even number&quot</a><a id="change">)</a>

        x = x.view(B, H, W, C)

        x0 = x[:, 0::2, 0::2, :]  &#47&#47 B H/2 W/2 C</code></pre><h3>After Change</h3><pre><code class='java'>
        
        H, W = self.input_resolution
        B, L, C = x.shape
        <a id="change">assert </a>L == H * W, "input feature has wrong size"
        assert H % 2 == 0 and W % 2 == 0, f"x size ({H}*{W}) are not even."

        x = x.view(B, H, W, C)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/eora-ai/torchok/commit/ab2534f05b48a529d03f8c28af2579245772f4e0#diff-698ef303146f83333dbef91357773726560288f0e3fb7831ae9727aff9b7965bL33' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 7088812</div><div id='project'> Project Name: eora-ai/torchok</div><div id='commit'> Commit Name: ab2534f05b48a529d03f8c28af2579245772f4e0</div><div id='time'> Time: 2022-07-11</div><div id='author'> Author: rashit.bayazitov.1995@gmail.com</div><div id='file'> File Name: src/models/modules/blocks/patch_merging.py</div><div id='m_class'> M Class Name: PatchMerging</div><div id='n_method'> N Class Name: PatchMerging</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/models/modules/blocks/patch_merging.py</div><div id='n_file'> N File Name: src/models/modules/blocks/patch_merging.py</div><div id='m_start'> M Start Line: 33</div><div id='m_end'> M End Line: 40</div><div id='n_start'> N Start Line: 38</div><div id='n_end'> N End Line: 39</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    def forward(self, x):
        B, C, H, W = x.shape
        <a id="change">if H != self.img_size[0]</a><a id="change">:
            </a>raise ValueError(f"PatchEmbed module. Input image height ({H}) doesn&quott match model ({self.img_size[0]}).")
        <a id="change">if W != self.img_size[1]</a><a id="change">:
            raise </a><a id="change">ValueError(f"PatchEmbed module. Input image width ({W}) doesn&quott match model ({self.img_size[1]})."</a><a id="change">)</a>
        x = self.proj(x)
        if self.flatten:
            x = x.flatten(2).transpose(1, 2)  &#47&#47 BCHW -&gt; BNC
        x = self.norm(x)</code></pre><h3>After Change</h3><pre><code class='java'>
    def forward(self, x):
        B, C, H, W = x.shape
        &#47&#47 FIXME look at relaxing size constraints
        <a id="change">assert </a>H == self.img_size[0] and W == self.img_size[1], \
            f"Input image size ({H}*{W}) doesn&quott match model ({self.img_size[0]}*{self.img_size[1]})."
        x = self.proj(x).flatten(2).transpose(1, 2)  &#47&#47 B Ph*Pw C
        if self.norm is not None:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/eora-ai/torchok/commit/ab2534f05b48a529d03f8c28af2579245772f4e0#diff-8ea48274a2159a0abc4b0425f2fb246399f29a78d6a46d98cdbda118b48a4195L28' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 7088843</div><div id='project'> Project Name: eora-ai/torchok</div><div id='commit'> Commit Name: ab2534f05b48a529d03f8c28af2579245772f4e0</div><div id='time'> Time: 2022-07-11</div><div id='author'> Author: rashit.bayazitov.1995@gmail.com</div><div id='file'> File Name: src/models/modules/blocks/patch_embedding.py</div><div id='m_class'> M Class Name: PatchEmbed</div><div id='n_method'> N Class Name: PatchEmbed</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/models/modules/blocks/patch_embedding.py</div><div id='n_file'> N File Name: src/models/modules/blocks/patch_embedding.py</div><div id='m_start'> M Start Line: 30</div><div id='m_end'> M End Line: 37</div><div id='n_start'> N Start Line: 50</div><div id='n_end'> N End Line: 55</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            batch, permutation_dim, -1
        )

        <a id="change">if self.combining_operation == "mean"</a><a id="change">:
            </a>e = iid_embeddings.mean(dim=1)
        elif <a id="change">self.combining_operation == "sum"</a><a id="change">:
            </a>e = iid_embeddings.sum(dim=1)
        else:
            <a id="change">raise </a><a id="change">ValueError("combining_operation must be in [&quotsum&quot, &quotmean&quot]."</a><a id="change">)</a>

        embedding = self.fc_subnet(e)

        return embedding</code></pre><h3>After Change</h3><pre><code class='java'>

            combined_embedding = torch.stack(combined_embedding, dim=0)

        <a id="change">assert </a>not torch.isnan(combined_embedding).any(), "NaNs in embedding."

        &#47&#47 add number of trials as additional input
        &#47&#47 print(torch.cat([combined_embedding, trial_counts], dim=1))</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mackelab/sbi/commit/1352e77bdbc47aa4a4130679903b57672e48218c#diff-672ba10e6c3065a6f5554033b9b173c4fe88f4c05ffc31c70a9198691e6c6659L262' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 7088822</div><div id='project'> Project Name: mackelab/sbi</div><div id='commit'> Commit Name: 1352e77bdbc47aa4a4130679903b57672e48218c</div><div id='time'> Time: 2023-03-01</div><div id='author'> Author: jan.boelts@tum.de</div><div id='file'> File Name: sbi/neural_nets/embedding_nets.py</div><div id='m_class'> M Class Name: PermutationInvariantEmbedding</div><div id='n_method'> N Class Name: PermutationInvariantEmbedding</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: sbi/neural_nets/embedding_nets.py</div><div id='n_file'> N File Name: sbi/neural_nets/embedding_nets.py</div><div id='m_start'> M Start Line: 271</div><div id='m_end'> M End Line: 284</div><div id='n_start'> N Start Line: 277</div><div id='n_end'> N End Line: 304</div><BR>