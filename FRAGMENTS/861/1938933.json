{"BEFORE":"        config_trend,\n        n_lags=0,\n        n_changepoints=0,\n        trend_smoothness=0,\n        num_hidden_layers=0,\n        d_hidden=None,\n        season_dims=None,\n        season_mode=\"additive\",\n        covar_config=None,\n        events_dims=None,\n        regressors_dims=None,\n    ):\n        \"\"\"\n        Args:\n            n_forecasts (int): number of steps to forecast. Aka number of model outputs.\n            n_lags (int): number of previous steps of time series used as input. Aka AR-order.\n                0 (default): no auto-regression\n            n_changepoints (int): number of trend changepoints.\n                0 (default): no changepoints\n            trend_smoothness (int\/float): how much to regularize the trend changepoints\n                0 (default): segmentwise trend with continuity (individual k for each segment)\n                -1: discontinuous segmentwise trend (individual k, m for each segment)\n            num_hidden_layers (int): number of hidden layers (for AR-Net)\n                0 (default): no hidden layers, corresponds to classic Auto-Regression\n            d_hidden (int): dimensionality of hidden layers  (for AR-Net). ignored if no hidden layers.\n                None (default): sets to n_lags + n_forecasts\n            season_dims (OrderedDict(int)): ordered Dict with entries: <seasonality name>: vector dimension\n                None (default): No seasonality\n            season_mode (str): 'additive', 'multiplicative', how seasonality term is accounted for in forecast.\n                'additive' (default): add seasonality component to outputs of other model components\n            covar_config (OrderedDict): Names of covariate variables.\n            events_dims (pd.DataFrame): Dataframe with columns 'event' and 'event_delim'\n            regressors_dims (OrderedDict): Configs of regressors with mode and index.\n        \"\"\"\n        super(TimeNet, self).__init__()\n        # General\n        self.n_forecasts = n_forecasts\n\n        # Bias\n        self.forecast_bias = new_param(dims=[self.n_forecasts])\n\n        # Trend\n        self.config_trend = config_trend\n        self.segmentwise_trend = self.config_trend.reg_lambda == 0\n        if self.config_trend.changepoints is None:\n            # create equidistant changepoint times, including zero.\n            linear_t = np.arange(self.config_trend.n_changepoints + 1).astype(float)\n            linear_t = linear_t \/ (self.config_trend.n_changepoints + 1)\n            self.config_trend.changepoints = self.config_trend.cp_range * linear_t\n        self.trend_changepoints_t = torch.tensor(self.config_trend.changepoints, requires_grad=False, dtype=torch.float)\n        self.trend_k0 = new_param(dims=[1])\n        self.trend_m0 = new_param(dims=[1])\n        if self.config_trend.n_changepoints > 0:\n            self.trend_deltas = new_param(dims=[self.config_trend.n_changepoints + 1])  # including first segment\n            if self.config_trend.growth == \"discontinuous\":\n                self.trend_m = new_param(dims=[self.config_trend.n_changepoints + 1])  # including first segment\n\n        # Seasonalities\n        self.season_dims = season_dims\n        self.season_mode = season_mode\n        if self.season_dims is not None:\n            if self.season_mode not in [\"additive\", \"multiplicative\"]:\n                raise NotImplementedError(\"Seasonality Mode {} not implemented\".format(self.season_mode))\n            self.season_params = nn.ParameterDict(\n                {name: new_param(dims=[dim]) for name, dim in self.season_dims.items()}\n            )\n            # self.season_params_vec = torch.cat([self.season_params[name] for name in self.season_params.keys()])\n\n        # Events\n        self.events_dims = events_dims\n        if self.events_dims is not None:\n            self.event_params = nn.ParameterDict({})\n            n_additive_event_params = 0\n            n_multiplicative_event_params = 0\n            for event, configs in self.events_dims.items():\n                if configs[\"mode\"] == \"additive\":\n                    n_additive_event_params += len(configs[\"event_indices\"])\n                else:\n                    n_multiplicative_event_params += len(configs[\"event_indices\"])\n\n            self.event_params[\"additive\"] = new_param(dims=[n_additive_event_params])\n            self.event_params[\"multiplicative\"] = new_param(dims=[n_multiplicative_event_params])\n        else:\n            self.event_params = None\n\n        ## Autoregression\n        self.n_lags = n_lags\n        self.num_hidden_layers = num_hidden_layers\n        self.d_hidden = n_lags + n_forecasts if d_hidden is None else d_hidden\n        if self.n_lags > 0:\n            self.ar_net = nn.ModuleList()\n            d_inputs = self.n_lags\n            for i in range(self.num_hidden_layers):\n                self.ar_net.append(nn.Linear(d_inputs, self.d_hidden, bias=True))\n                d_inputs = self.d_hidden\n            self.ar_net.append(nn.Linear(d_inputs, self.n_forecasts, bias=False))\n            for lay in self.ar_net:\n                nn.init.kaiming_normal_(lay.weight, mode=\"fan_in\")\n\n        ## Covariates\n        if covar_config is not None:\n            assert self.n_lags > 0\n            self.covar_nets = nn.ModuleDict({})\n            for covar in covar_config.keys():\n                covar_net = nn.ModuleList()\n                d_inputs = self.n_lags\n                if covar_config[covar].as_scalar:\n                    d_inputs = 1\n                for i in range(self.num_hidden_layers):\n                    covar_net.append(nn.Linear(d_inputs, self.d_hidden, bias=True))\n                    d_inputs = self.d_hidden\n                covar_net.append(nn.Linear(d_inputs, self.n_forecasts, bias=False))\n                for lay in covar_net:\n                    nn.init.kaiming_normal_(lay.weight, mode=\"fan_in\")\n                self.covar_nets[covar] = covar_net\n\n        ## Regressors\n        self.regressors_dims = regressors_dims\n","AFTER":"        config_trend=None,\n        config_season=None,\n        config_covar=None,\n        config_regressors=None,\n        config_events=None,\n        config_holidays=None,\n        n_forecasts=1,\n        n_lags=0,\n        num_hidden_layers=0,\n        d_hidden=None,\n    ):\n        \"\"\"\n        Args:\n            config_trend (configure.Trend):\n            config_season (configure.Season):\n            config_covar (OrderedDict):\n            config_regressors (OrderedDict): Configs of regressors with mode and index.\n            config_events (OrderedDict):\n            config_holidays (OrderedDict):\n            n_forecasts (int): number of steps to forecast. Aka number of model outputs.\n            n_lags (int): number of previous steps of time series used as input. Aka AR-order.\n                0 (default): no auto-regression\n            num_hidden_layers (int): number of hidden layers (for AR-Net)\n                0 (default): no hidden layers, corresponds to classic Auto-Regression\n            d_hidden (int): dimensionality of hidden layers  (for AR-Net). ignored if no hidden layers.\n                None (default): sets to n_lags + n_forecasts\n        \"\"\"\n        super(TimeNet, self).__init__()\n        # General\n        self.n_forecasts = n_forecasts\n\n        # Bias\n        self.forecast_bias = new_param(dims=[self.n_forecasts])\n\n        # Trend\n        self.config_trend = config_trend\n        self.segmentwise_trend = self.config_trend.reg_lambda == 0\n        if self.config_trend.changepoints is None:\n            # create equidistant changepoint times, including zero.\n            linear_t = np.arange(self.config_trend.n_changepoints + 1).astype(float)\n            linear_t = linear_t \/ (self.config_trend.n_changepoints + 1)\n            self.config_trend.changepoints = self.config_trend.cp_range * linear_t\n        self.trend_changepoints_t = torch.tensor(self.config_trend.changepoints, requires_grad=False, dtype=torch.float)\n        self.trend_k0 = new_param(dims=[1])\n        self.trend_m0 = new_param(dims=[1])\n        if self.config_trend.n_changepoints > 0:\n            self.trend_deltas = new_param(dims=[self.config_trend.n_changepoints + 1])  # including first segment\n            if self.config_trend.growth == \"discontinuous\":\n                self.trend_m = new_param(dims=[self.config_trend.n_changepoints + 1])  # including first segment\n\n        # Seasonalities\n        self.config_season = config_season\n        self.season_dims = season_config_to_model_dims(self.config_season)\n        if self.season_dims is not None:\n            if self.config_season.mode not in [\"additive\", \"multiplicative\"]:\n                log.error(\n                    \"Seasonality Mode {} not implemented. Defaulting to 'additive'.\".format(self.config_season.mode)\n                )\n                self.config_season.mode = \"additive\"\n            self.season_params = nn.ParameterDict(\n                {name: new_param(dims=[dim]) for name, dim in self.season_dims.items()}\n            )\n            # self.season_params_vec = torch.cat([self.season_params[name] for name in self.season_params.keys()])\n\n        # Events\n        self.events_dims = events_config_to_model_dims(config_events, config_holidays)\n        if self.events_dims is not None:\n            self.event_params = nn.ParameterDict({})\n            n_additive_event_params = 0\n            n_multiplicative_event_params = 0\n            for event, configs in self.events_dims.items():\n                if configs[\"mode\"] == \"additive\":\n                    n_additive_event_params += len(configs[\"event_indices\"])\n                else:\n                    n_multiplicative_event_params += len(configs[\"event_indices\"])\n            self.event_params[\"additive\"] = new_param(dims=[n_additive_event_params])\n            self.event_params[\"multiplicative\"] = new_param(dims=[n_multiplicative_event_params])\n        else:\n            self.event_params = None\n\n        # Autoregression\n        self.n_lags = n_lags\n        self.num_hidden_layers = num_hidden_layers\n        self.d_hidden = n_lags + n_forecasts if d_hidden is None else d_hidden\n        if self.n_lags > 0:\n            self.ar_net = nn.ModuleList()\n            d_inputs = self.n_lags\n            for i in range(self.num_hidden_layers):\n                self.ar_net.append(nn.Linear(d_inputs, self.d_hidden, bias=True))\n                d_inputs = self.d_hidden\n            self.ar_net.append(nn.Linear(d_inputs, self.n_forecasts, bias=False))\n            for lay in self.ar_net:\n                nn.init.kaiming_normal_(lay.weight, mode=\"fan_in\")\n\n        # Covariates\n        self.config_covar = config_covar\n        if self.config_covar is not None:\n            assert self.n_lags > 0\n            self.covar_nets = nn.ModuleDict({})\n            for covar in self.config_covar.keys():\n                covar_net = nn.ModuleList()\n                d_inputs = self.n_lags\n                if self.config_covar[covar].as_scalar:\n                    d_inputs = 1\n                for i in range(self.num_hidden_layers):\n                    covar_net.append(nn.Linear(d_inputs, self.d_hidden, bias=True))\n                    d_inputs = self.d_hidden\n                covar_net.append(nn.Linear(d_inputs, self.n_forecasts, bias=False))\n                for lay in covar_net:\n                    nn.init.kaiming_normal_(lay.weight, mode=\"fan_in\")\n                self.covar_nets[covar] = covar_net\n\n        ## Regressors\n        self.regressors_dims = regressors_config_to_model_dims(config_regressors)\n"}