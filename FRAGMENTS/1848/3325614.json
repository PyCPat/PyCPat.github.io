{"BEFORE":"        w = width\n        conv_out_dim = 64 * w\n        conv_layers = [\n            # at input: (96, 96) (assuming MAGICAL; for other domains it will\n            # be 84x84)\n            *conv_block(observation_space.shape[0], 32 * w, kernel_size=5, stride=1, padding=2),\n            # now: (96, 96)\n            *conv_block(32 * w, 64 * w, kernel_size=3, stride=2, padding=1),\n            # now: (48, 48)\n            *conv_block(64 * w, 64 * w, kernel_size=3, stride=2, padding=1),\n            # now: (24, 24)\n            *conv_block(64 * w, 64 * w, kernel_size=3, stride=2, padding=1),\n            # now: (12, 12)\n            *conv_block(64 * w, conv_out_dim, kernel_size=3, stride=2, padding=1),\n            # now (6,6)\n            nn.Flatten()\n        ]\n","AFTER":"        w = width\n        self.architecture_definition = NETWORK_ARCHITECTURE_DEFINITIONS['MAGICALCNN']\n        conv_layers = []\n        in_dim = observation_space.shape[0]\n        for i in range(len(self.architecture_definition)):\n            conv_layers += conv_block(in_dim,\n                                      self.architecture_definition[i]['out_dim']*w,\n                                      kernel_size=self.architecture_definition[i]['kernel_size'],\n                                      stride=self.architecture_definition[i]['stride'],\n                                      padding=self.architecture_definition[i]['padding'])\n            in_dim = self.architecture_definition[i]['out_dim']*w\n        conv_layers.append(nn.Flatten())\n"}