{"BEFORE":"        if isinstance(norm, int) and norm:\n            norm_name = 'cLN' if causal else 'gLN'\n        else:\n            norm_name = norm\n        \n        self.positional_encoding = PositionalEncoding(num_features, batch_first=False)\n        encoder_layer = nn.TransformerEncoderLayer(num_features, num_heads, d_ff, dropout=dropout, activation=nonlinear, layer_norm_eps=eps, batch_first=False, norm_first=norm_first)\n        layer_norm = LayerNormWrapper(norm_name, num_features, causal=causal, batch_first=False, eps=eps)\n","AFTER":"        if isinstance(norm, int):\n            if norm:\n                norm_name = 'cLN' if causal else 'gLN'\n                layer_norm = LayerNormWrapper(norm_name, num_features, causal=False, batch_first=False, eps=eps)\n            else:\n                layer_norm = None\n        else:\n            norm_name = norm\n            layer_norm = LayerNormWrapper(norm_name, num_features, causal=False, batch_first=False, eps=eps)\n        \n        self.positional_encoding = PositionalEncoding(num_features, batch_first=False)\n"}