{"BEFORE":"        for layer, params in network_structure:\n            if layer == 'linear':\n                self.operators.append(nn.Linear(current_layer_size, params))\n                current_layer_size = params\n\n            elif layer == 'relu':\n                assert params is None, 'No argument for ReLU please'\n                self.operators.append(nn.ReLU())\n            elif layer == 'gelu':\n                assert params is None, 'No argument for GeLU'\n","AFTER":"        self.operators = nn.ModuleList([\n            Flatten()\n        ])\n\n        current_layer_size = in_dim + action_dim\n\n        for layer, params in network_structure:\n            if layer == 'linear':\n                self.operators.append(nn.Linear(current_layer_size, params))\n                current_layer_size = params\n            elif layer == 'relu':\n                assert params is None, 'No argument for ReLU please'\n                self.operators.append(nn.ReLU())\n            elif layer == 'selu':\n                assert params is None, 'No argument for SeLU please'\n                self.operators.append(nn.SELU())\n            elif layer == 'tanh':\n                assert params is None, 'No argument for Tanh please'\n                self.operators.append(nn.Tanh())\n            elif layer == 'gelu':\n                assert params is None, 'No argument for GreLU please'\n"}