{"BEFORE":"        self.seq = nn.Sequential()\n        if kernel>=2:\n            self.seq.add_module('_pad', getattr(nn, pad.capitalize()+'Pad2d')(kernel\/\/2))\n        self.seq.add_module('_conv', nn.Conv2d(\n            in_ch, out_ch, kernel,\n            stride=1, padding=0,\n            bias=not bn,\n            **kwargs\n        ))\n        if bn:\n            self.seq.add_module('_bn', nn.BatchNorm2d(out_ch))\n        if act:\n            self.seq.add_module('_act', relu())\n","AFTER":"        bias='auto', norm=False, act=False, \n        **kwargs\n    ):\n        super().__init__()\n        seq = []\n        if kernel_size >= 2:\n            seq.append(getattr(nn, pad_mode.capitalize()+'Pad2d')(kernel_size\/\/2))\n        seq.append(\n            nn.Conv2d(\n                in_ch, out_ch, kernel_size,\n                stride=1, padding=0,\n                bias=(False if norm else True) if bias=='auto' else bias,\n                **kwargs\n            )\n        )\n        if norm:\n            if norm is True:\n                norm = make_norm(out_ch)\n            seq.append(norm)\n        if act:\n            if act is True:\n                act = make_act()\n            seq.append(act)\n        self.seq = nn.Sequential(*seq)\n"}