{"BEFORE":"    def __init__(self, in_dim, hidden_dim, n_classes):\n        super(Classifier, self).__init__()\n\n        self.layers = nn.ModuleList([\n            GCN(in_dim, hidden_dim, F.relu),\n            GCN(hidden_dim, hidden_dim, F.relu)])\n        self.classify = nn.Linear(hidden_dim, n_classes)\n","AFTER":"        self.vars = nn.ParameterList()\n        self.graph_conv = []\n\n        for i, (name, param) in enumerate(self.config):\n            if name is 'linear':\n                w = nn.Parameter(torch.ones(*param))\n                # gain=1 according to cbfinn's implementation\n                init.kaiming_normal_(w)\n                self.vars.append(w)\n                # [ch_out]\n                self.vars.append(nn.Parameter(torch.zeros(param[0])))\n            if name is 'GraphConv':\n                # param: in_dim, hidden_dim\n                w = nn.Parameter(torch.Tensor(param[0], param[1]))\n                init.xavier_uniform_(w)\n                self.vars.append(w)\n                self.vars.append(nn.Parameter(torch.zeros(param[1])))\n                self.graph_conv.append(GraphConv(param[0], param[1], activation = F.relu))\n       \n    def forward(self, g, vars = None):\n"}