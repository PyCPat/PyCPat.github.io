{"BEFORE":"        ix = 0\n\n        spans = []\n        for word_token in self.tokenize(text):\n            if word_token in ('``', \"''\"):\n                orig_idx = text.find(word_token, ix)\n                quote_idx = text.find('\"', ix)\n                if orig_idx < 0:\n                    real_token = '\"'\n                elif quote_idx < 0:\n                    real_token = word_token\n                elif orig_idx < quote_idx:\n                    real_token = word_token\n                else:\n                    real_token = '\"'\n            else:\n                real_token = word_token\n            ix = text.find(real_token, ix)\n            end = ix + len(real_token)\n            spans.append((ix, end))\n            ix = end\n\n        return spans\n","AFTER":"        raw_tokens = self.tokenize(text)\n\n        # Convert converted quotes back to original double quotes\n        # Do this only if original text contains double quote(s) or double\n        # single-quotes (because '' might be transformed to `` if it is\n        # treated as starting quotes).\n        if ('\"' in text) or (\"''\" in text):\n            # Find double quotes and converted quotes\n            matched = [m.group() for m in re.finditer(r\"``|'{2}|\\\"\", text)]\n            \n            # Replace converted quotes back to double quotes\n            tokens = [matched.pop(0) if tok in ['\"', \"``\", \"''\"] else tok for tok in raw_tokens]\n        else:\n            tokens = raw_tokens\n\n        return align_tokens(tokens, text)\n"}