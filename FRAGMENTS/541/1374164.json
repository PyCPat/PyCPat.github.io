{"BEFORE":"    def __init__(self, channels, kernel_size, output_units, leaky=0.0,\n                 output_fn=None):\n        \"\"\"\n        Constructor\n        :param channels: List of channels of conv layers, first entry is in_channels\n        :param kernel_size: List of kernel sizes, same for height and width\n        :param output_units: List of two ints\n        :param leaky: Leaky part of ReLU\n        :param output_fn: String, function to be applied to the output, either\n        None, \"sigmoid\", or \"clampexp\"\n        \"\"\"\n        super().__init__()\n        # Build network\n        net = nn.ModuleList([])\n        for i in range(len(kernel_size)):\n","AFTER":"    def __init__(self, channels, output_units, kernel_size=3, stride=1,\n                 leaky=0.0, output_fn=None):\n        \"\"\"\n        Constructor\n        :param channels: List of channels of conv layers, first entry is in_channels\n        :param kernel_size: Int of list of ints, same for height and width, if int\n        same kernel size for each layer is chosen\n        :param output_units: List of two ints\n        :param stride: Int or list of int, if int same stride for all layers is used\n        :param leaky: Leaky part of ReLU\n        :param output_fn: String, function to be applied to the output, either\n        None, \"sigmoid\", or \"clampexp\"\n        \"\"\"\n        super().__init__()\n        # Prepare parameters\n        n_layers = len(channels) - 1\n        if isinstance(stride, int):\n            stride = n_layers * [stride]\n        if isinstance(kernel_size, int):\n            kernel_size = n_layers * [kernel_size]\n        # Build network\n        net = nn.ModuleList([])\n        for i in range(n_layers):\n"}