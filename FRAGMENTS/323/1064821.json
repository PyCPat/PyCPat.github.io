{"BEFORE":"        probability = 1.0\n        MIN_PROB = IBMModel.MIN_PROB\n\n        def null_generation_term():\n            # Binomial distribution: B(m - null_fertility, p1)\n            value = 1.0\n            p1 = self.p1\n            p0 = 1 - p1\n            null_fertility = alignment_info.fertility_of_i(0)\n            m = len(alignment_info.trg_sentence) - 1\n            value *= (pow(p1, null_fertility) * pow(p0, m - 2 * null_fertility))\n            if value < MIN_PROB:\n                return MIN_PROB\n\n            # Combination: (m - null_fertility) choose null_fertility\n            for i in range(1, null_fertility + 1):\n                value *= (m - null_fertility - i + 1) \/ i\n            return value\n\n        def fertility_term():\n            value = 1.0\n            src_sentence = alignment_info.src_sentence\n            for i in range(1, len(src_sentence)):\n                fertility = alignment_info.fertility_of_i(i)\n                value *= (factorial(fertility) *\n                          self.fertility_table[fertility][src_sentence[i]])\n                if value < MIN_PROB:\n                    return MIN_PROB\n            return value\n\n        def lexical_translation_term(j):\n            t = alignment_info.trg_sentence[j]\n            i = alignment_info.alignment[j]\n            s = alignment_info.src_sentence[i]\n            return self.translation_table[t][s]\n\n        def distortion_term(j):\n            t = alignment_info.trg_sentence[j]\n            i = alignment_info.alignment[j]\n            if i == 0:\n                # case 1: t is aligned to NULL\n                return 1.0\n            if alignment_info.is_head_word(j):\n                # case 2: t is the first word of a tablet\n                previous_cept = alignment_info.previous_cept(j)\n                src_class = None\n                if previous_cept is not None:\n                    previous_s = alignment_info.src_sentence[previous_cept]\n                    src_class = self.src_classes[previous_s]\n                trg_class = self.trg_classes[t]\n                dj = j - alignment_info.center_of_cept(previous_cept)\n                return self.head_distortion_table[dj][src_class][trg_class]\n\n            # case 3: t is a subsequent word of a tablet\n            previous_position = alignment_info.previous_in_tablet(j)\n            trg_class = self.trg_classes[t]\n            dj = j - previous_position\n            return self.non_head_distortion_table[dj][trg_class]\n        # end nested functions\n\n        # Abort computation whenever probability falls below MIN_PROB at\n        # any point, since MIN_PROB can be considered as zero\n        probability *= null_generation_term()\n        if probability < MIN_PROB:\n            return MIN_PROB\n\n        probability *= fertility_term()\n        if probability < MIN_PROB:\n            return MIN_PROB\n\n        for j in range(1, len(alignment_info.trg_sentence)):\n            probability *= lexical_translation_term(j)\n            if probability < MIN_PROB:\n                return MIN_PROB\n\n            probability *= distortion_term(j)\n            if probability < MIN_PROB:\n                return MIN_PROB\n\n        return probability\n","AFTER":"        return IBMModel4.model4_prob_t_a_given_s(alignment_info, self)\n"}