{"BEFORE":"        dropout_cnn_out: float,\r\n        resnet: int,\r\n        pretrained_resnet: bool,\r\n    ):\r\n        super(EncoderCNN, self).__init__()\r\n        resnet: models.resnet.ResNet = get_resnet(resnet, pretrained_resnet)\r\n        original_modules: List[nn.Module] = list(resnet.children())[:-1]\r\n        modules: List[Union[nn.Module, nn.Dropout]] = []  # delete the last fc layer.\r\n\r\n        for layer_no, layer in enumerate(original_modules):\r\n            modules.append(layer)\r\n            if layer_no + 1 != len(original_modules):\r\n                modules.append(nn.Dropout(dropout_cnn))\r\n\r\n        self.resnet: nn.Module = nn.Sequential(*modules)\r\n\r\n        # if resnet.fc.in_features != embedded_size:\r\n        self.fc: nn.Linear = nn.Linear(resnet.fc.in_features, embedded_size)\r\n","AFTER":"        dropout_cnn_out: float,\r\n        cnn_model_name: str,\r\n        pretrained_cnn: bool,\r\n    ):\r\n        super(EncoderCNN, self).__init__()\r\n\r\n        self.cnn, self.cnn_output_size = get_cnn(\r\n            cnn_model_name=cnn_model_name, pretrained=pretrained_cnn\r\n        )\r\n\r\n        # if resnet.fc.in_features != embedded_size:\r\n        self.fc: nn.Linear = nn.Linear(self.cnn_output_size, embedded_size)\r\n"}