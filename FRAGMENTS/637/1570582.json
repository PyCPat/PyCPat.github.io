{"BEFORE":"        kwargs[\"batch_first\"] = True\n        self.ch = ch\n        self.freqs = freqs\n        io_size = ch * freqs\n        self.gru = nn.GRU(io_size, hidden_size, *args, **kwargs)\n        self.norm = nn.LayerNorm(hidden_size)\n        self.fc = nn.Linear(hidden_size, io_size)\n","AFTER":"        in_ch,\n        out_ch,\n        kernel,\n        fstride: int,\n        gru_dim: int,\n        gru_groups=1,\n        gru_mode: str = \"skip\",\n    ):\n        super().__init__()\n        self.conv = Conv2dNormAct(in_ch, out_ch, kernel_size=kernel, fstride=fstride)\n        assert gru_mode in (\"skip\", \"scale\")\n        if gru_mode == \"skip\":\n            skip = nn.Identity\n            scale = None\n        else:\n            skip = None\n            scale = nn.Sigmoid\n        self.gru = GruSE(out_ch, gru_dim, groups=gru_groups, skip=skip, scale_activation=scale)\n"}