{"BEFORE":"        raw_tokens = self.tokenize(text)\n\n        # Convert converted quotes back to original double quotes\n        # Do this only if original text contains double quote(s)\n        if '\"' in text:\n            # Find double quotes and converted quotes\n            matched = [m.group() for m in re.finditer(r'[(``)(\\'\\')(\")]+', text)]\n            \n            # Replace converted quotes back to double quotes\n            index = 0\n            tokens = []\n            for tok in raw_tokens:\n                if tok in ['\"', \"``\", \"''\"]:\n                    tokens.append(matched[index])\n                    index += 1\n                else:\n                    tokens.append(tok)\n        else:\n","AFTER":"        raw_tokens = self.tokenize(text)\n\n        # Convert converted quotes back to original double quotes\n        # Do this only if original text contains double quote(s)\n        if '\"' in text:\n            # Find double quotes and converted quotes\n            matched = [m.group() for m in re.finditer(r'[(``)(\\'\\')(\")]+', text)]\n            \n            # Replace converted quotes back to double quotes\n            tokens = [matched.pop(0) if tok in ['\"', \"``\", \"''\"] else tok for tok in raw_tokens]\n"}