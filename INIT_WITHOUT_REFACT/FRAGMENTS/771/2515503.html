<link rel="stylesheet" href="../default.css">
<script src="../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        else:
            raise ValueError(&quotThis similarity is not implemented.&quot)
        loss = list()
        <a id="change">for </a><a id="change">i</a> in range(batch_size)<a id="change">:
            </a>pos_index = labels == labels[i]
            pos_index[i] = 0
            neg_index = labels != labels[i]
            pos_pair_ = sim_mat[i][pos_index]
            neg_pair_<a id="change"> = </a><a id="change">sim_mat[i][neg_index]</a>

            alpha_p = torch.relu(-pos_pair_ + 1 + self.margin)
            alpha_n = torch.relu(neg_pair_ + self.margin)
            margin_p = 1 - self.margin
            margin_n = self.margin
            loss_p = torch.sum(torch.exp(-self.scale * alpha_p * (pos_pair_ - margin_p)))
            loss_n = torch.sum(torch.exp(self.scale * alpha_n * (neg_pair_ - margin_n)))
            <a id="change">loss.append(</a>torch.log(1 + loss_p * loss_n)<a id="change">)</a>

        loss = sum(loss) / batch_size
        return loss</code></pre><h3>After Change</h3><pre><code class='java'>
            f"feats.size(0): {feats.size(0)} is not equal to labels.size(0): {labels.size(0)}"

        m = labels.size(0)
        mask<a id="change"> = </a><a id="change">labels.expand(m, m).t().eq(labels.expand(m, m)).float()</a>
        pos_mask = mask.triu(diagonal=1)
        neg_mask = (mask<a id="change"> - </a>1).abs_().triu(diagonal=1)
        if self.similarity == &quotdot&quot:
            sim_mat = torch.matmul(feats, torch.t(feats))
        elif self.similarity == &quotcos&quot:
            feats = F.normalize(feats)
            sim_mat = feats.mm(feats.t())
        else:
            raise ValueError(&quotThis similarity is not implemented.&quot)

        pos_pair_<a id="change"> = </a>sim_mat[pos_mask == 1]
        neg_pair_<a id="change"> = </a>sim_mat[neg_mask == 1]

        alpha_p = torch.relu(-pos_pair_ + 1 + self.margin)
        alpha_n = torch.relu(neg_pair_ + self.margin)</code></pre>