{"BEFORE":"        alignments = torch.stack(alignments).transpose(0, 1)\n        outputs = torch.stack(outputs).transpose(0, 1).contiguous()\n        return outputs, alignments\n","AFTER":"        stop_tokens = []\n        t = 0\n        memory_input = initial_memory\n        while True:\n            if t > 0:\n                if greedy:\n                    memory_input = outputs[-1]\n                else:\n                    memory_input = memory[t-1]\n            # Prenet\n            processed_memory = self.prenet(memory_input)\n            # Attention RNN\n            attention_rnn_hidden, current_context_vec, alignment = self.attention_rnn(\n                processed_memory, current_context_vec, attention_rnn_hidden, inputs)\n            # Concat RNN output and attention context vector\n            decoder_input = self.project_to_decoder_in(\n                torch.cat((attention_rnn_hidden, current_context_vec), -1))\n            # Pass through the decoder RNNs\n            for idx in range(len(self.decoder_rnns)):\n                decoder_rnn_hiddens[idx] = self.decoder_rnns[idx](\n                    decoder_input, decoder_rnn_hiddens[idx])\n                # Residual connectinon\n                decoder_input = decoder_rnn_hiddens[idx] + decoder_input\n            output = decoder_input\n            # predict mel vectors from decoder vectors\n            output = self.proj_to_mel(output)\n            # predict stop token\n            stop_token = self.stopnet(output)\n            outputs += [output]\n            alignments += [alignment]\n            stop_tokens += stop_token\n            t += 1\n            if (not greedy and self.training) or (greedy and memory is not None):\n                if t >= T_decoder:\n                    break\n            else:\n                if t > 1 and is_end_of_frames(output.view(self.r, -1), alignment, self.eps):\n                    break\n                elif t > self.max_decoder_steps:\n                    print(\" !! Decoder stopped with 'max_decoder_steps'. \\\n                          Something is probably wrong.\")\n                    break\n        assert greedy or len(outputs) == T_decoder\n        # Back to batch first\n        alignments = torch.stack(alignments).transpose(0, 1)\n        outputs = torch.stack(outputs).transpose(0, 1).contiguous()\n        stop_tokens = torch.stack(stop_tokens).transpose(0, 1)\n        return outputs, alignments, stop_tokens\n"}