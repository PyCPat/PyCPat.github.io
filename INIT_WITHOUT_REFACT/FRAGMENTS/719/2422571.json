{"BEFORE":"                 observation_shape,\n                 hidden_units=None,\n                 use_batch_norm=False,\n                 use_dense=False,\n                 activation=torch.relu):\n        super().__init__()\n        self.observation_shape = observation_shape\n\n        if hidden_units is None:\n            hidden_units = [256, 256]\n\n        self.use_batch_norm = use_batch_norm\n        self.feature_size = hidden_units[-1]\n        self.activation = activation\n        self.use_dense = use_dense\n\n        in_units = [observation_shape[0]] + hidden_units[:-1]\n","AFTER":"                 observation_shape: Sequence[int],\n                 hidden_units: Optional[Sequence[int]] = None,\n                 use_batch_norm: bool = False,\n                 use_dense: bool = False,\n                 activation: Callable[[torch.Tensor],\n                                      torch.Tensor] = torch.relu):\n        super().__init__()\n        self._observation_shape = observation_shape\n\n        if hidden_units is None:\n            hidden_units = [256, 256]\n\n        self._use_batch_norm = use_batch_norm\n        self._feature_size = hidden_units[-1]\n        self._activation = activation  # type: ignore\n        self._use_dense = use_dense\n\n        in_units = [observation_shape[0]] + list(hidden_units[:-1])\n"}