{"BEFORE":"        output, attn = self.attention(\n            q, k, v, key_mask=key_mask, query_mask=query_mask, mapping_mask=mapping_mask)\n\n        output = output.view(n_head, sz_b, len_q, d_v)\n        output = (\n            output.permute(1, 2, 0, 3).contiguous().view(sz_b, len_q, -1)\n        )  # b x lq x (n*dv)\n\n        output = self.dropout(self.fc(output))\n        output = output + residual\n        # output = self.layer_norm(output)\n\n        if indivisual_attn:\n            attn = attn.view(n_head, sz_b, len_q, len_k)\n\n        return output, attn\n","AFTER":"    def forward(self, q, k, v, key_mask=None, query_mask=None, mapping_mask=None, indivisual_attn=False, attn_prior=None):\n\n        d_k, d_v, n_head = self.d_k, self.d_v, self.n_head\n\n        sz_b, len_q, _ = q.size()\n        sz_b, len_k, _ = k.size()\n        sz_b, len_v, _ = v.size()\n\n        residual = q\n\n        q = self.w_qs(q).view(sz_b, len_q, n_head, d_k)\n        k = self.w_ks(k).view(sz_b, len_k, n_head, d_k)\n        v = self.w_vs(v).view(sz_b, len_v, n_head, d_v)\n        q = q.permute(2, 0, 1, 3).contiguous().view(-1,\n                                                    len_q, d_k)  # (n*b) x lq x dk\n        k = k.permute(2, 0, 1, 3).contiguous().view(-1,\n                                                    len_k, d_k)  # (n*b) x lk x dk\n        v = v.permute(2, 0, 1, 3).contiguous().view(-1,\n                                                    len_v, d_v)  # (n*b) x lv x dv\n\n        if key_mask is not None:\n            key_mask = key_mask.repeat(n_head, 1, 1)  # (n*b) x .. x ..\n        if query_mask is not None:\n            query_mask = query_mask.repeat(n_head, 1, 1)  # (n*b) x .. x ..\n        if mapping_mask is not None:\n            mapping_mask = mapping_mask.repeat(n_head, 1, 1)  # (n*b) x .. x ..\n        if attn_prior is not None:\n            attn_prior = attn_prior.repeat(n_head, 1, 1)\n        output, attns, attn_logprob = self.attention(\n            q, k, v, key_mask=key_mask, query_mask=query_mask, mapping_mask=mapping_mask, attn_prior=attn_prior)\n\n        output = output.view(n_head, sz_b, len_q, d_v)\n        output = (\n            output.permute(1, 2, 0, 3).contiguous().view(sz_b, len_q, -1)\n        )  # b x lq x (n*dv)\n\n        output = self.dropout(self.fc(output))\n        output = output + residual\n        # output = self.layer_norm(output)\n\n        if indivisual_attn:\n            attns = tuple([attn.view(n_head, sz_b, len_q, len_k) for attn in attns])\n            attn_logprob = attn_logprob.view(n_head, sz_b, 1, len_q, len_k)\n\n        return output, attns, attn_logprob\n"}