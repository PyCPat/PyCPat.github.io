{"BEFORE":"        greedy = memory is None\n\n        if memory is not None:\n\n            # Grouping multiple frames if necessary\n            if memory.size(-1) == self.memory_dim:\n                memory = memory.view(B, memory.size(1) \/\/ self.r, -1)\n            assert memory.size(-1) == self.memory_dim * self.r,\\\n                \" !! Dimension mismatch {} vs {} * {}\".format(memory.size(-1),\n                                                         self.memory_dim, self.r)\n            T_decoder = memory.size(1)\n\n        # go frame - 0 frames tarting the sequence\n        initial_memory = Variable(\n            inputs.data.new(B, self.memory_dim * self.r).zero_())\n\n        # Init decoder states\n        attention_rnn_hidden = Variable(\n            inputs.data.new(B, 256).zero_())\n        decoder_rnn_hiddens = [Variable(\n            inputs.data.new(B, 256).zero_())\n            for _ in range(len(self.decoder_rnns))]\n        current_context_vec = Variable(\n            inputs.data.new(B, 256).zero_())\n\n        # Time first (T_decoder, B, memory_dim)\n        if memory is not None:\n            memory = memory.transpose(0, 1)\n\n        outputs = []\n        alignments = []\n\n        t = 0\n        memory_input = initial_memory\n        while True:\n            if t > 0:\n                memory_input = outputs[-1] if greedy else memory[t - 1]\n","AFTER":"        greedy = memory is None\n\n        if memory is not None:\n\n            # Grouping multiple frames if necessary\n            if memory.size(-1) == self.memory_dim:\n                memory = memory.view(B, memory.size(1) \/\/ self.r, -1)\n            assert memory.size(-1) == self.memory_dim * self.r,\\\n                \" !! Dimension mismatch {} vs {} * {}\".format(memory.size(-1),\n                                                         self.memory_dim, self.r)\n            T_decoder = memory.size(1)\n\n        # go frame - 0 frames tarting the sequence\n        initial_memory = Variable(\n            inputs.data.new(B, self.memory_dim * self.r).zero_())\n\n        # Init decoder states\n        attention_rnn_hidden = Variable(\n            inputs.data.new(B, 256).zero_())\n        decoder_rnn_hiddens = [Variable(\n            inputs.data.new(B, 256).zero_())\n            for _ in range(len(self.decoder_rnns))]\n        current_context_vec = Variable(\n            inputs.data.new(B, 256).zero_())\n\n        # Time first (T_decoder, B, memory_dim)\n        if memory is not None:\n            memory = memory.transpose(0, 1)\n\n        outputs = []\n        alignments = []\n\n        t = 0\n        memory_input = initial_memory\n        while True:\n            if t > 0:\n                # using harmonized teacher-forcing.\n                # from https:\/\/arxiv.org\/abs\/1707.06588\n                if greedy:\n                    memory_input = outputs[-1]\n                else:\n                    # combine prev. model output and prev. real target\n                    memory_input = torch.div(outputs[-1] + memory[t-1], 2.0)\n                    # add a random noise\n                    memory_input += torch.autograd.Variable(\n                        torch.randn(memory_input.size())).type_as(memory_input)\n\n            # Prenet\n            processed_memory = self.prenet(memory_input)\n"}