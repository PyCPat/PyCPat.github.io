<link rel="stylesheet" href="../default.css">
<script src="../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

    def forward(self, pred, target):
        log_prob = F.log_softmax(pred, dim=-1)
        dist = torch.empty_like(pred).fill_(self.smoothing / (<a id="change">pred.size(-1</a><a id="change">)</a> - 1))
        dist.scatter_(dim=-1, index=target[..., None], value=(1 - self.smoothing))
        loss = F.kl_div(log_prob, dist)
        <a id="change">return </a>loss
</code></pre><h3>After Change</h3><pre><code class='java'>
    def forward(self, pred: torch.Tensor, target: torch.Tensor, mask: torch.Tensor):
        pred = pred.flatten(0, 1)
        target = target.flatten(0, 1)
        mask = <a id="change">mask.flatten(</a>0, <a id="change">1</a><a id="change">)</a>.float()
        chunked_pred = torch.chunk(pred, chunks=self.chunk, dim=0)
        chunked_target = torch.chunk(target, chunks=self.chunk, dim=0)
        chunked_mask = torch.chunk(mask, chunks=self.chunk, dim=0)
        log_prob = [F.log_softmax(p, dim=-1) for p in chunked_pred]
        loss = [self.smoothed_loss(p, t, m)[None]\
            for p, t, m in zip(log_prob, chunked_target, chunked_mask)]
        loss = torch.cat(loss, dim=0).sum()
        <a id="change">return </a>loss / mask.sum()

    def smoothed_loss(self, log_prob: torch.Tensor, target: torch.Tensor, mask: torch.Tensor) -&gt; torch.Tensor:
        dist = torch.full_like(log_prob, fill_value=self.smoothing / (self.vocab - 2))</code></pre>