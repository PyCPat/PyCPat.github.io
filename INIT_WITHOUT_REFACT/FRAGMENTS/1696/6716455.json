{"BEFORE":"            dots.masked_fill_(~mask, float('-inf'))\n\n        mask = torch.ones(t, kv_len, **to(x)).triu_(diagonal = 1 + kv_len).bool()\n        dots.masked_fill_(mask[None, None, ...], float('-inf'))\n","AFTER":"        dots = torch.einsum('bhid,bhjd->bhij', q, k) * self.scale\n        mask_value = max_neg_value(dots)\n\n        if pos_emb is not None:\n            pos_dots = torch.einsum('bhid,hjd->bhij', q, pos_emb) * self.scale\n            pos_dots = shift(pos_dots)\n            dots = dots + pos_dots\n\n        if input_mask is not None:\n            mask = input_mask[:, None, :, None] * input_mask[:, None, None, :]\n            mask = F.pad(mask, (mem_len + cmem_len, 0), value = False)\n            dots.masked_fill_(~mask, mask_value)\n\n        mask = torch.ones(t, kv_len, **to(x)).triu_(diagonal = 1 + kv_len).bool()\n        dots.masked_fill_(mask[None, None, ...], mask_value)\n"}