{"BEFORE":"        p = p.view(bs, self.nA, self.nC + 5, nG, nG).permute(0, 1, 3, 4, 2).contiguous()  # prediction\n\n        if self.training:\n            return p\n\n        elif ONNX_EXPORT:\n            grid_xy = self.grid_xy.repeat((1, self.nA, 1, 1, 1)).view((1, -1, 2))\n            anchor_wh = self.anchor_wh.repeat((1, 1, nG, nG, 1)).view((1, -1, 2)) \/ nG\n\n            # p = p.view(-1, 5 + self.nC)\n            # xy = torch.sigmoid(p[..., 0:2]) + grid_xy[0]  # x, y\n            # wh = torch.exp(p[..., 2:4]) * anchor_wh[0]  # width, height\n            # p_conf = torch.sigmoid(p[:, 4:5])  # Conf\n            # p_cls = F.softmax(p[:, 5:85], 1) * p_conf  # SSD-like conf\n            # return torch.cat((xy \/ nG, wh, p_conf, p_cls), 1).t()\n\n            p = p.view(1, -1, 5 + self.nC)\n            xy = torch.sigmoid(p[..., 0:2]) + grid_xy  # x, y\n            wh = torch.exp(p[..., 2:4]) * anchor_wh  # width, height\n            p_conf = torch.sigmoid(p[..., 4:5])  # Conf\n            p_cls = p[..., 5:85]\n            # Broadcasting only supported on first dimension in CoreML. See onnx-coreml\/_operators.py\n            # p_cls = F.softmax(p_cls, 2) * p_conf  # SSD-like conf\n            p_cls = torch.exp(p_cls).permute((2, 1, 0))\n            p_cls = p_cls \/ p_cls.sum(0).unsqueeze(0) * p_conf.permute((2, 1, 0))  # F.softmax() equivalent\n            p_cls = p_cls.permute(2, 1, 0)\n            return torch.cat((xy \/ nG, wh, p_conf, p_cls), 2).squeeze().t()\n\n        else:  # inference\n            p[..., 0:2] = torch.sigmoid(p[..., 0:2]) + self.grid_xy  # xy\n            p[..., 2:4] = torch.exp(p[..., 2:4]) * self.anchor_wh  # wh yolo method\n            # p[..., 2:4] = ((torch.sigmoid(p[..., 2:4]) * 2) ** 2) * self.anchor_wh  # wh power method\n            p[..., 4] = torch.sigmoid(p[..., 4])  # p_conf\n            p[..., 5:] = torch.sigmoid(p[..., 5:])  # p_class\n            # p[..., 5:] = F.softmax(p[..., 5:], dim=4)  # p_class\n            p[..., :4] *= self.stride\n\n            # reshape from [1, 3, 13, 13, 85] to [1, 507, 85]\n            return p.view(bs, -1, 5 + self.nC)\n","AFTER":"        p = p.view(bs, self.nA, self.nC + 5, nG, nG).permute(0, 1, 3, 4, 2).contiguous()  # prediction\n\n        if self.training:\n            return p\n\n        elif ONNX_EXPORT:\n            grid_xy = self.grid_xy.repeat((1, self.nA, 1, 1, 1)).view((1, -1, 2))\n            anchor_wh = self.anchor_wh.repeat((1, 1, nG, nG, 1)).view((1, -1, 2)) \/ nG\n\n            # p = p.view(-1, 5 + self.nC)\n            # xy = torch.sigmoid(p[..., 0:2]) + grid_xy[0]  # x, y\n            # wh = torch.exp(p[..., 2:4]) * anchor_wh[0]  # width, height\n            # p_conf = torch.sigmoid(p[:, 4:5])  # Conf\n            # p_cls = F.softmax(p[:, 5:85], 1) * p_conf  # SSD-like conf\n            # return torch.cat((xy \/ nG, wh, p_conf, p_cls), 1).t()\n\n            p = p.view(1, -1, 5 + self.nC)\n            xy = torch.sigmoid(p[..., 0:2]) + grid_xy  # x, y\n            wh = torch.exp(p[..., 2:4]) * anchor_wh  # width, height\n            p_conf = torch.sigmoid(p[..., 4:5])  # Conf\n            p_cls = p[..., 5:85]\n            # Broadcasting only supported on first dimension in CoreML. See onnx-coreml\/_operators.py\n            # p_cls = F.softmax(p_cls, 2) * p_conf  # SSD-like conf\n            p_cls = torch.exp(p_cls).permute((2, 1, 0))\n            p_cls = p_cls \/ p_cls.sum(0).unsqueeze(0) * p_conf.permute((2, 1, 0))  # F.softmax() equivalent\n            p_cls = p_cls.permute(2, 1, 0)\n            return torch.cat((xy \/ nG, wh, p_conf, p_cls), 2).squeeze().t()\n\n        else:  # inference\n            io = p.clone()  # inference output\n            io[..., 0:2] = torch.sigmoid(io[..., 0:2]) + self.grid_xy  # xy\n            io[..., 2:4] = torch.exp(io[..., 2:4]) * self.anchor_wh  # wh yolo method\n            # io[..., 2:4] = ((torch.sigmoid(io[..., 2:4]) * 2) ** 2) * self.anchor_wh  # wh power method\n            io[..., 4:] = torch.sigmoid(io[..., 4:])  # p_conf, p_cls\n            # io[..., 5:] = F.softmax(io[..., 5:], dim=4)  # p_cls\n            io[..., :4] *= self.stride\n\n            # reshape from [1, 3, 13, 13, 85] to [1, 507, 85]\n            return io.view(bs, -1, 5 + self.nC), p\n"}