{"BEFORE":"        self.num_features = num_features\n        self.layers = nn.ModuleList()\n\n        for i in range(num_layers):\n            if i != num_layers - 1:\n                self.layers.append(\n                    GraphConvolution(num_features[i], num_features[i + 1], activation=activation, dropout=True))\n            else:\n                self.layers.append(GraphConvolution(num_features[i], num_features[i + 1]))\n\n    def forward(self, x, adj, dropout=0):\n","AFTER":"    def __init__(self, in_features, out_features, hidden_features, activation=F.relu, dropout=True):\n        super(GCN, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        if type(hidden_features) is int:\n            hidden_features = [hidden_features]\n\n        self.layers = nn.ModuleList()\n        self.layers.append(GCNConv(in_features, hidden_features[0], activation=activation, dropout=dropout))\n        for i in range(len(hidden_features) - 1):\n            self.layers.append(\n                GCNConv(hidden_features[i], hidden_features[i + 1], activation=activation, dropout=dropout))\n        self.layers.append(GCNConv(hidden_features[-1], out_features))\n        self.reset_parameters()\n"}