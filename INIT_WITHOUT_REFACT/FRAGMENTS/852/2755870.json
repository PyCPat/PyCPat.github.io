{"BEFORE":"        self.device = device\n        self.sd_version = sd_version\n\n        print(f'[INFO] loading stable diffusion...')\n        \n        if hf_key is not None:\n            print(f'[INFO] using hugging face custom model key: {hf_key}')\n            model_key = hf_key\n        elif self.sd_version == '2.1':\n            model_key = \"stabilityai\/stable-diffusion-2-1-base\"\n        elif self.sd_version == '2.0':\n            model_key = \"stabilityai\/stable-diffusion-2-base\"\n        elif self.sd_version == '1.5':\n            model_key = \"runwayml\/stable-diffusion-v1-5\"\n        else:\n            raise ValueError(f'Stable-diffusion version {self.sd_version} not supported.')\n\n        # Create model\n        if memory_saving_sd_config:\n            self.vae = AutoencoderKL.from_pretrained(model_key, subfolder=\"vae\", torch_dtype=torch.float16).to(self.device)\n            self.tokenizer = CLIPTokenizer.from_pretrained(model_key, subfolder=\"tokenizer\", torch_dtype=torch.float16)\n            self.text_encoder = CLIPTextModel.from_pretrained(model_key, subfolder=\"text_encoder\", torch_dtype=torch.float16).to(self.device)\n            self.unet = UNet2DConditionModel.from_pretrained(model_key, subfolder=\"unet\", torch_dtype=torch.float16).to(self.device)\n            self.unet.set_attention_slice(\"auto\")\n        else:\n            self.vae = AutoencoderKL.from_pretrained(model_key, subfolder=\"vae\").to(self.device)\n            self.tokenizer = CLIPTokenizer.from_pretrained(model_key, subfolder=\"tokenizer\")\n            self.text_encoder = CLIPTextModel.from_pretrained(model_key, subfolder=\"text_encoder\").to(self.device)\n            self.unet = UNet2DConditionModel.from_pretrained(model_key, subfolder=\"unet\").to(self.device)\n\n        if is_xformers_available():\n            self.unet.enable_xformers_memory_efficient_attention()\n        \n        self.scheduler = DDIMScheduler.from_pretrained(model_key, subfolder=\"scheduler\")\n","AFTER":"        if vram_O > 0:\n            pipe = StableDiffusionPipeline.from_pretrained(model_key, torch_dtype=torch.float16)\n            if vram_O > 1:\n                pipe.enable_sequential_cpu_offload()\n            pipe.enable_attention_slicing(1)\n            self.vae = pipe.vae\n            self.tokenizer = pipe.tokenizer\n            self.text_encoder = pipe.text_encoder\n            self.unet = pipe.unet\n            self.scheduler = DDIMScheduler.from_pretrained(model_key, subfolder=\"scheduler\", torch_dtype=torch.float16)\n        else:\n            self.vae = AutoencoderKL.from_pretrained(model_key, subfolder=\"vae\").to(self.device)\n            self.tokenizer = CLIPTokenizer.from_pretrained(model_key, subfolder=\"tokenizer\")\n            self.text_encoder = CLIPTextModel.from_pretrained(model_key, subfolder=\"text_encoder\").to(self.device)\n            self.unet = UNet2DConditionModel.from_pretrained(model_key, subfolder=\"unet\").to(self.device)\n            self.scheduler = DDIMScheduler.from_pretrained(model_key, subfolder=\"scheduler\")\n"}