{"BEFORE":"        chunk_size = frames_per_chunk * tokens_per_frame\n\n        for ind, q_chunk in enumerate(q.split(chunk_size, dim = 1)):\n\n            # slice the keys and values to the appropriate frames, accounting for padding along frames dimension\n\n            kv_start_pos = ind\n            kv_end_pos = kv_start_pos + (ind + frames_per_chunk + video_padding * 2)\n            kv_frame_range = slice(kv_start_pos, kv_end_pos)\n\n            k_slice, v_slice = map(lambda t: t[:, :, kv_frame_range], (k, v))\n\n            # slice causal mask to the appropriate query chunk windows - no padding need to be accounted for\n\n            mask_start_pos = ind * chunk_size\n            mask_end_pos = mask_start_pos + q_chunk.shape[1]\n            mask_range = slice(mask_start_pos, mask_end_pos)\n\n            causal_mask_slice = self.causal_mask[mask_range]\n","AFTER":"        chunk_size = frames_per_chunk * tokens_per_frame\n\n        q_chunks = q.split(chunk_size, dim = 1)\n\n        causal_mask = self.causal_mask[:(n - 1)]\n        causal_mask_chunks = causal_mask.split(chunk_size, dim = 0)\n\n        for ind, (q_chunk, causal_mask_chunk) in enumerate(zip(q_chunks, causal_mask_chunks)):\n"}