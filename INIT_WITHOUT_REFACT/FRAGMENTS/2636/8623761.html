<link rel="stylesheet" href="../default.css">
<script src="../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            alibi = build_alibi_tensor(hidden_states.shape[1], n_head=self.num_heads, dtype=hidden_states.dtype)
        &#47&#47 hidden_states: [batch_size, seq_length, hidden_size]
        &#47&#47 repeat alibi tensor with the batch size
        alibi = <a id="change">alibi.repeat(hidden_states.shape[0]</a>, <a id="change">1</a>, <a id="change">1</a><a id="change">)</a>.to(hidden_states.device)  &#47&#47 TODO eliminate cpu-gpu transfer!

        &#47&#47 apply preprocessing if the input is padded
        if attention_mask is not None and 0 in attention_mask:  &#47&#47 TODO REMOVE CUDA SYNC</code></pre><h3>After Change</h3><pre><code class='java'>
            alibi = pre_process_alibi_for_pad(alibi, attention_mask)
        &#47&#47 otherwise repeat alibi tensor with the batch size
        else:
            alibi = <a id="change">alibi.repeat(hidden_states.shape[0]</a>, <a id="change">1</a>, <a id="change">1</a><a id="change">)</a>

        mixed_x_layer = self.query_key_value(hidden_states)

        &#47&#47 [batch_size, seq_length, 3 x hidden_size] --&gt; [batch_size, seq_length, num_heads, 3 x head_dim]</code></pre>