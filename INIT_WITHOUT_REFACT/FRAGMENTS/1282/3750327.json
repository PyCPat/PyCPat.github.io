{"BEFORE":"        input0 = features[2]\n        h0 = torch.zeros(self.num_layers, input0.size(0),\n                         self.hidden_size).to(device)\n        c0 = torch.zeros(self.num_layers, input0.size(0),\n                         self.hidden_size).to(device)\n        out, _ = self.lstm(input0, (h0, c0))\n        out = self.attention_net(out)\n        out = self.fc(out[:, -1, :])\n        return out\n","AFTER":"        inp = features[0]\n        self.sequence_length = inp.size(1)\n        out, _ = self.lstm(inp)\n        out = self.attention_net(out, device)\n        out = self.fc1(out)\n        out = self.fc2(out)\n        return out, out\n"}