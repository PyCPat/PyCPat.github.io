{"BEFORE":"        sparse_emb_list = self.embedding_layer(data)\n        feature_emb = torch.stack(sparse_emb_list, dim=1).squeeze(2)\n","AFTER":"        feature_emb = self.embedding_layer(data)\n        senet_emb = self.senet_layer(feature_emb)\n        bilinear_p = self.bilinear_interaction(feature_emb)\n        bilinear_q = self.bilinear_interaction(senet_emb)\n        comb_out = torch.flatten(torch.cat([bilinear_p, bilinear_q], dim=1), start_dim=1)\n\n        dense_input = get_linear_input(self.enc_dict, data)\n        comb_out = torch.cat([comb_out, dense_input], dim=1)\n"}