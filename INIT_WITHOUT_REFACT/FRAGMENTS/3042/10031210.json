{"BEFORE":"        features = self.backbone(images.tensors)\n        if isinstance(features, torch.Tensor):\n            features = OrderedDict([(0, features)])\n\n        proposals= self.rpn(images, features, targets)\n        # Alex: RoI layer returns only detections\n        detections = self.roi_heads(features, proposals, images.image_sizes, targets)\n        # No need to postprocess detections\n        scores_covid_boxes = self.s2new(detections[0]['ranked_boxes'])\n        # Alex: update losses with predictions from each module\n        scores_covid_img = [dict(final_scores=scores_covid_boxes.squeeze_(0))]\n        return scores_covid_img\n","AFTER":"        original_image_sizes = [img.shape[-2:] for img in images]\n        images, targets = self.transform(images, targets)\n        features = self.backbone(images.tensors)\n        # Alex\n        # Segmentation step is the same as in torchvision\n        if self.model_type==\"segmentation\":\n           proposals, proposal_losses = self.rpn(images, features, targets)\n           detections, detector_losses = self.roi_heads(features, proposals, images.image_sizes, targets)\n           detections = self.transform.postprocess(detections, images.image_sizes, original_image_sizes)\n\n           losses = {}\n           losses.update(detector_losses)\n           losses.update(proposal_losses)\n\n           if self.training:\n              return losses\n\n           return detections\n        # Classification: compute only the loss in the S module\n        else:\n           proposals = self.rpn(images, features, targets)\n           detections = self.roi_heads(features, proposals, images.image_sizes, targets)\n           scores_covid_boxes = self.s2new(detections[0]['ranked_boxes'])\n           scores_covid_img = [dict(final_scores=scores_covid_boxes.squeeze_(0))]\n           return scores_covid_img\n"}