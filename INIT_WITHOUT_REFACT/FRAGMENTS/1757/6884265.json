{"BEFORE":"        return 0.\n","AFTER":"        x = self.categorical_embeds(x_categ)\n\n        for attn, ff in self.layers:\n            x = attn(x)\n            x = ff(x)\n\n        flat_categ = x.flatten(1)\n        normed_cont = self.norm(x_cont)\n\n        x = torch.cat((flat_categ, normed_cont), dim = -1)\n        return self.mlp(x)\n"}