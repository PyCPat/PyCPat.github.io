{"BEFORE":"        if \"encode_layer\" in self.custom_config[\"model_arch_args\"]:\n            encode_layer = self.custom_config[\"model_arch_args\"][\"encode_layer\"]\n            encoder_layer_dim = encode_layer.split(\"-\")\n            encoder_layer_dim = [int(i) for i in encoder_layer_dim]\n        else:  # default config\n            encoder_layer_dim = []\n            for i in range(self.custom_config[\"model_arch_args\"][\"fc_layer\"]):\n                out_dim = self.custom_config[\"model_arch_args\"][\"out_dim_fc_{}\".format(i)]\n                encoder_layer_dim.append(out_dim)\n\n        self.encoder_layer_dim = encoder_layer_dim\n        self.activation = model_config.get(\"fcnet_activation\")\n        self.obs_size = _get_size(obs_space)\n\n        # encoder\n        layers = []\n        if \"fc_layer\" in self.custom_config[\"model_arch_args\"]:\n            input_dim = self.obs_size\n            for out_dim in self.encoder_layer_dim:\n                layers.append(\n                    SlimFC(in_size=input_dim,\n                           out_size=out_dim,\n                           initializer=normc_initializer(1.0),\n                           activation_fn=self.activation))\n                input_dim = out_dim\n        elif \"conv_layer\" in self.custom_config[\"model_arch_args\"]:\n            input_dim = obs_space.shape[2]\n            for i in range(self.custom_config[\"model_arch_args\"][\"conv_layer\"]):\n                conv_f = nn.Conv2d(\n                    in_channels=input_dim,\n                    out_channels=self.custom_config[\"model_arch_args\"][\"out_channel_layer_{}\".format(i)],\n                    kernel_size=self.custom_config[\"model_arch_args\"][\"kernel_size_layer_{}\".format(i)],\n                    stride=self.custom_config[\"model_arch_args\"][\"stride_layer_{}\".format(i)],\n                    padding=self.custom_config[\"model_arch_args\"][\"padding_layer_{}\".format(i)],\n                )\n                relu_f = nn.ReLU()\n                pool_f = nn.MaxPool2d(kernel_size=self.custom_config[\"model_arch_args\"][\"pool_size_layer_{}\".format(i)])\n\n                layers.append(conv_f)\n                layers.append(relu_f)\n                layers.append(pool_f)\n\n                input_dim = self.custom_config[\"model_arch_args\"][\"out_channel_layer_{}\".format(i)]\n\n        else:\n            raise ValueError()\n\n        self.encoder = nn.Sequential(\n            *layers\n        )\n\n        self.hidden_state_size = self.custom_config[\"model_arch_args\"][\"hidden_state_size\"]\n        self.rnn = nn.GRUCell(input_dim, self.hidden_state_size)\n        self.q_value = nn.Linear(self.hidden_state_size, num_outputs)\n","AFTER":"        self.full_obs_space = getattr(obs_space, \"original_space\", obs_space)\n        self.n_agents = self.custom_config[\"num_agents\"]\n\n        # only support gru cell\n        if self.custom_config[\"model_arch_args\"][\"core_arch\"] != \"gru\":\n            raise ValueError(\n                \"core arch should be gru, got {}\".format(self.custom_config[\"model_arch_args\"][\"core_arch\"]))\n\n        self.activation = model_config.get(\"fcnet_activation\")\n\n        # encoder\n        layers = []\n        if \"fc_layer\" in self.custom_config[\"model_arch_args\"]:\n            if \"encode_layer\" in self.custom_config[\"model_arch_args\"]:\n                encode_layer = self.custom_config[\"model_arch_args\"][\"encode_layer\"]\n                encoder_layer_dim = encode_layer.split(\"-\")\n                encoder_layer_dim = [int(i) for i in encoder_layer_dim]\n            else:  # default config\n                encoder_layer_dim = []\n                for i in range(self.custom_config[\"model_arch_args\"][\"fc_layer\"]):\n                    out_dim = self.custom_config[\"model_arch_args\"][\"out_dim_fc_{}\".format(i)]\n                    encoder_layer_dim.append(out_dim)\n\n            self.encoder_layer_dim = encoder_layer_dim\n            self.obs_size = self.full_obs_space.shape[0]\n            input_dim = self.obs_size\n            for out_dim in self.encoder_layer_dim:\n                layers.append(\n                    SlimFC(in_size=input_dim,\n                           out_size=out_dim,\n                           initializer=normc_initializer(1.0),\n                           activation_fn=self.activation))\n                input_dim = out_dim\n        elif \"conv_layer\" in self.custom_config[\"model_arch_args\"]:\n            self.obs_size = self.full_obs_space.shape\n            input_dim = self.obs_size[2]\n            for i in range(self.custom_config[\"model_arch_args\"][\"conv_layer\"]):\n                layers.append(\n                    SlimConv2d(\n                        in_channels=input_dim,\n                        out_channels=self.custom_config[\"model_arch_args\"][\"out_channel_layer_{}\".format(i)],\n                        kernel=self.custom_config[\"model_arch_args\"][\"kernel_size_layer_{}\".format(i)],\n                        stride=self.custom_config[\"model_arch_args\"][\"stride_layer_{}\".format(i)],\n                        padding=self.custom_config[\"model_arch_args\"][\"padding_layer_{}\".format(i)],\n                        activation_fn=self.activation\n                    )\n                )\n                pool_f = nn.MaxPool2d(kernel_size=self.custom_config[\"model_arch_args\"][\"pool_size_layer_{}\".format(i)])\n                layers.append(pool_f)\n\n                input_dim = self.custom_config[\"model_arch_args\"][\"out_channel_layer_{}\".format(i)]\n\n        else:\n            raise ValueError()\n\n        self.encoder = nn.Sequential(\n            *layers\n        )\n\n        self.hidden_state_size = self.custom_config[\"model_arch_args\"][\"hidden_state_size\"]\n        self.rnn = nn.GRUCell(input_dim, self.hidden_state_size)\n        self.q_value = SlimFC(\n            in_size=self.hidden_state_size,\n            out_size=num_outputs,\n            initializer=normc_initializer(0.01),\n            activation_fn=None)\n"}