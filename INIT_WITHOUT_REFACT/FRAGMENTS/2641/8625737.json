{"BEFORE":"        lmem = default(lmem, lambda: torch.empty(b, 0, d, **to(x)))\n\n        mem_len, lmem_len = map(lambda t: t.shape[2], (mem, lmem))\n        total_len = mem_len + lmem_len + self.seq_len\n\n        pos_emb = self.pos_emb[:, (self.seq_len - t):total_len]\n\n        mem_iter = iterate_tensor(mem)\n\n        hiddens = []\n\n        for ind, (attn, ff) in enumerate(zip(self.attn_layers, self.ff_layers)):\n            layer_num = ind + 1\n            use_memory = layer_num in self.memory_layers\n            memories = next(mem_iter), lmem if use_memory else None\n","AFTER":"        lmem = default(lmem, lambda: torch.empty(b, 0, d, **to(x)))\n\n        mem_len, lmem_len = map(lambda t: t.shape[2], (mem, lmem))\n        total_len = mem_len + lmem_len + self.seq_len\n\n        pos_emb = self.pos_emb[:, (self.seq_len - t):total_len]\n\n        mem_iter = iterate_tensor(mem)\n\n        hiddens = []\n\n        for ind, (attn, ff) in enumerate(zip(self.attn_layers, self.ff_layers)):\n            layer_num = ind + 1\n            use_memory = layer_num in self.memory_layers\n            memories = (next(mem_iter), lmem) if use_memory else None\n"}