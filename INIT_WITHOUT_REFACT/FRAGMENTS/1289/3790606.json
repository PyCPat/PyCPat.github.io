{"BEFORE":"            output = decoder_input\n            output = self.proj_to_mel(output)\n\n            # Store predictions\n            mel_outputs += [output]\n            attn_scores += [attention_score]\n\n            if greedy:\n                if t > 1 and is_end_of_frames(output):\n                    break\n                elif t > self.max_decoder_steps:\n                    print(\"Warning! doesn't seems to be converged\")\n                    break\n            else:\n                if t >= T_decoder:\n                    break\n\n        # Validation check\n        assert greedy or len(mel_outputs) == T_decoder\n\n        # Back to batch first\n        attn_scores = torch.stack(attn_scores).transpose(0, 1)\n        mel_outputs = torch.stack(mel_outputs).transpose(0, 1).contiguous()\n\n        return mel_outputs, attn_scores\n","AFTER":"        mel_outputs, attn_scores, stop_tokens = [], [], []\n\n        # Run the decoder loop\n        t = 0\n        current_input = initial_input\n        while True:\n            if t > 0:\n                current_input = outputs[-1] if greedy else inputs[t - 1]\n            t += 1\n\n            # Prenet\n            current_input = self.prenet(current_input)\n\n            # Attention RNN\n            attention_rnn_hidden, attention_context, attention_score = self.attention_rnn(\n                current_input, attention_context, attention_rnn_hidden,\n                encoder_outputs, processed_memory=processed_memory, mask=mask)\n\n            # Concat RNN output and attention context vector\n            decoder_input = self.project_to_decoder_in(\n                torch.cat((attention_rnn_hidden, attention_context), -1))\n\n            # Pass through the decoder RNNs\n            for idx in range(len(self.decoder_rnns)):\n                decoder_rnn_hiddens[idx] = self.decoder_rnns[idx](\n                    decoder_input, decoder_rnn_hiddens[idx])\n                # Residual connectinon\n                decoder_input = decoder_rnn_hiddens[idx] + decoder_input\n            decoder_output = decoder_input\n\n            # Project to mel\n            output = self.mel_proj(decoder_output)\n\n            # Stop token prediction\n            stop = self.stop_proj(decoder_output)\n            stop = torch.sigmoid(stop)\n\n            # Store predictions\n            mel_outputs += [output]\n            attn_scores += [attention_score]\n            stop_tokens += [stop] * self.r\n\n            if greedy:\n                if t > 1 and is_end_of_frames(output):\n                    break\n                elif t > self.max_decoder_steps:\n                    print(\"Warning! doesn't seems to be converged\")\n                    break\n            else:\n                if t >= T_decoder:\n                    break\n\n        # Validation check\n        assert greedy or len(mel_outputs) == T_decoder\n\n        # Back to batch first\n        attn_scores = torch.stack(attn_scores).transpose(0, 1)\n        mel_outputs = torch.stack(mel_outputs).transpose(0, 1).contiguous()\n        stop_tokens = torch.stack(stop_tokens).transpose(0, 1).squeeze(2)\n\n        return mel_outputs, attn_scores, stop_tokens\n"}