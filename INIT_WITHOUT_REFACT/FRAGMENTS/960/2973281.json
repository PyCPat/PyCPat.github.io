{"BEFORE":"        q = q.view(b, c, -1).view(b, self.num_heads, -1, h * w)\n        k = k.view(b, c, -1).view(b, self.num_heads, -1, h * w)\n        v = v.view(b, c, -1).view(b, self.num_heads, -1, h * w)\n        q, k = F.normalize(q, dim=-1), F.normalize(k, dim=-1)\n\n        attn = torch.softmax(torch.matmul(q, k.transpose(-2, -1)) * self.temperature, dim=-1)\n        out = self.project_out(torch.matmul(attn, v).view(b, -1, h * w).view(b, -1, h, w))\n","AFTER":"        q = q.reshape(b, self.num_heads, -1, h * w)\n        k = k.reshape(b, self.num_heads, -1, h * w)\n        v = v.reshape(b, self.num_heads, -1, h * w)\n        q, k = F.normalize(q, dim=-1), F.normalize(k, dim=-1)\n\n        attn = torch.softmax(torch.matmul(q, k.transpose(-2, -1).contiguous()) * self.temperature, dim=-1)\n        out = self.project_out(torch.matmul(attn, v).reshape(b, -1, h, w))\n"}