{"BEFORE":"            node_encodings = box_features[counter: counter+n]\n            # Duplicate human nodes\n            h_node_encodings = node_encodings[:n_h]\n            # Get the pairwise index between every human and object instance\n            x, y = torch.meshgrid(\n                torch.arange(n_h, device=device),\n                torch.arange(n, device=device)\n            )\n            # Remove pairs consisting of the same human instance\n            x_keep, y_keep = torch.nonzero(x != y).unbind(1)\n            if len(x_keep) == 0:\n                # Should never happen, just to be safe\n                continue\n            # Human nodes have been duplicated and will be treated independently\n            # of the humans included amongst object nodes\n            x = x.flatten(); y = y.flatten()\n\n            adjacency_matrix = torch.ones(n_h, n, device=device)\n            for i in range(self.num_iter):\n                # Compute weights of each edge\n                weights = self.adjacency(torch.cat([\n                    h_node_encodings[x],\n                    node_encodings[y]\n                ], 1))\n                adjacency_matrix = weights.reshape(n_h, n)\n\n                # Update human nodes\n                h_node_encodings = self.sub_update(torch.cat([\n                    h_node_encodings,\n                    torch.mm(adjacency_matrix, self.obj_to_sub(node_encodings))\n                ], 1))\n\n                # Update object nodes (including human nodes)\n                node_encodings = self.obj_update(torch.cat([\n                    node_encodings,\n                    torch.mm(adjacency_matrix.t(), self.sub_to_obj(h_node_encodings))\n                ], 1))\n","AFTER":"            node_encodings = box_features[counter: counter+n]\n            # Duplicate human nodes\n            h_node_encodings = node_encodings[:n_h]\n            # Get the pairwise index between every human and object instance\n            x, y = torch.meshgrid(\n                torch.arange(n_h, device=device),\n                torch.arange(n, device=device)\n            )\n            # Remove pairs consisting of the same human instance\n            x_keep, y_keep = torch.nonzero(x != y).unbind(1)\n            if len(x_keep) == 0:\n                # Should never happen, just to be safe\n                continue\n            # Human nodes have been duplicated and will be treated independently\n            # of the humans included amongst object nodes\n            x = x.flatten(); y = y.flatten()\n\n            adjacency_matrix = torch.ones(n_h, n, device=device)\n            for i in range(self.num_iter):\n                # Compute weights of each edge\n                weights = self.adjacency(torch.cat([\n                    h_node_encodings[x],\n                    node_encodings[y]\n                ], 1))\n                adjacency_matrix = weights.reshape(n_h, n)\n\n                # Update human nodes\n                messages_to_h = F.relu(torch.mm(\n                    adjacency_matrix.softmax(dim=1),\n                    self.obj_to_sub(node_encodings)\n                ))\n                h_node_encodings = self.norm_h(\n                    h_node_encodings + messages_to_h\n                )\n\n                # Update object nodes (including human nodes)\n                messages_to_o = F.relu(torch.mm(\n                    adjacency_matrix.t().softmax(dim=1),\n                    self.sub_to_obj(h_node_encodings)\n                ))\n                node_encodings = self.norm_o(\n                    node_encodings + messages_to_o\n                )\n"}