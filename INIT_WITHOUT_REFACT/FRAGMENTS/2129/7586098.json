{"BEFORE":"        tokens = self.image_to_tokens(img)\n        n = tokens.shape[1]\n\n        pos_embs = self.pos_emb(torch.arange(n, device = device))\n        bottom_level = tokens + rearrange(pos_embs, 'n d -> () n d')\n        levels = repeat(self.init_levels, 'l d -> b n l d', b = b, n = n)\n\n        return tokens\n","AFTER":"    def forward(self, img, iters = None):\n        b, device = img.shape[0], img.device\n        iters = default(iters, self.levels * 2)   # need to have twice the number of levels of iterations in order for information to propagate up and back down. can be overridden\n\n        tokens = self.image_to_tokens(img)\n        n = tokens.shape[1]\n\n        pos_embs = self.pos_emb(torch.arange(n, device = device))\n        bottom_level = tokens + rearrange(pos_embs, 'n d -> () n d')\n        bottom_level = rearrange(bottom_level, 'b n d -> b n () d')\n\n        levels = repeat(self.init_levels, 'l d -> b n l d', b = b, n = n)\n\n        for _ in range(iters):\n            levels = torch.cat((bottom_level, levels), dim = -2)  # each iteration, attach original input (with positional embedding) at the bottom level\n\n            bottom_up_out = self.bottom_up(levels[..., :-1, :])\n            top_down_out = self.top_down(levels[..., 1:, :])\n\n            bottom_up_out = torch.cat((bottom_level, bottom_up_out), dim = -2)\n            top_down_out = F.pad(top_down_out, (0, 0, 0, 1), value = 0.)\n\n            consensus = self.attention(levels)\n\n            levels = torch.stack((levels, bottom_up_out, top_down_out, consensus)).mean(dim = 0) # hinton said to use the weighted mean of (1) bottom up (2) top down (3) previous level value {t - 1} (4) consensus value\n            levels = levels[..., 1:, :]  # excise out the bottom level\n\n        return levels\n"}