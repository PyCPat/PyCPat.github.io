{"BEFORE":"        pred_conf = torch.sigmoid(prediction[..., 5])\n        pred_cls = torch.sigmoid(prediction[..., 6:])\n\n        # grid.shape-> [1, 1, 52, 52, 1]\n        # 預測出來的(pred_x, pred_y)是相對於每個cell左上角的點，因此這邊需要由左上角往右下角配合grid_size加上對應的offset，畫出的圖才會在正確的位置上\n        grid_x = torch.arange(grid_size, device=device).repeat(grid_size, 1).view([1, 1, grid_size, grid_size])\n        grid_y = torch.arange(grid_size, device=device).repeat(grid_size, 1).t().view([1, 1, grid_size, grid_size])\n\n        # anchor.shape-> [1, 3, 1, 1, 1]\n        masked_anchors = torch.tensor(self.masked_anchors, device=device)\n        anchor_w = masked_anchors[:, 0].view([1, self.num_anchors, 1, 1])\n        anchor_h = masked_anchors[:, 1].view([1, self.num_anchors, 1, 1])\n        anchor_a = masked_anchors[:, 2].view([1, self.num_anchors, 1, 1])\n\n        # decode\n        pred_boxes = torch.empty((prediction[..., :5].shape), device=device)\n        pred_boxes[..., 0] = (pred_x + grid_x)\n        pred_boxes[..., 1] = (pred_y + grid_y)\n        pred_boxes[..., 2] = (torch.exp(pred_w) * anchor_w)\n        pred_boxes[..., 3] = (torch.exp(pred_h) * anchor_h)\n        pred_boxes[..., 4] = pred_a + anchor_a\n\n        output = torch.cat(\n            (\n                torch.cat([pred_boxes[..., :4] * self.stride, pred_boxes[..., 4:]], dim=-1).view(batch_size, -1, 5),\n                pred_conf.view(batch_size, -1, 1),\n                pred_cls.view(batch_size, -1, self.num_classes),\n            ),\n            -1,\n        )\n\n        if target is None:\n            return output, 0\n        else:\n            iou_scores, skew_iou, ciou_loss, class_mask, obj_mask, noobj_mask, ta, tcls, tconf = self.build_targets(\n                pred_boxes=pred_boxes, pred_cls=pred_cls, target=target, masked_anchors=masked_anchors\n            )\n            # --------------------\n            # - Calculating Loss -\n            # --------------------\n\n            # Reg Loss for bounding box prediction\n            iou_const = skew_iou[obj_mask]\n            angle_loss = F.smooth_l1_loss(pred_a[obj_mask], ta[obj_mask], reduction=\"none\")\n            reg_loss = angle_loss + ciou_loss[obj_mask]\n            with torch.no_grad():\n                reg_const = iou_const \/ reg_loss\n            reg_loss = (reg_loss * reg_const).mean()\n\n            # Focal Loss for object's prediction\n            FOCAL = FocalLoss(reduction=self.reduction)\n            conf_loss = (\n                    FOCAL(pred_conf[obj_mask], tconf[obj_mask])\n                    + FOCAL(pred_conf[noobj_mask], tconf[noobj_mask])\n            )\n\n            # Binary Cross Entropy Loss for class' prediction\n            cls_loss = F.binary_cross_entropy(pred_cls[obj_mask], tcls[obj_mask], reduction=self.reduction)\n","AFTER":"        pred_conf = torch.sigmoid(prediction[..., 5])\n        pred_cls = torch.sigmoid(prediction[..., 6:])\n\n        # grid.shape-> [1, 1, 52, 52, 1]\n        # 預測出來的(pred_x, pred_y)是相對於每個cell左上角的點，因此這邊需要由左上角往右下角配合grid_size加上對應的offset，畫出的圖才會在正確的位置上\n        grid_x = torch.arange(grid_size, device=device).repeat(grid_size, 1).view([1, 1, grid_size, grid_size])\n        grid_y = torch.arange(grid_size, device=device).repeat(grid_size, 1).t().view([1, 1, grid_size, grid_size])\n\n        # anchor.shape-> [1, 3, 1, 1, 1]\n        masked_anchors = torch.tensor(self.masked_anchors, device=device)\n        anchor_w = masked_anchors[:, 0].view([1, self.num_anchors, 1, 1])\n        anchor_h = masked_anchors[:, 1].view([1, self.num_anchors, 1, 1])\n        anchor_a = masked_anchors[:, 2].view([1, self.num_anchors, 1, 1])\n\n        # decode\n        pred_boxes = torch.empty((prediction[..., :5].shape), device=device)\n        pred_boxes[..., 0] = (pred_x + grid_x)\n        pred_boxes[..., 1] = (pred_y + grid_y)\n        pred_boxes[..., 2] = (torch.exp(pred_w) * anchor_w)\n        pred_boxes[..., 3] = (torch.exp(pred_h) * anchor_h)\n        pred_boxes[..., 4] = pred_a + anchor_a\n\n        output = torch.cat(\n            (\n                torch.cat([pred_boxes[..., :4] * self.stride, pred_boxes[..., 4:]], dim=-1).view(batch_size, -1, 5),\n                pred_conf.view(batch_size, -1, 1),\n                pred_cls.view(batch_size, -1, self.num_classes),\n            ),\n            -1,\n        )\n\n        if target is None:\n            return output, 0\n        else:\n            iou_scores, skew_iou, ciou_loss, class_mask, obj_mask, noobj_mask, ta, tcls, tconf = self.build_targets(\n                pred_boxes=pred_boxes, pred_cls=pred_cls, target=target, masked_anchors=masked_anchors\n            )\n            # --------------------\n            # - Calculating Loss -\n            # --------------------\n            reg_loss, conf_loss, cls_loss = torch.zeros(1, device=device), torch.zeros(1, device=device), torch.zeros(1, device=device)\n            FOCAL = FocalLoss(reduction=self.reduction)\n\n            if len(target) > 0:\n                # Reg Loss for bounding box prediction\n                iou_const = skew_iou[obj_mask]\n                angle_loss = F.smooth_l1_loss(pred_a[obj_mask], ta[obj_mask], reduction=\"none\")\n                reg_vector = angle_loss + ciou_loss[obj_mask]\n                with torch.no_grad():\n                    reg_magnitude = iou_const \/ reg_vector\n                reg_loss += (reg_magnitude * reg_vector).mean()\n\n                # Focal Loss for object's prediction\n                conf_loss += FOCAL(pred_conf[obj_mask], tconf[obj_mask])\n\n                # Binary Cross Entropy Loss for class' prediction\n                cls_loss += F.binary_cross_entropy(pred_cls[obj_mask], tcls[obj_mask], reduction=self.reduction)\n\n            conf_loss += FOCAL(pred_conf[noobj_mask], tconf[noobj_mask])\n"}