<link rel="stylesheet" href="../default.css">
<script src="../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                            batch_first=True, bidirectional=True)

    def forward(self, x, input_lengths):
        <a id="change">for conv</a> in self.convolutions<a id="change">:
            </a>x = F.dropout(F.relu(<a id="change">conv(</a>x<a id="change">)</a>), 0.5, self.training)

        x = x.transpose(1, 2)
        total_length = x.size(1)

        &#47&#47 pytorch tensor are not reversible, hence the conversion
        input_lengths = input_lengths.cpu().numpy()
        x<a id="change"> = </a>nn.utils.rnn.pack_padded_sequence(
            x, input_lengths, batch_first=True)

        self.lstm.flatten_parameters()</code></pre><h3>After Change</h3><pre><code class='java'>
    def forward(self, x):
        &#47&#47 transpose to (B, embed_dim, T) for convolution,
        &#47&#47 and then back
        x = <a id="change">self.conv1ds(x.transpose(1, 2)).transpose(1</a>, <a id="change">2</a><a id="change">)</a>

        &#47&#47 (B, T, conv_channels)
        &#47&#47 TODO: pack_padded, and pad_packed?
        self.lstm.flatten_parameters()</code></pre>