{"BEFORE":"        padding_mask: Optional[torch.Tensor] = None,\n    ) -> torch.Tensor:\n\n        seq_len = x.shape[1]  # Batch first = True\n\n        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n        x *= math.sqrt(self.d_model)\n        x += self.pos_encoding[:, :seq_len, :]\n        x = self.dropout(x)\n\n        # Batch first = True in decoder\n        for i in range(self.num_layers):\n            x = self.dec_layers[i](\n                tgt=x, memory=enc_output, tgt_mask=look_ahead_mask, memory_mask=padding_mask\n            )\n\n        # shape (batch_size, target_seq_len, d_model)\n        return x\n","AFTER":"        source_mask: Optional[torch.Tensor] = None,\n        target_mask: Optional[torch.Tensor] = None,\n    ) -> torch.Tensor:\n\n        tgt = self.embed(tgt) * math.sqrt(self.d_model)\n        pos_enc_tgt = self.positional_encoding(tgt)\n        output = pos_enc_tgt\n\n        for i in range(self.num_layers):\n            normed_output = self.layer_norm(output)\n            output = output + self.dropout(\n                self.attention[i](normed_output, normed_output, normed_output, target_mask)\n            )\n            normed_output = self.layer_norm(output)\n            output = output + self.dropout(\n                self.source_attention[i](normed_output, memory, memory, source_mask)\n            )\n            normed_output = self.layer_norm(output)\n            output = output + self.dropout(self.position_feed_forward[i](normed_output))\n\n        return self.layer_norm(output)\n"}