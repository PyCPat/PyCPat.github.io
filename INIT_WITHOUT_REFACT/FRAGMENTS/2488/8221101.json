{"BEFORE":"    batch_features = self.__cnn__(images) # (N, features_dim, block_num, block_num)\n    \n    conv_features = self.__img2embed_conv__(batch_features).permute(0, 2, 3, 1) # (N, block_num, block_num, embed_dim * 0.5)\n    apool = torch.mean(conv_features, dim = 1) # (N, block_num, embed_dim * 0.5)\n    mpool, _ = torch.max(conv_features, dim = 1) # (N, block_num, embed_dim * 0.5)\n\n    imgs_embed = torch.cat([apool, mpool], dim = 2) # (N, block_num, embed_dim)\n\n    words_embed = self.__content_embed__(input_ids) # (N, seq_len, embed_dim)\n    indices  = torch.arange(self.seq_len + self.block_num).expand(batch, -1).to(device)\n    position_embed = self.__position_embed__(indices)\n\n    h = self.__embed_drop__(torch.cat([imgs_embed, words_embed], dim = 1) + position_embed).to(device) # (N, seq_len + self.block_num, embed_dim)\n    for i in range(self.layer_num):\n        h = self.__hidden_layers__[i](h)[0]        \n        h[:, :self.block_num, :] = imgs_embed + position_embed[:, :self.block_num, :]\n\n    preds = self.__fc_layer__(self.dropout(self.__layer_norm__(h[:, self.block_num:, :]))) # (N, seg_len, vocab_dim)\n","AFTER":"  def forward(self, images, input_ids = None, tag_ids = None):\n    batch = images.shape[0] # (N)\n\n    \n    with torch.no_grad():\n      batch_features = self.__clip__.encode_image(images)\n      \n    #text_input = self.__get_text_input__(tag_ids)\n    #batch_texts = self.__clip__.encode_text(text_input)\n\n    #tags_embed = self.__text2embed__(self.__clip_drop__(batch_texts.float())).unsqueeze(1)\n    imgs_embed = self.__img2embed__(self.__clip_drop__(batch_features.float())).unsqueeze(1)\n\n    words_embed = self.__content_embed__(input_ids) \n    indices  = torch.arange(self.seq_len + self.tags_num + self.block_num).expand(batch, -1).to(device)\n    position_embed = self.__position_embed__(indices)\n\n    h = self.__embed_drop__(torch.cat([imgs_embed, words_embed], dim = 1) + position_embed).to(device) # (N, seq_len + self.block_num, embed_dim)\n    for i in range(self.layer_num):\n        h = self.__hidden_layers__[i](h)[0]        \n        h[:, :self.block_num, :] = imgs_embed + position_embed[:, :self.block_num, :]\n\n    preds = self.__fc_layer__(self.dropout(self.__layer_norm__(h[:, int(self.block_num + self.tags_num):, :]))) # (N, seg_len, vocab_dim)\n"}