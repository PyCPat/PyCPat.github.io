{"BEFORE":"        if not self.batch_first:\n            # (t, b, c, h, w) -> (b, t, c, h, w)\n            input_tensor = input_tensor.permute(1, 0, 2, 3, 4)\n\n        b, _, _, h, w = input_tensor.size()\n\n        # Implement stateful ConvLSTM\n        if hidden_state is not None:\n            raise NotImplementedError()\n        else:\n            # Since the init is done in forward. Can send image size here\n            hidden_state = self._init_hidden(batch_size=b, image_size=(h, w))\n\n        layer_output_list = []\n        last_state_list = []\n\n        seq_len = input_tensor.size(1)\n        cur_layer_input = input_tensor\n\n        for layer_idx in range(self.num_layers):\n\n            h, c = hidden_state[layer_idx]\n            output_inner = []\n            for t in range(seq_len):\n                h, c = self.cell_list[layer_idx](\n                    input_tensor=cur_layer_input[:, t, :, :, :], cur_state=[h, c]\n                )\n                output_inner.append(h)\n\n            layer_output = torch.stack(output_inner, dim=1)\n            cur_layer_input = layer_output\n\n            layer_output_list.append(layer_output)\n            last_state_list.append([h, c])\n\n        if not self.return_all_layers:\n            layer_output_list = layer_output_list[-1:]\n            last_state_list = last_state_list[-1:]\n\n        return layer_output_list, last_state_list\n","AFTER":"        cur_layer_input = torch.unbind(input, dim=int(self.batch_first))\n\n        if not hidden_state:\n            hidden_state = self.get_init_states(cur_layer_input[0].size(int(not self.batch_first)))\n\n        seq_len = len(cur_layer_input)\n\n        layer_output_list = []\n        last_state_list = []\n\n        for layer_idx in range(self.num_layers):\n            h, c = hidden_state[layer_idx]\n            output_inner = []\n            for t in range(seq_len):\n                h, c = self.cell_list[layer_idx](input=cur_layer_input[t], prev_state=[h, c])\n                output_inner.append(h)\n\n            cur_layer_input = output_inner\n            last_state_list.append((h, c))\n\n        layer_output = torch.stack(output_inner, dim=int(self.batch_first))\n\n        return layer_output, last_state_list\n"}