<link rel="stylesheet" href="../default.css">
<script src="../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    def __init__(self):
        super().__init__()
    def forward(self, x):
        <a id="change">return </a>x

class FastSelfAttention(nn.Module):
    def __init__(self):</code></pre><h3>After Change</h3><pre><code class='java'>
        q_kernel = softmax_kernel(q, projection_matrix, is_query = True)
        k_kernel = softmax_kernel(k, projection_matrix, is_query = False)

        context<a id="change"> = torch.einsum(&quot...nd,...ne-&gt;...de&quot</a>, k_kernel, v<a id="change">)</a>
        out<a id="change"> = </a><a id="change">torch.einsum(&quot...de,...nd-&gt;...ne&quot</a>, context, q_kernel<a id="change">)</a>

        <a id="change">return </a>out

class FastSelfAttention(nn.Module):
    def __init__(self, dim, heads = 8, nb_features = 256, redraw_projection = True):</code></pre>