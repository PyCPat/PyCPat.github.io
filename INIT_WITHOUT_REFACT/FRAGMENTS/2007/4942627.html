<link rel="stylesheet" href="../default.css">
<script src="../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            dilation: int = 1,
            norm_layer: Optional[Callable[..., nn.Module]] = None
    ) -&gt; None:
        <a id="change">super(</a>Bottleneck, self<a id="change">)</a>.__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        width = int(planes * (base_width / 64.)) * groups</code></pre><h3>After Change</h3><pre><code class='java'>
        super().__init__()
        width_ratio = out_channels / (widen_factor * 64.)
        D = cardinality * int(base_width * width_ratio)
        self.conv_reduce = <a id="change">nn.Conv2d(
            </a>in_channels, D<a id="change">, kernel_size=1, stride=1, padding=0, bias=False)</a>
        self.bn_reduce = nn.BatchNorm2d(D, momentum=0.001)
        self.conv_conv = nn.Conv2d(D, D,
                                   kernel_size=3, stride=stride, padding=1,
                                   groups=cardinality, bias=False)
        self.bn = nn.BatchNorm2d(D, momentum=0.001)
        self.act = mish
        self.conv_expand = nn.Conv2d(
            D, out_channels, kernel_size=1, stride=1, padding=0, bias=False)
        self.bn_expand = nn.BatchNorm2d(out_channels, momentum=0.001)

        self.shortcut = nn.Sequential()
        if in_channels != out_channels:
            self.shortcut.add_module(&quotshortcut_conv&quot,
                                     nn.Conv2d(in_channels, out_channels,
                                               kernel_size=1,
                                               stride=stride,
                                               padding=0,
                                               bias=False))
            self.shortcut.add_module(
                &quotshortcut_bn&quot, <a id="change">nn.BatchNorm2d(</a>out_channels<a id="change">, momentum=0.001)</a>)

    def forward(self, x):
        bottleneck = self.conv_reduce.forward(x)</code></pre>