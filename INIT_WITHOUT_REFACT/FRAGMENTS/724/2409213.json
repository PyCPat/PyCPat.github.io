{"BEFORE":"        all_boxes_h = []; all_boxes_o = []\n        all_labels = []; all_prior = []\n        all_box_pair_features = []\n        for b_idx, (coords, labels, scores) in enumerate(zip(box_coords, box_labels, box_scores)):\n            n = num_boxes[b_idx]\n            device = box_features.device\n\n            human_box_idx = torch.nonzero(labels == self.human_idx).squeeze(1).tolist()\n            n_h = len(human_box_idx)\n            # Skip image when there are no detected human or object instances\n            if n_h == 0 or n == 0:\n                continue\n            if n_h == n:\n                node_encodings = box_features[counter: counter+n]\n            else:\n                # Permute the boxes so that humans are on the top\n                permutation = torch.cat([\n                    torch.as_tensor(human_box_idx, device=device),\n                    torch.as_tensor([i for i in range(n) if i not in human_box_idx], device=device)\n                ])\n                coords = coords[permutation]\n                labels = labels[permutation]\n                scores = scores[permutation]\n                node_encodings = box_features[counter: counter+n][permutation]\n\n            # Duplicate human nodes\n            h_node_encodings = node_encodings[:n_h]\n            # Get the pairwise index between every human and object instance\n            x, y = torch.meshgrid(\n                torch.arange(n_h, device=device),\n                torch.arange(n, device=device)\n            )\n            # Remove pairs consisting of the same human instance\n            x_keep, y_keep = torch.nonzero(x != y).unbind(1)\n            # Human nodes have been duplicated and will be treated independently\n            # of the humans included amongst object nodes\n            x = x.flatten(); y = y.flatten()\n\n            for i in range(self.num_iter):\n                # Compute weights of each edge\n                weights = self.adjacency(torch.cat([\n                    h_node_encodings[x],\n                    node_encodings[y]\n                ], 1))\n                adjacency_matrix = weights.reshape(n_h, n)\n\n                # Update human nodes\n                h_node_encodings = self.sub_update(torch.cat([\n                    h_node_encodings,\n                    torch.mm(adjacency_matrix, self.obj_to_sub(node_encodings))\n                ], 1))\n\n                # Update object nodes (including human nodes)\n                node_encodings = self.obj_update(torch.cat([\n                    node_encodings,\n                    torch.mm(adjacency_matrix.t(), self.sub_to_obj(h_node_encodings))\n                ], 1))\n\n            if self.training:\n                all_labels.append(self.associate_with_ground_truth(\n                    coords[x_keep], coords[y_keep], targets[b_idx])\n                )\n                \n            all_box_pair_features.append(torch.cat([\n                h_node_encodings[x_keep], node_encodings[y_keep]\n            ], 1))\n            all_boxes_h.append(coords[x_keep])\n            all_boxes_o.append(coords[y_keep])\n            # The prior score is the product between edge weights and the\n            # pre-computed object detection scores with LIS\n            all_prior.append(\n                adjacency_matrix[x_keep, y_keep, None] *\n                self.compute_prior_scores(x_keep, y_keep, scores, labels)\n            )\n\n            counter += n\n\n        all_box_pair_features = torch.cat(all_box_pair_features)\n        all_prior = torch.cat(all_prior)\n\n        return all_box_pair_features, all_boxes_h, all_boxes_o, all_labels, all_prior\n","AFTER":"        all_boxes_h = []; all_boxes_o = []; all_object_class = []\n        all_labels = []; all_prior = []\n        all_box_pair_features = []\n        for b_idx, (coords, labels, scores) in enumerate(zip(box_coords, box_labels, box_scores)):\n            n = num_boxes[b_idx]\n            device = box_features.device\n\n            human_box_idx = torch.nonzero(labels == self.human_idx).squeeze(1).tolist()\n            n_h = len(human_box_idx)\n            # Skip image when there are no detected human or object instances\n            if n_h == 0 or n == 0:\n                continue\n            if n_h == n:\n                node_encodings = box_features[counter: counter+n]\n            else:\n                # Permute the boxes so that humans are on the top\n                permutation = torch.cat([\n                    torch.as_tensor(human_box_idx, device=device),\n                    torch.as_tensor([i for i in range(n) if i not in human_box_idx], device=device)\n                ])\n                coords = coords[permutation]\n                labels = labels[permutation]\n                scores = scores[permutation]\n                node_encodings = box_features[counter: counter+n][permutation]\n\n            # Duplicate human nodes\n            h_node_encodings = node_encodings[:n_h]\n            # Get the pairwise index between every human and object instance\n            x, y = torch.meshgrid(\n                torch.arange(n_h, device=device),\n                torch.arange(n, device=device)\n            )\n            # Remove pairs consisting of the same human instance\n            x_keep, y_keep = torch.nonzero(x != y).unbind(1)\n            # Human nodes have been duplicated and will be treated independently\n            # of the humans included amongst object nodes\n            x = x.flatten(); y = y.flatten()\n\n            for i in range(self.num_iter):\n                # Compute weights of each edge\n                weights = self.adjacency(torch.cat([\n                    h_node_encodings[x],\n                    node_encodings[y]\n                ], 1))\n                adjacency_matrix = weights.reshape(n_h, n)\n\n                # Update human nodes\n                h_node_encodings = self.sub_update(torch.cat([\n                    h_node_encodings,\n                    torch.mm(adjacency_matrix, self.obj_to_sub(node_encodings))\n                ], 1))\n\n                # Update object nodes (including human nodes)\n                node_encodings = self.obj_update(torch.cat([\n                    node_encodings,\n                    torch.mm(adjacency_matrix.t(), self.sub_to_obj(h_node_encodings))\n                ], 1))\n\n            if self.training:\n                all_labels.append(self.associate_with_ground_truth(\n                    coords[x_keep], coords[y_keep], targets[b_idx])\n                )\n                \n            all_box_pair_features.append(torch.cat([\n                h_node_encodings[x_keep], node_encodings[y_keep]\n            ], 1))\n            all_boxes_h.append(coords[x_keep])\n            all_boxes_o.append(coords[y_keep])\n            all_object_class.append(labels[y_keep])\n            # The prior score is the product between edge weights and the\n            # pre-computed object detection scores with LIS\n            all_prior.append(\n                adjacency_matrix[x_keep, y_keep, None] *\n                self.compute_prior_scores(x_keep, y_keep, scores, labels)\n            )\n\n            counter += n\n\n        all_box_pair_features = torch.cat(all_box_pair_features)\n        all_prior = torch.cat(all_prior)\n\n        return all_box_pair_features, all_boxes_h, all_boxes_o, all_object_class, all_labels, all_prior\n"}