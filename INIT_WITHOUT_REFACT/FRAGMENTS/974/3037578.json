{"BEFORE":"        self.hidden = self.init_hidden()\n\n        embed_out = self.embedding(x)\n        lstm_out, self.hidden = self.lstm(embed_out, self.hidden)\n        lstm_out = self.dropout(lstm_out)\n        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n","AFTER":"    def forward(self, x, x_len):\n        embed_out = self.dropout(self.embedding(x))\n\n        packed_embed_out = nn.utils.rnn.pack_padded_sequence(\n            embed_out, x_len, batch_first=True, enforce_sorted=False\n        )\n        _, (hidden, cell) = self.lstm(packed_embed_out)\n\n        hidden = self.dropout(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1))\n"}