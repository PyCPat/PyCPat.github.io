{"BEFORE":"        super(Decoder, self).__init__()\n\n        self.d_model = d_model\n        self.num_layers = num_layers\n\n        self.embedding = nn.Embedding(vocab_size + 3, d_model)  # 3 more classes EOS\/SOS\/PAD\n        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n\n        self.dec_layers = [\n            nn.TransformerDecoderLayer(\n                d_model=d_model,\n                nhead=num_heads,\n                dim_feedforward=dff,\n                dropout=dropout,\n                activation='relu',\n            ) for _ in range(num_layers)\n        ]\n","AFTER":"        super().__init__()\n\n        self.d_model = d_model\n        self.num_layers = num_layers\n\n        self.embedding = nn.Embedding(vocab_size + 3, d_model)  # 3 more classes EOS\/SOS\/PAD\n        self.register_buffer('pos_encoding', positional_encoding(maximum_position_encoding, d_model))\n\n        self.dec_layers = nn.ModuleList([\n            nn.TransformerDecoderLayer(\n                d_model=d_model,\n                nhead=num_heads,\n                dim_feedforward=dff,\n                dropout=dropout,\n                activation='relu',\n            ) for _ in range(num_layers)\n        ])\n"}