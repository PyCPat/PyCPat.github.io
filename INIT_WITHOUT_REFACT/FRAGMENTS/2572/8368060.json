{"BEFORE":"        u_hat = torch.einsum('ijk, jkl -> ijl', x, self.route_weights)\n\n        # Dynamic route\n        b = torch.zeros(x.shape[1], self.num_capsules, requires_grad=True)\n        for it in range(self.num_iterations):\n            c = b.softmax(dim=-1)\n\n            # Shape of s \/ v: (batch_size, num_capsules, out_channels)\n            s = torch.einsum('ijk, jl -> ilk', u_hat, c)\n            v = squash(s, dim=-1)\n\n            # Update b\n            if it < self.num_iterations - 1:\n                b = b + torch.einsum('ijk, ilk -> jl', u_hat, v)\n            else:\n                return v\n\n\nclass CapsNet(nn.Module):\n","AFTER":"        batch_size = x.shape[0]\n        # x: (batch_size, num_route_nodes, in_channels)\n        # route_weights: (num_route_nodes, num_capsules, in_channels, out_channels)\n        # u_hat: (batch_size, num_capsules, num_route_nodes, out_channels)\n        u_hat = torch.einsum('ijk, jlkm -> iljm', x, self.route_weights)\n        # Detatch u_hat during routing iterations\n        u_hat_temp = u_hat.detach()\n\n        # Dynamic route\n        # b: (batch_size, num_capsules, num_route_nodes)\n        b = torch.zeros(batch_size, self.num_capsules, self.num_route_nodes).to(device)\n        for it in range(self.num_iterations - 1):\n            c = b.softmax(dim=1)\n\n            # c: (batch_size, num_capsules, num_route_nodes)\n            # u_hat: (batch_size, num_capsules, num_route_nodes, out_channels)\n            # s: (batch_size, num_capsules, out_channels)\n            s = torch.einsum('ijk, ijkl -> ijl', c, u_hat_temp)\n            v = squash(s)\n\n            # Update b\n            # u_hat: (batch_size, num_capsules, num_route_nodes, out_channels)\n            # v: (batch_size, num_capsules, out_channels)\n            # Shape of b: (batch_size, num_capsules, num_route_nodes)\n            uv = torch.einsum('ijkl, ijl -> ijk', u_hat_temp, v)\n            b += uv\n\n        # Last iteration with original u_hat to pass gradient\n        c = b.softmax(dim=1)\n        s = torch.einsum('ijk, ijkl -> ijl', c, u_hat_temp)\n        v = squash(s)\n\n        return v\n"}