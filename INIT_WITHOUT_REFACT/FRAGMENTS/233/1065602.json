{"BEFORE":"        has_act = act_layer is not None\n        self.conv = nn.Conv1d(1, 1, kernel_size=kernel_size, padding=(kernel_size - 1) \/\/ 2, bias=has_act)\n        self.act = create_act_layer(act_layer) if has_act else nn.Identity()\n","AFTER":"            rd_ratio=1\/8, rd_channels=None, rd_divisor=8, use_mlp=False):\n        super(EcaModule, self).__init__()\n        if channels is not None:\n            t = int(abs(math.log(channels, 2) + beta) \/ gamma)\n            kernel_size = max(t if t % 2 else t + 1, 3)\n        assert kernel_size % 2 == 1\n        padding = (kernel_size - 1) \/\/ 2\n        if use_mlp:\n            # NOTE 'mlp' mode is a timm experiment, not in paper\n            assert channels is not None\n            if rd_channels is None:\n                rd_channels = make_divisible(channels * rd_ratio, divisor=rd_divisor)\n            act_layer = act_layer or nn.ReLU\n            self.conv = nn.Conv1d(1, rd_channels, kernel_size=1, padding=0, bias=True)\n            self.act = create_act_layer(act_layer)\n            self.conv2 = nn.Conv1d(rd_channels, 1, kernel_size=kernel_size, padding=padding, bias=True)\n        else:\n            self.conv = nn.Conv1d(1, 1, kernel_size=kernel_size, padding=padding, bias=False)\n            self.act = None\n            self.conv2 = None\n        self.gate = create_act_layer(gate_layer)\n"}