{"BEFORE":"        blocks = self.blocks\n        block_args = route_args(self.args_route, kwargs, len(self.blocks))\n\n        if self.training and self.layer_dropout > 0:\n            to_drop = torch.empty(len(self.blocks)).uniform_(0, 1) < self.layer_dropout\n            blocks = [block for block, drop in zip(self.blocks, to_drop) if not drop]\n            blocks = self.blocks[:1] if len(blocks) == 0 else blocks\n\n        block_args = list(map(lambda x: {'f_args': x[0], 'g_args': x[1]}, block_args))\n        return _ReversibleFunction.apply(x, blocks, block_args)\n","AFTER":"        x = torch.cat([x, x], dim=-1)\n\n        blocks = self.blocks\n        args = route_args(self.args_route, kwargs, len(blocks))\n        args = list(map(lambda x: {'f_args': x[0], 'g_args': x[1]}, args))\n\n        layers_and_args = list(zip(blocks, args))\n\n        if self.training and self.layer_dropout > 0:\n            layers_and_args = layer_drop(layers_and_args, self.layer_dropout)\n            blocks, args = map(lambda ind: list(map(itemgetter(ind), layers_and_args)), (0, 1))\n\n        out =  _ReversibleFunction.apply(x, blocks, args)\n        return torch.stack(out.chunk(2, dim=-1)).sum(dim=0)\n"}