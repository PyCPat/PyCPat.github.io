{"BEFORE":"        assert mols_per_minibatch == self.args.minibatch_size, \\\n            f\"calculated minibatch size: {mols_per_minibatch}, given in args: {self.args.minibatch_size}\"\n\n        encodings = encodings * seq_masks                           # mask out padding\n        encodings = torch.reshape(encodings,                        # [t, N * K, h] => [t, N, K, h]\n                                  [self.args.max_seq_len,\n                                   batch_size,\n                                   self.args.minibatch_size,\n                                   self.hidden_size])\n        batch_lens = torch.reshape(batch_lens,                      # [N * K] => [N, K, 1]\n                                   [batch_size,\n                                    self.args.minibatch_size, 1])\n","AFTER":"        batch, phase = batch\n        batch_token_ids, batch_lens, batch_size = batch             # [N * K, t], [N * K]\n        enc_in = batch_token_ids.transpose(0, 1).unsqueeze(-1)      # [N * K, t] => [t, N * K, 1]\n        # logging.info(\"---------------------batch_token_ids-------------------\")\n        # logging.info(batch_token_ids.shape)\n        # logging.info(\"---------------------end_in-------------------\")\n        # logging.info(enc_in.shape)\n        # logging.info(\"---------------------batch_lens-------------------\")\n        # logging.info(batch_lens)\n        # logging.info(batch_lens.shape)\n        lengths = torch.tensor([self.args.max_seq_len] * batch_lens.shape[0],\n                               dtype=torch.long,\n                               device=batch_lens.device)\n\n        _, encodings, _ = self.encoder(src=enc_in,\n                                       lengths=lengths)             # [t, N * K, h]\n        seq_masks = sequence_mask(                                  # [N * K] => [t, N * K]\n            batch_lens, maxlen=self.args.max_seq_len)\n        seq_masks = seq_masks.unsqueeze(-1)                         # [t, N * K] => [t, N * K, 1]\n\n        mols_per_minibatch = encodings.shape[1] \/ batch_size\n        # TODO: for multi-GPU training, mols_per_minibatch == self.args.minibatch_size \/\/ torch.cuda.device_count()\n        # assert mols_per_minibatch == self.args.minibatch_size, \\\n        #     f\"calculated minibatch size: {mols_per_minibatch}, given in args: {self.args.minibatch_size}\"\n\n        encodings = encodings * seq_masks                           # mask out padding\n        # TODO: 3rd dim needs to switch between args.minibatch_size & args.minibatch_eval depending on phase\n        if phase == 'train':\n            encodings = torch.reshape(encodings,                        # [t, N * K, h] => [t, N, K, h]\n                                    [self.args.max_seq_len,\n                                    -1, # batch_size\n                                    self.args.minibatch_size,\n                                    self.hidden_size])\n            batch_lens = torch.reshape(batch_lens,                      # [N * K] => [N, K, 1]\n                                    [-1, #batch_size,\n                                    self.args.minibatch_size, 1])\n        else:\n            encodings = torch.reshape(encodings,                        # [t, N * K, h] => [t, N, K, h]\n                                    [self.args.max_seq_len,\n                                    -1, # batch_size\n                                    self.args.minibatch_eval,\n                                    self.hidden_size])\n            batch_lens = torch.reshape(batch_lens,                      # [N * K] => [N, K, 1]\n                                    [-1, #batch_size,\n                                    self.args.minibatch_eval, 1])\n\n        if self.pooling_method == \"CLS\":                            # [t, N, K, h] => [N, K, h]\n            pooled_encoding = encodings[0, :, :, :]\n        elif self.pooling_method == \"mean\":\n            pooled_encoding = torch.sum(encodings, dim=0, keepdim=False)\n            pooled_encoding = pooled_encoding \/ batch_lens\n        else:\n            raise ValueError(f\"Unsupported pooling method: {self.pooling_method}\")\n\n        energies = self.output(pooled_encoding)                     # [N, K, h] => [N, K, 1]\n        del pooled_encoding, encodings, seq_masks, batch_token_ids\n"}