{"BEFORE":"        x_pos = Variable(x_pos.unsqueeze(0).repeat(batch_size, 1, 1), requires_grad=False)\n        if self.use_cuda:\n            x_pos.cuda()\n        x_input = x_emb + x_pos\n","AFTER":"        batch_size = x.shape[0]\n        x_len = x.shape[1]\n        x_pos = self.pos_emb(torch.arange(x_len).type(torch.cuda.FloatTensor if self.use_cuda else torch.FloatTensor)) # len x n_state\n        x_pos = Variable(x_pos.unsqueeze(0).repeat(batch_size, 1, 1), requires_grad=False).cuda() if self.use_cuda else Variable(x_pos.unsqueeze(0).repeat(batch_size, 1, 1), requires_grad=False)\n"}