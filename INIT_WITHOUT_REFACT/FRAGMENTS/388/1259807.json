{"BEFORE":"    def __init__(self, n_e, e_dim, beta):\n        super(VectorQuantizer, self).__init__()\n","AFTER":"    def __init__(self, n_e, e_dim, beta, remap=None, unknown_index=\"random\",\n                 sane_index_shape=False, legacy=True):\n        super().__init__()\n        self.n_e = n_e\n        self.e_dim = e_dim\n        self.beta = beta\n        self.legacy = legacy\n\n        self.embedding = nn.Embedding(self.n_e, self.e_dim)\n        self.embedding.weight.data.uniform_(-1.0 \/ self.n_e, 1.0 \/ self.n_e)\n\n        self.remap = remap\n        if self.remap is not None:\n            self.register_buffer(\"used\", torch.tensor(np.load(self.remap)))\n            self.re_embed = self.used.shape[0]\n            self.unknown_index = unknown_index # \"random\" or \"extra\" or integer\n            if self.unknown_index == \"extra\":\n                self.unknown_index = self.re_embed\n                self.re_embed = self.re_embed+1\n            print(f\"Remapping {self.n_e} indices to {self.re_embed} indices. \"\n                  f\"Using {self.unknown_index} for unknown indices.\")\n        else:\n            self.re_embed = n_e\n\n        self.sane_index_shape = sane_index_shape\n"}