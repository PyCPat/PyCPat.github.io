{"BEFORE":"            nn.Linear(args.head_latent_size, nce_logits_output_size),\n            nn.BatchNorm1d(nce_logits_output_size)\n","AFTER":"                 total_training_steps,\n                 base_decay=0.996):\n        \"\"\"BYOL model.\n\n        :param base_network_output_size: output-size of resnet50 embedding\n        :param projection_output_size: output size of projection and prediction heads\n        :param classifier_output_size: number of classes in classifier problem\n        :param total_training_steps: total steps for a single training epoch\n        :param base_decay: the decay for the target network\n        :returns: BYOL object\n        :rtype: nn.Module\n\n        \"\"\"\n        super(BYOL, self).__init__()\n        self.base_network_output_size = base_network_output_size\n\n        # The base network, head network and predictor used for the self-supervised objective\n        model_fn = models.__dict__[args.arch]\n        self.base_network = nn.Sequential(\n            *list(model_fn(pretrained=False).children())[:-1]  # No dense projection\n        )\n        self.head = nn.Sequential(\n            nn.Linear(base_network_output_size, args.head_latent_size),\n            nn.BatchNorm1d(args.head_latent_size),\n            nn.ReLU(),\n            nn.Linear(args.head_latent_size, projection_output_size),\n        )\n        self.predictor = nn.Sequential(\n            nn.Linear(projection_output_size, args.head_latent_size),\n            nn.BatchNorm1d(args.head_latent_size),\n            nn.ReLU(),\n            nn.Linear(args.head_latent_size, projection_output_size),\n        )\n\n        # The linear classifer head which we will stop-grad to\n        self.linear_classifier = nn.Linear(base_network_output_size, classifier_output_size)\n\n        # Initialize the target network.\n        self.target_network = CosEMA(total_training_steps, base_decay)\n        self.target_network(nn.utils.parameters_to_vector(self.parameters()))\n"}