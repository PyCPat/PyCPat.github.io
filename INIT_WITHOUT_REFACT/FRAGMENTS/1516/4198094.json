{"BEFORE":"        self.block_sizes = [*range(1, max_block_size + 1)]\n        self.block_pad_multiple = lcm(*self.block_sizes)\n","AFTER":"        assert exists(max_block_size) ^ exists(blocks), 'either max_block_size or blocks are given on initialization'\n        self.token_emb = nn.Embedding(num_tokens, dim)\n\n        if exists(blocks):\n            assert isinstance(blocks, tuple), 'blocks must be a tuple of block sizes'\n            self.blocks = tuple(map(lambda el: el if isinstance(el, tuple) else (el, 0), blocks))\n            assert all([(offset < block_size) for block_size, offset in self.blocks]), 'offset must be always smaller than the block size'\n\n            max_block_size = max(list(map(lambda t: t[0], self.blocks)))\n        else:\n            self.blocks = tuple(map(lambda el: (el, 0), range(1, max_block_size + 1)))\n\n        self.pos_conv = nn.Sequential(\n            Pad((0, 0, 0, max_block_size - 1)),\n            Rearrange('b n d -> b d n'),\n            DepthwiseConv1d(dim, dim, kernel_size = max_block_size),\n            Rearrange('b d n -> b n d')\n        )\n\n        self.score_fn = nn.Sequential(\n            nn.Linear(dim, 1),\n            Rearrange('... () -> ...')\n        )\n\n        self.score_consensus_attn = score_consensus_attn\n\n        assert downsample_factor <= max_block_size, 'final downsample factor should be less than the maximum block size'\n\n        self.block_pad_multiple = lcm(*[block_size for block_size, _ in self.blocks])\n"}