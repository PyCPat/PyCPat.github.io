{"BEFORE":"    def __init__(self, input_shape=32, output_shape=8, dataset=None, mode=None, sa_num=None, width_mult=1.0, type='D', alpha_value=2.19):\n        super(VGG, self).__init__()\n        self.dataset = dataset\n        self.mode = mode\n        self.sa_num = sa_num\n        self.input_shape = input_shape\n        self.shape_list = []\n        self.alpha_value = alpha_value\n        self.filter = {\n            'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512],\n            'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512],\n            'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512],\n            'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512],\n        }\n\n        self.filter[type] = [int(i * width_mult) if i != 'M' else i for i in self.filter[type]][:-1] + [512]\n\n        # define VGG-19 feature extractor layers\n        if self.input_shape > 64:\n            self.filter[type].append('M')\n        layers = []\n        channel_in = 3  # input RGB images\n        self.features = nn.ModuleList()\n        for ch in self.filter[type]:\n            if ch == 'M':\n                # AutoSC mode is built on original network with *along with* the network shape\n                if 'human' in self.mode or self.mode == 'autosc':\n                    layers += [nn.MaxPool2d(2, 2)]\n            else:\n                # Standard mode is built on the original network *without* the network shape\n                layers += [nn.Conv2d(channel_in, ch, kernel_size=3, padding=1),\n                           nn.BatchNorm2d(ch),\n                           nn.ReLU(inplace=True)]\n                channel_in = ch\n        self.features = nn.Sequential(*layers)\n\n        # Define two types of shape adaptor modes:\n        if self.mode == 'shape-adaptor':\n            ShapeAdaptor.type = 'local'\n            self.max_pool = nn.MaxPool2d(2, 2)  # max-pool is considered as the down-sample branch.\n            # We don't apply shape adaptor at the last layer, thus \"-3\".\n            self.sampling_index_full = [i for i in range(len(self.features)-3) if isinstance(self.features[i], nn.ReLU)]\n            if self.sa_num is None:\n                # Automatically define optimal number of shape adaptors.\n                self.sa_num = int(np.log2(self.input_shape \/ 2))\n\n            # Compute the gap between layers for each shape adaptor\n            index_gap = len(self.sampling_index_full) \/ self.sa_num\n            self.sampling_index = [self.sampling_index_full[int(i * index_gap)] for i in range(self.sa_num)]\n\n        elif self.mode == 'autosc':\n            ShapeAdaptor.type = 'global'\n            self.max_pool = nn.MaxPool2d(2, 2, ceil_mode=True)  # use ceil mode to avoid 0 pixel feature layer\n            # We don't insert shape adaptors on top of maxpooling layer. (excessive reshaping at the same location)\n            self.sampling_index_full = [i for i in range(len(self.features)-3) if isinstance(self.features[i], nn.ReLU)\n                                        and not isinstance(self.features[i+1], nn.MaxPool2d)]\n            if self.sa_num is None:\n                self.sa_num = 2 if self.input_shape < 64 else 4\n            index_gap = len(self.sampling_index_full) \/ self.sa_num\n            self.sampling_index = [self.sampling_index_full[int(i * index_gap)] for i in range(self.sa_num)]\n\n        # define fully-connected prediction layers; we use one fc-layer across all methods for consistency\n        self.classifier = nn.Sequential(\n            nn.Linear(512, CLASS_NB[dataset]),\n        )\n\n        if 'human' not in self.mode:\n            if self.mode == 'shape-adaptor':\n                self.alpha = nn.Parameter(torch.tensor([SA_init(input_shape, output_shape, self.sa_num)] * self.sa_num, requires_grad=True))\n            elif self.mode == 'autosc':\n                # Initialise as the original network shape: s(\\alpha) = 0.95\n                self.alpha = nn.Parameter(torch.tensor([alpha_value] * self.sa_num, requires_grad=True))\n","AFTER":"        self.mode = mode\n        self.sa_num = sa_num\n        self.input_shape = input_shape\n        self.shape_list = []\n        self.filter = {\n            'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512],\n            'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512],\n            'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512],\n            'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512],\n        }\n\n        # define VGG feature extractor layers\n        if self.input_shape > 64:\n            # human-designed network will attach another max-pool layer before classifier (in large-resolution datasets)\n            self.filter[type].append('M')\n\n        layers = []\n        channel_in = 3  # input RGB images\n        self.features = nn.ModuleList()\n        for ch in self.filter[type]:\n            if ch == 'M':\n                # AutoSC mode is built on the human-designed network *along with* the original resizing layers\n                if 'human' in self.mode:\n                    layers += [nn.MaxPool2d(2, 2)]\n                elif self.mode == 'autosc':\n                    layers += [nn.MaxPool2d(2, 2, ceil_mode=True)]\n            else:\n                # Standard mode is built on the human-designed network *without* the original resizing layers\n                layers += [nn.Conv2d(channel_in, ch, kernel_size=3, padding=1),\n                           nn.BatchNorm2d(ch),\n                           nn.ReLU(inplace=True)]\n                channel_in = ch\n        self.features = nn.Sequential(*layers)\n\n        # define two types of shape adaptor modes:\n        if self.mode == 'shape-adaptor':\n            ShapeAdaptor.type = 'local'\n            self.max_pool = nn.MaxPool2d(2, 2)  # max-pool is considered as the down-sample branch.\n            # we don't apply shape adaptor at the last layer, thus \"-3\": -1 * 3 operations in each conv layer.\n            self.sampling_index_full = [i for i in range(len(self.features) - 3) if isinstance(self.features[i], nn.ReLU)]\n\n            if self.sa_num is None:\n                # automatically define the optimal number of shape adaptors based on a heuristic.\n                self.sa_num = int(np.log2(self.input_shape \/ 2))\n\n            # insert shape adaptors uniformly\n            index_gap = len(self.sampling_index_full) \/ self.sa_num\n            self.sampling_index = [self.sampling_index_full[int(i * index_gap)] for i in range(self.sa_num)]\n\n        elif self.mode == 'autosc':\n            ShapeAdaptor.type = 'global'\n            self.max_pool = nn.MaxPool2d(2, 2, ceil_mode=True)  # use ceil mode to avoid 0 dimension feature layer\n            # we don't insert shape adaptors on top of max-pooling layer. (excessive reshaping at the same position)\n            self.sampling_index_full = [i for i in range(len(self.features)-3) if isinstance(self.features[i], nn.ReLU)\n                                        and not isinstance(self.features[i+1], nn.MaxPool2d)]\n\n            if self.sa_num is None:\n                # number of shape adaptors found by a grid search, this number is possibly not optimal\n                self.sa_num = 2 if self.input_shape < 64 else 4\n\n            # insert shape adaptors uniformly\n            index_gap = len(self.sampling_index_full) \/ self.sa_num\n            self.sampling_index = [self.sampling_index_full[int(i * index_gap)] for i in range(self.sa_num)]\n\n        # define fully-connected prediction layers; we use one fc-layer across all methods for consistency\n        self.classifier = nn.Sequential(\n            nn.Linear(512, CLASS_NB[dataset]),\n        )\n\n        if 'human' not in self.mode:\n            if self.mode == 'shape-adaptor':\n                # compute shape adaptor initialisation by a heuristic\n                self.alpha = nn.Parameter(torch.tensor([SA_init(input_shape, output_shape, self.sa_num)] * self.sa_num, requires_grad=True))\n            elif self.mode == 'autosc':\n                # initialise shape adaptors to be the original network shape: s(alpha) = 0.95, alpha = 2.19\n                self.alpha = nn.Parameter(torch.tensor([2.19] * self.sa_num, requires_grad=True))\n"}