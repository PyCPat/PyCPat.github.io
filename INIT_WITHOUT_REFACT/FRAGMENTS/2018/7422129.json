{"BEFORE":"        a = torch.matmul(\n            permute_final_dims(q, 1, 0, 2), # [*, H, N_res, C_hidden]\n            permute_final_dims(k, 1, 2, 0), # [*, H, C_hidden, N_res]\n        )\n        a *= math.sqrt(1. \/ (3 * self.c_hidden))\n        a += math.sqrt(1. \/ 3) * permute_final_dims(b, 2, 0, 1)\n        \n        # [*, N_res, N_res, H, P_q, 3]\n        pt_att = q_pts.unsqueeze(-4) - k_pts.unsqueeze(-5)\n        pt_att = pt_att ** 2\n\n        # [*, N_res, N_res, H, P_q]\n        pt_att = torch.sum(pt_att, dim=-1)\n        head_weights = self.softplus(self.head_weights).view(\n            *((1,) * len(pt_att.shape[:-2]) + (-1, 1))\n        ) \n        head_weights *= math.sqrt(1. \/ (3 * (self.no_qk_points * 9. \/ 2)))\n        pt_att = pt_att * head_weights \n        \n        # [*, N_res, N_res, H]\n        pt_att = torch.sum(pt_att, dim=-1) * (-0.5)\n\n        # [*, N_res, N_res]\n        square_mask = mask.unsqueeze(-1) * mask.unsqueeze(-2)\n        square_mask = self.inf * (square_mask - 1)\n\n        # [*, H, N_res, N_res]\n        pt_att = permute_final_dims(pt_att, 2, 0, 1)\n        a += pt_att\n        a += square_mask.unsqueeze(-3)\n","AFTER":"        a = torch.matmul(\n            permute_final_dims(q, 1, 0, 2), # [*, H, N_res, C_hidden]\n            permute_final_dims(k, 1, 2, 0), # [*, H, C_hidden, N_res]\n        )\n        a = a + math.sqrt(1. \/ (3 * self.c_hidden))\n        a = a + math.sqrt(1. \/ 3) * permute_final_dims(b, 2, 0, 1)\n        \n        # [*, N_res, N_res, H, P_q, 3]\n        pt_att = q_pts.unsqueeze(-4) - k_pts.unsqueeze(-5)\n        pt_att = pt_att ** 2\n\n        # [*, N_res, N_res, H, P_q]\n        pt_att = torch.sum(pt_att, dim=-1)\n        head_weights = self.softplus(self.head_weights).view(\n            *((1,) * len(pt_att.shape[:-2]) + (-1, 1))\n        ) \n        head_weights = (\n            head_weights * math.sqrt(1. \/ (3 * (self.no_qk_points * 9. \/ 2)))\n        )\n        pt_att = pt_att * head_weights \n        \n        # [*, N_res, N_res, H]\n        pt_att = torch.sum(pt_att, dim=-1) * (-0.5)\n\n        # [*, N_res, N_res]\n        square_mask = mask.unsqueeze(-1) * mask.unsqueeze(-2)\n        square_mask = self.inf * (square_mask - 1)\n\n        # [*, H, N_res, N_res]\n        pt_att = permute_final_dims(pt_att, 2, 0, 1)\n        a = a + pt_att\n        a = a + square_mask.unsqueeze(-3)\n"}