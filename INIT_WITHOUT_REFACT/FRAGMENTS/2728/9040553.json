{"BEFORE":"            h1 = F.elu(h1)\n            \n            # h2 = self.graphsage[l](blocks[l], h)\n            # h2 = self.norm_layers[5 * l + 1](h2)\n            # h2 = F.elu(h2)\n            \n            # h3 = self.graphconv[l](blocks[l], h)\n            # h3 = self.norm_layers[5 * l + 2](h3)\n            # h3 = F.elu(h3)\n            \n            h4 = self.graphattn[l](blocks[l], h).flatten(1)\n            h4 = self.norm_layers[5 * l + 3](h4)\n            h4 = F.elu(h4)\n            \n            # h = torch.stack([h1, h2, h3, h4], dim=1)\n            h = torch.stack([h1, h4], dim=1)\n            attn_weights = F.softmax(self.gnn_attns[l](h), dim=1)\n            attn_weights = attn_weights.transpose(-1, -2)\n            print('attn_weights.shape:', attn_weights.shape)\n            print('h: ',h.shape)\n            h = torch.bmm(attn_weights, h)[:, 0]\n","AFTER":"        h = feature\n        for l in range(self.num_layers):     \n            h1 = expand_as_pair(h, blocks[l])[1]\n            h1 = self.skips[l](h1)\n            h1 = self.norm_layers[5 * l](h1)\n            h1 = F.elu(h1)\n            \n            h2 = self.graphsage[l](blocks[l], h)\n            h2 = self.norm_layers[5 * l + 1](h2)\n            h2 = F.elu(h2)\n            \n            # h3 = self.graphconv[l](blocks[l], h)\n            # h3 = self.norm_layers[5 * l + 2](h3)\n            # h3 = F.elu(h3)\n            \n            h4 = self.graphattn[l](blocks[l], h).flatten(1)\n            h4 = self.norm_layers[5 * l + 3](h4)\n            h4 = F.elu(h4)\n            \n            # h = torch.stack([h1, h2, h3, h4], dim=1)\n            # h = torch.stack([h1, h4], dim=1)\n            # attn_weights = F.softmax(self.gnn_attns[l](h), dim=1)\n            # attn_weights = attn_weights.transpose(-1, -2)\n            # h = torch.bmm(attn_weights, h)[:, 0]\n            # 上面是unimp模型的残差连接\n            # 下面是se的残差连接\n            h = self.mul[l](h1, h2, h4)\n"}