{"BEFORE":"        pos_index = SCHP.max_unit_type + AHP.entity_x_y_index  # 13 + 1 + 5 + 5\r\n        entity_x_y = state.entity_state[:, :, pos_index: pos_index + 8 * 2]\r\n\r\n        #map_skip, embedded_spatial = self.spatial_encoder(state.map_state, entity_embeddings, entity_x_y)\r\n        map_skip, embedded_spatial = self.spatial_encoder(state.map_state)\r\n\r\n        embedded_scalar, scalar_context = self.scalar_encoder(state.statistical_state)\r\n\r\n        print(\"entity_embeddings.shape:\", entity_embeddings.shape) if debug else None\r\n\r\n        lstm_output, hidden_state = self.core(embedded_scalar, embedded_entity, embedded_spatial, \r\n                                              batch_size, sequence_length, hidden_state)\r\n\r\n        print('lstm_output.shape:', lstm_output.shape) if debug else None\r\n        print('lstm_output is nan:', torch.isnan(lstm_output).any()) if debug else None\r\n\r\n        action_type_logits, action_type, autoregressive_embedding = self.action_type_head(lstm_output, scalar_context)\r\n        print(\"action_type:\", action_type) if debug else None\r\n\r\n        delay_logits, delay, autoregressive_embedding = self.delay_head(autoregressive_embedding)\r\n        queue_logits, queue, autoregressive_embedding = self.queue_head(autoregressive_embedding, action_type, embedded_entity)\r\n        units_logits, units, autoregressive_embedding = self.selected_units_head(autoregressive_embedding, action_type, entity_embeddings)\r\n\r\n        target_unit_logits, target_unit = self.target_unit_head(autoregressive_embedding, action_type, entity_embeddings)\r\n        target_location_logits, target_location = self.location_head(autoregressive_embedding, action_type, map_skip)\r\n\r\n        # return [action_type_logits, delay_logits, queue_logits, units_logits, target_unit_logits, target_location_logits], \r\n        #[action_type, delay, queue, units, target_unit, target_location]\r\n        action = ArgsAction(action_type=action_type, delay=delay, queue=queue,\r\n                            units=units, target_unit=target_unit, target_location=target_location)\r\n        action_logits = ArgsActionLogits(action_type=action_type_logits, delay=delay_logits, queue=queue_logits,\r\n                                         units=units_logits, target_unit=target_unit_logits, \r\n                                         target_location=target_location_logits)\r\n","AFTER":"                return_baseline=False, multi_gpu_supvised_learning=False):\r\n        # shapes of embedded_entity, embedded_spatial, embedded_scalar are all [batch_size x embedded_size]\r\n\r\n        # pos_index = SCHP.max_unit_type + AHP.entity_x_y_index  # 13 + 1 + 5 + 5\r\n        #entity_x_y = state.entity_state[:, :, pos_index: pos_index + 8 * 2]\r\n        #map_skip, embedded_spatial = self.spatial_encoder(state.map_state, entity_embeddings, entity_x_y)\r\n        entity_embeddings, embedded_entity = self.entity_encoder(state.entity_state)   \r\n        map_skip, embedded_spatial = self.spatial_encoder(state.map_state)\r\n        embedded_scalar, scalar_context = self.scalar_encoder(state.statistical_state)\r\n\r\n        lstm_output, hidden_state = self.core(embedded_scalar, embedded_entity, embedded_spatial, \r\n                                              batch_size, sequence_length, hidden_state)\r\n        print('lstm_output.shape:', lstm_output.shape) if debug else None\r\n        print('lstm_output is nan:', torch.isnan(lstm_output).any()) if debug else None\r\n\r\n        action_type_logits, action_type, autoregressive_embedding = self.action_type_head(lstm_output, scalar_context)\r\n        delay_logits, delay, autoregressive_embedding = self.delay_head(autoregressive_embedding)\r\n        queue_logits, queue, autoregressive_embedding = self.queue_head(autoregressive_embedding, action_type, embedded_entity)\r\n\r\n        units_logits, units, autoregressive_embedding = self.selected_units_head(autoregressive_embedding, action_type, entity_embeddings)\r\n\r\n        target_unit_logits, target_unit = self.target_unit_head(autoregressive_embedding, action_type, entity_embeddings)\r\n        target_location_logits, target_location = self.location_head(autoregressive_embedding, action_type, map_skip)\r\n\r\n        action_logits = ArgsActionLogits(action_type=action_type_logits, delay=delay_logits, queue=queue_logits,\r\n                                         units=units_logits, target_unit=target_unit_logits, \r\n                                         target_location=target_location_logits)\r\n        action = ArgsAction(action_type=action_type, delay=delay, queue=queue,\r\n                            units=units, target_unit=target_unit, target_location=target_location)\r\n\r\n        if multi_gpu_supvised_learning:\r\n            return action_type, action_type_logits, delay_logits, queue_logits, \\\r\n                units_logits, target_unit_logits, target_location_logits\r\n\r\n        if return_logits:\r\n"}