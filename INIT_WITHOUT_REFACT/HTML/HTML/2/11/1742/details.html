<html><h3>Pattern ID :1742
</h3><img src='6867645.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        self.embedding.weight.data.uniform_(1./self.K, 1./self.K)

    def forward(self, input: Tensor):
        input = <a id="change">input.permute(</a>0, <a id="change">2</a>, <a id="change">3</a>, <a id="change">1</a><a id="change">)</a> &#47&#47 [B x D x H x W] -&gt; [B x H x W x D]
        input_shape = input.shape
        flat_input = <a id="change">input.contiguous()</a>.view(-1, self.D)    &#47&#47 [BHW x D]

        &#47&#47 Compute L2 distance between input and embedding weights
        dist = torch.sum(flat_input**2, dim = 1, keepdim=True) + \</code></pre><h3>After Change</h3><pre><code class='java'>
        self.embedding.weight.data.uniform_(-1 / self.K, 1 / self.K)

    def forward(self, latents: Tensor) -&gt; Tensor:
        latents = <a id="change">latents.permute(0, 2, 3, 1).contiguous()</a>  &#47&#47 [B x D x H x W] -&gt; [B x H x W x D]
        latents_shape = latents.shape
        flat_latents = latents.view(-1, self.D)  &#47&#47 [BHW x D]

        &#47&#47 Compute L2 distance between latents and embedding weights
        dist = torch.sum(flat_latents ** 2, dim=1, keepdim=True) + \
               torch.sum(self.embedding.weight ** 2, dim=1) - \
               2 * torch.matmul(flat_latents, self.embedding.weight.t())  &#47&#47 [BHW x K]

        &#47&#47 Get the encoding that has the min distance
        encoding_inds = torch.argmin(dist, dim=1).unsqueeze(1)  &#47&#47 [BHW, 1]

        &#47&#47 Convert to one-hot encodings
        device = latents.device
        encoding_one_hot = torch.zeros(encoding_inds.size(0), self.K, device=device)
        encoding_one_hot.scatter_(1, encoding_inds, 1)  &#47&#47 [BHW x K]

        &#47&#47 Quantize the latents
        quantized_latents = torch.matmul(encoding_one_hot, self.embedding.weight)  &#47&#47 [BHW, D]
        quantized_latents = quantized_latents.view(latents_shape)  &#47&#47 [B x H x W x D]

        &#47&#47 Compute the VQ Losses
        commitment_loss = F.mse_loss(quantized_latents.detach(), latents)
        embedding_loss<a id="change"> = </a>F.mse_loss(quantized_latents, latents.detach())

        vq_loss = commitment_loss * self.beta + embedding_loss
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/antixk/pytorch-vae/commit/330681d5b01126be50ee4d64433252591e50452e#diff-d886e8949de3b9b5bf99d61736c8bcb8525ea1e0ff2e12be13feb9227801c96eL19' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6867645</div><div id='project'> Project Name: antixk/pytorch-vae</div><div id='commit'> Commit Name: 330681d5b01126be50ee4d64433252591e50452e</div><div id='time'> Time: 2020-02-14</div><div id='author'> Author: anandkrish894@gmail.com</div><div id='file'> File Name: models/vq_vae.py</div><div id='m_class'> M Class Name: VectorQuantizer</div><div id='n_method'> N Class Name: VectorQuantizer</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/vq_vae.py</div><div id='n_file'> N File Name: models/vq_vae.py</div><div id='m_start'> M Start Line: 19</div><div id='m_end'> M End Line: 40</div><div id='n_start'> N Start Line: 25</div><div id='n_end'> N End Line: 55</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        with g.local_scope():
            h_prime = []
            emb = <a id="change">emb.permute(1, 0, 2).contiguous()</a>
            for i in range(self.num_heads):
                g.edata[&quotalpha&quot] = edge_attention[:, i]
                g.srcdata.update({&quotemb&quot: emb[i]})
                g.update_all(Fn.u_mul_e(&quotemb&quot, &quotalpha&quot, &quotm&quot),</code></pre><h3>After Change</h3><pre><code class='java'>
            edge_attention = edge_attention.unsqueeze(1)

        with g.local_scope():
            emb = <a id="change">emb.permute(0, 2, 1).contiguous()</a>
            g.edata[&quotalpha&quot] = edge_attention
            g.srcdata[&quotemb&quot]<a id="change"> = </a>emb
            g.update_all(Fn.u_mul_e(&quotemb&quot, &quotalpha&quot, &quotm&quot),
                         Fn.sum(&quotm&quot, &quotemb&quot))
            &#47&#47 g.apply_edges(Fn.u_mul_e(&quotemb&quot, &quotalpha&quot, &quotm&quot))</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/bupt-gamma/openhgnn/commit/c2a6b5ad048e2d937b6642b0106dad5faa75a335#diff-59f1f6852baf41601055fbdbc029a635a162bb43b4244576cc8c6184f15c96d5L156' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6867648</div><div id='project'> Project Name: bupt-gamma/openhgnn</div><div id='commit'> Commit Name: c2a6b5ad048e2d937b6642b0106dad5faa75a335</div><div id='time'> Time: 2022-02-25</div><div id='author'> Author: 996179900@qq.com</div><div id='file'> File Name: openhgnn/models/SimpleHGN.py</div><div id='m_class'> M Class Name: SimpleHGNConv</div><div id='n_method'> N Class Name: SimpleHGNConv</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: openhgnn/models/SimpleHGN.py</div><div id='n_file'> N File Name: openhgnn/models/SimpleHGN.py</div><div id='m_start'> M Start Line: 159</div><div id='m_end'> M End Line: 190</div><div id='n_start'> N Start Line: 158</div><div id='n_end'> N End Line: 190</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        x, _ = self.rnn(x)
        x = self.linear(x)
        x = x.view(batch_size, W, out_channels, H)
        output = <a id="change">x.permute(0, 2, 3, 1).contiguous()</a>

        return output

class RNNBeforeDenseBlock(nn.Module):</code></pre><h3>After Change</h3><pre><code class='java'>
        x = self.dense_block(input)
        x_rnn = self.bottleneck_conv2d(x)
        x_rnn = x_rnn.squeeze(dim=1)
        x_rnn<a id="change"> = x_rnn.permute(0, 2, 1).contiguous()</a>
        x_rnn, _ = self.rnn(x_rnn)
        x_rnn = self.linear(x_rnn)
        x_rnn = x_rnn.view(batch_size, W, 1, H)
        x_rnn = x_rnn.permute(0, 2, 3, 1).contiguous()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/tky823/dnn-based_source_separation/commit/a03228ac5d881722942f5d3b8f51c12b05045f49#diff-c4583de27288d3ca1427dcdebe94ac7c663a338bc0a093c70b5ec1d51e3e2363L45' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6867651</div><div id='project'> Project Name: tky823/dnn-based_source_separation</div><div id='commit'> Commit Name: a03228ac5d881722942f5d3b8f51c12b05045f49</div><div id='time'> Time: 2021-10-18</div><div id='author'> Author: delta9guitar97@gmail.com</div><div id='file'> File Name: src/models/dense_rnn.py</div><div id='m_class'> M Class Name: RNNAfterDenseBlock</div><div id='n_method'> N Class Name: RNNAfterDenseBlock</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/models/dense_rnn.py</div><div id='n_file'> N File Name: src/models/dense_rnn.py</div><div id='m_start'> M Start Line: 53</div><div id='m_end'> M End Line: 62</div><div id='n_start'> N Start Line: 57</div><div id='n_end'> N End Line: 66</div><BR>