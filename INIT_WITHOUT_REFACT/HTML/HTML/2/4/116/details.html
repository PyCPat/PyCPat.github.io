<html><h3>Pattern ID :116
</h3><img src='550520.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            self.relative_positions_encoding = nn.Embedding(kwargs.get(&quotrelative_attention_num_buckets&quot), self.num_attention_heads)

        elif self.p_bias == &quotdeberta_v2&quot:  &#47&#47 deberta_v2
            self.pos_att_type = <a id="change">kwargs.get(&quotpos_att_type&quot</a><a id="change">)</a>
            self.relative_positions = RelativePositionsEncodingDebertaV2(qlen=kwargs.get(&quotmax_position&quot), 
                                                                         klen=kwargs.get(&quotmax_position&quot), 
                                                                         position_buckets=kwargs.get(&quotposition_buckets&quot),</code></pre><h3>After Change</h3><pre><code class='java'>

        elif self.p_bias == &quotdeberta_v2&quot:  &#47&#47 deberta_v2
            &#47&#47 配置文件
            self.share_att_key = <a id="change">kwargs.get("share_att_key"</a>, False<a id="change">)</a>
            self.position_buckets = kwargs.get("position_buckets", -1)
            self.max_relative_positions = kwargs.get("max_relative_positions", -1)
            if self.max_relative_positions &lt; 1:</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 5</div><BR><div id='size'>Non-data size: 2</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/tongjilibo/bert4torch/commit/65380d4a068efef61addb7cc2fc695c9420a3424#diff-423158f6414177c50deaf8ff8d75202474ddccb543fca22c762f1c3c0e973f8eL65' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 550520</div><div id='project'> Project Name: tongjilibo/bert4torch</div><div id='commit'> Commit Name: 65380d4a068efef61addb7cc2fc695c9420a3424</div><div id='time'> Time: 2022-11-16</div><div id='author'> Author: tongjilibo@163.com</div><div id='file'> File Name: bert4torch/layers.py</div><div id='m_class'> M Class Name: MultiHeadAttentionLayer</div><div id='n_method'> N Class Name: MultiHeadAttentionLayer</div><div id='m_method'> M Method Name: __init__(8)</div><div id='n_method'> N Method Name: __init__(7)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: bert4torch/layers.py</div><div id='n_file'> N File Name: bert4torch/layers.py</div><div id='m_start'> M Start Line: 103</div><div id='m_end'> M End Line: 114</div><div id='n_start'> N Start Line: 65</div><div id='n_end'> N End Line: 125</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 assert hidden_size % num_attention_heads == 0  &#47&#47 旧逻辑，t5_pegasus_small中不可以整除
        &#47&#47 兼容t5_pegasus_small
        if kwargs.get(&quotattention_head_size&quot):
            self.attention_head_size = <a id="change">kwargs.get(&quotattention_head_size&quot</a><a id="change">)</a>
        else:
            self.attention_head_size = int(hidden_size / num_attention_heads)
</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 t5_pegasus_small中hidden_size/num_attention_heads != 0
        &#47&#47 苏神的roberta small中qk的维度和v不同
        self.attention_head_size = kwargs.get(&quotattention_head_size&quot, int(hidden_size/num_attention_heads))
        self.attention_key_size = <a id="change">kwargs.get(&quotattention_key_size&quot</a>, self.attention_head_size<a id="change">)</a>
        self.qk_inner_dim = self.attention_key_size * self.num_attention_heads
        self.v_inner_dim = self.attention_head_size * self.num_attention_heads
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/tongjilibo/bert4torch/commit/e19c489d261e8cdd0af71a627a4807c01ac3c84f#diff-423158f6414177c50deaf8ff8d75202474ddccb543fca22c762f1c3c0e973f8eL65' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 550523</div><div id='project'> Project Name: tongjilibo/bert4torch</div><div id='commit'> Commit Name: e19c489d261e8cdd0af71a627a4807c01ac3c84f</div><div id='time'> Time: 2023-03-31</div><div id='author'> Author: tongjilibo@163.com</div><div id='file'> File Name: bert4torch/layers.py</div><div id='m_class'> M Class Name: MultiHeadAttentionLayer</div><div id='n_method'> N Class Name: MultiHeadAttentionLayer</div><div id='m_method'> M Method Name: __init__(9)</div><div id='n_method'> N Method Name: __init__(9)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: bert4torch/layers.py</div><div id='n_file'> N File Name: bert4torch/layers.py</div><div id='m_start'> M Start Line: 69</div><div id='m_end'> M End Line: 95</div><div id='n_start'> N Start Line: 69</div><div id='n_end'> N End Line: 84</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        )

        last_pad = 0
        last_pad = <a id="change">self.model_cfg.get(&quotlast_pad&quot</a>, last_pad<a id="change">)</a>

        self.conv_out = spconv.SparseSequential(
            &#47&#47 [200, 150, 5] -&gt; [200, 150, 2]
            spconv.SparseConv3d(64, 128, (3, 1, 1), stride=(2, 1, 1), padding=last_pad,</code></pre><h3>After Change</h3><pre><code class='java'>
            block(64, 64, 3, norm_fn=norm_fn, padding=1, indice_key=&quotsubm4&quot),
        )

        if <a id="change">self.model_cfg.get(&quotRETURN_ENCODED_TENSOR&quot</a>, True<a id="change">)</a>:
            last_pad = self.model_cfg.get(&quotlast_pad&quot, 0)

            self.conv_out = spconv.SparseSequential(</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/open-mmlab/openpcdet/commit/e6f6151c5f81a874b6394febf2893f9a42cf7ff8#diff-b8c2032ddbdb8ec34df3f6e96c6e75b80d5fbf9bb8884a72e0d048b16c41fe68L53' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 550525</div><div id='project'> Project Name: open-mmlab/openpcdet</div><div id='commit'> Commit Name: e6f6151c5f81a874b6394febf2893f9a42cf7ff8</div><div id='time'> Time: 2020-07-22</div><div id='author'> Author: shaoshuaics@gmail.com</div><div id='file'> File Name: pcdet/models/backbones_3d/spconv_unet.py</div><div id='m_class'> M Class Name: UNetV2</div><div id='n_method'> N Class Name: UNetV2</div><div id='m_method'> M Method Name: __init__(6)</div><div id='n_method'> N Method Name: __init__(6)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: pcdet/models/backbones_3d/spconv_unet.py</div><div id='n_file'> N File Name: pcdet/models/backbones_3d/spconv_unet.py</div><div id='m_start'> M Start Line: 94</div><div id='m_end'> M End Line: 103</div><div id='n_start'> N Start Line: 55</div><div id='n_end'> N End Line: 109</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if &quotresnet&quot in arch_str:
            block = BasicResidualBlock
        for layer_definition in self.architecture_definition:
            if <a id="change">layer_definition.get(&quotresidual&quot</a>, False<a id="change">)</a>:
                block_kwargs = {
                    &quotstride&quot: layer_definition[&quotstride&quot],
                    &quotdownsample&quot: nn.Sequential(nn.Conv2d(in_dim,</code></pre><h3>After Change</h3><pre><code class='java'>
        for layer_definition in self.architecture_definition:
            layer_stride = layer_definition[&quotstride&quot]
            layer_out_dim = layer_definition[&quotout_dim&quot]
            if <a id="change">layer_definition.get(&quotresidual&quot</a>, False<a id="change">)</a>:
                block_kwargs = {
                    &quotstride&quot: layer_stride,
                    &quotdownsample&quot: nn.Sequential(nn.Conv2d(in_dim,</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/humancompatibleai/eirli/commit/a9a41d691e422c432b76a0a09882a1e0c9cdd013#diff-7b6cc32084df7e0a6941bc1a899e44b49b70998170146371889b15f6324f629dL194' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 550516</div><div id='project'> Project Name: humancompatibleai/eirli</div><div id='commit'> Commit Name: a9a41d691e422c432b76a0a09882a1e0c9cdd013</div><div id='time'> Time: 2021-05-17</div><div id='author'> Author: sam@qxcv.net</div><div id='file'> File Name: src/il_representations/algos/encoders.py</div><div id='m_class'> M Class Name: MAGICALCNN</div><div id='n_method'> N Class Name: MAGICALCNN</div><div id='m_method'> M Method Name: __init__(8)</div><div id='n_method'> N Method Name: __init__(8)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/il_representations/algos/encoders.py</div><div id='n_file'> N File Name: src/il_representations/algos/encoders.py</div><div id='m_start'> M Start Line: 209</div><div id='m_end'> M End Line: 244</div><div id='n_start'> N Start Line: 209</div><div id='n_end'> N End Line: 252</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.embed_noise = kwargs.get("embed_noise", .0)
        self.dropoute = kwargs.get("dropoute", .7)
        self.rnn_size = kwargs.get("rnn_size", 100)
        self.rnn_layers = <a id="change">kwargs.get("rnn_layers"</a>, 2<a id="change">)</a>
        self.rnn_dropouti = kwargs.get("rnn_dropouti", .5)
        self.rnn_dropouto = kwargs.get("rnn_dropouto", .5)
        self.rnn_dropoutw = kwargs.get("rnn_dropoutw", .5)
        self.pack = kwargs.get("pack", True)</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 dropouts
        self.dropoute = kwargs.get("dropoute", .3) &#47&#47 embedding layer dropout
        self.rnn_dropouti = kwargs.get("rnn_dropouti", .5) &#47&#47 rnn input dropout
        self.rnn_wdrop = <a id="change">kwargs.get("rnn_wdrop"</a>, .5<a id="change">)</a> &#47&#47 rnn recurrent dropout
        self.rnn_dropouth = kwargs.get("rnn_dropouth", .5) &#47&#47 rnn output dropout
        self.rnn_dropout = kwargs.get("rnn_dropout", .5) &#47&#47 not sure yet
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mourga/variational-lstm/commit/65e51fb6108e9a94804db631bfa1240f18ab2d72#diff-dcfeaa5ac3dffd54264034760914588d92fc7395c81eaa9274715840dc28100bL11' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 550518</div><div id='project'> Project Name: mourga/variational-lstm</div><div id='commit'> Commit Name: 65e51fb6108e9a94804db631bfa1240f18ab2d72</div><div id='time'> Time: 2020-02-06</div><div id='author'> Author: katerina.margatina@gmail.com</div><div id='file'> File Name: models.py</div><div id='m_class'> M Class Name: RNNClassifier</div><div id='n_method'> N Class Name: RNNClassifier</div><div id='m_method'> M Method Name: __init__(3)</div><div id='n_method'> N Method Name: __init__(3)</div><div id='m_parent_class'> M Parent Class: nn.Module,RecurrentHelper</div><div id='n_parent_class'> N Parent Class: nn.Module,RecurrentHelper</div><div id='m_file'> M File Name: models.py</div><div id='n_file'> N File Name: models.py</div><div id='m_start'> M Start Line: 21</div><div id='m_end'> M End Line: 56</div><div id='n_start'> N Start Line: 28</div><div id='n_end'> N End Line: 71</div><BR>