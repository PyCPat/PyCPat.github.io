<html><h3>Pattern ID :813
</h3><img src='2703992.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        self.fc2 = nn.Linear(256, 256)

        if use_batch_norm:
            self.bn1 = <a id="change">nn.BatchNorm1d(</a>256<a id="change">)</a>
            self.bn2 = nn.BatchNorm1d(256)

    def forward(self, x):
        h = torch.relu(self.fc1(x))</code></pre><h3>After Change</h3><pre><code class='java'>
        self.feature_size = hidden_units[-1]

        in_units = [observation_shape[0]] + hidden_units[:-1]
        self.fcs<a id="change"> = </a><a id="change">nn.ModuleList()</a>
        self.bns = nn.ModuleList()
        for in_unit, out_unit in zip(in_units, hidden_units):
            <a id="change">self.fcs.append(</a>nn.Linear(in_unit, out_unit)<a id="change">)</a>
            if use_batch_norm:
                self.bns.append(nn.BatchNorm1d(out_unit))

    def forward(self, x):</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/takuseno/d3rlpy/commit/557b11a8d5cf75edfc0a2928399d5192d1757ddb#diff-9039460d6f630d68f293a43c69c5f66cf03d3a614353b7c827a27367930ff0b0L84' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2703992</div><div id='project'> Project Name: takuseno/d3rlpy</div><div id='commit'> Commit Name: 557b11a8d5cf75edfc0a2928399d5192d1757ddb</div><div id='time'> Time: 2020-06-16</div><div id='author'> Author: takuma.seno@gmail.com</div><div id='file'> File Name: skbrl/models/torch/heads.py</div><div id='m_class'> M Class Name: VectorHead</div><div id='n_method'> N Class Name: VectorHead</div><div id='m_method'> M Method Name: __init__(4)</div><div id='n_method'> N Method Name: __init__(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: skbrl/models/torch/heads.py</div><div id='n_file'> N File Name: skbrl/models/torch/heads.py</div><div id='m_start'> M Start Line: 84</div><div id='m_end'> M End Line: 91</div><div id='n_start'> N Start Line: 96</div><div id='n_end'> N End Line: 114</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

            in_features = hid
        if bn:
            conv2.append(<a id="change">nn.BatchNorm1d(</a>in_features<a id="change">)</a>)
        conv2.append(RobustConv(in_features, out_features, gamma=gamma, bias=bias))
        self.conv2 = conv2
        self.dropout = nn.Dropout(dropout)</code></pre><h3>After Change</h3><pre><code class='java'>
            self.bn1 = lambda x : x

        conv2 = nn.ModuleList()
        bn2<a id="change"> = </a><a id="change">nn.ModuleList()</a>

        in_features = hids[0]
        for hid, act in zip(hids[1:], acts[1:]):
            conv2.append(RobustConv(in_features,
                                    hid,
                                    bias=bias,
                                    gamma=gamma,
                                    activation=activations.get(act)))
            if bn:
                bn2.append(nn.BatchNorm1d(hid))
            else:
                <a id="change">bn2.append(</a>lambda x : x<a id="change">)</a>
                
            in_features = hid
                
        conv2.append(RobustConv(in_features, out_features, gamma=gamma, bias=bias))</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/edisonleeeee/graphwar/commit/2485cc5800c0fa6cc8e8f7815bfb618c5755147b#diff-30a341d079472928135bb4cab92d8c0f1aba540659a2ffbf8920a90d7922119eL31' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2703981</div><div id='project'> Project Name: edisonleeeee/graphwar</div><div id='commit'> Commit Name: 2485cc5800c0fa6cc8e8f7815bfb618c5755147b</div><div id='time'> Time: 2022-01-06</div><div id='author'> Author: cnljt@outlook.com</div><div id='file'> File Name: graphwar/defense/model_level/robust_gcn.py</div><div id='m_class'> M Class Name: RobustGCN</div><div id='n_method'> N Class Name: RobustGCN</div><div id='m_method'> M Method Name: __init__(9)</div><div id='n_method'> N Method Name: __init__(9)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: graphwar/defense/model_level/robust_gcn.py</div><div id='n_file'> N File Name: graphwar/defense/model_level/robust_gcn.py</div><div id='m_start'> M Start Line: 64</div><div id='m_end'> M End Line: 89</div><div id='n_start'> N Start Line: 64</div><div id='n_end'> N End Line: 93</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.z_dim = z_dim
        self.device=device
        self.fc1 = nn.Linear(z_dim, hidden_dim, bias = False)
        self.bn1 = <a id="change">nn.BatchNorm1d(</a>hidden_dim<a id="change">, affine = False, eps=1e-6, momentum = 0.5)</a>
        self.fc2 = nn.Linear(hidden_dim, hidden_dim, bias = False)
        self.bn2 = nn.BatchNorm1d(hidden_dim, affine = False, eps=1e-6, momentum = 0.5)
        self.fc3 = LinearWeightNorm(hidden_dim, input_dim, weight_scale = 1)
        self.bn1_b = Parameter(torch.zeros(hidden_dim))</code></pre><h3>After Change</h3><pre><code class='java'>
        self.device=device
        self.hidden_dim=hidden_dim
        self.layers = torch.nn.ModuleList()
        self.bn_layers<a id="change">=</a><a id="change">torch.nn.ModuleList()</a>
        self.bn_b = torch.nn.ParameterList()
        self.num_hidden=len(hidden_dim)
        self.activations=activations
        for _ in range(self.num_hidden):
            if _==0:
                in_dim=z_dim
            else:
                in_dim=hidden_dim[_-1]
            out_dim=hidden_dim[_]
            fc=nn.Linear(in_dim, out_dim, bias=False)
            nn.init.xavier_uniform(fc.weight)
            self.layers.append(fc)
            <a id="change">self.bn_layers.append(</a>nn.BatchNorm1d(out_dim, affine = False, eps=1e-6, momentum = 0.5)<a id="change">)</a>
            self.bn_b.append(Parameter(torch.zeros(out_dim)))
        self.fc = LinearWeightNorm(hidden_dim[self.num_hidden-1], input_dim, weight_scale = 1)

</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/ygzwqzd/lamda-ssl/commit/ea5ee280fc4c0242970da002d41f42c1aaed9c96#diff-72cf7a184e0e3476b2e50c4e1939413e43421cb45b09cfeab614ed346f61e702L59' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2703988</div><div id='project'> Project Name: ygzwqzd/lamda-ssl</div><div id='commit'> Commit Name: ea5ee280fc4c0242970da002d41f42c1aaed9c96</div><div id='time'> Time: 2022-03-18</div><div id='author'> Author: 1129198222@qq.com</div><div id='file'> File Name: Semi_sklearn/Network/ImprovedGan.py</div><div id='m_class'> M Class Name: Generator</div><div id='n_method'> N Class Name: Generator</div><div id='m_method'> M Method Name: __init__(6)</div><div id='n_method'> N Method Name: __init__(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: Semi_sklearn/Network/ImprovedGan.py</div><div id='n_file'> N File Name: Semi_sklearn/Network/ImprovedGan.py</div><div id='m_start'> M Start Line: 63</div><div id='m_end'> M End Line: 71</div><div id='n_start'> N Start Line: 70</div><div id='n_end'> N End Line: 91</div><BR>