<html><h3>Pattern ID :939
</h3><img src='2862728.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 Back to batch first
        attn_scores = torch.stack(attn_scores).transpose(0, 1)
        mel_outputs = <a id="change">torch.stack(</a>mel_outputs<a id="change">)</a>.transpose(0, 1).contiguous()
        stop_tokens = torch.stack(stop_tokens).transpose(0, 1).squeeze(2)

        &#47&#47 (B, T&quot, mel_dim*r) -&gt; (B, T, mel_dim)
        mel_outputs<a id="change"> = </a>mel_outputs.reshape(B, -1, self.mel_dim)

        return mel_outputs, stop_tokens, attn_scores
</code></pre><h3>After Change</h3><pre><code class='java'>

            &#47&#47 Store predictions
            mel_outputs.append(output)
            <a id="change">attn_scores.append(</a>attention_score.unsqueeze(1)<a id="change">)</a>
            stop_tokens.extend([stop] * self.r)

            if greedy:
                if stop &gt; self.stop_threshold:</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/thuhcsi/tacotron/commit/fea9ec535ec373aad564646f4f292fbee0217c29#diff-d9b8d279159e71117d405f97592a8727c16e635c5fc8b968d2c0b3bf1f1d9df1L87' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2862728</div><div id='project'> Project Name: thuhcsi/tacotron</div><div id='commit'> Commit Name: fea9ec535ec373aad564646f4f292fbee0217c29</div><div id='time'> Time: 2021-03-18</div><div id='author'> Author: johnson.tsing@gmail.com</div><div id='file'> File Name: model/tacotron.py</div><div id='m_class'> M Class Name: Decoder</div><div id='n_method'> N Class Name: Decoder</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: model/tacotron.py</div><div id='n_file'> N File Name: model/tacotron.py</div><div id='m_start'> M Start Line: 87</div><div id='m_end'> M End Line: 187</div><div id='n_start'> N Start Line: 88</div><div id='n_end'> N End Line: 180</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            normed_embed = embed_norm(embed)
            normed_embeds.append(normed_embed)

        normed_embeds<a id="change"> = </a><a id="change">torch.stack(</a>normed_embeds<a id="change">, dim = -2)</a>
        normed_ngram_embeds = torch.stack(normed_ngram_embeds, dim = -2)

        if self.concat_ngrams:
            input_sliced_dim = normed_embeds.shape[-1] - normed_ngram_embeds.shape[-1]</code></pre><h3>After Change</h3><pre><code class='java'>
            ngram_ids_for_head = multi_way_hash_ids(ngram_ids, head_num + 1, head_num + 1, prime, vocab_size)

            ngram_embed = ngram_emb(ngram_ids_for_head)
            <a id="change">ngram_embeds.append(</a>ngram_embed<a id="change">)</a>

        embeds = rearrange(embeds, &quotb n (h d) -&gt; b n h d&quot, h = num_heads)
        normed_embeds = self.embeds_layernorm(embeds)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/n-grammer-pytorch/commit/d8d421956f3d05e96bfe5314c1e6ea16669e5d52#diff-0c3ddd526295d130fa7445934eb77fe5427874e894b9bef4e8591641b0b0fdceL141' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2862713</div><div id='project'> Project Name: lucidrains/n-grammer-pytorch</div><div id='commit'> Commit Name: d8d421956f3d05e96bfe5314c1e6ea16669e5d52</div><div id='time'> Time: 2021-12-03</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: n_grammer_pytorch/n_grammer_pytorch.py</div><div id='m_class'> M Class Name: Ngrammer</div><div id='n_method'> N Class Name: Ngrammer</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: n_grammer_pytorch/n_grammer_pytorch.py</div><div id='n_file'> N File Name: n_grammer_pytorch/n_grammer_pytorch.py</div><div id='m_start'> M Start Line: 150</div><div id='m_end'> M End Line: 167</div><div id='n_start'> N Start Line: 162</div><div id='n_end'> N End Line: 175</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 Back to batch first
        attn_scores = torch.stack(attn_scores).transpose(0, 1)
        mel_outputs = <a id="change">torch.stack(</a>mel_outputs<a id="change">)</a>.transpose(0, 1).contiguous()
        stop_tokens = torch.stack(stop_tokens).transpose(0, 1).squeeze(2)

        &#47&#47 (B, T&quot, mel_dim*r) -&gt; (B, T, mel_dim)
        mel_outputs<a id="change"> = </a>mel_outputs.reshape(B, -1, self.mel_dim)

        return mel_outputs, stop_tokens, attn_scores
</code></pre><h3>After Change</h3><pre><code class='java'>

            &#47&#47 Store predictions
            mel_outputs.append(output)
            <a id="change">attn_scores.append(</a>attention_score.unsqueeze(1)<a id="change">)</a>
            stop_tokens.extend([stop] * self.r)

            if greedy:
                if stop &gt; self.stop_threshold:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/thuhcsi/tacotron/commit/fea9ec535ec373aad564646f4f292fbee0217c29#diff-7ad5d3b60745b0b46860cc4003e6b1af82b421d3df25282bfacabd1db690e1b9L110' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2862723</div><div id='project'> Project Name: thuhcsi/tacotron</div><div id='commit'> Commit Name: fea9ec535ec373aad564646f4f292fbee0217c29</div><div id='time'> Time: 2021-03-18</div><div id='author'> Author: johnson.tsing@gmail.com</div><div id='file'> File Name: model/tacotron2.py</div><div id='m_class'> M Class Name: Decoder</div><div id='n_method'> N Class Name: Decoder</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: model/tacotron2.py</div><div id='n_file'> N File Name: model/tacotron2.py</div><div id='m_start'> M Start Line: 127</div><div id='m_end'> M End Line: 224</div><div id='n_start'> N Start Line: 127</div><div id='n_end'> N End Line: 216</div><BR>