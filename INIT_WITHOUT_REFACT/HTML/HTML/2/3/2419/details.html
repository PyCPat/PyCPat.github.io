<html><h3>Pattern ID :2419
</h3><img src='8113279.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            weight = weight * rearrange(pos_x, &quoti -&gt; i ()&quot) * rearrange(pos_y, &quotj -&gt; () j&quot)

        if self.causal:
            weight, bias = weight[:n, :n], bias[<a id="change">:n</a>]
            mask = torch.ones(weight.shape[:2], device = device).triu_(1).bool()
            weight = weight.masked_fill(mask, 0.)
</code></pre><h3>After Change</h3><pre><code class='java'>
            weight = weight * rearrange(pos_x, &quoth i -&gt; h i ()&quot) * rearrange(pos_y, &quoth j -&gt; h () j&quot)

        if self.causal:
            weight, bias = weight[:, :n, :n], <a id="change">bias</a>[:, <a id="change">:</a>n]
            mask = torch.ones(weight.shape[-2:], device = device).triu_(1).bool()
            mask = rearrange(mask, &quoti j -&gt; () i j&quot)
            weight = weight.masked_fill(mask, 0.)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 5</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lucidrains/g-mlp-pytorch/commit/9be8eed91fdd4626c1b485db06b7518b23e99dff#diff-44034403ad35d2d6dad50e7e4379a1df7da10aa3cd01d85a3d96b8361931c8b1L105' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8113279</div><div id='project'> Project Name: lucidrains/g-mlp-pytorch</div><div id='commit'> Commit Name: 9be8eed91fdd4626c1b485db06b7518b23e99dff</div><div id='time'> Time: 2021-08-13</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: g_mlp_pytorch/g_mlp_pytorch.py</div><div id='m_class'> M Class Name: SpatialGatingUnit</div><div id='n_method'> N Class Name: SpatialGatingUnit</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: g_mlp_pytorch/g_mlp_pytorch.py</div><div id='n_file'> N File Name: g_mlp_pytorch/g_mlp_pytorch.py</div><div id='m_start'> M Start Line: 105</div><div id='m_end'> M End Line: 125</div><div id='n_start'> N Start Line: 110</div><div id='n_end'> N End Line: 142</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            attention_weighted_encoding = gate * attention_weighted_encoding
            h, c = self.decode_step(
                torch.cat([embeddings[:batch_size_t, t, :], attention_weighted_encoding], dim=1),
                (h[:batch_size_t], c[<a id="change">:batch_size_t</a>]))  &#47&#47 (batch_size_t, decoder_dim)
            preds = self.fc(self.dropout(h))  &#47&#47 (batch_size_t, vocab_size)
            predictions[:batch_size_t, t, :] = preds
            alphas[:batch_size_t, t, :] = alpha</code></pre><h3>After Change</h3><pre><code class='java'>
                    h[:batch_size_t])  &#47&#47 (batch_size_t, decoder_dim)
            else:
                h = self.decode_step(
                    torch.cat([self.embedding(torch.argmax(<a id="change">predictions</a>[<a id="change">:</a>batch_size_t, t, :],dim = 1)), attention_weighted_encoding], dim=1),
                    h[:batch_size_t])  &#47&#47 (batch_size_t, decoder_dim)
            preds = self.fc(self.dropout(h))  &#47&#47 (batch_size_t, vocab_size)
            predictions[:batch_size_t, t, :] = preds</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/qs956/latex_ocr_pytorch/commit/0455746d6d3141dfc06cd15fb9cd67a0b9defcfc#diff-62e0d959e50d9f4003df8124a1c19d98c77320268642d433b1cc28c58cf73a85L205' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8113266</div><div id='project'> Project Name: qs956/latex_ocr_pytorch</div><div id='commit'> Commit Name: 0455746d6d3141dfc06cd15fb9cd67a0b9defcfc</div><div id='time'> Time: 2020-03-21</div><div id='author'> Author: qs956@163.com</div><div id='file'> File Name: model/model.py</div><div id='m_class'> M Class Name: DecoderWithAttention</div><div id='n_method'> N Class Name: DecoderWithAttention</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: model/model.py</div><div id='n_file'> N File Name: model/model.py</div><div id='m_start'> M Start Line: 231</div><div id='m_end'> M End Line: 250</div><div id='n_start'> N Start Line: 214</div><div id='n_end'> N End Line: 271</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            resyn_audio = torch.cat([self.output_cache.to(audio.device), resyn_audio], dim=-1)
            if resyn_audio.shape[-1] &gt; orig_len:
                resyn_audio = resyn_audio[:, :orig_len]
                self.output_cache = resyn_audio[<a id="change">orig_len:</a>]
            return resyn_audio</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 output cache (delay)
            resyn_audio = torch.cat([self.output_cache.to(audio.device), resyn_audio], dim=-1)
            if resyn_audio.shape[-1] &gt; orig_len:
                self.output_cache = <a id="change">resyn_audio</a>[:, <a id="change">orig_len</a>:]
                resyn_audio = resyn_audio[:, :orig_len]
            return resyn_audio</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/hyakuchiki/realtimeddsp/commit/3e605ad62ee6bdd1474b2394c6a2fd89a8ed23a0#diff-08191b15ac0a6f9e0560c05e7408f21d8bfe8f3198341d9f685555271f9b6747L194' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8113281</div><div id='project'> Project Name: hyakuchiki/realtimeddsp</div><div id='commit'> Commit Name: 3e605ad62ee6bdd1474b2394c6a2fd89a8ed23a0</div><div id='time'> Time: 2022-06-11</div><div id='author'> Author: nmwmb23@outlook.jp</div><div id='file'> File Name: diffsynth/stream.py</div><div id='m_class'> M Class Name: CachedStreamEstimatorFLSynth</div><div id='n_method'> N Class Name: CachedStreamEstimatorFLSynth</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: diffsynth/stream.py</div><div id='n_file'> N File Name: diffsynth/stream.py</div><div id='m_start'> M Start Line: 199</div><div id='m_end'> M End Line: 222</div><div id='n_start'> N Start Line: 197</div><div id='n_end'> N End Line: 219</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 prepare precomputed causal mask

        causal_mask = self.causal_mask[<a id="change">:n</a>]
        causal_mask = repeat(causal_mask, &quoti j -&gt; b i j&quot, b = b * h)

        &#47&#47 compute keys and values</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 causal mask

        i, j = sim.shape[-2:]
        causal_mask = <a id="change">self</a>.causal_mask[<a id="change">:</a>i, :j]
        causal_mask = repeat(causal_mask, &quoti j -&gt; b i j&quot, b = b * h)

        sim = sim.masked_fill(causal_mask, -torch.finfo(sim.dtype).max)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/nuwa-pytorch/commit/7e90aea7b2fffd2df6c4c674ff848f39d03df9ed#diff-47b637f0a46bb7e4f245f382a9b47f0351b6a5fda8ab6476a0476b4677441eddL329' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8113287</div><div id='project'> Project Name: lucidrains/nuwa-pytorch</div><div id='commit'> Commit Name: 7e90aea7b2fffd2df6c4c674ff848f39d03df9ed</div><div id='time'> Time: 2022-01-02</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: nuwa_pytorch/nuwa_pytorch.py</div><div id='m_class'> M Class Name: Sparse3DNA</div><div id='n_method'> N Class Name: Sparse3DNA</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: nuwa_pytorch/nuwa_pytorch.py</div><div id='n_file'> N File Name: nuwa_pytorch/nuwa_pytorch.py</div><div id='m_start'> M Start Line: 335</div><div id='m_end'> M End Line: 358</div><div id='n_start'> N Start Line: 352</div><div id='n_end'> N End Line: 408</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            ord_prob = F.log_softmax(concat_feats, dim=1)
            return ord_prob.view(-1, ord_num, H, W)

        ord_prob = F.softmax(C, dim=1)[:, 1, <a id="change">:</a>:]
        ord_prob = ord_prob.view(-1, ord_num, H, W)
        ord_label = torch.sum((ord_prob &gt; 0.5), dim=1).view(-1, 1, H, W)
        return ord_prob, ord_label</code></pre><h3>After Change</h3><pre><code class='java'>
            ord_prob[:, 1::2, :, :] = prob[:, 1, :, :, :]
            return ord_prob

        ord_prob = <a id="change">F</a>.softmax(concat_feats, dim=1)[:, 0, <a id="change">:</a>:]
        ord_label = torch.sum((ord_prob &gt; 0.5), dim=1).reshape((N, 1, H, W))
        return ord_prob, ord_label
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/dontlovebugs/superviseddepthprediction/commit/07fe1714fc568b25bd80debe8dd3ab800ff576a8#diff-4113dbf82d3c85db8d660e5485c3df3048dd9c7cefb1a9060e9e80ba9a7c2cc5L19' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8113284</div><div id='project'> Project Name: dontlovebugs/superviseddepthprediction</div><div id='commit'> Commit Name: 07fe1714fc568b25bd80debe8dd3ab800ff576a8</div><div id='time'> Time: 2020-05-02</div><div id='author'> Author: wangxin_buaa@163.com</div><div id='file'> File Name: dp/modules/decoders/OrdinalRegression.py</div><div id='m_class'> M Class Name: OrdinalRegressionLayer</div><div id='n_method'> N Class Name: OrdinalRegressionLayer</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: dp/modules/decoders/OrdinalRegression.py</div><div id='n_file'> N File Name: dp/modules/decoders/OrdinalRegression.py</div><div id='m_start'> M Start Line: 26</div><div id='m_end'> M End Line: 41</div><div id='n_start'> N Start Line: 28</div><div id='n_end'> N End Line: 45</div><BR>