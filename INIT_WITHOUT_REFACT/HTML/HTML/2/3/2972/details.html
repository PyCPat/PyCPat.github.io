<html><h3>Pattern ID :2972
</h3><img src='9914917.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        batch_size = encoder_out.size(0)
        encoder_dim = encoder_out.size(-1)
        vocab_size = self.vocab_size
        num_pixels = <a id="change">encoder_out.size(</a>1<a id="change">)</a>

        &#47&#47 Sort input data by decreasing lengths; why? For each of data in the batch, when len(prediction) = len(caption_lengths), Stop.
        caption_lengths, sort_ind = caption_lengths.squeeze(1).sort(dim=0, descending=True)</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 0 0 0 0 1 2
        &#47&#47 0 0 0 0 1 1
        dec_outputs = self.tgt_emb(encoded_captions) + self.pos_emb(torch.LongTensor([list(range(52))]*batch_size).to(device))
        dec_outputs<a id="change"> = </a><a id="change">self.dropout(</a>dec_outputs<a id="change">)</a>
        dec_self_attn_pad_mask = self.get_attn_pad_mask(encoded_captions, encoded_captions)
        dec_self_attn_subsequent_mask = self.get_attn_subsequent_mask(encoded_captions)
        dec_self_attn_mask = torch.gt((dec_self_attn_pad_mask + dec_self_attn_subsequent_mask), 0)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/royalskye/image-caption/commit/569502dd85be28a1e6a10bc8873b7cd0446556b8#diff-7b7030687899150ad5cd420914b35858a8cc34b1d59e5cab0d629393a328448cL150' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9914917</div><div id='project'> Project Name: royalskye/image-caption</div><div id='commit'> Commit Name: 569502dd85be28a1e6a10bc8873b7cd0446556b8</div><div id='time'> Time: 2020-04-06</div><div id='author'> Author: a19970417b@qq.com</div><div id='file'> File Name: transformer.py</div><div id='m_class'> M Class Name: Decoder</div><div id='n_method'> N Class Name: Decoder</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: transformer.py</div><div id='n_file'> N File Name: transformer.py</div><div id='m_start'> M Start Line: 150</div><div id='m_end'> M End Line: 189</div><div id='n_start'> N Start Line: 160</div><div id='n_end'> N End Line: 191</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                    memory_input = torch.div(outputs[-1] + memory[t-1], 2.0)
                    &#47&#47 add a random noise
                    memory_input += torch.autograd.Variable(
                        torch.randn(<a id="change">memory_input.size()</a>)).type_as(memory_input)

            &#47&#47 Prenet
            processed_memory = self.prenet(memory_input)</code></pre><h3>After Change</h3><pre><code class='java'>
                else:
                    &#47&#47 combine prev. model output and prev. real target
                    memory_input = torch.div(outputs[-1] + memory[t-1], 2.0)
                    memory_input = <a id="change">torch.nn.functional.dropout(</a>memory_input,
                                                               0.1<a id="change">,
                                                               training=True)</a>
                    &#47&#47 add a random noise
                    noise = torch.autograd.Variable(
                        memory_input.data.new(ins.size()).normal_(0.0, 1.0))
                    memory_input<a id="change"> = </a>memory_input + noise

            &#47&#47 Prenet
            processed_memory = self.prenet(memory_input)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/coqui-ai/tts/commit/56f8b2d19f90807ce7e5801b780a8d4a6da96541#diff-63415e5bdfe9c172be8a9cadb35d1f47d718fea5f15c6879f5715ebb9e331155L239' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9914915</div><div id='project'> Project Name: coqui-ai/tts</div><div id='commit'> Commit Name: 56f8b2d19f90807ce7e5801b780a8d4a6da96541</div><div id='time'> Time: 2018-02-26</div><div id='author'> Author: egolge@mozilla.com</div><div id='file'> File Name: layers/tacotron.py</div><div id='m_class'> M Class Name: Decoder</div><div id='n_method'> N Class Name: Decoder</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: layers/tacotron.py</div><div id='n_file'> N File Name: layers/tacotron.py</div><div id='m_start'> M Start Line: 309</div><div id='m_end'> M End Line: 312</div><div id='n_start'> N Start Line: 309</div><div id='n_end'> N End Line: 316</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            Args:
                input: N x T x D
        
        length = <a id="change">input.size(</a>1<a id="change">)</a>

        return self.pe[:, :length]

</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 x is batch, channels, seq_len
        x = x + self.pe[:, :, :x.size(2)]

        x<a id="change"> = </a><a id="change">self.dropout(</a>x<a id="change">)</a>

        x = x.permute(0, 2, 1).contiguous()

        return x</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/zhongyang-debug/attention-is-all-you-need-in-speech-separation/commit/361486e2e14685189e9a65a81fa779b4728c6e18#diff-7c8acbb8793a584bfe2ae80520bfb2e801e64479bf65e6f723edd575961f9c17L128' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9914911</div><div id='project'> Project Name: zhongyang-debug/attention-is-all-you-need-in-speech-separation</div><div id='commit'> Commit Name: 361486e2e14685189e9a65a81fa779b4728c6e18</div><div id='time'> Time: 2022-08-16</div><div id='author'> Author: 68770882+Zhongyang-debug@users.noreply.github.com</div><div id='file'> File Name: model/sepformer.py</div><div id='m_class'> M Class Name: Positional_Encoding</div><div id='n_method'> N Class Name: Positional_Encoding</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: model/sepformer.py</div><div id='n_file'> N File Name: model/sepformer.py</div><div id='m_start'> M Start Line: 133</div><div id='m_end'> M End Line: 135</div><div id='n_start'> N Start Line: 143</div><div id='n_end'> N End Line: 155</div><BR>