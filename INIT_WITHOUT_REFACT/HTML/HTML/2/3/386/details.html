<html><h3>Pattern ID :386
</h3><img src='1504247.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

                &#47&#47 return early results
                if uncertain &lt; inference_speed:
                    <a id="change">return </a>prob, i, uncertain_infos
            return prob, i, uncertain_infos

        &#47&#47 Training phase: the first phase corresponds to the backbone training</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 positions will keep track of the original position of each element in the
            &#47&#47 batch when elements will be removed
            final_probs = torch.zeros((hidden_states[0].shape[0], 2), device=device)
            positions = <a id="change">torch.arange(start=0, end=hidden_states[0].shape[0], device=device).long()</a>

            for i, (layer_module, (k, layer_classifier_module)) in enumerate(
                    zip(self.layer, self.layer_classifiers.items())):

                hidden_states = layer_module(hidden_states[0], attention_mask)
                logits = layer_classifier_module(hidden_states[0])
                prob = F.softmax(logits, dim=-1)
                log_prob = F.log_softmax(logits, dim=-1)
                uncertain = torch.sum(prob * log_prob, 1) / (-torch.log(self.num_class))

                &#47&#47 checking if there&quots enough information
                enough_info = uncertain &lt; inference_speed

                right_pos = positions[enough_info]
                final_probs[right_pos] = prob[enough_info]

                hidden_states = (hidden_states[0][~enough_info],)
                attention_mask = attention_mask[~enough_info]

                &#47&#47 if we have processed all the samples
                if hidden_states[0].shape[0] == 0:
                    return final_probs, i

                positions<a id="change"> = </a>positions[~enough_info]  &#47&#47 updating the positions to fit the new batch

            return final_probs, i
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/julesbelveze/bert-squeeze/commit/3cb14b8f1e742b86fe609843f2779e3bb36de4aa#diff-aac748de92a29499c39463320f41c1eaeb283dae0ed8ead9584db8318265a4acL49' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 1504247</div><div id='project'> Project Name: julesbelveze/bert-squeeze</div><div id='commit'> Commit Name: 3cb14b8f1e742b86fe609843f2779e3bb36de4aa</div><div id='time'> Time: 2021-12-11</div><div id='author'> Author: 32683010+JulesBelveze@users.noreply.github.com</div><div id='file'> File Name: bert-squeeze/models/custom_transformers/fastbert.py</div><div id='m_class'> M Class Name: FastBertGraph</div><div id='n_method'> N Class Name: FastBertGraph</div><div id='m_method'> M Method Name: forward(7)</div><div id='n_method'> N Method Name: forward(6)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: bert-squeeze/models/custom_transformers/fastbert.py</div><div id='n_file'> N File Name: bert-squeeze/models/custom_transformers/fastbert.py</div><div id='m_start'> M Start Line: 57</div><div id='m_end'> M End Line: 70</div><div id='n_start'> N Start Line: 49</div><div id='n_end'> N End Line: 87</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
			y = y.long()
			loss = self.Loss(preds_, torch.squeeze(y))
			return preds, loss
		<a id="change">return </a>preds

</code></pre><h3>After Change</h3><pre><code class='java'>
			preds = self.Linear(hs.contiguous().view(x.size(0), -1))
			preds_.append(preds)
			if y is not None:
				loss<a id="change">+=</a>self.Loss(preds, <a id="change">y[:,i].squeeze().long()</a>)
		preds_ = torch.stack(preds_, dim = 1)
		if y is not None:
			loss/=len(xs)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/dido1998/recurrent-independent-mechanisms/commit/d87a800096eaa36730cbabac535eea24973f3799#diff-e5165d0379320c04b38a0f79666ae179299255ae3019498345e3dd6fc2ef1521L253' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 1504244</div><div id='project'> Project Name: dido1998/recurrent-independent-mechanisms</div><div id='commit'> Commit Name: d87a800096eaa36730cbabac535eea24973f3799</div><div id='time'> Time: 2020-02-11</div><div id='author'> Author: adidolkar123@gmail.com</div><div id='file'> File Name: networks.py</div><div id='m_class'> M Class Name: CopyingModel</div><div id='n_method'> N Class Name: CopyingModel</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: networks.py</div><div id='n_file'> N File Name: networks.py</div><div id='m_start'> M Start Line: 255</div><div id='m_end'> M End Line: 276</div><div id='n_start'> N Start Line: 291</div><div id='n_end'> N End Line: 313</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        super().__init__()

    def forward(self, x):
        <a id="change">return </a>x
</code></pre><h3>After Change</h3><pre><code class='java'>
    def forward(self, img, *args, **kwargs):
        b, c, h, w, device, img_size, = *img.shape, img.device, self.image_size
        assert h == img_size and w == img_size, f&quotheight and width of image must be {img_size}&quot
        t<a id="change"> = </a><a id="change">torch.randint(0, self.num_timesteps, (b,), device=device).long()</a>

        img = normalize_to_neg_one_to_one(img)
        return self.p_losses(img, t, *args, **kwargs)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/med-seg-diff-pytorch/commit/e37e2110c991bb233438542af9b766b3e3b00739#diff-844b38754380e73816a9a883698d0be58ade3c98292bfe9b915c180f02596398L11' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 1504243</div><div id='project'> Project Name: lucidrains/med-seg-diff-pytorch</div><div id='commit'> Commit Name: e37e2110c991bb233438542af9b766b3e3b00739</div><div id='time'> Time: 2022-11-27</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: med_seg_diff_pytorch/med_seg_diff_pytorch.py</div><div id='m_class'> M Class Name: MedSegDiff</div><div id='n_method'> N Class Name: MedSegDiff</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: med_seg_diff_pytorch/med_seg_diff_pytorch.py</div><div id='n_file'> N File Name: med_seg_diff_pytorch/med_seg_diff_pytorch.py</div><div id='m_start'> M Start Line: 12</div><div id='m_end'> M End Line: 12</div><div id='n_start'> N Start Line: 646</div><div id='n_end'> N End Line: 651</div><BR>