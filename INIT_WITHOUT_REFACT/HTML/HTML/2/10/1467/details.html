<html><h3>Pattern ID :1467
</h3><img src='4311361.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        t_0 = self.l_4(t_0, attention_mask=decoder_attention_mask, position_bias=x1, encoder_hidden_states=x0, encoder_attention_mask=inverted_encoder_attention_mask, encoder_decoder_position_bias=x2)
        &#47&#47 returning:
        &#47&#47 T5ForConditionalGeneration/T5Stack[decoder]/T5Block[16]
        <a id="change">return </a>(t_0<a id="change"></a>,)

    def state_dict(self,*args,**kwargs):
        &#47&#47 we return the state dict of this part as it should be in the original model</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47 moving inputs to current device no op if already on the correct device
        attention_mask, decoder_attention_mask, inverted_encoder_attention_mask, x0, x1, x2 = move_tensors(unflatten(args,self.input_structure), self.device)
        t_0 = self.l_0(x1, attention_mask=attention_mask, position_bias=x0, encoder_hidden_states=None, encoder_attention_mask=None, encoder_decoder_position_bias=None)
        t_0<a id="change"> = </a>self.l_1(t_0, attention_mask=attention_mask, position_bias=x0, encoder_hidden_states=None, encoder_attention_mask=None, encoder_decoder_position_bias=None)
        t_0 = self.l_2(t_0)
        t_0 = self.l_3(t_0)
        t_1 = self.l_4(x2)
        t_1 = self.l_5(t_1, attention_mask=decoder_attention_mask, position_bias=None, encoder_hidden_states=t_0, encoder_attention_mask=inverted_encoder_attention_mask, encoder_decoder_position_bias=None)
        t_2<a id="change"> = </a>t_1[0]
        t_3<a id="change"> = </a>t_1[1]
        t_1<a id="change"> = t_1[2]</a>
        t_2 = self.l_6(t_2, attention_mask=decoder_attention_mask, position_bias=t_3, encoder_hidden_states=t_0, encoder_attention_mask=inverted_encoder_attention_mask, encoder_decoder_position_bias=t_1)
        t_2 = self.l_7(t_2, attention_mask=decoder_attention_mask, position_bias=t_3, encoder_hidden_states=t_0, encoder_attention_mask=inverted_encoder_attention_mask, encoder_decoder_position_bias=t_1)
        t_2 = self.l_8(t_2, attention_mask=decoder_attention_mask, position_bias=t_3, encoder_hidden_states=t_0, encoder_attention_mask=inverted_encoder_attention_mask, encoder_decoder_position_bias=t_1)
        t_2 = self.l_9(t_2, attention_mask=decoder_attention_mask, position_bias=t_3, encoder_hidden_states=t_0, encoder_attention_mask=inverted_encoder_attention_mask, encoder_decoder_position_bias=t_1)
        t_2 = self.l_10(t_2, attention_mask=decoder_attention_mask, position_bias=t_3, encoder_hidden_states=t_0, encoder_attention_mask=inverted_encoder_attention_mask, encoder_decoder_position_bias=t_1)
        t_2<a id="change"> = </a>self.l_11(t_2, attention_mask=decoder_attention_mask, position_bias=t_3, encoder_hidden_states=t_0, encoder_attention_mask=inverted_encoder_attention_mask, encoder_decoder_position_bias=t_1)
        &#47&#47 returning:
        &#47&#47 T5ForConditionalGeneration/T5Stack[encoder]/Dropout[dropout]
        &#47&#47 T5ForConditionalGeneration/T5Stack[decoder]/tuple::__getitem___130
        &#47&#47 T5ForConditionalGeneration/T5Stack[decoder]/tuple::__getitem___132
        &#47&#47 T5ForConditionalGeneration/T5Stack[decoder]/T5Block[6]
        <a id="change">return </a>list(flatten((t_0<a id="change">, t_3, t_1, t_2</a>)))

    def state_dict(self,*args,**kwargs):
        &#47&#47 we return the state dict of this part as it should be in the original model</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 5</div><BR><div id='size'>Non-data size: 10</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/saareliad/ftpipe/commit/e959641a351e7827214f66e1a3a0675b9059392e#diff-d0be6aca0bdc49b9a5cfa74ef6f4d9a78ebbf8a7f6c923df203d594715ce1306L963' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4311361</div><div id='project'> Project Name: saareliad/ftpipe</div><div id='commit'> Commit Name: e959641a351e7827214f66e1a3a0675b9059392e</div><div id='time'> Time: 2020-08-17</div><div id='author'> Author: saareliad@campus.technion.ac.il</div><div id='file'> File Name: models/partitioned/t5_large_tied_lmhead_8p_bw12_async_squad1.py</div><div id='m_class'> M Class Name: Partition6</div><div id='n_method'> N Class Name: Partition6</div><div id='m_method'> M Method Name: forward(1)</div><div id='n_method'> N Method Name: forward(1)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/partitioned/t5_large_tied_lmhead_8p_bw12_async_squad1.py</div><div id='n_file'> N File Name: models/partitioned/t5_large_tied_lmhead_8p_bw12_async_squad1.py</div><div id='m_start'> M Start Line: 1079</div><div id='m_end'> M End Line: 1087</div><div id='n_start'> N Start Line: 963</div><div id='n_end'> N End Line: 984</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        t_0 = self.l_1(t_0, attention_mask=attention_mask, position_bias=x0, encoder_hidden_states=None, encoder_attention_mask=None, encoder_decoder_position_bias=None)
        t_0 = self.l_2(t_0, attention_mask=attention_mask, position_bias=x0, encoder_hidden_states=None, encoder_attention_mask=None, encoder_decoder_position_bias=None)
        t_0 = self.l_3(t_0)
        t_0<a id="change"> = </a>self.l_4(t_0)
        t_1 = self.l_5(x2)
        t_1 = self.l_6(t_1, attention_mask=decoder_attention_mask, position_bias=None, encoder_hidden_states=t_0, encoder_attention_mask=inverted_encoder_attention_mask, encoder_decoder_position_bias=None)
        t_2<a id="change"> = </a>t_1[0]
        t_3<a id="change"> = </a>t_1[1]
        t_1<a id="change"> = t_1[2]</a>
        t_2<a id="change"> = </a>self.l_7(t_2, attention_mask=decoder_attention_mask, position_bias=t_3, encoder_hidden_states=t_0, encoder_attention_mask=inverted_encoder_attention_mask, encoder_decoder_position_bias=t_1)
        &#47&#47 returning:
        &#47&#47 T5ForConditionalGeneration/T5Stack[encoder]/Dropout[dropout]
        &#47&#47 T5ForConditionalGeneration/T5Stack[decoder]/tuple::__getitem___130
        &#47&#47 T5ForConditionalGeneration/T5Stack[decoder]/tuple::__getitem___132
        &#47&#47 T5ForConditionalGeneration/T5Stack[decoder]/T5Block[1]
        <a id="change">return </a>list(flatten((t_0<a id="change">, t_3, t_1, t_2</a>)))

    def state_dict(self,*args,**kwargs):
        &#47&#47 we return the state dict of this part as it should be in the original model</code></pre><h3>After Change</h3><pre><code class='java'>
        t_0 = self.l_3(t_0, attention_mask=attention_mask, position_bias=x0, encoder_hidden_states=None, encoder_attention_mask=None, encoder_decoder_position_bias=None)
        &#47&#47 returning:
        &#47&#47 T5ForConditionalGeneration/T5Stack[encoder]/T5Block[13]
        <a id="change">return </a>(t_0<a id="change"></a>,)

    def state_dict(self,*args,**kwargs):
        &#47&#47 we return the state dict of this part as it should be in the original model</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/saareliad/ftpipe/commit/e959641a351e7827214f66e1a3a0675b9059392e#diff-d0be6aca0bdc49b9a5cfa74ef6f4d9a78ebbf8a7f6c923df203d594715ce1306L795' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4311363</div><div id='project'> Project Name: saareliad/ftpipe</div><div id='commit'> Commit Name: e959641a351e7827214f66e1a3a0675b9059392e</div><div id='time'> Time: 2020-08-17</div><div id='author'> Author: saareliad@campus.technion.ac.il</div><div id='file'> File Name: models/partitioned/t5_large_tied_lmhead_8p_bw12_async_squad1.py</div><div id='m_class'> M Class Name: Partition3</div><div id='n_method'> N Class Name: Partition3</div><div id='m_method'> M Method Name: forward(1)</div><div id='n_method'> N Method Name: forward(1)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/partitioned/t5_large_tied_lmhead_8p_bw12_async_squad1.py</div><div id='n_file'> N File Name: models/partitioned/t5_large_tied_lmhead_8p_bw12_async_squad1.py</div><div id='m_start'> M Start Line: 812</div><div id='m_end'> M End Line: 829</div><div id='n_start'> N Start Line: 702</div><div id='n_end'> N End Line: 706</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        
        &#47&#47 TODO: loop if window_size is greater than 2 (for cycle loss)
        bsz, encoder_dim, n_points = keypoint_desc.size()
        batch_size<a id="change"> = </a>int(bsz / self.window_size)
        _, _, height, width = desc_dense.size()

        src_desc = keypoint_desc[::self.window_size]  &#47&#47 B x C x N
        src_desc = F.normalize(src_desc, dim=1)

        tgt_desc_dense<a id="change"> = desc_dense[1::self.window_size]</a>  &#47&#47 B x C x H x W
        tgt_desc_unrolled = F.normalize(tgt_desc_dense.view(batch_size, encoder_dim, -1), dim=1)  &#47&#47 B x C x HW

        match_vals = torch.matmul(src_desc.transpose(2, 1), tgt_desc_unrolled)  &#47&#47 B x N x HW
        soft_match_vals = F.softmax(match_vals / self.softmax_temp, dim=2)  &#47&#47 B x N x HW

        v_coord, u_coord = torch.meshgrid([torch.arange(0, height), torch.arange(0, width)])
        v_coord = v_coord.reshape(height * width).float()  &#47&#47 HW
        u_coord = u_coord.reshape(height * width).float()
        coords = torch.stack((u_coord, v_coord), dim=1)  &#47&#47 HW x 2
        tgt_coords_dense = coords.unsqueeze(0).expand(batch_size, height * width, 2).to(self.gpuid)  &#47&#47 B x HW x 2

        pseudo_coords = torch.matmul(tgt_coords_dense.transpose(2, 1),
                                     soft_match_vals.transpose(2, 1)).transpose(2, 1)  &#47&#47 BxNx2

        &#47&#47 GET SCORES for pseudo point locations
        pseudo_norm = normalize_coords(pseudo_coords, height, width).unsqueeze(1)          &#47&#47 B x 1 x N x 2
        tgt_scores_dense = scores_dense[1::self.window_size]
        pseudo_scores = F.grid_sample(tgt_scores_dense, pseudo_norm, mode=&quotbilinear&quot)           &#47&#47 B x 1 x 1 x N
        pseudo_scores = pseudo_scores.reshape(batch_size, 1, n_points)                          &#47&#47 B x 1 x N
        &#47&#47 GET DESCRIPTORS for pseudo point locations
        pseudo_desc = F.grid_sample(tgt_desc_dense, pseudo_norm, mode=&quotbilinear&quot)               &#47&#47 B x C x 1 x N
        pseudo_desc = pseudo_desc.reshape(batch_size, encoder_dim, n_points)                    &#47&#47 B x C x N

        desc_match_score = torch.sum(src_desc * pseudo_desc, dim=1, keepdim=True) / float(encoder_dim)  &#47&#47 Bx1xN
        src_scores = keypoint_scores[::self.window_size]
        if self.score_comp:
            match_weights = 0.5 * (desc_match_score + 1) * src_scores * pseudo_scores
        else:
            match_weights = pseudo_scores

        <a id="change">return </a>pseudo_coords<a id="change">, match_weights</a>

def normalize_coords(coords_2D, width, height):
    Normalizes coords_2D (B x N x 2) to be within [-1, 1] 
    batch_size = coords_2D.size(0)</code></pre><h3>After Change</h3><pre><code class='java'>
        _, _, height, width = desc_dense.size()
        kp_inds, dense_inds = get_indices(batch_size, self.window_size)

        src_desc<a id="change"> = </a>keypoint_desc[kp_inds]  &#47&#47 B x C x N
        src_desc = F.normalize(src_desc, dim=1)
        B<a id="change"> = </a>src_desc.size(0)

        tgt_desc_dense<a id="change"> = </a>desc_dense[dense_inds]  &#47&#47 B x C x H x W
        tgt_desc_unrolled = F.normalize(tgt_desc_dense.view(B, encoder_dim, -1), dim=1)  &#47&#47 B x C x HW

        match_vals = torch.matmul(src_desc.transpose(2, 1), tgt_desc_unrolled)  &#47&#47 B x N x HW
        soft_match_vals = F.softmax(match_vals / self.softmax_temp, dim=2)  &#47&#47 B x N x HW

        v_coord, u_coord = torch.meshgrid([torch.arange(0, height), torch.arange(0, width)])
        v_coord = v_coord.reshape(height * width).float()  &#47&#47 HW
        u_coord = u_coord.reshape(height * width).float()
        coords = torch.stack((u_coord, v_coord), dim=1)  &#47&#47 HW x 2
        tgt_coords_dense = coords.unsqueeze(0).expand(B, height * width, 2).to(self.gpuid)  &#47&#47 B x HW x 2

        pseudo_coords = torch.matmul(tgt_coords_dense.transpose(2, 1),
                                     soft_match_vals.transpose(2, 1)).transpose(2, 1)  &#47&#47 BxNx2

        &#47&#47 GET SCORES for pseudo point locations
        pseudo_norm = normalize_coords(pseudo_coords, height, width).unsqueeze(1)          &#47&#47 B x 1 x N x 2
        tgt_scores_dense = scores_dense[dense_inds]
        pseudo_scores = F.grid_sample(tgt_scores_dense, pseudo_norm, mode=&quotbilinear&quot)           &#47&#47 B x 1 x 1 x N
        pseudo_scores = pseudo_scores.reshape(B, 1, n_points)                          &#47&#47 B x 1 x N
        &#47&#47 GET DESCRIPTORS for pseudo point locations
        pseudo_desc = F.grid_sample(tgt_desc_dense, pseudo_norm, mode=&quotbilinear&quot)               &#47&#47 B x C x 1 x N
        pseudo_desc = pseudo_desc.reshape(B, encoder_dim, n_points)                    &#47&#47 B x C x N

        desc_match_score = torch.sum(src_desc * pseudo_desc, dim=1, keepdim=True) / float(encoder_dim)  &#47&#47 Bx1xN
        src_scores = keypoint_scores[kp_inds]
        if self.score_comp:
            match_weights = 0.5 * (desc_match_score + 1) * src_scores * pseudo_scores
        else:
            match_weights = pseudo_scores

        <a id="change">return </a>pseudo_coords<a id="change">, match_weights, kp_inds</a>

def normalize_coords(coords_2D, width, height):
    Normalizes coords_2D (B x N x 2) to be within [-1, 1] 
    batch_size = coords_2D.size(0)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/utiasasrl/hero_radar_odometry/commit/3393ae645f3b4eea057784a2cd3746aefb0c81b1#diff-23e0da2f9fd5de38a06280e99a19331414bae7133b397e03cf546a99b3ddce20L17' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4311379</div><div id='project'> Project Name: utiasasrl/hero_radar_odometry</div><div id='commit'> Commit Name: 3393ae645f3b4eea057784a2cd3746aefb0c81b1</div><div id='time'> Time: 2021-01-08</div><div id='author'> Author: keenburn2004@gmail.com</div><div id='file'> File Name: networks/softmax_matcher.py</div><div id='m_class'> M Class Name: SoftmaxMatcher</div><div id='n_method'> N Class Name: SoftmaxMatcher</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: networks/softmax_matcher.py</div><div id='n_file'> N File Name: networks/softmax_matcher.py</div><div id='m_start'> M Start Line: 26</div><div id='m_end'> M End Line: 63</div><div id='n_start'> N Start Line: 27</div><div id='n_end'> N End Line: 66</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        out, h_out = self.lstm(cat, h_in)
        
        prob = F.relu(self.norm_pi1(self.fc_pi1(out)))
        prob<a id="change"> = </a>self.fc_pi2(prob)
        prob = F.softmax(prob, dim=2)

        v = F.relu(self.norm_v1(self.fc_v1(out)))
        v = self.fc_v2(v)

        <a id="change">return </a>prob<a id="change">, v, h_out</a>

    def make_batch(self, data):
        &#47&#47 data = [tr1, tr2, ..., tr10] * batch_size
        s_player_batch, s_ball_batch, s_left_batch, s_left_closest_batch, s_right_batch, s_right_closest_batch=  [], [], [], [], [], []</code></pre><h3>After Change</h3><pre><code class='java'>
        left_closest_state = state_dict["left_closest"]
        right_team_state = state_dict["right_team"]  
        right_closest_state = state_dict["right_closest"]
        avail<a id="change"> = state_dict["avail"]</a>
        
        player_embed = self.norm_player(self.fc_player(player_state))
        ball_embed = self.norm_ball(self.fc_ball(ball_state))
        left_team_embed = self.norm_left(self.fc_left(left_team_state))
        left_closest_embed = self.norm_left_closest(self.fc_left_closest(left_closest_state))
        right_team_embed = self.norm_right(self.fc_right(right_team_state))
        right_closest_embed = self.norm_right_closest(self.fc_right_closest(right_closest_state))
        
        left_team_embed = self.pool(left_team_embed).squeeze(2)
        right_team_embed = self.pool(right_team_embed).squeeze(2)

        cat = torch.cat([player_embed, ball_embed, left_team_embed, right_team_embed, left_closest_embed, right_closest_embed], 2)
        cat = F.relu(self.norm_cat(self.fc_cat(cat)))
        h_in = state_dict["hidden"]
        out, h_out = self.lstm(cat, h_in)
        
        a_out = F.relu(self.norm_pi_a1(self.fc_pi_a1(out)))
        a_out<a id="change"> = </a>self.fc_pi_a2(a_out)
        logit = a_out + (avail-1)*1e8
        prob = F.softmax(logit, dim=2)
        
        prob_m = F.relu(self.norm_pi_m1(self.fc_pi_m1(out)))
        prob_m<a id="change"> = </a>self.fc_pi_m2(prob_m)
        prob_m<a id="change"> = </a>F.softmax(prob_m, dim=2)

        v = F.relu(self.norm_v1(self.fc_v1(out)))
        v = self.fc_v2(v)

        <a id="change">return </a>prob<a id="change">, prob_m, v, h_out</a>

    def make_batch(self, data):
        &#47&#47 data = [tr1, tr2, ..., tr10] * batch_size
        s_player_batch, s_ball_batch, s_left_batch, s_left_closest_batch, s_right_batch, s_right_closest_batch, avail_batch =  [],[],[],[],[],[],[]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/seungeunrho/football-paris/commit/98e6f2e9e75b4a124ecd2be32d7ece32abe24101#diff-83673cb4d5ed44d31919eb99e2dbb22fbc3ed2445ddaa2958b711a542e0be39bL48' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4311368</div><div id='project'> Project Name: seungeunrho/football-paris</div><div id='commit'> Commit Name: 98e6f2e9e75b4a124ecd2be32d7ece32abe24101</div><div id='time'> Time: 2020-10-26</div><div id='author'> Author: seungeun07@snu.ac.kr</div><div id='file'> File Name: Model/ppo.py</div><div id='m_class'> M Class Name: PPO</div><div id='n_method'> N Class Name: PPO</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: Model/ppo.py</div><div id='n_file'> N File Name: Model/ppo.py</div><div id='m_start'> M Start Line: 71</div><div id='m_end'> M End Line: 78</div><div id='n_start'> N Start Line: 59</div><div id='n_end'> N End Line: 88</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 it will be returned early.
        &#47&#47 Note: during inference batch_size needs to be 1
        if inference:
            uncertain_infos<a id="change"> = </a>[]
            for i, (layer_module, (k, layer_classifier_module)) in enumerate(
                    zip(self.layer, self.layer_classifiers.items())):
                hidden_states = layer_module(hidden_states[0], attention_mask)
                logits = layer_classifier_module(hidden_states[0])
                prob = F.softmax(logits, dim=-1)
                log_prob = F.log_softmax(logits, dim=-1)
                uncertain = torch.sum(prob * log_prob, 1) / (-torch.log(self.num_class))
                uncertain_infos.append([uncertain, prob])

                &#47&#47 return early results
                if uncertain &lt; inference_speed:
                    <a id="change">return </a>prob<a id="change">, i, uncertain_infos</a>
            return prob, i, uncertain_infos

        &#47&#47 Training phase: the first phase corresponds to the backbone training
        &#47&#47 the second phase to the branches training (actual distillation)</code></pre><h3>After Change</h3><pre><code class='java'>
        if inference:
            &#47&#47 positions will keep track of the original position of each element in the
            &#47&#47 batch when elements will be removed
            final_probs<a id="change"> = </a>torch.zeros((hidden_states[0].shape[0], 2), device=device)
            positions<a id="change"> = </a>torch.arange(start=0, end=hidden_states[0].shape[0], device=device).long()

            for i, (layer_module, (k, layer_classifier_module)) in enumerate(
                    zip(self.layer, self.layer_classifiers.items())):

                hidden_states = layer_module(hidden_states[0], attention_mask)
                logits = layer_classifier_module(hidden_states[0])
                prob = F.softmax(logits, dim=-1)
                log_prob = F.log_softmax(logits, dim=-1)
                uncertain = torch.sum(prob * log_prob, 1) / (-torch.log(self.num_class))

                &#47&#47 checking if there&quots enough information
                enough_info = uncertain &lt; inference_speed

                right_pos<a id="change"> = </a>positions[enough_info]
                final_probs[right_pos]<a id="change"> = prob[enough_info]</a>

                hidden_states = (hidden_states[0][~enough_info],)
                attention_mask = attention_mask[~enough_info]

                &#47&#47 if we have processed all the samples
                if hidden_states[0].shape[0] == 0:
                    <a id="change">return </a>final_probs<a id="change">, i</a>

                positions = positions[~enough_info]  &#47&#47 updating the positions to fit the new batch

            return final_probs, i</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/julesbelveze/bert-squeeze/commit/3cb14b8f1e742b86fe609843f2779e3bb36de4aa#diff-aac748de92a29499c39463320f41c1eaeb283dae0ed8ead9584db8318265a4acL49' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4311423</div><div id='project'> Project Name: julesbelveze/bert-squeeze</div><div id='commit'> Commit Name: 3cb14b8f1e742b86fe609843f2779e3bb36de4aa</div><div id='time'> Time: 2021-12-11</div><div id='author'> Author: 32683010+JulesBelveze@users.noreply.github.com</div><div id='file'> File Name: bert-squeeze/models/custom_transformers/fastbert.py</div><div id='m_class'> M Class Name: FastBertGraph</div><div id='n_method'> N Class Name: FastBertGraph</div><div id='m_method'> M Method Name: forward(7)</div><div id='n_method'> N Method Name: forward(6)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: bert-squeeze/models/custom_transformers/fastbert.py</div><div id='n_file'> N File Name: bert-squeeze/models/custom_transformers/fastbert.py</div><div id='m_start'> M Start Line: 57</div><div id='m_end'> M End Line: 70</div><div id='n_start'> N Start Line: 49</div><div id='n_end'> N End Line: 87</div><BR>