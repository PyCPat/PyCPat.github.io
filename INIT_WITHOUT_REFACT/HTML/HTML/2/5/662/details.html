<html><h3>Pattern ID :662
</h3><img src='2296898.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            mask = rearrange(mask, &quotb n -&gt; b () n ()&quot)
            k.masked_fill_(~mask, -torch.finfo(k.dtype).max)

        q = <a id="change">q.softmax(dim = -1)</a>
        k = k.softmax(dim = -2)

        q = q * self.scale

        if exists(mask):
            v.masked_fill_(~mask, 0.)

        context = einsum(&quotb h n d, b h n e -&gt; b h d e&quot, k, v)
        out<a id="change"> = </a>einsum(&quotb h d e, b h n d -&gt; b h n e&quot, context, q)
        out = rearrange(out, &quotb h n d -&gt; b n (h d)&quot)
        <a id="change">return </a>self.to_out(out)<a id="change">, 0</a>

class EquivariantAttention(nn.Module):
    def __init__(
        self,</code></pre><h3>After Change</h3><pre><code class='java'>
    def forward(self, x, queries, mask = None):
        induced = self.attn1(queries, x, mask = mask)
        out     = self.attn2(x, induced)
        <a id="change">return </a>out, 0

class EquivariantAttention(nn.Module):
    def __init__(</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lucidrains/en-transformer/commit/6bd1817d780502d24a2515e850c9cd1600f24642#diff-f288a1692c1c58a186cb9ac763046f632757db1647271b97852e59e3fc5696b9L132' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2296898</div><div id='project'> Project Name: lucidrains/en-transformer</div><div id='commit'> Commit Name: 6bd1817d780502d24a2515e850c9cd1600f24642</div><div id='time'> Time: 2021-06-04</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: en_transformer/en_transformer.py</div><div id='m_class'> M Class Name: GlobalLinearAttention</div><div id='n_method'> N Class Name: GlobalLinearAttention</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: en_transformer/en_transformer.py</div><div id='n_file'> N File Name: en_transformer/en_transformer.py</div><div id='m_start'> M Start Line: 132</div><div id='m_end'> M End Line: 151</div><div id='n_start'> N Start Line: 160</div><div id='n_end'> N End Line: 162</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        act1 = F.softmax(self.act1(x), dim=1)
        act2<a id="change"> = </a><a id="change">F.softmax(</a>self.act2(x)<a id="change">, dim=1)</a>
        <a id="change">return </a>act1<a id="change">, act2</a>

def mini_batch(buffer):
    batch = random.sample(buffer, batch_size)
    obs, acts, rewards, next_obs, done = [], [], [], [], []</code></pre><h3>After Change</h3><pre><code class='java'>
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        acts = [F.softmax(self.acts[idx](x), dim=1) for idx in range(num_act)]
        <a id="change">return </a>acts

def mini_batch(buffer):
    batch = random.sample(buffer, batch_size)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/rl-max/deep-reinforcement-learning-pytorch/commit/8d887659e1f8e488123279511313b2690ded38a6#diff-fe15883d6810d35395ad4a7612b9ad47eac3d12c25bad024697a2156fa15fdeeL29' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2296903</div><div id='project'> Project Name: rl-max/deep-reinforcement-learning-pytorch</div><div id='commit'> Commit Name: 8d887659e1f8e488123279511313b2690ded38a6</div><div id='time'> Time: 2021-04-07</div><div id='author'> Author: poiroth946@gmail.com</div><div id='file'> File Name: c51.py</div><div id='m_class'> M Class Name: QNet</div><div id='n_method'> N Class Name: QNet</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: c51.py</div><div id='n_file'> N File Name: c51.py</div><div id='m_start'> M Start Line: 31</div><div id='m_end'> M End Line: 34</div><div id='n_start'> N Start Line: 32</div><div id='n_end'> N End Line: 33</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if self.training:
            &#47&#47 Compute head probability distribution.
            logits_arc = logits_arc.softmax(-1)
            logits_label<a id="change"> = </a><a id="change">logits_label.softmax(</a>-1<a id="change">)</a>

        <a id="change">return </a>logits_arc<a id="change">, logits_label</a>
</code></pre><h3>After Change</h3><pre><code class='java'>
        logits = logits.squeeze(-1)

        if self.training:
            <a id="change">return </a>logits.softmax(-1)
        else:
            return logits
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/explosion/spacy-experimental/commit/b11c33d56db81f0be1a4e04fcda0042b9c500f37#diff-510501f7cb2d459202a440b1750a360ccbcdc4c5f42a0298478a064ab610aad0L97' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2296904</div><div id='project'> Project Name: explosion/spacy-experimental</div><div id='commit'> Commit Name: b11c33d56db81f0be1a4e04fcda0042b9c500f37</div><div id='time'> Time: 2021-10-29</div><div id='author'> Author: me@danieldk.eu</div><div id='file'> File Name: biaffine_parser/pytorch_biaffine_model.py</div><div id='m_class'> M Class Name: BiaffineModel</div><div id='n_method'> N Class Name: BiaffineModel</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: biaffine_parser/pytorch_biaffine_model.py</div><div id='n_file'> N File Name: biaffine_parser/pytorch_biaffine_model.py</div><div id='m_start'> M Start Line: 102</div><div id='m_end'> M End Line: 128</div><div id='n_start'> N Start Line: 95</div><div id='n_end'> N End Line: 117</div><BR>