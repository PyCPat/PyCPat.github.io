<html><h3>Pattern ID :1770
</h3><img src='6893544.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            real_number = real_number_tensor[i]
            real_number = real_number if real_number != 0 else 1
            for j, entity in enumerate(batch):
                <a id="change">if j &gt;= real_number_tensor[i]</a><a id="change">:
                    </a>break        
                mean_entity<a id="change"> = </a>mean_entity + entity
            mean_entity = mean_entity / (real_number)
            tensor_list.append(mean_entity.reshape(1, -1))
        tensor_mean = torch.cat(tensor_list, dim=0)</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 mask: [batch_size, max_entities]
        device = next(self.parameters()).device
        mask = <a id="change">mask.to(</a>device<a id="change">)</a>

        &#47&#47 assert the input shape is : batch_seq_size x entities_size x embeding_size
        &#47&#47 note: because the feature size of entity is not equal to 256, so it can not fed into transformer directly.
        &#47&#47 thus, we add a embedding layer to transfer it to right size.
        &#47&#47 x is batch_entities_tensor (dim = 3). Shape: batch_seq_size x entities_size x embeding_size
        x = self.embedd(x)
        print(&quotx.shape:&quot, x.shape) if debug else None

        &#47&#47 mask for transformer need a special format
        mask_seq_len = mask.shape[-1]
        tran_mask<a id="change"> = </a>mask.unsqueeze(1)

        &#47&#47 tran_mask: [batch_seq_size x max_entities x max_entities]
        tran_mask = tran_mask.repeat(1, mask_seq_len, 1)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 5</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/liuruoze/mini-alphastar/commit/612d42a7bf5ef827e1e919198d839fce106155cd#diff-71869e70f9cb835282d541d2d3529d25b6ed6795c79bc770e860e9318619f6b1L716' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6893544</div><div id='project'> Project Name: liuruoze/mini-alphastar</div><div id='commit'> Commit Name: 612d42a7bf5ef827e1e919198d839fce106155cd</div><div id='time'> Time: 2021-11-25</div><div id='author'> Author: liuruoze@163.com</div><div id='file'> File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='m_class'> M Class Name: EntityEncoder</div><div id='n_method'> N Class Name: EntityEncoder</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='n_file'> N File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='m_start'> M Start Line: 721</div><div id='m_end'> M End Line: 758</div><div id='n_start'> N Start Line: 716</div><div id='n_end'> N End Line: 778</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        u_coord = u_coord.reshape(height * width).float()
        coords = torch.stack((u_coord, v_coord), dim=1)  &#47&#47 HW x 2
        tgt_coords_dense = coords.unsqueeze(0).expand(batch_size, height * width, 2) &#47&#47 B x HW x 2
        <a id="change">if config[&quotgpuid&quot] != &quotcpu&quot</a><a id="change">:
            </a>tgt_coords_dense<a id="change"> = </a>tgt_coords_dense.cuda()

        pseudo_coords = torch.matmul(tgt_coords_dense.transpose(2, 1).contiguous(),
            soft_match_vals.transpose(2, 1).contiguous()).transpose(2, 1).contiguous()  &#47&#47 BxNx2</code></pre><h3>After Change</h3><pre><code class='java'>
        v_coord = v_coord.reshape(height * width).float()  &#47&#47 HW
        u_coord = u_coord.reshape(height * width).float()
        coords = torch.stack((u_coord, v_coord), dim=1)  &#47&#47 HW x 2
        tgt_coords_dense = <a id="change">coords.unsqueeze(0).expand(batch_size, height * width, 2).to(</a>self.gpuid<a id="change">)</a> &#47&#47 B x HW x 2

        pseudo_coords = torch.matmul(tgt_coords_dense.transpose(2, 1).contiguous(),
            soft_match_vals.transpose(2, 1).contiguous()).transpose(2, 1).contiguous()  &#47&#47 BxNx2

        &#47&#47 GET SCORES for pseudo point locations
        pseudo_norm<a id="change"> = </a>normalize_coords(pseudo_coords, height, width).unsqueeze(1)               &#47&#47 B x 1 x N x 2
        tgt_scores_dense = scores_dense[1::self.window_size]
        pseudo_scores = F.grid_sample(tgt_scores_dense, pseudo_norm, mode=&quotbilinear&quot)           &#47&#47 B x 1 x 1 x N
        pseduo_scores = pseduo_scores.reshape(batch_size, 1, n_points)                          &#47&#47 B x 1 x N</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/utiasasrl/hero_radar_odometry/commit/dcd5074dd5dff7bab272cddac2ba50b426590076#diff-23e0da2f9fd5de38a06280e99a19331414bae7133b397e03cf546a99b3ddce20L12' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6893551</div><div id='project'> Project Name: utiasasrl/hero_radar_odometry</div><div id='commit'> Commit Name: dcd5074dd5dff7bab272cddac2ba50b426590076</div><div id='time'> Time: 2020-11-13</div><div id='author'> Author: keenburn2004@gmail.com</div><div id='file'> File Name: networks/softmax_matcher.py</div><div id='m_class'> M Class Name: SoftmaxMatcher</div><div id='n_method'> N Class Name: SoftmaxMatcher</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: networks/softmax_matcher.py</div><div id='n_file'> N File Name: networks/softmax_matcher.py</div><div id='m_start'> M Start Line: 20</div><div id='m_end'> M End Line: 54</div><div id='n_start'> N Start Line: 21</div><div id='n_end'> N End Line: 52</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        batch_graph.node_features["rnn_emb"] = batch_graph.node_features[&quotnode_feat&quot]

        batch_graph_list_decoder_input = from_batch(batch_graph)
        <a id="change">if </a>self.use_copy and <a id="change">"token_id_oov" not in batch_graph.node_features.keys()</a><a id="change">:
            </a>for g, g_ in zip(batch_graph_list_decoder_input, graph_list):
                g.node_features[&quottoken_id_oov&quot]<a id="change"> = </a>g_.node_features[&quottoken_id_oov&quot]

        loss = self.decoder(g=batch_graph_list_decoder_input,
                            tgt_tree_batch=tgt_tree_batch, oov_dict=oov_dict)</code></pre><h3>After Change</h3><pre><code class='java'>
                                      tgt_vocab=self.tgt_vocab)

    def forward(self, batch_graph, tgt_tree_batch, oov_dict=None):
        batch_graph.batch_node_features["token_id"]<a id="change"> = </a><a id="change">batch_graph.batch_node_features["token_id"].to(</a>self.device<a id="change">)</a>
        batch_graph = self.graph_topology(batch_graph)
        batch_graph = self.encoder(batch_graph)
        batch_graph.node_features["rnn_emb"] = batch_graph.node_features[&quotnode_feat&quot]
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/graph4ai/graph4nlp/commit/352b1f48261e410927deb0040c99903e33475c21#diff-c3cd5f271f5d136f0361244f7d10a28d51ff1212bf0c5759c0bcedcbdf2618e7L186' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6893536</div><div id='project'> Project Name: graph4ai/graph4nlp</div><div id='commit'> Commit Name: 352b1f48261e410927deb0040c99903e33475c21</div><div id='time'> Time: 2021-04-07</div><div id='author'> Author: scheng_lee@qq.com</div><div id='file'> File Name: examples/pytorch/math_word_problem/src/runner_mathqa.py</div><div id='m_class'> M Class Name: Graph2Tree</div><div id='n_method'> N Class Name: Graph2Tree</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: examples/pytorch/math_word_problem/src/runner_mathqa.py</div><div id='n_file'> N File Name: examples/pytorch/math_word_problem/src/runner_mathqa.py</div><div id='m_start'> M Start Line: 187</div><div id='m_end'> M End Line: 196</div><div id='n_start'> N Start Line: 187</div><div id='n_end'> N End Line: 188</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                    affine_list.append(self.info_proj_linear(z_info))

            if self.g_cond_mtd != "W/O":
                <a id="change">if shared_label is None</a><a id="change">:
                    </a>shared_label<a id="change"> = </a>self.shared(label)
                affine_list.append(shared_label)
            if len(affine_list) &gt; 0:
                affines = torch.cat(affine_list, 1)</code></pre><h3>After Change</h3><pre><code class='java'>
    def forward(self, z, label, shared_label=None, eval=False):
        affine_list = []
        if self.g_cond_mtd != "W/O":
            label<a id="change"> = </a><a id="change">F.one_hot(label, num_classes=self.num_classes).to(</a>torch.float32<a id="change">)</a>
        with torch.cuda.amp.autocast() if self.mixed_precision and not eval else misc.dummy_context_mgr() as mp:
            if self.MODEL.info_type != "N/A":
                if self.g_info_injection == "concat":
                    z = self.info_mix_linear(z)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/postech-cvlab/pytorch-studiogan/commit/5de1fd6542062ad5f6618aa4acc0bfba4f68fcd3#diff-32f9903dd9a14d37c5300ee56d88ce85da3b030c80d54d5b026b73976800555cL138' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6893552</div><div id='project'> Project Name: postech-cvlab/pytorch-studiogan</div><div id='commit'> Commit Name: 5de1fd6542062ad5f6618aa4acc0bfba4f68fcd3</div><div id='time'> Time: 2022-03-05</div><div id='author'> Author: first287@naver.com</div><div id='file'> File Name: src/models/resnet.py</div><div id='m_class'> M Class Name: Generator</div><div id='n_method'> N Class Name: Generator</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/models/resnet.py</div><div id='n_file'> N File Name: src/models/resnet.py</div><div id='m_start'> M Start Line: 148</div><div id='m_end'> M End Line: 152</div><div id='n_start'> N Start Line: 139</div><div id='n_end'> N End Line: 151</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                    affine_list.append(self.info_proj_linear(z_info))

            if self.g_cond_mtd != "W/O":
                <a id="change">if shared_label is None</a><a id="change">:
                    </a>shared_label<a id="change"> = </a>self.shared(label)
                affine_list.append(shared_label)
            if len(affine_list) &gt; 0:
                affines = torch.cat(affine_list, 1)</code></pre><h3>After Change</h3><pre><code class='java'>
    def forward(self, z, label, shared_label=None, eval=False):
        affine_list = []
        if self.g_cond_mtd != "W/O":
            label<a id="change"> = </a><a id="change">F.one_hot(label, num_classes=self.num_classes).to(</a>torch.float32<a id="change">)</a>
        with torch.cuda.amp.autocast() if self.mixed_precision and not eval else misc.dummy_context_mgr() as mp:
            if self.MODEL.info_type != "N/A":
                if self.g_info_injection == "concat":
                    z = self.info_mix_linear(z)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/postech-cvlab/pytorch-studiogan/commit/5de1fd6542062ad5f6618aa4acc0bfba4f68fcd3#diff-931cdb3d837d9d48aff7ce2833ba70c5795c6f8b08abf23b68d9d1be4a377694L97' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 6893539</div><div id='project'> Project Name: postech-cvlab/pytorch-studiogan</div><div id='commit'> Commit Name: 5de1fd6542062ad5f6618aa4acc0bfba4f68fcd3</div><div id='time'> Time: 2022-03-05</div><div id='author'> Author: first287@naver.com</div><div id='file'> File Name: src/models/deep_conv.py</div><div id='m_class'> M Class Name: Generator</div><div id='n_method'> N Class Name: Generator</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/models/deep_conv.py</div><div id='n_file'> N File Name: src/models/deep_conv.py</div><div id='m_start'> M Start Line: 107</div><div id='m_end'> M End Line: 111</div><div id='n_start'> N Start Line: 98</div><div id='n_end'> N End Line: 110</div><BR>