<html><h3>Pattern ID :2641
</h3><img src='8625731.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            layer_num = ind + 1
            use_memory = layer_num in self.memory_layers

            memories = (<a id="change">next(</a>mem_iter<a id="change">), next(cmem_iter)</a>) if use_memory else None

            x, (mem_out, cmem_out), layer_aux_loss = attn(x, memories = memories, calc_memory = use_memory, input_mask = mask, pos_emb = pos_emb)
            x, = ff(x)</code></pre><h3>After Change</h3><pre><code class='java'>
            use_memory = layer_num in self.memory_layers

            memories = None
            if <a id="change">use_memory</a>:
                memories = (<a id="change">next(</a>mem_iter<a id="change">), next(cmem_iter)</a>)

            x, (mem_out, cmem_out), layer_aux_loss = attn(x, memories = memories, calc_memory = use_memory, input_mask = mask, pos_emb = pos_emb)
            x, = ff(x)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lucidrains/compressive-transformer-pytorch/commit/e82fe1fa4efce3fbdb3ed5fb127872f9bcc0b7df#diff-493cd95e4b724ba15b0c327254df365435ee9204e2a14c51200a07a55d030b8dL279' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8625731</div><div id='project'> Project Name: lucidrains/compressive-transformer-pytorch</div><div id='commit'> Commit Name: e82fe1fa4efce3fbdb3ed5fb127872f9bcc0b7df</div><div id='time'> Time: 2020-07-03</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: compressive_transformer_pytorch/compressive_transformer_pytorch.py</div><div id='m_class'> M Class Name: CompressiveTransformer</div><div id='n_method'> N Class Name: CompressiveTransformer</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: compressive_transformer_pytorch/compressive_transformer_pytorch.py</div><div id='n_file'> N File Name: compressive_transformer_pytorch/compressive_transformer_pytorch.py</div><div id='m_start'> M Start Line: 279</div><div id='m_end'> M End Line: 296</div><div id='n_start'> N Start Line: 295</div><div id='n_end'> N End Line: 301</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

            memories = None
            if use_memory:
                memories = (next(mem_iter)<a id="change">, next(cmem_iter)</a>)

            x, (mem_out, cmem_out), layer_aux_loss = attn(x, memories = memories, calc_memory = use_memory, input_mask = mask, pos_emb = pos_emb)
            x, = ff(x)</code></pre><h3>After Change</h3><pre><code class='java'>
            layer_num = ind + 1

            use_memory = layer_num in self.memory_layers
            memories = (next(mem_iter)<a id="change">, next(cmem_iter)</a>) if <a id="change">use_memory</a> else None

            x, (mem_out, cmem_out), layer_aux_loss = attn(x, memories = memories, calc_memory = use_memory, input_mask = mask, pos_emb = pos_emb)
            x,  = ff(x)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/compressive-transformer-pytorch/commit/a7396bd065e5edcdb7f4c884a891e3f2e7da0606#diff-493cd95e4b724ba15b0c327254df365435ee9204e2a14c51200a07a55d030b8dL312' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8625730</div><div id='project'> Project Name: lucidrains/compressive-transformer-pytorch</div><div id='commit'> Commit Name: a7396bd065e5edcdb7f4c884a891e3f2e7da0606</div><div id='time'> Time: 2020-07-22</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: compressive_transformer_pytorch/compressive_transformer_pytorch.py</div><div id='m_class'> M Class Name: CompressiveTransformer</div><div id='n_method'> N Class Name: CompressiveTransformer</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: compressive_transformer_pytorch/compressive_transformer_pytorch.py</div><div id='n_file'> N File Name: compressive_transformer_pytorch/compressive_transformer_pytorch.py</div><div id='m_start'> M Start Line: 338</div><div id='m_end'> M End Line: 351</div><div id='n_start'> N Start Line: 339</div><div id='n_end'> N End Line: 351</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        for ind, (attn, ff) in enumerate(zip(self.attn_layers, self.ff_layers)):
            layer_num = ind + 1
            use_memory = layer_num in self.memory_layers
            memories = <a id="change">next(</a>mem_iter<a id="change">), lmem if use_memory else None</a>

            if use_memory:
                hiddens.append(x)
</code></pre><h3>After Change</h3><pre><code class='java'>
        for ind, (attn, ff) in enumerate(zip(self.attn_layers, self.ff_layers)):
            layer_num = ind + 1
            use_memory = layer_num in self.memory_layers
            memories = (<a id="change">next(</a>mem_iter<a id="change">), lmem</a>) if <a id="change">use_memory</a> else None

            if use_memory:
                hiddens.append(x)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/memory-transformer-xl/commit/8d25bac85975ec46b1ccbd03f5c25ff181146eb0#diff-a0bf60cdef5ad628f9a83f0454c9c66a535268529835e839bb54088805dba051L379' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8625737</div><div id='project'> Project Name: lucidrains/memory-transformer-xl</div><div id='commit'> Commit Name: 8d25bac85975ec46b1ccbd03f5c25ff181146eb0</div><div id='time'> Time: 2020-07-30</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: memory_transformer_xl/memory_transformer_xl.py</div><div id='m_class'> M Class Name: MemoryTransformerXL</div><div id='n_method'> N Class Name: MemoryTransformerXL</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: memory_transformer_xl/memory_transformer_xl.py</div><div id='n_file'> N File Name: memory_transformer_xl/memory_transformer_xl.py</div><div id='m_start'> M Start Line: 392</div><div id='m_end'> M End Line: 406</div><div id='n_start'> N Start Line: 392</div><div id='n_end'> N End Line: 406</div><BR>