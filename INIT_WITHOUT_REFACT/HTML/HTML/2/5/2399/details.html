<html><h3>Pattern ID :2399
</h3><img src='8078959.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
                   "{}/logits_fake".format(split): logits_fake.detach().mean()
                   }

            if <a id="change">self.training and disc_factor and global_step % 16 == 0</a>:
                gradients, = torch.autograd.grad(outputs=logits_real.sum(), inputs=inputs, create_graph=True)
                gradients = gradients.view(inputs.shape[0], -1)
</code></pre><h3>After Change</h3><pre><code class='java'>
        if optimizer_idx == 1:
            &#47&#47 second pass for discriminator update
            disc_factor = 1 if global_step &gt;= self.discriminator_iter_start else 0
            do_r1 = <a id="change">self.training and bool(disc_factor) and global_step % 16 == 0</a>

            logits_real = self.discriminator(inputs.detach().requires_grad_(do_r1))
            logits_fake = self.discriminator(reconstructions.detach())
            
            d_loss = disc_factor * self.disc_loss(logits_fake, logits_real)
            if do_r1:
                gradients, = torch.autograd.grad(outputs=logits_real.sum(), inputs=inputs, create_graph=True)
                gradients = gradients.view(inputs.shape[0], -1)

                gradients_norm = gradients.norm(2, dim=1).pow(2).mean()
                d_loss += 10 * gradients_norm/2

            log = {"{}/disc_loss".format(split): d_loss.detach(),
                   "{}/logits_real".format(split): logits_real.detach().mean(),
                   "{}/logits_fake".format(split): logits_fake.detach().mean()
                   }

            <a id="change">if </a>do_r1<a id="change">:
                </a>log["{}/r1_reg".format(split)] = gradients_norm.detach()
            
            return d_loss, log
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/thuangb/enhancing-transformers/commit/2d20f168741dde3d04f60b3fb3f9256f7827ef2e#diff-3c6ac22014c2f11bfe22feae8ab09e7f751bb723b3867ab3979a4fa3672f4283L103' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8078959</div><div id='project'> Project Name: thuangb/enhancing-transformers</div><div id='commit'> Commit Name: 2d20f168741dde3d04f60b3fb3f9256f7827ef2e</div><div id='time'> Time: 2022-06-14</div><div id='author'> Author: 87744278+thuangb@users.noreply.github.com</div><div id='file'> File Name: enhancing/losses/vqperceptual.py</div><div id='m_class'> M Class Name: VQLPIPSWithDiscriminator</div><div id='n_method'> N Class Name: VQLPIPSWithDiscriminator</div><div id='m_method'> M Method Name: forward(8)</div><div id='n_method'> N Method Name: forward(8)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: enhancing/losses/vqperceptual.py</div><div id='n_file'> N File Name: enhancing/losses/vqperceptual.py</div><div id='m_start'> M Start Line: 103</div><div id='m_end'> M End Line: 168</div><div id='n_start'> N Start Line: 103</div><div id='n_end'> N End Line: 168</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if residual is None:
            residual = x

        if <a id="change">self.input_size == 1 and self.hidden_size == 1</a>:
            return residual

        x = self.fc1(x)</code></pre><h3>After Change</h3><pre><code class='java'>
        if residual is None:
            residual = x

        <a id="change">if </a><a id="change">self.input_size == 1 and self.hidden_size == 1:
            </a>x = torch.zeros_like(residual, device=residual.device)
            x = self.add_norm(x, residual)
            return x
        else:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/jdb78/pytorch-forecasting/commit/b86eaa01b49a5108df9780b9dded33086a9dda80#diff-9a8b783572f864adbf7d350ca9150d50513b8e1d871585f96c7310e6336d1c87L138' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8078958</div><div id='project'> Project Name: jdb78/pytorch-forecasting</div><div id='commit'> Commit Name: b86eaa01b49a5108df9780b9dded33086a9dda80</div><div id='time'> Time: 2020-08-07</div><div id='author'> Author: beitner.jan@bcg.com</div><div id='file'> File Name: pytorch_forecasting/models/temporal_fusion_transformer/sub_modules.py</div><div id='m_class'> M Class Name: GatedResidualNetwork</div><div id='n_method'> N Class Name: GatedResidualNetwork</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: pytorch_forecasting/models/temporal_fusion_transformer/sub_modules.py</div><div id='n_file'> N File Name: pytorch_forecasting/models/temporal_fusion_transformer/sub_modules.py</div><div id='m_start'> M Start Line: 139</div><div id='m_end'> M End Line: 154</div><div id='n_start'> N Start Line: 159</div><div id='n_end'> N End Line: 176</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if self.cal_f != 0 and self.cal is not None:
            lsnr_gt = self.lsnr(clean, noise=noisy - clean, max_bin=self.nb_df)
            cal = self.cal(df_alpha, target_lsnr=lsnr_gt)
        if <a id="change">self.store_losses and self.istft is not None</a>:
            enhanced_td = self.istft(enhanced)
            clean_td = self.istft(clean)
            self.store_summaries(enhanced_td, clean_td, snrs, ml, sl, cal)</code></pre><h3>After Change</h3><pre><code class='java'>
        if self.cal_f != 0 and self.cal is not None:
            lsnr_gt = self.lsnr(clean, noise=noisy - clean, max_bin=self.nb_df)
            cal = self.cal(df_alpha, target_lsnr=lsnr_gt)
        <a id="change">if </a><a id="change">self.store_losses and self.istft is not None:
            </a>self.store_summaries(enhanced_td, clean_td, snrs, ml, sl, cal)  &#47&#47 type: ignore
        return ml + sl + cal

    def reset_summaries(self):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/rikorose/deepfilternet/commit/767f713efb53582ac5d91ab365e5ef0f2be57c22#diff-bb896194128eb37561935a04f142d629f33c23c5617c6717dd129c556d97e5c3L351' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8078963</div><div id='project'> Project Name: rikorose/deepfilternet</div><div id='commit'> Commit Name: 767f713efb53582ac5d91ab365e5ef0f2be57c22</div><div id='time'> Time: 2022-01-14</div><div id='author'> Author: h.schroeter@pm.me</div><div id='file'> File Name: DeepFilterNet/df/loss.py</div><div id='m_class'> M Class Name: Loss</div><div id='n_method'> N Class Name: Loss</div><div id='m_method'> M Method Name: forward(9)</div><div id='n_method'> N Method Name: forward(9)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: DeepFilterNet/df/loss.py</div><div id='n_file'> N File Name: DeepFilterNet/df/loss.py</div><div id='m_start'> M Start Line: 378</div><div id='m_end'> M End Line: 382</div><div id='n_start'> N Start Line: 447</div><div id='n_end'> N End Line: 466</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 TODO line 482 in albef/models/xbert.py
        &#47&#47 compatibility for ALBEF and BLIP
        if <a id="change">mode in ["multimodal", "fusion"] and hasattr(self, "crossattention")</a>:
            assert (
                encoder_hidden_states is not None
            ), "encoder_hidden_states must be given for cross-attention layers"</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 TODO line 482 in albef/models/xbert.py
        &#47&#47 compatibility for ALBEF and BLIP
        <a id="change">if </a><a id="change">mode in ["multimodal", "fusion"] and hasattr(self, "crossattention"):
            </a>assert (
                encoder_hidden_states is not None
            ), "encoder_hidden_states must be given for cross-attention layers"
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/salesforce/lavis/commit/8e1fe6000035bca09d390796e5be6893908dff8b#diff-2c04f882086a279a2aceda292050e69aa8ad368fb0f174b50c90c9a5d3fda036L406' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8078962</div><div id='project'> Project Name: salesforce/lavis</div><div id='commit'> Commit Name: 8e1fe6000035bca09d390796e5be6893908dff8b</div><div id='time'> Time: 2022-05-30</div><div id='author'> Author: dongxu_li@outlook.com</div><div id='file'> File Name: lavis/models/med.py</div><div id='m_class'> M Class Name: BertLayer</div><div id='n_method'> N Class Name: BertLayer</div><div id='m_method'> M Method Name: forward(9)</div><div id='n_method'> N Method Name: forward(9)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: lavis/models/med.py</div><div id='n_file'> N File Name: lavis/models/med.py</div><div id='m_start'> M Start Line: 435</div><div id='m_end'> M End Line: 452</div><div id='n_start'> N Start Line: 428</div><div id='n_end'> N End Line: 471</div><BR>