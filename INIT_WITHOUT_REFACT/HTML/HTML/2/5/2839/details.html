<html><h3>Pattern ID :2839
</h3><img src='9433999.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 note, different batch may contain different number of real entities
        tensor_list = []
        for i, batch in enumerate(out):
            mean_entity<a id="change"> = </a>0.
            real_number = real_number_tensor[i]
            real_number = real_number if real_number != 0 else 1
            for j, entity in enumerate(batch):
                <a id="change">if </a>j &gt;= real_number_tensor[i]<a id="change">:
                    </a>break        
                mean_entity<a id="change"> = </a>mean_entity + entity
            mean_entity = mean_entity / (real_number)
            tensor_list.append(mean_entity.reshape(1, -1))
        tensor_mean = torch.cat(tensor_list, dim=0)</code></pre><h3>After Change</h3><pre><code class='java'>
        print(&quotentity_num:&quot, entity_num) if debug else None

        &#47&#47 generate the mask for transformer
        mask = <a id="change">torch.arange(</a>0, self.max_entities<a id="change">)</a>.float()
        mask = mask.repeat(batch_size, 1)
        mask = mask &lt; entity_num.unsqueeze(dim=1)

        print(&quotmask:&quot, mask) if debug else None
        print(&quotmask.shape:&quot, mask.shape) if debug else None

        &#47&#47 mask: [batch_size, max_entities]
        device = next(self.parameters()).device
        mask = mask.to(device)

        &#47&#47 assert the input shape is : batch_seq_size x entities_size x embeding_size
        &#47&#47 note: because the feature size of entity is not equal to 256, so it can not fed into transformer directly.
        &#47&#47 thus, we add a embedding layer to transfer it to right size.
        &#47&#47 x is batch_entities_tensor (dim = 3). Shape: batch_seq_size x entities_size x embeding_size
        x = self.embedd(x)
        print(&quotx.shape:&quot, x.shape) if debug else None

        &#47&#47 mask for transformer need a special format
        mask_seq_len = mask.shape[-1]
        tran_mask = mask.unsqueeze(1)

        &#47&#47 tran_mask: [batch_seq_size x max_entities x max_entities]
        tran_mask<a id="change"> = </a>tran_mask.repeat(1, mask_seq_len, 1)

        &#47&#47 out: [batch_seq_size x entities_size x embeding_size]
        out = self.transformer(x, mask=tran_mask)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/liuruoze/mini-alphastar/commit/612d42a7bf5ef827e1e919198d839fce106155cd#diff-71869e70f9cb835282d541d2d3529d25b6ed6795c79bc770e860e9318619f6b1L716' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9433999</div><div id='project'> Project Name: liuruoze/mini-alphastar</div><div id='commit'> Commit Name: 612d42a7bf5ef827e1e919198d839fce106155cd</div><div id='time'> Time: 2021-11-25</div><div id='author'> Author: liuruoze@163.com</div><div id='file'> File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='m_class'> M Class Name: EntityEncoder</div><div id='n_method'> N Class Name: EntityEncoder</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='n_file'> N File Name: alphastarmini/core/arch/entity_encoder.py</div><div id='m_start'> M Start Line: 721</div><div id='m_end'> M End Line: 758</div><div id='n_start'> N Start Line: 716</div><div id='n_end'> N End Line: 778</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if not exists(self.rel_pos) or not self.cache_rel_pos:
            positions = [torch.arange(d, device = device) for d in dimensions]
            grid = torch.stack(torch.meshgrid(*positions, indexing = &quotij&quot))
            grid<a id="change"> = </a>rearrange(grid, &quotc ... -&gt; (...) c&quot)
            rel_pos = rearrange(grid, &quoti c -&gt; i 1 c&quot) - rearrange(grid, &quotj c -&gt; 1 j c&quot)

            <a id="change">if </a>self.log_dist<a id="change">:
                </a>rel_pos<a id="change"> = </a>torch.sign(rel_pos) * torch.log(rel_pos.abs() + 1)

            self.register_buffer(&quotrel_pos&quot, rel_pos, persistent = False)
</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 get all relative positions across all dimensions

        rel_positions<a id="change"> = </a>[<a id="change">torch.arange(</a>-d + 1, d<a id="change">, device = device)</a> for d in dimensions]
        rel_pos_grid = torch.stack(torch.meshgrid(*rel_positions, indexing = &quotij&quot), dim = -1)
        rel_pos_grid = rearrange(rel_pos_grid, &quot... c -&gt; (...) c&quot)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/make-a-video-pytorch/commit/b6e0a17c5488b923d884272f7e46170352b0f0d5#diff-a7a81e9a1aa252916dd3f29e813ef72db53e9b9a100d00fdf0a022c1823ac77bL107' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9433960</div><div id='project'> Project Name: lucidrains/make-a-video-pytorch</div><div id='commit'> Commit Name: b6e0a17c5488b923d884272f7e46170352b0f0d5</div><div id='time'> Time: 2023-03-18</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: make_a_video_pytorch/make_a_video.py</div><div id='m_class'> M Class Name: ContinuousPositionBias</div><div id='n_method'> N Class Name: ContinuousPositionBias</div><div id='m_method'> M Method Name: forward(1)</div><div id='n_method'> N Method Name: forward(1)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: make_a_video_pytorch/make_a_video.py</div><div id='n_file'> N File Name: make_a_video_pytorch/make_a_video.py</div><div id='m_start'> M Start Line: 110</div><div id='m_end'> M End Line: 126</div><div id='n_start'> N Start Line: 105</div><div id='n_end'> N End Line: 142</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            timespans = x.new_ones(x.shape[:-1]+(1,)) / x.shape[1]

        for t in range(seq_len):
            inputs<a id="change"> = </a>x[:, t]
            ts = timespans[:, t].squeeze()
            hidden_state = self.rnn_cell.forward(inputs, hidden_state, ts)
            current_output = self.fc(hidden_state[0])
            outputs.append(current_output)
            last_output = current_output
        <a id="change">if </a>self.return_sequences<a id="change">:
            </a>outputs = torch.stack(outputs, dim=1)  &#47&#47 return entire sequence
        else:
            outputs<a id="change"> = </a>last_output  &#47&#47 only last item
        return outputs, hidden_state</code></pre><h3>After Change</h3><pre><code class='java'>
        L = u.size(-1)
        if lengths is not None:
            assert isinstance(lengths, torch.Tensor) and lengths.ndim == 1 and lengths.size(0) in [1, u.size(0)]
            mask = torch.where(<a id="change">torch.arange(</a>L<a id="change">, device=lengths.device)</a> &lt; lengths[:, None, None], 1., 0.)
            u = u * mask

        device = u.device
        batch_size<a id="change"> = </a>u.size(0)
        seq_len = u.size(1)
        hidden_state = [
            torch.zeros((batch_size, self.d_hidden), device=device),</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/raminmh/liquid-s4/commit/52f2ec0442e4b1472915480269dff07788ed7f97#diff-ab2372bdc1906ad2a23c39f4d39f3f048c08b9f7b91891862db640d26d4916afL83' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 9433923</div><div id='project'> Project Name: raminmh/liquid-s4</div><div id='commit'> Commit Name: 52f2ec0442e4b1472915480269dff07788ed7f97</div><div id='time'> Time: 2022-08-30</div><div id='author'> Author: mlech26l@gmail.com</div><div id='file'> File Name: src/models/sequence/mm.py</div><div id='m_class'> M Class Name: mmRNN</div><div id='n_method'> N Class Name: mmRNN</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/models/sequence/mm.py</div><div id='n_file'> N File Name: src/models/sequence/mm.py</div><div id='m_start'> M Start Line: 83</div><div id='m_end'> M End Line: 108</div><div id='n_start'> N Start Line: 89</div><div id='n_end'> N End Line: 123</div><BR>