<html><h3>Pattern ID :914
</h3><img src='2829147.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        if self.mode == &quotmse&quot:
            return ((fea_s-fea_t)**2).mean() * self.factor

        <a id="change">if </a>self.mode == &quotpdf&quot<a id="change">:
            </a>with torch.no_grad():
                x1 = conf_t.sigmoid()
                x2 = conf_s.sigmoid()
                disagree = (x1 - x2) ** 2
                disagree = disagree.sum(-1).unsqueeze(1).sqrt()
                if self.multi_anchor:
                    disagree = F.avg_pool1d(disagree, kernel_size=6, stride=6, padding=0)
                disagree = disagree.permute(0,2,1).expand_as(fea_t)
                weight = disagree / disagree.sum()
            <a id="change">return </a>(weight*((fea_s-fea_t)**2)).sum() * self.factor

        raise NotImplementedError</code></pre><h3>After Change</h3><pre><code class='java'>
    def forward(self, pred_t, pred_s, priors, targets):

        loc_t, conf_t, fea_t = pred_t[&quotloc&quot], pred_t[&quotconf&quot], pred_t[&quotfeature&quot]
        loc_t<a id="change">, conf_t, fea_t</a> = loc_t.detach(), <a id="change">conf_t.detach()</a>, fea_t.detach()
        loc_s, conf_s, fea_s = pred_s[&quotloc&quot], pred_s[&quotconf&quot], pred_s[&quotfeature&quot]

        if self.mode == &quotmse&quot:</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 4</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/zhangheng19931123/mutualguide/commit/d9f6d3090253f102f88a9b09b343ba674d3a4367#diff-d2bcfaf4bcb171ba68596d7ed8e728035e9ce7a200837f5e0f100638c72874f1L18' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2829147</div><div id='project'> Project Name: zhangheng19931123/mutualguide</div><div id='commit'> Commit Name: d9f6d3090253f102f88a9b09b343ba674d3a4367</div><div id='time'> Time: 2021-12-08</div><div id='author'> Author: heng.zhang@irisa.fr</div><div id='file'> File Name: utils/loss/hint_loss.py</div><div id='m_class'> M Class Name: HintLoss</div><div id='n_method'> N Class Name: HintLoss</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(8)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: utils/loss/hint_loss.py</div><div id='n_file'> N File Name: utils/loss/hint_loss.py</div><div id='m_start'> M Start Line: 18</div><div id='m_end'> M End Line: 35</div><div id='n_start'> N Start Line: 20</div><div id='n_end'> N End Line: 46</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        if self.mode == &quotmse&quot:
            return ((fea_s-fea_t)**2).mean() * self.factor

        <a id="change">if </a>self.mode == &quotpdf&quot<a id="change">:
            </a>with torch.no_grad():
                x1 = conf_t.sigmoid()
                x2 = conf_s.sigmoid()
                disagree = (x1 - x2) ** 2
                disagree = disagree.sum(-1).unsqueeze(1).sqrt()
                if self.multi_anchor:
                    disagree = F.avg_pool1d(disagree, kernel_size=6, stride=6, padding=0)
                disagree = disagree.permute(0,2,1).expand_as(fea_t)
                weight = disagree / disagree.sum()
            <a id="change">return </a>(weight*((fea_s-fea_t)**2)).sum() * self.factor

        raise NotImplementedError</code></pre><h3>After Change</h3><pre><code class='java'>

    def forward(self, pred_t, pred_s, priors, targets):

        loc_t<a id="change">, conf_t, fea_t</a> = pred_t[&quotloc&quot], pred_t[&quotconf&quot], pred_t[&quotfeature&quot]
        loc_t, conf_t, fea_t = loc_t.detach(), <a id="change">conf_t.detach()</a>, fea_t.detach()
        loc_s, conf_s, fea_s = pred_s[&quotloc&quot], pred_s[&quotconf&quot], pred_s[&quotfeature&quot]

        if self.mode == &quotmse&quot:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/zhangheng19931123/mutualguide/commit/d9f6d3090253f102f88a9b09b343ba674d3a4367#diff-d2bcfaf4bcb171ba68596d7ed8e728035e9ce7a200837f5e0f100638c72874f1L18' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2829146</div><div id='project'> Project Name: zhangheng19931123/mutualguide</div><div id='commit'> Commit Name: d9f6d3090253f102f88a9b09b343ba674d3a4367</div><div id='time'> Time: 2021-12-08</div><div id='author'> Author: heng.zhang@irisa.fr</div><div id='file'> File Name: utils/loss/hint_loss.py</div><div id='m_class'> M Class Name: HintLoss</div><div id='n_method'> N Class Name: HintLoss</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(8)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: utils/loss/hint_loss.py</div><div id='n_file'> N File Name: utils/loss/hint_loss.py</div><div id='m_start'> M Start Line: 18</div><div id='m_end'> M End Line: 35</div><div id='n_start'> N Start Line: 20</div><div id='n_end'> N End Line: 46</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        return softmax

    def forward(self, logits, samples, soft):
        <a id="change">if </a>samples is None<a id="change">:
            return </a>self.gumbel_softmax(logits, self._temperature, self._eps, hard=True)
        else:
            return -torch.sum(-samples * F.log_softmax(logits, -1), -1)
</code></pre><h3>After Change</h3><pre><code class='java'>
    def forward(self, logits: torch.Tensor, tau: float = 1, hard: bool = False, dim: int = -1):
        gumbels = -torch.empty_like(logits, memory_format=torch.legacy_contiguous_format).exponential_().log()  &#47&#47 ~Gumbel(0,1)
        gumbels = (logits + gumbels) / tau  &#47&#47 ~Gumbel(logits,tau)
        <a id="change">y_soft</a> = gumbels.softmax(dim)

        if hard:
            &#47&#47 Straight through.
            index = y_soft.max(dim, keepdim=True)[1]
            y_hard = torch.zeros_like(logits, memory_format=torch.legacy_contiguous_format).scatter_(dim, index, 1.0)
            ret = y_hard - <a id="change">y_soft.detach()</a> + y_soft
        else:
            &#47&#47 Reparametrization trick.
            ret = y_soft
        return ret<a id="change">, y_soft</a>
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/xiaosu-zhu/mcquic/commit/e12be331e275549e5b8a7ef6a7c8dbf6d4e387bf#diff-78f56a8e01e054eb5275963e005db8baab5fb8a2f945a6f3947cc3a95166a313L40' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2829143</div><div id='project'> Project Name: xiaosu-zhu/mcquic</div><div id='commit'> Commit Name: e12be331e275549e5b8a7ef6a7c8dbf6d4e387bf</div><div id='time'> Time: 2021-04-08</div><div id='author'> Author: xiaosu.zhu@outlook.com</div><div id='file'> File Name: src/mcqc/layers/gumbelSoftmax.py</div><div id='m_class'> M Class Name: GumbelSoftmax</div><div id='n_method'> N Class Name: GumbelSoftmax</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/mcqc/layers/gumbelSoftmax.py</div><div id='n_file'> N File Name: src/mcqc/layers/gumbelSoftmax.py</div><div id='m_start'> M Start Line: 40</div><div id='m_end'> M End Line: 44</div><div id='n_start'> N Start Line: 8</div><div id='n_end'> N End Line: 21</div><BR>