<html><h3>Pattern ID :971
</h3><img src='3118733.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

        &#47&#47 setting the device

        <a id="change">if </a>not <a id="change">exists(</a>accelerator<a id="change">)</a> and not exists(device)<a id="change">:
            </a>diffusion_prior_device<a id="change"> = </a>next(diffusion_prior.parameters()).device
            self.print(f&quotaccelerator not given, and device not specified: defaulting to device of diffusion prior parameters - {diffusion_prior_device}&quot)
            self.device = diffusion_prior_device
        else:</code></pre><h3>After Change</h3><pre><code class='java'>
        
        self.scheduler = LambdaLR(self.optimizer, lr_lambda = lambda _: 1.0)
        
        self.warmup_scheduler = warmup.LinearWarmup(self.optimizer, warmup_period = warmup_steps)<a id="change"> if </a><a id="change">exists(</a>warmup_steps<a id="change">) else </a>None

        &#47&#47 distribute the model if using HFA
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lucidrains/dalle2-pytorch/commit/f9423d308b6f36e51152c2c45045ff4ebb308287#diff-617450527162fa367141dbf45e8b201673573479820af0ffc56ba93b7f70947fL177' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 3118733</div><div id='project'> Project Name: lucidrains/dalle2-pytorch</div><div id='commit'> Commit Name: f9423d308b6f36e51152c2c45045ff4ebb308287</div><div id='time'> Time: 2022-07-20</div><div id='author'> Author: 51308183+nousr@users.noreply.github.com</div><div id='file'> File Name: dalle2_pytorch/trainer.py</div><div id='m_class'> M Class Name: DiffusionPriorTrainer</div><div id='n_method'> N Class Name: DiffusionPriorTrainer</div><div id='m_method'> M Method Name: __init__(10)</div><div id='n_method'> N Method Name: __init__(12)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: dalle2_pytorch/trainer.py</div><div id='n_file'> N File Name: dalle2_pytorch/trainer.py</div><div id='m_start'> M Start Line: 182</div><div id='m_end'> M End Line: 240</div><div id='n_start'> N Start Line: 177</div><div id='n_end'> N End Line: 246</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            ConvOut1d(
                channels=out_channels,
                kernel_sizes=kernel_sizes_out,
            )<a id="change">
            if </a><a id="change">exists(</a>kernel_sizes_out<a id="change">)
            else </a>nn.Identity(),
        )

    def get_channels(</code></pre><h3>After Change</h3><pre><code class='java'>
        self.use_context_time = use_context_time
        self.use_context_features = use_context_features
        self.use_context_channels = use_context_channels
        self.use_post_out_block = <a id="change">exists(</a>kernel_sizes_out<a id="change">)</a>

        context_channels_pad_length = num_layers + 1 - len(context_channels)
        context_channels = context_channels + [0] * context_channels_pad_length
        self.context_channels = context_channels

        if use_context_channels:
            has_context = [c &gt; 0 for c in context_channels]
            self.has_context = has_context
            self.channels_ids = [sum(has_context[:i]) for i in range(len(has_context))]

        assert (
            len(factors) == num_layers
            and len(attentions) == num_layers
            and len(num_blocks) == num_layers
        )

        self.to_in = nn.Sequential(
            Rearrange("b c (l p) -&gt; b (c p) l", p=patch_size),
            CrossEmbed1d(
                in_channels=(in_channels + context_channels[0]) * patch_size,
                out_channels=channels,
                kernel_sizes=kernel_sizes_init,
                stride=1,
            ),
        )

        if use_context_time or use_context_features:
            context_mapping_features = channels * 4

            self.to_mapping = nn.Sequential(
                nn.Linear(context_mapping_features, context_mapping_features),
                nn.GELU(),
                nn.Linear(context_mapping_features, context_mapping_features),
                nn.GELU(),
            )

        if use_context_time:
            assert exists(context_mapping_features)
            self.to_time = nn.Sequential(
                TimePositionalEmbedding(
                    dim=channels, out_features=context_mapping_features
                ),
                nn.GELU(),
            )

        if use_context_features:
            assert exists(context_features) and exists(context_mapping_features)
            self.to_features = nn.Sequential(
                nn.Linear(
                    in_features=context_features, out_features=context_mapping_features
                ),
                nn.GELU(),
            )

        self.downsamples = nn.ModuleList(
            [
                DownsampleBlock1d(
                    in_channels=channels * multipliers[i],
                    out_channels=channels * multipliers[i + 1],
                    context_mapping_features=context_mapping_features,
                    context_channels=context_channels[i + 1],
                    context_embedding_features=context_embedding_features,
                    num_layers=num_blocks[i],
                    factor=factors[i],
                    kernel_multiplier=kernel_multiplier_downsample,
                    num_groups=resnet_groups,
                    use_pre_downsample=True,
                    use_skip=True,
                    use_attention=attentions[i],
                    attention_heads=attention_heads,
                    attention_features=attention_features,
                    attention_multiplier=attention_multiplier,
                )
                for i in range(num_layers)
            ]
        )

        self.bottleneck = BottleneckBlock1d(
            channels=channels * multipliers[-1],
            context_mapping_features=context_mapping_features,
            context_embedding_features=context_embedding_features,
            num_groups=resnet_groups,
            use_attention=use_attention_bottleneck,
            attention_heads=attention_heads,
            attention_features=attention_features,
        )

        self.upsamples = nn.ModuleList(
            [
                UpsampleBlock1d(
                    in_channels=channels * multipliers[i + 1],
                    out_channels=channels * multipliers[i],
                    context_mapping_features=context_mapping_features,
                    context_embedding_features=context_embedding_features,
                    num_layers=num_blocks[i] + (1 if attentions[i] else 0),
                    factor=factors[i],
                    use_nearest=use_nearest_upsample,
                    num_groups=resnet_groups,
                    use_skip_scale=use_skip_scale,
                    use_pre_upsample=False,
                    use_skip=True,
                    skip_channels=channels * multipliers[i + 1],
                    use_attention=attentions[i],
                    attention_heads=attention_heads,
                    attention_features=attention_features,
                    attention_multiplier=attention_multiplier,
                )
                for i in reversed(range(num_layers))
            ]
        )

        self.to_pre_out = ResnetBlock1d(
            in_channels=channels,
            out_channels=channels,
            num_groups=resnet_groups,
            context_mapping_features=context_mapping_features,
        )

        self.to_out = nn.Sequential(
            Conv1d(
                in_channels=channels,
                out_channels=out_channels * patch_size,
                kernel_size=1,
            ),
            Rearrange("b (c p) l -&gt; b c (l p)", p=patch_size),
        )

        <a id="change">if </a>self.use_post_out_block<a id="change">:
            </a>assert exists(kernel_sizes_out)
            self.to_post_out<a id="change"> = </a>ConvOut1d(
                channels=out_channels,
                kernel_sizes=kernel_sizes_out,
            )</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/archinetai/audio-diffusion-pytorch/commit/3c710edf168da06dcc89c23ef12023d0f8b63043#diff-daa41e4baa3d2f79ac9df5a1fdce9cb4f87f4b10c9335e3653c38e64ecae3966L796' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 3118732</div><div id='project'> Project Name: archinetai/audio-diffusion-pytorch</div><div id='commit'> Commit Name: 3c710edf168da06dcc89c23ef12023d0f8b63043</div><div id='time'> Time: 2022-09-21</div><div id='author'> Author: flavio.schneider.97@gmail.com</div><div id='file'> File Name: audio_diffusion_pytorch/modules.py</div><div id='m_class'> M Class Name: UNet1d</div><div id='n_method'> N Class Name: UNet1d</div><div id='m_method'> M Method Name: __init__(23)</div><div id='n_method'> N Method Name: __init__(21)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: audio_diffusion_pytorch/modules.py</div><div id='n_file'> N File Name: audio_diffusion_pytorch/modules.py</div><div id='m_start'> M Start Line: 823</div><div id='m_end'> M End Line: 938</div><div id='n_start'> N Start Line: 842</div><div id='n_end'> N End Line: 997</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                nn.Linear(
                    in_features=context_time_features, out_features=out_channels * 2
                ),
            )<a id="change">
            if </a><a id="change">exists(</a>context_time_features<a id="change">)
            else </a>None
        )

        self.block1 = ConvBlock1d(</code></pre><h3>After Change</h3><pre><code class='java'>
    ) -&gt; None:
        super().__init__()

        self.use_mapping = <a id="change">exists(</a>context_mapping_features<a id="change">)</a>
        self.use_embedding = exists(context_embedding_features)

        self.block1 = ConvBlock1d(
            in_channels=in_channels,
            out_channels=out_channels,
            num_groups=num_groups,
            dilation=dilation,
        )

        <a id="change">if </a>self.use_mapping<a id="change">:
            </a>assert exists(context_mapping_features)
            self.to_scale_shift<a id="change"> = </a>MappingToScaleShift(
                features=context_mapping_features, channels=out_channels
            )
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/archinetai/audio-diffusion-pytorch/commit/3c710edf168da06dcc89c23ef12023d0f8b63043#diff-daa41e4baa3d2f79ac9df5a1fdce9cb4f87f4b10c9335e3653c38e64ecae3966L151' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 3118729</div><div id='project'> Project Name: archinetai/audio-diffusion-pytorch</div><div id='commit'> Commit Name: 3c710edf168da06dcc89c23ef12023d0f8b63043</div><div id='time'> Time: 2022-09-21</div><div id='author'> Author: flavio.schneider.97@gmail.com</div><div id='file'> File Name: audio_diffusion_pytorch/modules.py</div><div id='m_class'> M Class Name: ResnetBlock1d</div><div id='n_method'> N Class Name: ResnetBlock1d</div><div id='m_method'> M Method Name: __init__(0)</div><div id='n_method'> N Method Name: __init__(0)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: audio_diffusion_pytorch/modules.py</div><div id='n_file'> N File Name: audio_diffusion_pytorch/modules.py</div><div id='m_start'> M Start Line: 167</div><div id='m_end'> M End Line: 176</div><div id='n_start'> N Start Line: 147</div><div id='n_end'> N End Line: 163</div><BR>