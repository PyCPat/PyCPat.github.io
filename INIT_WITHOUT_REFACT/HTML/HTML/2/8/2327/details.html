<html><h3>Pattern ID :2327
</h3><img src='7983993.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            batch, permutation_dim, -1
        )

        <a id="change">if self.combining_operation == "mean"</a><a id="change">:
            </a>e<a id="change"> = </a>iid_embeddings.mean(dim=1)
        elif self.combining_operation == "sum":
            e = iid_embeddings.sum(dim=1)
        else:</code></pre><h3>After Change</h3><pre><code class='java'>
            trial_counts = torch.zeros(batch, 1)
            for i in range(batch):
                &#47&#47 remove NaNs
                valid_x<a id="change"> = </a>x[i, ~torch.isnan(x[i, :, 0]), :]
                trial_counts[i] = valid_x.shape[0]
                trial_embeddings = self.trial_net(valid_x)
                &#47&#47 apply combining operation over permutation dimension
                <a id="change">combined_embedding.append(
                    </a>self.combining_function(trial_embeddings, dim=0)<a id="change">
                )</a>

            combined_embedding<a id="change"> = </a><a id="change">torch.stack(combined_embedding</a><a id="change">, dim=0)</a>

        assert not torch.isnan(combined_embedding).any(), "NaNs in embedding."

        &#47&#47 add number of trials as additional input</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/mackelab/sbi/commit/1352e77bdbc47aa4a4130679903b57672e48218c#diff-672ba10e6c3065a6f5554033b9b173c4fe88f4c05ffc31c70a9198691e6c6659L271' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 7983993</div><div id='project'> Project Name: mackelab/sbi</div><div id='commit'> Commit Name: 1352e77bdbc47aa4a4130679903b57672e48218c</div><div id='time'> Time: 2023-03-01</div><div id='author'> Author: jan.boelts@tum.de</div><div id='file'> File Name: sbi/neural_nets/embedding_nets.py</div><div id='m_class'> M Class Name: PermutationInvariantEmbedding</div><div id='n_method'> N Class Name: PermutationInvariantEmbedding</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: sbi/neural_nets/embedding_nets.py</div><div id='n_file'> N File Name: sbi/neural_nets/embedding_nets.py</div><div id='m_start'> M Start Line: 271</div><div id='m_end'> M End Line: 284</div><div id='n_start'> N Start Line: 277</div><div id='n_end'> N End Line: 304</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            x = input3[:, i]
            x = self.fc2[i](torch.cat((x, comm), axis=-1))
            x = self.prelu5[i](x)
            <a id="change">if i == 0</a><a id="change">:
                </a>input4 = x.unsqueeze(1)
            else:
                input4<a id="change"> = </a>torch.cat((input4, x.unsqueeze(1)), dim=1)

        comm = torch.mean(input4, axis=1)
        for i in range(self.agents):</code></pre><h3>After Change</h3><pre><code class='java'>
        input1 = input.to(self.device) / 255.0

        &#47&#47 Shared layers
        input2<a id="change"> = </a>[]
        for i in range(self.agents):
            x = input1[:, i]
            x = self.conv0(x)
            x = self.prelu0(x)
            x = self.maxpool0(x)
            x = self.conv1(x)
            x = self.prelu1(x)
            x = self.maxpool1(x)
            x = self.conv2(x)
            x = self.prelu2(x)
            x = self.maxpool2(x)
            x = self.conv3(x)
            x = self.prelu3(x)
            x = x.view(-1, 512)
            input2.append(x)
        input2 = torch.stack(input2, dim=1)

        &#47&#47 Communication layers
        comm = torch.mean(input2, axis=1)
        <a id="change">input3</a> = []
        for i in range(self.agents):
            x = input2[:, i]
            x = self.fc1[i](torch.cat((x, comm), axis=-1))
            <a id="change">input3.append(</a>x<a id="change">)</a>
        input3<a id="change"> = </a><a id="change">torch.stack(</a>input3<a id="change">, dim=1)</a>
        input3 = self.prelu4(input3)

        comm = torch.mean(input3, axis=1)
        input4 = []</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/gml16/rl-medical/commit/a7aa4702050819ab83f9ad27fcfad2cfada3f306#diff-600a3995b91d3fac712ba595c951e8d897dde1cf5afa1225cbb8977770d3245dL248' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 7983976</div><div id='project'> Project Name: gml16/rl-medical</div><div id='commit'> Commit Name: a7aa4702050819ab83f9ad27fcfad2cfada3f306</div><div id='time'> Time: 2020-05-15</div><div id='author'> Author: g.m.leroy@outlook.com</div><div id='file'> File Name: examples/LandmarkDetection/DQN/DQNModel.py</div><div id='m_class'> M Class Name: CommNet</div><div id='n_method'> N Class Name: CommNet</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: examples/LandmarkDetection/DQN/DQNModel.py</div><div id='n_file'> N File Name: examples/LandmarkDetection/DQN/DQNModel.py</div><div id='m_start'> M Start Line: 256</div><div id='m_end'> M End Line: 308</div><div id='n_start'> N Start Line: 255</div><div id='n_end'> N End Line: 298</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            &#47&#47 collapse dimensions to BSx512 (resnet o/p)
            x = x.view(x.size(0), -1)
            &#47&#47 Unsqueeze for sequence length
            <a id="change">if t == 0</a><a id="change">:
                </a>gru_output<a id="change">, h_n = </a>self.rnn(x.unsqueeze(1))
            else:
                gru_output, h_n = self.rnn(x.unsqueeze(1), h_n)
            &#47&#47 output dim: BSx1 and Squeeze sequence length after completing GRU step</code></pre><h3>After Change</h3><pre><code class='java'>

    def forward(self, st_maps, target):
        batched_output_per_clip = []
        <a id="change">hr_per_clip</a> = []

        &#47&#47 Need to have so as to reflect a batch_size = 1 // if batched then comment out
        st_maps = st_maps.unsqueeze(0)
        for t in range(st_maps.size(1)):
            &#47&#47 with torch.no_grad():
            x = self.resnet18(st_maps[:, t, :, :, :])
            &#47&#47 collapse dimensions to BSx512 (resnet o/p)
            x = x.view(x.size(0), -1)
            &#47&#47 &#47&#47 Unsqueeze for sequence length
            &#47&#47 if t == 0:
            &#47&#47     gru_output, h_n = self.rnn(x.unsqueeze(1))
            &#47&#47 else:
            &#47&#47     gru_output, h_n = self.rnn(x.unsqueeze(1), h_n)
            &#47&#47 output dim: BSx1 and Squeeze sequence length after completing GRU step
            x = self.resnet_linear(x)
            &#47&#47 normalize by frame-rate: 25.0 for VIPL
            &#47&#47 x = x*25.0
            batched_output_per_clip.append(x.squeeze(0))
            &#47&#47 input should be (seq_len, batch, input_size)

        &#47&#47 the features extracted from the backbone CNN are fed to a one-layer GRU structure.
        output_seq = torch.stack(batched_output_per_clip, dim=0)
        gru_output, h_n = self.rnn(output_seq.unsqueeze(1))
        &#47&#47 gru_output = gru_output.squeeze(1)
        for i in range(gru_output.size(0)):
            hr<a id="change"> = </a>self.gru_fc_out(gru_output[i, :, :])
        &#47&#47     &#47&#47 hr = hr * 25.0
            <a id="change">hr_per_clip.append(</a>hr.flatten()<a id="change">)</a>

        output_seq<a id="change"> = </a><a id="change">torch.stack(</a>hr_per_clip<a id="change">, dim=0)</a>.permute(1,0)
        &#47&#47 return output_seq, gru_output.squeeze(0), fc_out
        return output_seq, output_seq.squeeze(0)[:6]
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/anweshcr7/rhythmnet/commit/0f9fc9b96933c04f723fbfa5b80cdf1a398828c3#diff-3fc5bf831ef8bd1cc5d50189ec691215fb3d3ae0cbb974e736200edc7f8c65cdL32' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 7983980</div><div id='project'> Project Name: anweshcr7/rhythmnet</div><div id='commit'> Commit Name: 0f9fc9b96933c04f723fbfa5b80cdf1a398828c3</div><div id='time'> Time: 2021-03-14</div><div id='author'> Author: anwesh.marwade@beyondsports.nl</div><div id='file'> File Name: src/models/rhythmNet.py</div><div id='m_class'> M Class Name: RhythmNet</div><div id='n_method'> N Class Name: RhythmNet</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/models/rhythmNet.py</div><div id='n_file'> N File Name: src/models/rhythmNet.py</div><div id='m_start'> M Start Line: 33</div><div id='m_end'> M End Line: 56</div><div id='n_start'> N Start Line: 33</div><div id='n_end'> N End Line: 64</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            batch, permutation_dim, -1
        )

        <a id="change">if self.combining_operation == "mean"</a><a id="change">:
            </a>e<a id="change"> = </a>iid_embeddings.mean(dim=1)
        elif self.combining_operation == "sum":
            e = iid_embeddings.sum(dim=1)
        else:</code></pre><h3>After Change</h3><pre><code class='java'>

        &#47&#47 otherwise we need to loop over the batch to account for varying trial lengths
        else:
            <a id="change">combined_embedding</a> = []
            trial_counts = torch.zeros(batch, 1)
            for i in range(batch):
                &#47&#47 remove NaNs
                valid_x = x[i, ~torch.isnan(x[i, :, 0]), :]
                trial_counts[i] = valid_x.shape[0]
                trial_embeddings<a id="change"> = </a>self.trial_net(valid_x)
                &#47&#47 apply combining operation over permutation dimension
                <a id="change">combined_embedding.append(
                    </a>self.combining_function(trial_embeddings, dim=0)<a id="change">
                )</a>

            combined_embedding<a id="change"> = </a><a id="change">torch.stack(</a>combined_embedding<a id="change">, dim=0)</a>

        assert not torch.isnan(combined_embedding).any(), "NaNs in embedding."

        &#47&#47 add number of trials as additional input</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/mackelab/sbi/commit/1352e77bdbc47aa4a4130679903b57672e48218c#diff-672ba10e6c3065a6f5554033b9b173c4fe88f4c05ffc31c70a9198691e6c6659L262' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 7983987</div><div id='project'> Project Name: mackelab/sbi</div><div id='commit'> Commit Name: 1352e77bdbc47aa4a4130679903b57672e48218c</div><div id='time'> Time: 2023-03-01</div><div id='author'> Author: jan.boelts@tum.de</div><div id='file'> File Name: sbi/neural_nets/embedding_nets.py</div><div id='m_class'> M Class Name: PermutationInvariantEmbedding</div><div id='n_method'> N Class Name: PermutationInvariantEmbedding</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: sbi/neural_nets/embedding_nets.py</div><div id='n_file'> N File Name: sbi/neural_nets/embedding_nets.py</div><div id='m_start'> M Start Line: 271</div><div id='m_end'> M End Line: 284</div><div id='n_start'> N Start Line: 277</div><div id='n_end'> N End Line: 304</div><BR>