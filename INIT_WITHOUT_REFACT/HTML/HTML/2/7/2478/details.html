<html><h3>Pattern ID :2478
</h3><img src='8189757.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        next_mem, next_lmem = map(torch.stack, (next_mem, next_lmem))
        next_mem, next_lmem = map(torch.detach, (next_mem, next_lmem))

        <a id="change">return </a>out, Memory(short = next_mem, long = next_lmem)
</code></pre><h3>After Change</h3><pre><code class='java'>
        init_mem = lambda: torch.empty(num_memory_layers, b, 0, d, **to(x))

        mem = default(mem, init_mem)
        lmem<a id="change"> = </a><a id="change">default(</a>lmem, init_mem<a id="change">)</a>

        mem_len, lmem_len = map(lambda t: t.shape[2], (mem, lmem))
        total_len = mem_len + lmem_len + self.seq_len

        pos_emb = self.pos_emb[:, (self.seq_len - t):total_len]
        mem_iter, lmem_iter = map(iterate_tensor, (mem, lmem))

        hiddens<a id="change"> = </a>[]

        for ind, (attn, ff) in enumerate(zip(self.attn_layers, self.ff_layers)):
            layer_num = ind + 1
            use_memory = layer_num in self.memory_layers
            memories = map(next, (mem_iter, lmem_iter)) if use_memory else None

            if use_memory:
                hiddens.append(x)

            x = attn(x, memories = memories, calc_memory = use_memory, input_mask = mask, pos_emb = pos_emb)
            x = ff(x)

        hiddens = torch.stack(hiddens)
        out = self.to_logits(x)

        &#47&#47 calculate next memory state

        next_memory<a id="change"> = </a>self.memory_network(lmem, mem, hiddens)
        <a id="change">return </a>out<a id="change">, next_memory</a>
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 7</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/lucidrains/memory-transformer-xl/commit/cbabe1ae6fa311092a9d0a88116c079a5ad8d790#diff-a0bf60cdef5ad628f9a83f0454c9c66a535268529835e839bb54088805dba051L255' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8189757</div><div id='project'> Project Name: lucidrains/memory-transformer-xl</div><div id='commit'> Commit Name: cbabe1ae6fa311092a9d0a88116c079a5ad8d790</div><div id='time'> Time: 2020-07-22</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: memory_transformer_xl/memory_transformer_xl.py</div><div id='m_class'> M Class Name: MemoryTransformerXL</div><div id='n_method'> N Class Name: MemoryTransformerXL</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: memory_transformer_xl/memory_transformer_xl.py</div><div id='n_file'> N File Name: memory_transformer_xl/memory_transformer_xl.py</div><div id='m_start'> M Start Line: 255</div><div id='m_end'> M End Line: 296</div><div id='n_start'> N Start Line: 306</div><div id='n_end'> N End Line: 345</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        x = self.token_emb(x)
        out = self.layers(x)
        out = self.to_logits(x)
        <a id="change">return </a>out
</code></pre><h3>After Change</h3><pre><code class='java'>
        x = self.token_emb(x)
        b, t, d = x.shape

        mem<a id="change"> = </a><a id="change">default(</a>mem, torch.empty(self.depth, b, 0, d)<a id="change">)</a>
        hidden_states<a id="change"> = </a>[]

        for attn, ff, m in zip(self.attn_layers, self.ff_layers, mem):
            hidden_states.append(x)
            x = attn(x, mem = m)
            x = ff(x)

        out = self.to_logits(x)

        hidden_states = torch.stack(hidden_states)
        new_mem<a id="change"> = </a>torch.cat((mem, hidden_states), dim=2)[:, :, -self.mem_len:, :].detach()
        <a id="change">return </a>out<a id="change">, new_mem</a>
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/compressive-transformer-pytorch/commit/47a5b8448090fce7ca1f7356001fb2ac381c2239#diff-493cd95e4b724ba15b0c327254df365435ee9204e2a14c51200a07a55d030b8dL101' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8189758</div><div id='project'> Project Name: lucidrains/compressive-transformer-pytorch</div><div id='commit'> Commit Name: 47a5b8448090fce7ca1f7356001fb2ac381c2239</div><div id='time'> Time: 2020-06-30</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: compressive_transformer_pytorch/compressive_transformer_pytorch.py</div><div id='m_class'> M Class Name: CompressiveTransformer</div><div id='n_method'> N Class Name: CompressiveTransformer</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: compressive_transformer_pytorch/compressive_transformer_pytorch.py</div><div id='n_file'> N File Name: compressive_transformer_pytorch/compressive_transformer_pytorch.py</div><div id='m_start'> M Start Line: 102</div><div id='m_end'> M End Line: 105</div><div id='n_start'> N Start Line: 112</div><div id='n_end'> N End Line: 128</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        super().__init__()

    def forward(self, x):
        <a id="change">return </a>x
</code></pre><h3>After Change</h3><pre><code class='java'>

    def forward(self, src, tgt, mems = None):
        b = src.shape[0]
        mems<a id="change"> = </a><a id="change">default(</a>mems, self.memory_slots<a id="change">)</a>

        if mems.ndim == 2:
            mems = repeat(mems, &quotn d -&gt; b n d&quot, b = b)

        enc<a id="change"> = </a>self.encoder(src, context = mems)
        out = self.decoder(tgt, context = enc)

        mems<a id="change"> = </a>self.mem_updater(mems, enc)
        <a id="change">return </a>out<a id="change">, mems</a>
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/lucidrains/memformer/commit/f8648dffb97894391d67166550584ddb60f7e413#diff-3739fa9ed5b04cd8606fb4ef1d563baf1344fd72b2610c00224ab2f0b223cd86L10' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8189768</div><div id='project'> Project Name: lucidrains/memformer</div><div id='commit'> Commit Name: f8648dffb97894391d67166550584ddb60f7e413</div><div id='time'> Time: 2020-10-28</div><div id='author'> Author: lucidrains@gmail.com</div><div id='file'> File Name: memformer/memformer.py</div><div id='m_class'> M Class Name: Memformer</div><div id='n_method'> N Class Name: Memformer</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: memformer/memformer.py</div><div id='n_file'> N File Name: memformer/memformer.py</div><div id='m_start'> M Start Line: 10</div><div id='m_end'> M End Line: 11</div><div id='n_start'> N Start Line: 150</div><div id='n_end'> N End Line: 161</div><BR>