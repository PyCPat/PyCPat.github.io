<html><h3>Pattern ID :1870
</h3><img src='7199849.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            l2QLoss.append(F.mse_loss(latent.detach(), q, reduction=&quotnone&quot).mean(axis=(1, 2, 3)))
            l1QLoss.append(F.l1_loss(latent.detach(), q, reduction=&quotnone&quot).mean(axis=(1, 2, 3)))
            l2QLoss.append(0.01 * F.mse_loss(latent, q.detach(), reduction=&quotnone&quot).mean(axis=(1, 2, 3)))
            l1QLoss.append(<a id="change">0.01</a><a id="change"> * </a><a id="change">F.l1_loss(latent, q.detach(), reduction=&quotnone&quot).mean(axis=(1, 2, 3))</a>)
            &#47&#47 regs.append(-1e-4 * ((latent ** 2).mean((1, 2, 3)) + (q ** 2).mean((1, 2, 3))))

        l1QLoss = sum(l1QLoss)</code></pre><h3>After Change</h3><pre><code class='java'>
                &#47&#47 N, H, W, K -&gt; N, HW, K
                batchWiseLogit = logit.reshape(len(logit), -1, logit.shape[-1])

                posterior = <a id="change">OneHotCategorical(logits=batchWiseLogit)</a>
                prior = <a id="change">OneHotCategorical(probs=torch.ones_like(batchWiseLogit) / batchWiseLogit.shape[-1])</a>
                reg<a id="change"> = </a><a id="change">torch.distributions.kl_divergence(</a>posterior, prior<a id="change">)</a>.sum(-1) + compute_penalties(batchWiseLogit, allowed_entropy=0.1, individual_entropy_coeff=1.0, allowed_js=4.0, js_coeff=1.0, cv_coeff=1.0, eps=Consts.Eps)
                regs.append(reg)
                &#47&#47 reg = reg / diversity
            regs = sum(regs)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/xiaosu-zhu/mcquic/commit/8c71ec66b33adcc34c3c3769caf2b9087dd03ff1#diff-93a462c5d42bc45838b4e4215cbb88d97c7a71ce0ceb9af896a4f1b48e34e718L130' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 7199849</div><div id='project'> Project Name: xiaosu-zhu/mcquic</div><div id='commit'> Commit Name: 8c71ec66b33adcc34c3c3769caf2b9087dd03ff1</div><div id='time'> Time: 2021-03-31</div><div id='author'> Author: xiaosu.zhu@outlook.com</div><div id='file'> File Name: src/mcqc/losses/structural.py</div><div id='m_class'> M Class Name: CompressionLossTwoStage</div><div id='n_method'> N Class Name: CompressionLossTwoStage</div><div id='m_method'> M Method Name: forward(6)</div><div id='n_method'> N Method Name: forward(6)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/mcqc/losses/structural.py</div><div id='n_file'> N File Name: src/mcqc/losses/structural.py</div><div id='m_start'> M Start Line: 130</div><div id='m_end'> M End Line: 151</div><div id='n_start'> N Start Line: 146</div><div id='n_end'> N End Line: 151</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            for latent, q in zip(latents, quantizeds):
                l2QLoss.append(F.mse_loss(latent.detach(), q, reduction=&quotnone&quot).mean(axis=(1, 2, 3)))
                l1QLoss.append(F.l1_loss(latent.detach(), q, reduction=&quotnone&quot).mean(axis=(1, 2, 3)))
                l2QLoss.append(<a id="change">0.00001</a><a id="change"> * </a><a id="change">F.mse_loss(latent, q.detach(), reduction=&quotnone&quot).mean(axis=(1, 2, 3))</a>)
                l1QLoss.append(0.00001 * F.l1_loss(latent, q.detach(), reduction=&quotnone&quot).mean(axis=(1, 2, 3)))

        l1QLoss = sum(l1QLoss)</code></pre><h3>After Change</h3><pre><code class='java'>
                &#47&#47 diversity = batchWiseLogit.std(1).mean(-1).sigmoid()

                &#47&#47 summedProb = batchWiseLogit.sum(1)
                posterior = <a id="change">OneHotCategorical(logits=batchWiseLogit)</a>
                prior = <a id="change">OneHotCategorical(probs=torch.ones_like(batchWiseLogit) / batchWiseLogit.shape[-1])</a>
                reg = <a id="change">torch.distributions.kl_divergence(</a>posterior, prior<a id="change">)</a>.sum(-1)
                reg<a id="change"> += </a>compute_penalties(batchWiseLogit, allowed_entropy=0.1, individual_entropy_coeff=cv, allowed_js=4.0, js_coeff=cv, cv_coeff=cv, eps=Consts.Eps)
                &#47&#47 reg = reg / diversity
                regs.append(reg)
            regs = sum(regs)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/xiaosu-zhu/mcquic/commit/6a7990547d3b9f68e7377cfc03ef1edd64929802#diff-93a462c5d42bc45838b4e4215cbb88d97c7a71ce0ceb9af896a4f1b48e34e718L48' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 7199848</div><div id='project'> Project Name: xiaosu-zhu/mcquic</div><div id='commit'> Commit Name: 6a7990547d3b9f68e7377cfc03ef1edd64929802</div><div id='time'> Time: 2021-03-24</div><div id='author'> Author: xiaosu.zhu@outlook.com</div><div id='file'> File Name: src/mcqc/losses/structural.py</div><div id='m_class'> M Class Name: CompressionLossTwoStage</div><div id='n_method'> N Class Name: CompressionLossTwoStage</div><div id='m_method'> M Method Name: forward(8)</div><div id='n_method'> N Method Name: forward(8)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/mcqc/losses/structural.py</div><div id='n_file'> N File Name: src/mcqc/losses/structural.py</div><div id='m_start'> M Start Line: 53</div><div id='m_end'> M End Line: 90</div><div id='n_start'> N Start Line: 69</div><div id='n_end'> N End Line: 90</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                batchWiseLogit = logit.reshape(len(logit), -1, logit.shape[-1])

                &#47&#47 [n, k]
                summedProb = <a id="change">batchWiseLogit.mean(</a>1<a id="change">)</a>.sigmoid()

                target = torch.ones_like(summedProb)<a id="change"> / 2.0</a>
                &#47&#47 [n, ]
                reg = F.binary_cross_entropy(summedProb, target, reduction=&quotnone&quot).sum(-1)

                &#47&#47 [n, k] -&gt; [n, ]</code></pre><h3>After Change</h3><pre><code class='java'>
                diversity = batchWiseLogit.var(1).sum(-1).sigmoid()

                summedProb = batchWiseLogit.sum(1)
                posterior = <a id="change">OneHotCategorical(logits=summedProb)</a>
                prior = <a id="change">OneHotCategorical(probs=torch.ones_like(summedProb) / summedProb.shape[-1])</a>
                reg<a id="change"> = </a><a id="change">torch.distributions.kl_divergence(</a>posterior, prior<a id="change">)</a> / diversity
                &#47&#47 reg += compute_penalties(unNormlogit, allowed_entropy=0.1, individual_entropy_coeff=cv, allowed_js=4.0, js_coeff=cv, cv_coeff=cv, eps=Consts.Eps)
                regs.append(reg)
            regs = sum(regs)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/xiaosu-zhu/mcquic/commit/a70c627dfb797c38494d697f152f70f80bea53e3#diff-93a462c5d42bc45838b4e4215cbb88d97c7a71ce0ceb9af896a4f1b48e34e718L48' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 7199844</div><div id='project'> Project Name: xiaosu-zhu/mcquic</div><div id='commit'> Commit Name: a70c627dfb797c38494d697f152f70f80bea53e3</div><div id='time'> Time: 2021-03-21</div><div id='author'> Author: xiaosu.zhu@outlook.com</div><div id='file'> File Name: src/mcqc/losses/structural.py</div><div id='m_class'> M Class Name: CompressionLossTwoStage</div><div id='n_method'> N Class Name: CompressionLossTwoStage</div><div id='m_method'> M Method Name: forward(8)</div><div id='n_method'> N Method Name: forward(8)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/mcqc/losses/structural.py</div><div id='n_file'> N File Name: src/mcqc/losses/structural.py</div><div id='m_start'> M Start Line: 49</div><div id='m_end'> M End Line: 86</div><div id='n_start'> N Start Line: 49</div><div id='n_end'> N End Line: 93</div><BR>