<html><h3>Pattern ID :1926
</h3><img src='7258974.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>

            y[1][..., :4] /= s[0]  &#47&#47 scale
            y[1][..., 0] = img_size[1] - y[1][..., 0]  &#47&#47 flip lr
            <a id="change">y[2][..., :4]</a> /= s[1]  &#47&#47 scale
            return torch.cat(y, 1), None  &#47&#47 augmented inference, train
        else:
            return self.forward_once(x, profile)  &#47&#47 single-scale inference, train</code></pre><h3>After Change</h3><pre><code class='java'>
            s = [1, 0.83, 0.67]  &#47&#47 scales
            f = [None, 3, None]  &#47&#47 flips (2-ud, 3-lr)
            y = []  &#47&#47 outputs
            <a id="change">for </a>si, <a id="change">fi</a> in <a id="change">zip(</a>s, f<a id="change">):
                </a>xi = torch_utils.scale_img(x.flip(fi) if fi else x, si)
                yi = self.forward_once(xi)[0]  &#47&#47 forward
                &#47&#47 cv2.imwrite(&quotimg%g.jpg&quot % s, 255 * xi[0].numpy().transpose((1, 2, 0))[:, :, ::-1])  &#47&#47 save
                yi[..., :4] /= si  &#47&#47 de-scale
                if fi is 2:
                    yi[..., 1] = img_size[0] - yi[..., 1]  &#47&#47 de-flip ud
                elif <a id="change">fi is 3</a><a id="change">:
                    </a>yi[..., 0] = img_size[1] - yi[..., 0]  &#47&#47 de-flip lr
                y.append(yi)
            return torch.cat(y, 1), None  &#47&#47 augmented inference, train
        else:</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 5</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/ultralytics/yolov5/commit/1d17b9af0f68ee97f9edc5f10fea51e9af9ef14e#diff-2cd118cbb69c9ca7b5544f4187b11335fc3addbaf2c3c5bb45435cac648c957bL84' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 7258974</div><div id='project'> Project Name: ultralytics/yolov5</div><div id='commit'> Commit Name: 1d17b9af0f68ee97f9edc5f10fea51e9af9ef14e</div><div id='time'> Time: 2020-07-24</div><div id='author'> Author: glenn.jocher@ultralytics.com</div><div id='file'> File Name: models/yolo.py</div><div id='m_class'> M Class Name: Model</div><div id='n_method'> N Class Name: Model</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/yolo.py</div><div id='n_file'> N File Name: models/yolo.py</div><div id='m_start'> M Start Line: 85</div><div id='m_end'> M End Line: 96</div><div id='n_start'> N Start Line: 84</div><div id='n_end'> N End Line: 98</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

            y[1][..., :4] /= s[0]  &#47&#47 scale
            y[1][..., 0] = img_size[1] - y[1][..., 0]  &#47&#47 flip lr
            <a id="change">y[2][..., :4]</a> /= s[1]  &#47&#47 scale
            return torch.cat(y, 1), None  &#47&#47 augmented inference, train
        else:
            return self.forward_once(x, profile)  &#47&#47 single-scale inference, train</code></pre><h3>After Change</h3><pre><code class='java'>
            s = [1, 0.83, 0.67]  &#47&#47 scales
            f = [None, 3, None]  &#47&#47 flips (2-ud, 3-lr)
            y = []  &#47&#47 outputs
            <a id="change">for </a>si, <a id="change">fi</a> in <a id="change">zip(</a>s, f<a id="change">):
                </a>xi = torch_utils.scale_img(x.flip(fi) if fi else x, si)
                yi = self.forward_once(xi)[0]  &#47&#47 forward
                &#47&#47 cv2.imwrite(&quotimg%g.jpg&quot % s, 255 * xi[0].numpy().transpose((1, 2, 0))[:, :, ::-1])  &#47&#47 save
                yi[..., :4] /= si  &#47&#47 de-scale
                <a id="change">if fi is 2</a><a id="change">:
                    </a>yi[..., 1] = img_size[0] - yi[..., 1]  &#47&#47 de-flip ud
                elif fi is 3:
                    yi[..., 0] = img_size[1] - yi[..., 0]  &#47&#47 de-flip lr
                y.append(yi)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/jeffwang0325/image-identification-for-self-driving-cars/commit/1d17b9af0f68ee97f9edc5f10fea51e9af9ef14e#diff-2cd118cbb69c9ca7b5544f4187b11335fc3addbaf2c3c5bb45435cac648c957bL82' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 7258975</div><div id='project'> Project Name: jeffwang0325/image-identification-for-self-driving-cars</div><div id='commit'> Commit Name: 1d17b9af0f68ee97f9edc5f10fea51e9af9ef14e</div><div id='time'> Time: 2020-07-24</div><div id='author'> Author: glenn.jocher@ultralytics.com</div><div id='file'> File Name: models/yolo.py</div><div id='m_class'> M Class Name: Model</div><div id='n_method'> N Class Name: Model</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/yolo.py</div><div id='n_file'> N File Name: models/yolo.py</div><div id='m_start'> M Start Line: 85</div><div id='m_end'> M End Line: 96</div><div id='n_start'> N Start Line: 84</div><div id='n_end'> N End Line: 98</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        output = []
        for step in range(input.size(1)):
            &#47&#47 Compute current time-step
            hidden_state = self.rnn_cell(<a id="change">input[:, step, :, :, :]</a>, hidden_state)
            output.append(hidden_state)
        &#47&#47 Stack the list of output hidden states into a tensor
        output = torch.stack(output, 0)</code></pre><h3>After Change</h3><pre><code class='java'>
        layer_output_list = []
        last_state_list = []

        <a id="change">for l</a>, (gru_cell, hid_dp) in enumerate(<a id="change">zip(</a>self.cell_list, self.hidden_dps<a id="change">)</a>)<a id="change">:
            </a>h = hidden_state[l]
            output_inner = []
            for t in range(seq_len):
                h = gru_cell(input=cur_layer_input[t], h_prev=h)
                output_inner.append(h)

            cur_layer_input = torch.stack(output_inner)  &#47&#47 list to array
            <a id="change">if l != self.n_layers</a><a id="change">:
                </a>cur_layer_input = hid_dp(cur_layer_input)
            last_state_list.append(h)

        layer_output = torch.stack(output_inner, dim=int(self.batch_first))</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/openclimatefix/skillful_nowcasting/commit/02c5ceadd01484d6ac8bce848ff76446fe7a6917#diff-cee00a565d888c684ec40bd3eac27669aa3223b223a80ae9f871383a9fb64917L268' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 7258970</div><div id='project'> Project Name: openclimatefix/skillful_nowcasting</div><div id='commit'> Commit Name: 02c5ceadd01484d6ac8bce848ff76446fe7a6917</div><div id='time'> Time: 2021-10-18</div><div id='author'> Author: jacob@bieker.tech</div><div id='file'> File Name: nowcasting_gan/layers/ConvGRU.py</div><div id='m_class'> M Class Name: ConvGRU</div><div id='n_method'> N Class Name: ConvGRU</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: nowcasting_gan/layers/ConvGRU.py</div><div id='n_file'> N File Name: nowcasting_gan/layers/ConvGRU.py</div><div id='m_start'> M Start Line: 269</div><div id='m_end'> M End Line: 276</div><div id='n_start'> N Start Line: 196</div><div id='n_end'> N End Line: 221</div><BR>