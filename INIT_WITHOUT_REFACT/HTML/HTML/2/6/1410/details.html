<html><h3>Pattern ID :1410
</h3><img src='4069247.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        if prediction.size() != target.size() or target.ndim &lt; 3:
            raise TypeError(fInputs must be of the same shape (batch_size,channels,samples) 
                            got {prediction.size()} and {target.size()} instead)
        prediction,target = <a id="change">prediction.unsqueeze(1</a><a id="change">),target.unsqueeze(1)</a>

class Avergeloss(nn.Module):

    def __init__(self,losses):</code></pre><h3>After Change</h3><pre><code class='java'>
        scaling_factor = torch.sum(prediction*target,keepdim=True,dim=-1) / target_energy
        target_projection = target * scaling_factor
        noise = prediction - target_projection
        ratio = torch.sum(target_projection**2,dim=-1) / <a id="change">torch.sum(</a>noise<a id="change">**</a>2<a id="change">,dim=-1)</a>
        si_sdr = 10*torch.log10(ratio).mean(dim=-1)

        if self.reduction == "sum":
            si_sdr = si_sdr.sum()
        elif self.reduction == "mean":
            si_sdr = si_sdr.mean()
        else:
            pass
    
        <a id="change">return </a>si_sdr


</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/shahules786/mayavoz/commit/838b7d2357c75c14e09bc7c4daef1518269fae63#diff-1216cd6e4983e226a4c9132377d64d3e0ec559180fde7d155e97f769dc93791cL49' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4069247</div><div id='project'> Project Name: shahules786/mayavoz</div><div id='commit'> Commit Name: 838b7d2357c75c14e09bc7c4daef1518269fae63</div><div id='time'> Time: 2022-09-28</div><div id='author'> Author: shahules786@gmail.com</div><div id='file'> File Name: enhancer/loss.py</div><div id='m_class'> M Class Name: Si_SDR</div><div id='n_method'> N Class Name: Si_SDR</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: enhancer/loss.py</div><div id='n_file'> N File Name: enhancer/loss.py</div><div id='m_start'> M Start Line: 49</div><div id='m_end'> M End Line: 49</div><div id='n_start'> N Start Line: 55</div><div id='n_end'> N End Line: 69</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        gap = self.global_avg_pool(x)
        gap_logit = self.global_avg_pool_fc(gap.view(x.size(0), -1))
        gap_weight = self.global_avg_pool_fc.linear.weight.data.clone()
        gap = x * <a id="change">gap_weight.unsqueeze(2).unsqueeze(3</a><a id="change">)</a>

        gmp = self.global_max_pool(x)
        gmp_logit = self.global_max_pool_fc(gmp.view(x.size(0), -1))
        gmp_weight = self.global_max_pool_fc.linear.weight.data.clone()
        gmp = x * gmp_weight.unsqueeze(2).unsqueeze(3)

        cam_logit = torch.cat([gap, gmp], dim=1)
        x = self.conv(cam_logit)
        return x<a id="change">, cam_logit</a>

class GammaBeta(nn.Module):
    def __init__(self,
        channels, resl</code></pre><h3>After Change</h3><pre><code class='java'>
        gmp = self.maxpool(x)
        gmp_logit = self.maxpool_fc(gmp.flatten(1))
        gmp_weight = self.maxpool_fc.weight.detach().clone()
        gmp = x<a id="change"> * </a>gmp_weight[:, :, None, None]

        cam_logit = torch.cat([gap_logit, gmp_logit], dim=1)
        x = torch.cat([gap, gmp], dim=1)
        x = self.conv(x)
        x = self.act(x)

        heatmap = <a id="change">torch.sum(</a>x<a id="change">, dim=1, keepdim=True)</a>

        <a id="change">return </a>x, cam_logit, heatmap


class GammaBeta(nn.Module):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/stomoya/animeface/commit/a90fefdcfa84ce38987194a1ebd71b59eee30e0b#diff-46b2d268f745a9596b4f5f343345806f96fb3f625a37a7a0ee82b059949f6192L109' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4069245</div><div id='project'> Project Name: stomoya/animeface</div><div id='commit'> Commit Name: a90fefdcfa84ce38987194a1ebd71b59eee30e0b</div><div id='time'> Time: 2022-03-23</div><div id='author'> Author: stomoya0110@gmail.com</div><div id='file'> File Name: implementations/UGATIT/model.py</div><div id='m_class'> M Class Name: CAM</div><div id='n_method'> N Class Name: CAM</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: implementations/UGATIT/model.py</div><div id='n_file'> N File Name: implementations/UGATIT/model.py</div><div id='m_start'> M Start Line: 112</div><div id='m_end'> M End Line: 123</div><div id='n_start'> N Start Line: 42</div><div id='n_end'> N End Line: 58</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        indices = torch.argmin(distances, dim=-1)

        encodings = F.one_hot(indices, M).float()
        quantized = torch.gather(self.embedding, 1, <a id="change">indices.unsqueeze(-1</a><a id="change">)</a>.expand(-1, -1, D))
        quantized = quantized.view_as(x)

        if self.training:
            self.ema_count = self.decay * self.ema_count + (1 - self.decay) * torch.sum(encodings, dim=1)

            n = torch.sum(self.ema_count, dim=-1, keepdim=True)
            self.ema_count = (self.ema_count + self.epsilon) / (n + M * self.epsilon) * n

            dw = torch.bmm(encodings.transpose(1, 2), x_flat)
            self.ema_weight = self.decay * self.ema_weight + (1 - self.decay) * dw

            self.embedding = self.ema_weight / self.ema_count.unsqueeze(-1)

        e_latent_loss = F.mse_loss(x, quantized.detach())
        loss = self.commitment_cost * e_latent_loss

        quantized = x + (quantized - x).detach()

        avg_probs = torch.mean(encodings, dim=1)
        perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs + 1e-10), dim=-1))

        return quantized.permute(1, 0, 3, 2).reshape(B, C, L)<a id="change">, loss, perplexity.sum()</a>


class ChannelNorm(nn.Module):
    def __init__(self,</code></pre><h3>After Change</h3><pre><code class='java'>
        x_flat = x.detach().reshape(-1, D)

        distances = torch.addmm(torch.sum(self.embedding ** 2, dim=1) +
                                <a id="change">torch.sum(</a>x_flat<a id="change"> ** </a>2<a id="change">, dim=1, keepdim=True)</a>,
                                x_flat, self.embedding.t(),
                                alpha=-2.0, beta=1.0)

        indices = torch.argmin(distances.float(), dim=-1)
        encodings = F.one_hot(indices, M).float()
        quantized = F.embedding(indices, self.embedding)
        quantized = quantized.view_as(x)

        if self.training:
            self.ema_count = self.decay * self.ema_count + (1 - self.decay) * torch.sum(encodings, dim=0)

            n = torch.sum(self.ema_count)
            self.ema_count = (self.ema_count + self.epsilon) / (n + M * self.epsilon) * n

            dw = torch.matmul(encodings.t(), x_flat)
            self.ema_weight = self.decay * self.ema_weight + (1 - self.decay) * dw

            self.embedding = self.ema_weight / self.ema_count.unsqueeze(-1)

        e_latent_loss = F.mse_loss(x, quantized.detach())
        loss = self.commitment_cost * e_latent_loss

        quantized = x + (quantized - x).detach()

        avg_probs = torch.mean(encodings, dim=0)
        perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs + 1e-10)))

        <a id="change">return </a>quantized, loss, perplexity


class CPCLoss(nn.Module):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/bshall/vectorquantizedcpc/commit/535c95415d62ececde085e376f451b3b76e1b624#diff-fada037ad086638e65c7ae77e3d223963e9afaa26326aab0ea718f4013176e43L20' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4069234</div><div id='project'> Project Name: bshall/vectorquantizedcpc</div><div id='commit'> Commit Name: 535c95415d62ececde085e376f451b3b76e1b624</div><div id='time'> Time: 2020-05-01</div><div id='author'> Author: benji.l.shall@gmail.com</div><div id='file'> File Name: model.py</div><div id='m_class'> M Class Name: VQEmbeddingEMA</div><div id='n_method'> N Class Name: VQEmbeddingEMA</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: model.py</div><div id='n_file'> N File Name: model.py</div><div id='m_start'> M Start Line: 21</div><div id='m_end'> M End Line: 54</div><div id='n_start'> N Start Line: 81</div><div id='n_end'> N End Line: 112</div><BR>