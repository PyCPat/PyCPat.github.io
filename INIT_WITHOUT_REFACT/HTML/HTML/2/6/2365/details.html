<html><h3>Pattern ID :2365
</h3><img src='8036242.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            raise RuntimeError("Unknown value for attention norm type")
        context = torch.bmm(alignment.unsqueeze(1), inputs)
        context = context.squeeze(1)
        return context<a id="change">, alignment</a>


class Postnet(nn.Module):
    def __init__(self, mel_dim, num_convs=5):</code></pre><h3>After Change</h3><pre><code class='java'>
            raise RuntimeError("Unknown value for attention norm type")
        if self.forward_attn:
            &#47&#47 forward attention
            prev_alpha = F.pad(<a id="change">self.alpha[:, :-1].clone()</a>, (1, 0, 0, 0)).to(inputs.device)
            self.alpha = (((1-self.u) * self.alpha.clone().to(inputs.device) + self.u * prev_alpha) + 1e-7) * alignment
            alpha_norm<a id="change"> = </a>self.alpha / self.alpha.sum(dim=1).unsqueeze(1)
            &#47&#47 compute context
            context = torch.bmm(alpha_norm.unsqueeze(1), inputs)
            context = context.squeeze(1)
            return context<a id="change">, alpha_norm, alignment</a>
        else:
            context = torch.bmm(alignment.unsqueeze(1), inputs)
            context = context.squeeze(1)
            return context<a id="change">, alignment, alignment</a>


class Postnet(nn.Module):
    def __init__(self, mel_dim, num_convs=5):</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/coqui-ai/tts/commit/961af0f5cdefbb5f267671f6847cf05659962d6c#diff-98fd28c1559c72435d1c59024b2baa25ece39483c2196f2377bfc9ee6c7f183bL173' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8036242</div><div id='project'> Project Name: coqui-ai/tts</div><div id='commit'> Commit Name: 961af0f5cdefbb5f267671f6847cf05659962d6c</div><div id='time'> Time: 2019-04-05</div><div id='author'> Author: egolge@mozilla.com</div><div id='file'> File Name: layers/tacotron2.py</div><div id='m_class'> M Class Name: Attention</div><div id='n_method'> N Class Name: Attention</div><div id='m_method'> M Method Name: forward(6)</div><div id='n_method'> N Method Name: forward(6)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: layers/tacotron2.py</div><div id='n_file'> N File Name: layers/tacotron2.py</div><div id='m_start'> M Start Line: 173</div><div id='m_end'> M End Line: 175</div><div id='n_start'> N Start Line: 193</div><div id='n_end'> N End Line: 208</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            p[..., 0:2] = torch.sigmoid(p[..., 0:2]) + self.grid_xy  &#47&#47 xy
            p[..., 2:4] = torch.exp(p[..., 2:4]) * self.anchor_wh  &#47&#47 wh yolo method
            &#47&#47 p[..., 2:4] = ((torch.sigmoid(p[..., 2:4]) * 2) ** 2) * self.anchor_wh  &#47&#47 wh power method
            p[...<a id="change">, 4</a>] = torch.sigmoid(p[...<a id="change">, 4</a>])  &#47&#47 p_conf
            p[..., 5:] = torch.sigmoid(p[..., 5:])  &#47&#47 p_class
            &#47&#47 p[..., 5:] = F.softmax(p[..., 5:], dim=4)  &#47&#47 p_class
            p[..., :4] *= self.stride</code></pre><h3>After Change</h3><pre><code class='java'>
            return torch.cat((xy / nG, wh, p_conf, p_cls), 2).squeeze().t()

        else:  &#47&#47 inference
            io<a id="change"> = </a><a id="change">p.clone()</a>  &#47&#47 inference output
            io[..., 0:2] = torch.sigmoid(io[..., 0:2]) + self.grid_xy  &#47&#47 xy
            io[..., 2:4] = torch.exp(io[..., 2:4]) * self.anchor_wh  &#47&#47 wh yolo method
            &#47&#47 io[..., 2:4] = ((torch.sigmoid(io[..., 2:4]) * 2) ** 2) * self.anchor_wh  &#47&#47 wh power method
            io[..., 4:] = torch.sigmoid(io[..., 4:])  &#47&#47 p_conf, p_cls
            &#47&#47 io[..., 5:] = F.softmax(io[..., 5:], dim=4)  &#47&#47 p_cls
            io[..., :4] *= self.stride

            &#47&#47 reshape from [1, 3, 13, 13, 85] to [1, 507, 85]
            return io.view(bs, -1, 5 + self.nC)<a id="change">, p</a>


class Darknet(nn.Module):
    YOLOv3 object detection model</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/nightsnack/yolobile/commit/cb352be02c7d8653bed408f5cc2cdea58145e678#diff-dcfeaa5ac3dffd54264034760914588d92fc7395c81eaa9274715840dc28100bL121' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8036232</div><div id='project'> Project Name: nightsnack/yolobile</div><div id='commit'> Commit Name: cb352be02c7d8653bed408f5cc2cdea58145e678</div><div id='time'> Time: 2019-04-05</div><div id='author'> Author: glenn.jocher@ultralytics.com</div><div id='file'> File Name: models.py</div><div id='m_class'> M Class Name: YOLOLayer</div><div id='n_method'> N Class Name: YOLOLayer</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models.py</div><div id='n_file'> N File Name: models.py</div><div id='m_start'> M Start Line: 130</div><div id='m_end'> M End Line: 168</div><div id='n_start'> N Start Line: 130</div><div id='n_end'> N End Line: 168</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            raise RuntimeError("Unknown value for attention norm type")
        context = torch.bmm(alignment.unsqueeze(1), inputs)
        context = context.squeeze(1)
        return context<a id="change">, alignment</a>


class Postnet(nn.Module):
    def __init__(self, mel_dim, num_convs=5):</code></pre><h3>After Change</h3><pre><code class='java'>
            raise RuntimeError("Unknown value for attention norm type")
        if self.forward_attn:
            &#47&#47 forward attention
            prev_alpha = F.pad(<a id="change">self.alpha[:, :-1].clone()</a>, (1, 0, 0, 0)).to(inputs.device)
            self.alpha<a id="change"> = </a>(((1-self.u) * self.alpha.clone().to(inputs.device) + self.u * prev_alpha) + 1e-7) * alignment
            alpha_norm = self.alpha / self.alpha.sum(dim=1).unsqueeze(1)
            &#47&#47 compute context
            context = torch.bmm(alpha_norm.unsqueeze(1), inputs)
            context = context.squeeze(1)
            return context<a id="change">, alpha_norm, alignment</a>
        else:
            context = torch.bmm(alignment.unsqueeze(1), inputs)
            context = context.squeeze(1)
            return context<a id="change">, alignment, alignment</a>


class Postnet(nn.Module):
    def __init__(self, mel_dim, num_convs=5):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/coqui-ai/tts/commit/961af0f5cdefbb5f267671f6847cf05659962d6c#diff-98fd28c1559c72435d1c59024b2baa25ece39483c2196f2377bfc9ee6c7f183bL145' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8036240</div><div id='project'> Project Name: coqui-ai/tts</div><div id='commit'> Commit Name: 961af0f5cdefbb5f267671f6847cf05659962d6c</div><div id='time'> Time: 2019-04-05</div><div id='author'> Author: egolge@mozilla.com</div><div id='file'> File Name: layers/tacotron2.py</div><div id='m_class'> M Class Name: Attention</div><div id='n_method'> N Class Name: Attention</div><div id='m_method'> M Method Name: forward(6)</div><div id='n_method'> N Method Name: forward(6)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: layers/tacotron2.py</div><div id='n_file'> N File Name: layers/tacotron2.py</div><div id='m_start'> M Start Line: 173</div><div id='m_end'> M End Line: 175</div><div id='n_start'> N Start Line: 193</div><div id='n_end'> N End Line: 208</div><BR>