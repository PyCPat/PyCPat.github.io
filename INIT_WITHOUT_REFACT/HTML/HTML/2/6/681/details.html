<html><h3>Pattern ID :681
</h3><img src='2414244.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        patch_dim = channels * patch_size * patch_size
        self.to_patch_embedding = nn.Sequential(
            Rearrange(&quotb c (h p1) (w p2) -&gt; b (h w) (p1 p2 c)&quot, p1=patch_size, p2=patch_size),
            <a id="change">nn.Linear(</a>patch_dim, emb_dim<a id="change">)</a>,
        )
        &#47&#47Embedding
        self.cls_token = nn.Parameter(torch.randn(1, 1, emb_dim))</code></pre><h3>After Change</h3><pre><code class='java'>
        self.fusions = nn.ModuleList(self.fusions)

        &#47&#47Head
        <a id="change">if type == "full"</a><a id="change">:
            </a>self.head_depth = HeadDepth(resample_dim)
            self.head_segmentation = HeadSeg(resample_dim, nclasses=nclasses)
        elif type == "depth":
            self.head_depth = HeadDepth(resample_dim)
            self.head_segmentation<a id="change"> = </a>None
        else:
            self.head_depth = None
            self.head_segmentation<a id="change"> = </a>HeadSeg(resample_dim, nclasses=nclasses)

    def forward(self, img):
        &#47&#47 x = self.to_patch_embedding(img)</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/antocad/focusondepth/commit/705d8789c4e66dbdbfdd3aeb7f20666f019481dd#diff-941ba600a0201cf159de01531ff7e943fc0434587165f1ce11d65e14346b32b6L25' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2414244</div><div id='project'> Project Name: antocad/focusondepth</div><div id='commit'> Commit Name: 705d8789c4e66dbdbfdd3aeb7f20666f019481dd</div><div id='time'> Time: 2022-01-03</div><div id='author'> Author: antoine.cadiou@icloud.com</div><div id='file'> File Name: FOD/FocusOnDepth.py</div><div id='m_class'> M Class Name: FocusOnDepth</div><div id='n_method'> N Class Name: FocusOnDepth</div><div id='m_method'> M Method Name: __init__(14)</div><div id='n_method'> N Method Name: __init__(12)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: FOD/FocusOnDepth.py</div><div id='n_file'> N File Name: FOD/FocusOnDepth.py</div><div id='m_start'> M Start Line: 38</div><div id='m_end'> M End Line: 69</div><div id='n_start'> N Start Line: 25</div><div id='n_end'> N End Line: 81</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                          nn.ReLU(),
                          &#47&#47nn.Linear(400, 200),
                          &#47&#47nn.ReLU(),
                          <a id="change">nn.Linear(</a>200, 200<a id="change">)</a>,
                          &#47&#47nn.Dropout(p=0.5),
                          &#47&#47nn.Linear(200, 100),
                          nn.ReLU(),</code></pre><h3>After Change</h3><pre><code class='java'>
    def __init__(self, number_of_labels, model_choice, embedding_size, dropout_layer, frozen):
          super(CustomBERTModel, self).__init__()

          <a id="change">if model_choice == "t5-3b"</a><a id="change">:

            </a>tokenizer = T5Tokenizer.from_pretrained(model_choice, model_max_length=512)
            model_encoding = T5EncoderModel.from_pretrained(model_choice)
            embedding_size<a id="change"> = </a>1024
            self.encoderModel = model_encoding

          else:

            tokenizer = AutoTokenizer.from_pretrained(model_choice, model_max_length=512)
                                                      &#47&#47attention_probs_dropout_prob=0.5)
                                                      &#47&#47hidden_dropout_prob=0.5)
            model_encoding = AutoModel.from_pretrained(model_choice)
            embedding_size = 768
            self.encoderModel<a id="change"> = </a>model_encoding


</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/allenai/embeddingrecycling/commit/e8f2ce21388322a4ea20ce43cd214ed12c49e8fd#diff-12e41abdf60fc3caafa5a98d28e44da28cba19f698fed890c00ceecc14b813a8L29' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2414246</div><div id='project'> Project Name: allenai/embeddingrecycling</div><div id='commit'> Commit Name: e8f2ce21388322a4ea20ce43cd214ed12c49e8fd</div><div id='time'> Time: 2022-03-15</div><div id='author'> Author: jonsaadfalcon@gmail.com</div><div id='file'> File Name: General_BiLSTM+LinearClassifer.py</div><div id='m_class'> M Class Name: CustomBERTModel</div><div id='n_method'> N Class Name: CustomBERTModel</div><div id='m_method'> M Method Name: __init__(6)</div><div id='n_method'> N Method Name: __init__(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: General_BiLSTM+LinearClassifer.py</div><div id='n_file'> N File Name: General_BiLSTM+LinearClassifer.py</div><div id='m_start'> M Start Line: 32</div><div id='m_end'> M End Line: 47</div><div id='n_start'> N Start Line: 30</div><div id='n_end'> N End Line: 62</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            input_dim = self.obs_size
            for i in range(self.custom_config["model_arch_args"]["fc_layer"]):
                out_dim = self.custom_config["model_arch_args"]["out_dim_fc_{}".format(i)]
                fc_layer = <a id="change">nn.Linear(</a>input_dim, out_dim<a id="change">)</a>
                layers.append(fc_layer)
                input_dim = out_dim
        elif "conv_layer" in self.custom_config["model_arch_args"]:
            self.obs_size = self.full_obs_space[&quotobs&quot].shape</code></pre><h3>After Change</h3><pre><code class='java'>
        self.full_obs_space = getattr(obs_space, "original_space", obs_space)
        self.n_agents = self.custom_config["num_agents"]

        <a id="change">if "encode_layer" in self.custom_config["model_arch_args"]</a><a id="change">:
            </a>encode_layer<a id="change"> = </a>self.custom_config["model_arch_args"]["encode_layer"]
            encoder_layer_dim = encode_layer.split("-")
            encoder_layer_dim = [int(i) for i in encoder_layer_dim]
        else:  &#47&#47 default config
            encoder_layer_dim<a id="change"> = </a>[]
            for i in range(self.custom_config["model_arch_args"]["fc_layer"]):
                out_dim = self.custom_config["model_arch_args"]["out_dim_fc_{}".format(i)]
                encoder_layer_dim.append(out_dim)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/replicable-marl/marllib/commit/229bfd1c9db33d2ff0761dbdbe21e47a47a9b87c#diff-e310323240be446aa2287d549762141aae57452d84612f7b2056cac71cf28a4eL18' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 2414240</div><div id='project'> Project Name: replicable-marl/marllib</div><div id='commit'> Commit Name: 229bfd1c9db33d2ff0761dbdbe21e47a47a9b87c</div><div id='time'> Time: 2023-02-23</div><div id='author'> Author: hhhusiyi@163.com</div><div id='file'> File Name: marllib/marl/models/zoo/rnn/base_rnn.py</div><div id='m_class'> M Class Name: Base_RNN</div><div id='n_method'> N Class Name: Base_RNN</div><div id='m_method'> M Method Name: __init__(6)</div><div id='n_method'> N Method Name: __init__(6)</div><div id='m_parent_class'> M Parent Class: TorchRNN,nn.Module</div><div id='n_parent_class'> N Parent Class: TorchRNN,nn.Module</div><div id='m_file'> M File Name: marllib/marl/models/zoo/rnn/base_rnn.py</div><div id='n_file'> N File Name: marllib/marl/models/zoo/rnn/base_rnn.py</div><div id='m_start'> M Start Line: 39</div><div id='m_end'> M End Line: 86</div><div id='n_start'> N Start Line: 34</div><div id='n_end'> N End Line: 105</div><BR>