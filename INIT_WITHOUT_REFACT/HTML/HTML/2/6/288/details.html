<html><h3>Pattern ID :288
</h3><img src='968934.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        self.stride = stride

    def forward(self, x):
        stride<a id="change"> = </a>self.stride
        assert (x.data.dim() == 4)
        B = x.data.size(0)
        C = x.data.size(1)
        H = x.data.size(2)
        W = x.data.size(3)
        ws = stride
        hs<a id="change"> = </a>stride
        x<a id="change"> = </a><a id="change">x.view(B, C, H, 1, W, 1).expand(B, C, H, stride, W, stride).contiguous()</a>.view(B, C, H * stride, W * stride)
        <a id="change">return </a>x


class Conv_Bn_Activation(nn.Module):</code></pre><h3>After Change</h3><pre><code class='java'>

    def forward(self, x, target_size):
        assert (x.data.dim() == 4)
        _<a id="change">, _, H, W</a> = target_size
        return F.interpolate(x, size=(H, W), mode=&quotnearest&quot)

</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/tianxiaomo/pytorch-yolov4/commit/9d415b48fb7e1aad2ec47d1b51695fbd3d2b5cd1#diff-dcfeaa5ac3dffd54264034760914588d92fc7395c81eaa9274715840dc28100bL19' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 968934</div><div id='project'> Project Name: tianxiaomo/pytorch-yolov4</div><div id='commit'> Commit Name: 9d415b48fb7e1aad2ec47d1b51695fbd3d2b5cd1</div><div id='time'> Time: 2020-05-23</div><div id='author'> Author: mark.weber1@rwth-aachen.de</div><div id='file'> File Name: models.py</div><div id='m_class'> M Class Name: Upsample</div><div id='n_method'> N Class Name: Upsample</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models.py</div><div id='n_file'> N File Name: models.py</div><div id='m_start'> M Start Line: 20</div><div id='m_end'> M End Line: 29</div><div id='n_start'> N Start Line: 19</div><div id='n_end'> N End Line: 22</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

        outputs = []
        alignments = []
        stop_outputs<a id="change"> = </a>[]

        t = 0
        memory_input = initial_memory
        while True:
            if t &gt; 0:
                if greedy:
                    memory_input = outputs[-1]
                else:
                    &#47&#47 combine prev. model output and prev. real target
                    &#47&#47 memory_input = torch.div(outputs[-1] + memory[t-1], 2.0)
                    &#47&#47 add a random noise
                    &#47&#47 noise = torch.autograd.Variable(
                        &#47&#47 memory_input.data.new(memory_input.size()).normal_(0.0, 0.5))
                    &#47&#47 memory_input = memory_input + noise
                    memory_input = memory[t-1]

            &#47&#47 Prenet
            processed_memory = self.prenet(memory_input)

            &#47&#47 Attention RNN
            attention_rnn_hidden, current_context_vec, alignment = self.attention_rnn(
                processed_memory, current_context_vec, attention_rnn_hidden,
                inputs)

            &#47&#47 Concat RNN output and attention context vector
            decoder_input = self.project_to_decoder_in(
                torch.cat((attention_rnn_hidden, current_context_vec), -1))

            &#47&#47 Pass through the decoder RNNs
            for idx in range(len(self.decoder_rnns)):
                decoder_rnn_hiddens[idx] = self.decoder_rnns[idx](
                    decoder_input, decoder_rnn_hiddens[idx])
                &#47&#47 Residual connectinon
                decoder_input = decoder_rnn_hiddens[idx] + decoder_input
            
            output = decoder_input
            stop_token_input = decoder_input
            
            &#47&#47 stop token prediction
            stop_token_input = torch.cat((output, current_context_vec), -1)
            stop_output = self.stop_token(stop_token_input)

            &#47&#47 predict mel vectors from decoder vectors
            output = self.proj_to_mel(output)

            outputs += [output]
            alignments += [alignment]
            stop_outputs<a id="change"> += </a>[stop_output]

            t += 1

            if (not greedy and self.training) or (greedy and memory is not None):
                if t &gt;= T_decoder:
                    break
            else:
                if t &gt; 1 and is_end_of_frames(output, self.eps):
                    break
                elif t &gt; self.max_decoder_steps:
                    print(" !! Decoder stopped with &quotmax_decoder_steps&quot. \
                          Something is probably wrong.")
                    break
                           
        assert greedy or len(outputs) == T_decoder

        &#47&#47 Back to batch first
        alignments = torch.stack(alignments).transpose(0, 1)
        outputs = torch.stack(outputs).transpose(0, 1).contiguous()
        stop_outputs<a id="change"> = </a><a id="change">torch.stack(stop_outputs).transpose(0, 1).contiguous()</a>

        <a id="change">return </a>outputs, alignments, stop_outputs


def is_end_of_frames(output, eps=0.2): &#47&#470.2</code></pre><h3>After Change</h3><pre><code class='java'>
        alignments = torch.stack(alignments).transpose(0, 1)
        outputs = torch.stack(outputs).transpose(0, 1).contiguous()

        return outputs<a id="change">, alignments</a>


def is_end_of_frames(output, eps=0.2): &#47&#470.2
    return (output.data &lt;= eps).all()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/coqui-ai/tts/commit/a925c9c75cdc699336b1c1b012db9b2e08bc23da#diff-63415e5bdfe9c172be8a9cadb35d1f47d718fea5f15c6879f5715ebb9e331155L239' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 968932</div><div id='project'> Project Name: coqui-ai/tts</div><div id='commit'> Commit Name: a925c9c75cdc699336b1c1b012db9b2e08bc23da</div><div id='time'> Time: 2018-03-22</div><div id='author'> Author: egolge@mozilla.com</div><div id='file'> File Name: layers/tacotron.py</div><div id='m_class'> M Class Name: Decoder</div><div id='n_method'> N Class Name: Decoder</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: layers/tacotron.py</div><div id='n_file'> N File Name: layers/tacotron.py</div><div id='m_start'> M Start Line: 280</div><div id='m_end'> M End Line: 359</div><div id='n_start'> N Start Line: 346</div><div id='n_end'> N End Line: 349</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
       &#47&#47 self.training |= self.export
        if self.export:
            for i in range(self.nl):
                x[i]<a id="change"> = </a>self.m[i](x[i])
                bs<a id="change">, _, ny, nx = </a>x[i].shape  &#47&#47 x(bs,48,20,20) to x(bs,3,20,20,16)
                x[i]<a id="change"> = </a><a id="change">x[i].view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()</a>

            <a id="change">return </a>x
        if self.export_cat:
            for i in range(self.nl):
                x[i] = self.m[i](x[i])  &#47&#47 conv</code></pre><h3>After Change</h3><pre><code class='java'>

                if self.grid[i].shape[2:4] != x[i].shape[2:4]:
                    &#47&#47 self.grid[i] = self._make_grid(nx, ny).to(x[i].device)
                    self.grid[i]<a id="change">, self.anchor_grid[i]</a> = self._make_grid_new(nx, ny,i)

                y = torch.full_like(x[i], 0)
                y = y + torch.cat((x[i][:, :, :, :, 0:5].sigmoid(), torch.cat((x[i][:, :, :, :, 5:15], x[i][:, :, :, :, 15:15+self.nc].sigmoid()), 4)), 4)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/deepcam-cn/yolov5-face/commit/dce28069b579d807dac4e694e87d3c0ee3f777ec#diff-2cd118cbb69c9ca7b5544f4187b11335fc3addbaf2c3c5bb45435cac648c957bL46' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 968933</div><div id='project'> Project Name: deepcam-cn/yolov5-face</div><div id='commit'> Commit Name: dce28069b579d807dac4e694e87d3c0ee3f777ec</div><div id='time'> Time: 2021-12-17</div><div id='author'> Author: lipengbo@kanzhun.com</div><div id='file'> File Name: models/yolo.py</div><div id='m_class'> M Class Name: Detect</div><div id='n_method'> N Class Name: Detect</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/yolo.py</div><div id='n_file'> N File Name: models/yolo.py</div><div id='m_start'> M Start Line: 50</div><div id='m_end'> M End Line: 64</div><div id='n_start'> N Start Line: 49</div><div id='n_end'> N End Line: 56</div><BR>