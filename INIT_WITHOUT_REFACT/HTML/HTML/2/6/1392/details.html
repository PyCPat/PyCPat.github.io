<html><h3>Pattern ID :1392
</h3><img src='4059964.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    def forward(self, latents, coeff, transform):
        quantizeds = list()
        codes = list()
        logits<a id="change"> = </a>list()
        for i, (xRaw, k) in enumerate(zip(latents, self._k)):
            n, c, h, w = xRaw.shape
            &#47&#47 [n, c, h, w] -&gt; [h, w, n, c]
            encoderIn = xRaw.permute(2, 3, 0, 1)
            &#47&#47 [h, w, n, c] -&gt; [h*w, n, c]
            if True:
                encoderIn = self._position(encoderIn).reshape(-1, n, c)
                &#47&#47 encoderIn = encoderIn.reshape(-1, n, c)
                &#47&#47 [h*w, n, c]
                x = self._encoder(encoderIn)
            else:
                x = encoderIn.reshape(-1, n ,c)
            &#47&#47 similar to scaled dot-product attention
            &#47&#47 [h*w, N, c]
            quantized, sample, logit = self._attention(x, i, False)
            if True:
                &#47&#47 [h*w, n, c]
                posistedQuantized = self._position(quantized.reshape(h, w, n, c)).reshape(-1, n, c)
                deTransformed = self._decoder(posistedQuantized, posistedQuantized).reshape(h, w, n, c).permute(2, 3, 0, 1)
            else:
                &#47&#47 [h*w, n, c] -&gt; [n, c, h*w] -&gt; [n, c, h, w]
                deTransformed = quantized.reshape(h, w, n, c).permute(2, 3, 0, 1)

            &#47&#47 mask = torch.rand_like(xRaw) &gt; coeff
            &#47&#47 mixed = mask * xRaw.detach() + torch.logical_not(mask) * deTransformed
            &#47&#47 [n, c, h, w]
            quantizeds.append(deTransformed)
            codes.append(sample.argmax(-1).permute(1, 0).reshape(n, h, w))
            <a id="change">logits.append(</a>logit.permute(1, 0, 2).reshape(n, h, w, k)<a id="change">)</a>
        return quantizeds, codes, logits


class TransformerQuantizerRein(nn.Module):</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 [n, c, h, w]
            quantizeds.append(deTransformed)
            samples = [s.argmax(-1).permute(1, 0).reshape(n, h, w) for s in samples]
            logits = [<a id="change">l.permute(1</a>, <a id="change">0</a>, <a id="change">2</a><a id="change">)</a>.reshape(n, h, w, k) for l in logits]
            &#47&#47 codes.append(samples.argmax(-1).permute(1, 0).reshape(n, h, w))
            &#47&#47 logits.append(logit.permute(1, 0, 2).reshape(n, h, w, k))
        return quantizeds, codes, logits</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 3</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/xiaosu-zhu/mcquic/commit/36075d9c06641e76ffab1b363262368618d53912#diff-6b290d83a36e7951ea6e9dbd33da6b8e0b6f40c45926540ce74b74ea4ab48a24L114' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4059964</div><div id='project'> Project Name: xiaosu-zhu/mcquic</div><div id='commit'> Commit Name: 36075d9c06641e76ffab1b363262368618d53912</div><div id='time'> Time: 2021-03-18</div><div id='author'> Author: xiaosu.zhu@outlook.com</div><div id='file'> File Name: src/mcqc/models/quantizer.py</div><div id='m_class'> M Class Name: TransformerQuantizer</div><div id='n_method'> N Class Name: TransformerQuantizer</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/mcqc/models/quantizer.py</div><div id='n_file'> N File Name: src/mcqc/models/quantizer.py</div><div id='m_start'> M Start Line: 114</div><div id='m_end'> M End Line: 144</div><div id='n_start'> N Start Line: 147</div><div id='n_end'> N End Line: 162</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        batch_size, num_of_vertices, in_channels, num_of_timesteps = x.shape
        data = Data(edge_index=edge_index, edge_attr=None, num_nodes=num_nodes)
        lambda_max = LaplacianLambdaMax()(data).lambda_max
        outputs<a id="change"> = </a>[]
        for time_step in range(num_of_timesteps):
            <a id="change">outputs.append(</a>torch.unsqueeze(self.cheb_conv(x=x[:,:,:,time_step], edge_index=edge_index,
                batch = batch_size, lambda_max=lambda_max), -1)<a id="change">)</a>

        spatial_gcn = F.relu(torch.cat(outputs, dim=-1)) &#47&#47 (b,N,F,T)

        &#47&#47 convolution along the time axis</code></pre><h3>After Change</h3><pre><code class='java'>
                batch = batch_size, lambda_max=lambda_max), -1))
        spatial_gcn = F.relu(torch.cat(outputs, dim=-1)) &#47&#47 (b,N,F,T)
        &quot&quot&quot
        tmp = <a id="change">x.permute(2</a>,0,<a id="change">1</a>,<a id="change">3</a><a id="change">)</a>.reshape(num_of_vertices, in_channels, num_of_timesteps*batch_size) &#47&#47 (N_nodes, F_in, B*T_in)
        tmp = tmp.permute(2,0,1) &#47&#47 (B*T_in, N_nodes, F_in)
        output = F.relu(self.cheb_conv(x=tmp, edge_index=edge_index,
                batch = batch_size*num_of_timesteps, lambda_max=lambda_max))</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/benedekrozemberczki/pytorch_geometric_temporal/commit/509a541a01913f5b45859b801c48b5fd264bd94a#diff-21666376be83b64a4fa768847ddfc3e4e7076772ef843870e346158dd7205045L18' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4059961</div><div id='project'> Project Name: benedekrozemberczki/pytorch_geometric_temporal</div><div id='commit'> Commit Name: 509a541a01913f5b45859b801c48b5fd264bd94a</div><div id='time'> Time: 2021-03-18</div><div id='author'> Author: He_YX@outlook.com</div><div id='file'> File Name: torch_geometric_temporal/nn/convolutional/mstgcn.py</div><div id='m_class'> M Class Name: MSTGCN_block</div><div id='n_method'> N Class Name: MSTGCN_block</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: torch_geometric_temporal/nn/convolutional/mstgcn.py</div><div id='n_file'> N File Name: torch_geometric_temporal/nn/convolutional/mstgcn.py</div><div id='m_start'> M Start Line: 36</div><div id='m_end'> M End Line: 41</div><div id='n_start'> N Start Line: 44</div><div id='n_end'> N End Line: 48</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        quantizeds = list()
        codes = list()
        logits = list()
        allCodewords<a id="change"> = </a>list()
        &#47&#47 probability = mixin / (mixin + 1.0)
        &#47&#47 rolloutDistribution = Bernoulli(probs=torch.tensor(probability).to(latents[0].device))
        for xRaw, prob, squeeze, codebook, k in zip(latents, self._prob, self._squeeze, self._codebook, self._k):
            n, c, h, w = xRaw.shape
            &#47&#47 [c, k]
            codewords = codebook.weight
            &#47&#47 [n, c, h, w] -&gt; [h, w, n, c]
            encoderIn = xRaw.permute(2, 3, 0, 1)
            &#47&#47 [h, w, n, c] -&gt; [h*w, n, c]
            encoderIn = self._position(encoderIn).reshape(-1, n, c)
            &#47&#47 [h*w, n, c]
            &#47&#47 x = self._encoder(posisted)
            x = self._encoder(encoderIn)
            &#47&#47 x += torch.randn_like(x)
            &#47&#47 x = self._dePosition(x.reshape(h, w, n, c)).reshape(-1, n, c)
            &#47&#47 x = encoderIn
            &#47&#47 [h*w, n, k]
            &#47&#47 logit = prob(x, h, w)
            &#47&#47 logit = torch.matmul(x / (x ** 2).sum(-1, keepdim=True), codewords / (codewords ** 2).sum(0, keepdim=True))
            logit = x @ codewords
            &#47&#47 soft = (logit / temperature).softmax(-1)
            &#47&#47 if hard:
            &#47&#47      hard = logit.argmax(-1)
            &#47&#47       hard = F.one_hot(hard, k)
            &#47&#47       sample = (hard - soft).detach() + soft
            &#47&#47 else:
            &#47&#47      sample = soft
            sample = F.gumbel_softmax(logit, temperature, hard)
            &#47&#47 sample = logit
            &#47&#47 [h*w, N, c] &lt;- [h*w, N, k] @ [k, C]
            quantized = codebook(sample)
            &#47&#47 quantized += torch.randn_like(quantized)
            &#47&#47 quantized = sample

            &#47&#47 normalize
            &#47&#47 quantized /= (k - 0.5) / (2 * k - 2)
            &#47&#47 [h*w, n, c]
            &#47&#47 quantized -= 0.5 / (k - 1)
            &#47&#47 quantized = squeeze(sample, h, w)
            posistedQuantized = self._position(quantized.reshape(h, w, n, c)).reshape(-1, n, c)

            &#47&#47 mixed = (mixin * encoderIn / (mixin + 1)) + (quantized / (mixin + 1))

            &#47&#47 mask = rolloutDistribution.sample((h*w, n, 1)).bool()

            &#47&#47 mixed = mask * encoderIn.detach() + torch.logical_not(mask) * quantized
            &#47&#47 [h*w, n, c] -&gt; [n, c, h*w] -&gt; [n, c, h, w]
            deTransformed = self._decoder(posistedQuantized, posistedQuantized).reshape(h, w, n, c).permute(2, 3, 0, 1)
            &#47&#47 deTransformed = quantized.permute(1, 2, 0).reshape(n, c, h, w)
            &#47&#47 deTransformed = self._dePosition(deTransformed.reshape(h, w, n, c)).permute(2, 3, 0, 1)
            &#47&#47 [n, c, h, w]
            quantizeds.append(deTransformed)
            codes.append(sample.argmax(-1).permute(1, 0).reshape(n, h, w))
            logits.append(logit.reshape(n, h, w, k))
            <a id="change">allCodewords.append(</a>codewords.t()<a id="change">)</a>
        return quantizeds, codes, logits, allCodewords


class TransformerQuantizerRein(nn.Module):</code></pre><h3>After Change</h3><pre><code class='java'>
            &#47&#47 [n, c, h, w]
            quantizeds.append(deTransformed)
            codes.append(sample.argmax(-1).permute(1, 0).reshape(n, h, w))
            logits.append(<a id="change">logit.permute(1</a>, <a id="change">0</a>, <a id="change">2</a><a id="change">)</a>.reshape(n, h, w, k))
        return quantizeds, codes, logits

</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/xiaosu-zhu/mcquic/commit/594ba7cd5c9d147e95ba5bd0b842270302dea2a2#diff-6b290d83a36e7951ea6e9dbd33da6b8e0b6f40c45926540ce74b74ea4ab48a24L282' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 4060072</div><div id='project'> Project Name: xiaosu-zhu/mcquic</div><div id='commit'> Commit Name: 594ba7cd5c9d147e95ba5bd0b842270302dea2a2</div><div id='time'> Time: 2021-03-02</div><div id='author'> Author: xiaosu.zhu@outlook.com</div><div id='file'> File Name: src/mcqc/models/quantizer.py</div><div id='m_class'> M Class Name: TransformerQuantizer</div><div id='n_method'> N Class Name: TransformerQuantizer</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/mcqc/models/quantizer.py</div><div id='n_file'> N File Name: src/mcqc/models/quantizer.py</div><div id='m_start'> M Start Line: 282</div><div id='m_end'> M End Line: 342</div><div id='n_start'> N Start Line: 295</div><div id='n_end'> N End Line: 320</div><BR>