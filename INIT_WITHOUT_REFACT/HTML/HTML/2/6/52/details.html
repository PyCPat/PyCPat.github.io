<html><h3>Pattern ID :52
</h3><img src='211075.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
		self.__initial_width = img_shape[1] // (2 ** n_adain_layers)
		self.__adain_dim = adain_dim

		self.fc_layers = <a id="change">nn.Sequential(
			</a>nn.Linear(
				in_features=content_dim,
				out_features=self.__initial_height * self.__initial_width * (adain_dim // 8)
			),

			nn.LeakyReLU(),

			<a id="change">nn.Linear(
				in_features=self.__initial_height * self.__initial_width * (adain_dim // 8),
				out_features=self.__initial_height * self.__initial_width * (adain_dim // 4)
			)</a>,

			nn.LeakyReLU(),

			nn.Linear(
				in_features=self.__initial_height * self.__initial_width * (adain_dim // 4),
				out_features=self.__initial_height * self.__initial_width * adain_dim
			),

			nn.LeakyReLU()<a id="change">
		)</a>

		self.adain_conv_layers = nn.ModuleList()
		for i in range(n_adain_layers):
			self.adain_conv_layers += [
				nn.Upsample(scale_factor=(2, 2)),
				nn.Conv2d(in_channels=adain_dim, out_channels=adain_dim, padding=1, kernel_size=3),
				nn.LeakyReLU(),
				AdaptiveInstanceNorm2d(adain_layer_idx=i)
			]

		self.adain_conv_layers = nn.Sequential(*self.adain_conv_layers)

		self.last_conv_layers<a id="change"> = nn</a><a id="change">.Sequential(
			</a>nn.Conv2d(in_channels=adain_dim, out_channels=64, padding=2, kernel_size=5),
			nn.LeakyReLU(),

			nn.Conv2d(in_channels=64, out_channels=img_shape[2], padding=3, kernel_size=7),
			nn.Sigmoid()<a id="change">
		)</a>

	def assign_adain_params(self, adain_params):
		for m in self.adain_conv_layers.modules():
			if m.__class__.__name__ == "AdaptiveInstanceNorm2d":</code></pre><h3>After Change</h3><pre><code class='java'>

		self.content_embedding = nn.Embedding(config[&quotn_imgs&quot], config[&quotcontent_dim&quot], config[&quotcontent_std&quot])
		self.class_embedding = nn.Embedding(config[&quotn_classes&quot], config[&quotclass_dim&quot])
		self.modulation = Modulation(<a id="change">config[&quotclass_dim&quot]</a>, config[&quotn_adain_layers&quot], config[&quotadain_dim&quot])
		self.decoder = Decoder(config[&quotcontent_dim&quot], config[&quotn_adain_layers&quot], config[&quotadain_dim&quot], config[&quotimg_shape&quot])

	def forward(self, img_id, class_id):</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 4</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/avivga/overlord/commit/5003297b3925f6c55beefdcd29353d4389f68d30#diff-44dac3f4f06b62a8129520d279f589b0b2144de4f2a7720992f263c496651b43L8' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 211075</div><div id='project'> Project Name: avivga/overlord</div><div id='commit'> Commit Name: 5003297b3925f6c55beefdcd29353d4389f68d30</div><div id='time'> Time: 2020-05-12</div><div id='author'> Author: avivga@gmail.com</div><div id='file'> File Name: model/modules.py</div><div id='m_class'> M Class Name: Generator</div><div id='n_method'> N Class Name: Generator</div><div id='m_method'> M Method Name: __init__(2)</div><div id='n_method'> N Method Name: __init__(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: model/modules.py</div><div id='n_file'> N File Name: model/modules.py</div><div id='m_start'> M Start Line: 71</div><div id='m_end'> M End Line: 118</div><div id='n_start'> N Start Line: 8</div><div id='n_end'> N End Line: 16</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
		self.__initial_width = img_shape[1] // (2 ** n_adain_layers)
		self.__adain_dim = adain_dim

		self.fc_layers = <a id="change">nn.Sequential(
			</a>nn.Linear(
				in_features=content_dim,
				out_features=self.__initial_height * self.__initial_width * (adain_dim // 8)
			),

			nn.LeakyReLU(),

			nn.Linear(
				in_features=self.__initial_height * self.__initial_width * (adain_dim // 8),
				out_features=self.__initial_height * self.__initial_width * (adain_dim // 4)
			),

			nn.LeakyReLU(),

			<a id="change">nn.Linear(
				in_features=self.__initial_height * self.__initial_width * (adain_dim // 4),
				out_features=self.__initial_height * self.__initial_width * adain_dim
			)</a>,

			nn.LeakyReLU()<a id="change">
		)</a>

		self.adain_conv_layers = nn.ModuleList()
		for i in range(n_adain_layers):
			self.adain_conv_layers += [
				nn.Upsample(scale_factor=(2, 2)),
				nn.Conv2d(in_channels=adain_dim, out_channels=adain_dim, padding=1, kernel_size=3),
				nn.LeakyReLU(),
				AdaptiveInstanceNorm2d(adain_layer_idx=i)
			]

		self.adain_conv_layers = nn.Sequential(*self.adain_conv_layers)

		self.last_conv_layers<a id="change"> = </a><a id="change">nn.Sequential(
			</a>nn.Conv2d(in_channels=adain_dim, out_channels=64, padding=2, kernel_size=5),
			nn.LeakyReLU(),

			nn.Conv2d(in_channels=64, out_channels=img_shape[2], padding=3, kernel_size=7),
			nn.Sigmoid()<a id="change">
		)</a>

	def assign_adain_params(self, adain_params):
		for m in self.adain_conv_layers.modules():
			if m.__class__.__name__ == "AdaptiveInstanceNorm2d":</code></pre><h3>After Change</h3><pre><code class='java'>
		self.content_embedding = nn.Embedding(config[&quotn_imgs&quot], config[&quotcontent_dim&quot], config[&quotcontent_std&quot])
		self.class_embedding = nn.Embedding(config[&quotn_classes&quot], config[&quotclass_dim&quot])
		self.modulation = Modulation(config[&quotclass_dim&quot], config[&quotn_adain_layers&quot], config[&quotadain_dim&quot])
		self.decoder = Decoder(config[&quotcontent_dim&quot], config[&quotn_adain_layers&quot], config[&quotadain_dim&quot], <a id="change">config[&quotimg_shape&quot]</a>)

	def forward(self, img_id, class_id):
		content_code = self.content_embedding(img_id)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/avivga/overlord/commit/5003297b3925f6c55beefdcd29353d4389f68d30#diff-44dac3f4f06b62a8129520d279f589b0b2144de4f2a7720992f263c496651b43L71' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 211073</div><div id='project'> Project Name: avivga/overlord</div><div id='commit'> Commit Name: 5003297b3925f6c55beefdcd29353d4389f68d30</div><div id='time'> Time: 2020-05-12</div><div id='author'> Author: avivga@gmail.com</div><div id='file'> File Name: model/modules.py</div><div id='m_class'> M Class Name: Generator</div><div id='n_method'> N Class Name: Generator</div><div id='m_method'> M Method Name: __init__(2)</div><div id='n_method'> N Method Name: __init__(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: model/modules.py</div><div id='n_file'> N File Name: model/modules.py</div><div id='m_start'> M Start Line: 71</div><div id='m_end'> M End Line: 118</div><div id='n_start'> N Start Line: 8</div><div id='n_end'> N End Line: 16</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        super(AddonNN, self).__init__()

        &#47&#47 keep everything but the last layer 
        self.featurizer<a id="change"> = </a><a id="change">nn.Sequential(</a>*<a id="change">list(model.classifier.children())[:-1])</a>
        
        &#47&#47 freeze the featurizer
        for param in self.featurizer.parameters():
            param.requires_grad_ = False

        &#47&#47 create small network that will take features as input
        &#47&#47 TODO: got to figure out what is input size
        self.addon_nn = <a id="change">nn.Sequential(
            </a><a id="change">nn.Linear(</a>feat_size, 4096<a id="change">)</a>, 
            nn.ReLU(), 
            nn.Linear(4096, 4096), 
            nn.ReLU(), 
            nn.Linear(4096, num_classes)<a id="change">)</a> 

    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:
        &#47&#47 pass through the original network up to the penultimate layer</code></pre><h3>After Change</h3><pre><code class='java'>
            param.requires_grad = False

        &#47&#47 create small network that will take features as input
        self.addon_nn = nn.Linear(<a id="change">self.FEAT_SIZE[stack_num]</a>, num_classes)
            

    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/microsoft/archai/commit/16a8b37ef55c82318b3c89402322a1a36f063113#diff-78d7ef277c143adf9ed48114cd24da6d03296baf18dcd78c4a97084c8797caa9L12' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 211099</div><div id='project'> Project Name: microsoft/archai</div><div id='commit'> Commit Name: 16a8b37ef55c82318b3c89402322a1a36f063113</div><div id='time'> Time: 2022-12-16</div><div id='author'> Author: dedey@microsoft.com</div><div id='file'> File Name: archai/algos/proxynas/addon_nn.py</div><div id='m_class'> M Class Name: AddonNN</div><div id='n_method'> N Class Name: AddonNN</div><div id='m_method'> M Method Name: __init__(4)</div><div id='n_method'> N Method Name: __init__(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: archai/algos/proxynas/addon_nn.py</div><div id='n_file'> N File Name: archai/algos/proxynas/addon_nn.py</div><div id='m_start'> M Start Line: 12</div><div id='m_end'> M End Line: 29</div><div id='n_start'> N Start Line: 8</div><div id='n_end'> N End Line: 23</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

		)

		self.projection = <a id="change">nn.Sequential(
			</a>nn.Linear(in_features=config[&quotcontent_dim&quot], out_features=256),
			nn.LeakyReLU(negative_slope=0.2),

			<a id="change">nn.Linear(in_features=256, out_features=256 * self.initial_size * self.initial_size)</a>,
			nn.LeakyReLU(negative_slope=0.2)<a id="change">
		)</a>

		self.decoder = nn.Sequential(
			AdainResBlk(dim_in=256, dim_out=256, style_dim=config[&quotstyle_dim&quot], upsample=False),
			AdainResBlk(dim_in=256, dim_out=256, style_dim=config[&quotstyle_dim&quot], upsample=False),

			AdainResBlk(dim_in=256, dim_out=256, style_dim=config[&quotstyle_dim&quot], upsample=True),
			AdainResBlk(dim_in=256, dim_out=256, style_dim=config[&quotstyle_dim&quot], upsample=True),
			AdainResBlk(dim_in=256, dim_out=128, style_dim=config[&quotstyle_dim&quot], upsample=True),
			AdainResBlk(dim_in=128, dim_out=64, style_dim=config[&quotstyle_dim&quot], upsample=True)
		)

		self.to_rgb<a id="change"> = </a><a id="change">nn.Sequential(
			</a>nn.InstanceNorm2d(num_features=64, affine=True),
			nn.LeakyReLU(negative_slope=0.2),
			nn.Conv2d(in_channels=64, out_channels=3, kernel_size=1, stride=1, padding=0),
			nn.Tanh()<a id="change">
		)</a>

		self.apply(he_init)

	def forward(self, content_img_id, style_code, class_id):</code></pre><h3>After Change</h3><pre><code class='java'>
		)

		self.modulation = Modulation(config[&quotstyle_dim&quot], n_adain_layers=4, adain_dim=256)
		self.decoder = Decoder(<a id="change">config[&quotcontent_dim&quot]</a>, n_adain_layers=4, adain_dim=256, img_shape=config[&quotimg_shape&quot])

		self.apply(self.weights_init)
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/avivga/overlord/commit/5fdf4019e9ff74b0574e25f5c6e8dc6a5e588cbe#diff-44dac3f4f06b62a8129520d279f589b0b2144de4f2a7720992f263c496651b43L12' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 211019</div><div id='project'> Project Name: avivga/overlord</div><div id='commit'> Commit Name: 5fdf4019e9ff74b0574e25f5c6e8dc6a5e588cbe</div><div id='time'> Time: 2020-05-23</div><div id='author'> Author: avivga@gmail.com</div><div id='file'> File Name: model/modules.py</div><div id='m_class'> M Class Name: Generator</div><div id='n_method'> N Class Name: Generator</div><div id='m_method'> M Method Name: __init__(2)</div><div id='n_method'> N Method Name: __init__(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: model/modules.py</div><div id='n_file'> N File Name: model/modules.py</div><div id='m_start'> M Start Line: 16</div><div id='m_end'> M End Line: 56</div><div id='n_start'> N Start Line: 29</div><div id='n_end'> N End Line: 32</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            self.feat1 = Mlp(in_channels=c[0], in_features=f[0], out_channels=c[1], out_features=f[1])
            self.acvt1 = nn.Sequential(nn.BatchNorm1d(c[1]), nn.Softsign())
            self.feat2 = Mlp(in_channels=c[1], in_features=f[1], out_channels=c[2], out_features=f[2])
            self.acvt2<a id="change"> = </a><a id="change">nn.Sequential(</a>nn.BatchNorm1d(c[2]), nn.Softsign()<a id="change">)</a>
            self.classifier = <a id="change">nn.Sequential(</a>nn.Flatten(), nn.Dropout(p=0.1), <a id="change">nn.Linear(</a>c[2]*f[2], num_class<a id="change">))</a>

    def forward(self, x, neighbor):
        if not self.ismlp:
            &#47&#47&#47&#47 Temp LGL works for k =1 &#47&#47&#47&#47 TODO this can be merge with KLGL</code></pre><h3>After Change</h3><pre><code class='java'>
        &#47&#47&#47&#47 the Flag ismlp will encode without neighbor
        super(LGL, self).__init__()
        self.ismlp = ismlp
        c = [1, 4, <a id="change">hidden[1]</a>]
        f = [feat_len, 16, 1]
            
        self.feat1 = FeatTrans1d(in_channels=c[0], in_features=f[0], out_channels=c[1], out_features=f[1])</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/wang-chen/lgl/commit/dd8f35ac79c1dcb4107c1d6bf229349c6f2ee91f#diff-fbd9344836a44eafaedec373420bcf410fcb79ee0bc21cb17b9b0f7ba1b57df3L35' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 211098</div><div id='project'> Project Name: wang-chen/lgl</div><div id='commit'> Commit Name: dd8f35ac79c1dcb4107c1d6bf229349c6f2ee91f</div><div id='time'> Time: 2021-05-19</div><div id='author'> Author: yuhengq@andrew.cmu.edu</div><div id='file'> File Name: models/lgl.py</div><div id='m_class'> M Class Name: LGL</div><div id='n_method'> N Class Name: LGL</div><div id='m_method'> M Method Name: __init__(5)</div><div id='n_method'> N Method Name: __init__(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: models/lgl.py</div><div id='n_file'> N File Name: models/lgl.py</div><div id='m_start'> M Start Line: 38</div><div id='m_end'> M End Line: 55</div><div id='n_start'> N Start Line: 37</div><div id='n_end'> N End Line: 48</div><BR>