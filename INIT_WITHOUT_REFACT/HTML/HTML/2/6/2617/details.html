<html><h3>Pattern ID :2617
</h3><img src='8568210.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
        &#47&#47 logits_flat: (batch * max_len, dim)
        input = input.view(-1, input.shape[-1])
        &#47&#47 target_flat: (batch * max_len, dim)
        target_flat = <a id="change">target.view(</a>-1, target.shape[-1]<a id="change">)</a>
        &#47&#47 losses_flat: (batch * max_len, dim)
        losses_flat = functional.mse_loss(
            input, target_flat, size_average=False, reduce=False)
        &#47&#47 losses: (batch, max_len, dim)
        losses = losses_flat.view(*<a id="change">target.size()</a>)

        &#47&#47 mask: (batch, max_len, 1)
        mask = sequence_mask(
            sequence_length=length, max_len=target.size(1)).unsqueeze(2)
        losses<a id="change"> = </a>losses * mask.float()
        loss = <a id="change">losses.sum()</a> / (length.float().sum() * float(target.shape[2]))
        return loss
</code></pre><h3>After Change</h3><pre><code class='java'>
            loss: An average loss value masked by the length.
        
        &#47&#47 mask: (batch, max_len, 1)
        mask = <a id="change">sequence_mask(
            sequence_length=length, max_len=target.size(1)).unsqueeze(2).float()</a>
        mask = mask.expand_as(input)
        loss = functional.mse_loss(
            input * mask, target * mask, reduction="sum")
        loss = loss / mask.sum()</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/coqui-ai/tts/commit/4326582bb1e68480ef79a02abbf4bfacc3aadede#diff-e2062370456db62dc9af5481873d2fcfe1d6e8a959459063dd6233f61d3f66d5L53' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8568210</div><div id='project'> Project Name: coqui-ai/tts</div><div id='commit'> Commit Name: 4326582bb1e68480ef79a02abbf4bfacc3aadede</div><div id='time'> Time: 2019-03-06</div><div id='author'> Author: egolge@mozilla.com</div><div id='file'> File Name: layers/losses.py</div><div id='m_class'> M Class Name: MSELossMasked</div><div id='n_method'> N Class Name: MSELossMasked</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: layers/losses.py</div><div id='n_file'> N File Name: layers/losses.py</div><div id='m_start'> M Start Line: 53</div><div id='m_end'> M End Line: 70</div><div id='n_start'> N Start Line: 54</div><div id='n_end'> N End Line: 59</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            loss: An average loss value masked by the length.
        
        input = input.contiguous()
        <a id="change">target</a> = target.contiguous()

        &#47&#47 logits_flat: (batch * max_len, dim)
        input = input.view(-1, input.shape[-1])
        &#47&#47 target_flat: (batch * max_len, dim)
        target_flat = <a id="change">target.view(</a>-1, target.shape[-1]<a id="change">)</a>
        &#47&#47 losses_flat: (batch * max_len, dim)
        losses_flat = functional.mse_loss(
            input, target_flat, size_average=False, reduce=False)
        &#47&#47 losses: (batch, max_len, dim)
        losses<a id="change"> = </a>losses_flat.view(*<a id="change">target.size()</a>)

        &#47&#47 mask: (batch, max_len, 1)
        mask = sequence_mask(
            sequence_length=length, max_len=target.size(1)).unsqueeze(2)
        losses = losses * mask.float()
        loss = <a id="change">losses.sum()</a> / (length.float().sum() * float(target.shape[2]))
        return loss
</code></pre><h3>After Change</h3><pre><code class='java'>
            loss: An average loss value masked by the length.
        
        &#47&#47 mask: (batch, max_len, 1)
        mask = <a id="change">sequence_mask(
            sequence_length=length, max_len=target.size(1)).unsqueeze(2).float()</a>
        mask = mask.expand_as(input)
        loss = functional.mse_loss(
            input * mask, target * mask, reduction="sum")
        loss = loss / mask.sum()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/coqui-ai/tts/commit/4326582bb1e68480ef79a02abbf4bfacc3aadede#diff-e2062370456db62dc9af5481873d2fcfe1d6e8a959459063dd6233f61d3f66d5L39' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8568211</div><div id='project'> Project Name: coqui-ai/tts</div><div id='commit'> Commit Name: 4326582bb1e68480ef79a02abbf4bfacc3aadede</div><div id='time'> Time: 2019-03-06</div><div id='author'> Author: egolge@mozilla.com</div><div id='file'> File Name: layers/losses.py</div><div id='m_class'> M Class Name: MSELossMasked</div><div id='n_method'> N Class Name: MSELossMasked</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: layers/losses.py</div><div id='n_file'> N File Name: layers/losses.py</div><div id='m_start'> M Start Line: 53</div><div id='m_end'> M End Line: 70</div><div id='n_start'> N Start Line: 54</div><div id='n_end'> N End Line: 59</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        self.register_buffer("ema_weight", self.embedding.clone())

    def forward(self, x):
        B, C, L = <a id="change">x.size()</a>
        N, M, D = self.embedding.size()
        assert C == N * D

        x<a id="change"> = </a><a id="change">x.view(</a>B, N, D, L<a id="change">)</a>.permute(1, 0, 3, 2)  &#47&#47 N, B, L, D
        x_flat = x.detach().reshape(N, -1, D)

        distances = torch.cdist(x_flat, self.embedding)
        indices = torch.argmin(distances, dim=-1)

        encodings = F.one_hot(indices, M).float()
        quantized = torch.gather(self.embedding, 1, indices.unsqueeze(-1).expand(-1, -1, D))
        quantized = quantized.view_as(x)

        if self.training:
            self.ema_count = self.decay * self.ema_count + (1 - self.decay) * torch.sum(encodings, dim=1)

            n = torch.sum(self.ema_count, dim=-1, keepdim=True)
            self.ema_count = (self.ema_count + self.epsilon) / (n + M * self.epsilon) * n

            dw = torch.bmm(encodings.transpose(1, 2), x_flat)
            self.ema_weight = self.decay * self.ema_weight + (1 - self.decay) * dw

            self.embedding = self.ema_weight / self.ema_count.unsqueeze(-1)

        e_latent_loss = F.mse_loss(x, quantized.detach())
        loss = self.commitment_cost * e_latent_loss

        quantized = x + (quantized - x).detach()

        avg_probs = torch.mean(encodings, dim=1)
        perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs + 1e-10), dim=-1))

        return quantized.permute(1, 0, 3, 2).reshape(B, C, L), loss, <a id="change">perplexity.sum()</a>


class ChannelNorm(nn.Module):
    def __init__(self,</code></pre><h3>After Change</h3><pre><code class='java'>
                                x_flat, self.embedding.t(),
                                alpha=-2.0, beta=1.0)

        indices = torch.argmin(<a id="change">distances.float()</a>, dim=-1)
        encodings = F.one_hot(indices, M).float()
        quantized = F.embedding(indices, self.embedding)
        quantized = quantized.view_as(x)</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/bshall/vectorquantizedcpc/commit/535c95415d62ececde085e376f451b3b76e1b624#diff-fada037ad086638e65c7ae77e3d223963e9afaa26326aab0ea718f4013176e43L20' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8568208</div><div id='project'> Project Name: bshall/vectorquantizedcpc</div><div id='commit'> Commit Name: 535c95415d62ececde085e376f451b3b76e1b624</div><div id='time'> Time: 2020-05-01</div><div id='author'> Author: benji.l.shall@gmail.com</div><div id='file'> File Name: model.py</div><div id='m_class'> M Class Name: VQEmbeddingEMA</div><div id='n_method'> N Class Name: VQEmbeddingEMA</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: model.py</div><div id='n_file'> N File Name: model.py</div><div id='m_start'> M Start Line: 21</div><div id='m_end'> M End Line: 54</div><div id='n_start'> N Start Line: 81</div><div id='n_end'> N End Line: 112</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            loss: An average loss value masked by the length.
        
        input = input.contiguous()
        <a id="change">target</a> = target.contiguous()

        &#47&#47 logits_flat: (batch * max_len, dim)
        input = input.view(-1, input.shape[-1])
        &#47&#47 target_flat: (batch * max_len, dim)
        target_flat = <a id="change">target.view(</a>-1, target.shape[-1]<a id="change">)</a>
        &#47&#47 losses_flat: (batch * max_len, dim)
        losses_flat = functional.l1_loss(
            input, target_flat, size_average=False, reduce=False)
        &#47&#47 losses: (batch, max_len, dim)
        losses<a id="change"> = </a>losses_flat.view(*<a id="change">target.size()</a>)

        &#47&#47 mask: (batch, max_len, 1)
        mask = sequence_mask(
            sequence_length=length, max_len=target.size(1)).unsqueeze(2)
        losses = losses * mask.float()
        loss = <a id="change">losses.sum()</a> / (length.float().sum() * float(target.shape[2]))
        return loss

</code></pre><h3>After Change</h3><pre><code class='java'>
            loss: An average loss value masked by the length.
        
        &#47&#47 mask: (batch, max_len, 1)
        mask = <a id="change">sequence_mask(
            sequence_length=length, max_len=target.size(1)).unsqueeze(2).float()</a>
        mask = mask.expand_as(input)
        loss = functional.l1_loss(
            input * mask, target * mask, reduction="sum")
        loss = loss / mask.sum()</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/coqui-ai/tts/commit/a15b3ec9a18377bf67356a9b5c29f4b767001d05#diff-e2062370456db62dc9af5481873d2fcfe1d6e8a959459063dd6233f61d3f66d5L11' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8568215</div><div id='project'> Project Name: coqui-ai/tts</div><div id='commit'> Commit Name: a15b3ec9a18377bf67356a9b5c29f4b767001d05</div><div id='time'> Time: 2018-08-13</div><div id='author'> Author: erengolge@gmail.com</div><div id='file'> File Name: layers/losses.py</div><div id='m_class'> M Class Name: L1LossMasked</div><div id='n_method'> N Class Name: L1LossMasked</div><div id='m_method'> M Method Name: forward(4)</div><div id='n_method'> N Method Name: forward(4)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: layers/losses.py</div><div id='n_file'> N File Name: layers/losses.py</div><div id='m_start'> M Start Line: 25</div><div id='m_end'> M End Line: 42</div><div id='n_start'> N Start Line: 26</div><div id='n_end'> N End Line: 31</div><BR>