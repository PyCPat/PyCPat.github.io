<html><h3>Pattern ID :2682
</h3><img src='8781077.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
    def forward(self, x):
        if self.training:
            total_blocks = sum([len(sx) for sx in x])
            mask_size = torch.Size(<a id="change">[</a>total_blocks<a id="change"></a>])
            binomial = torch.distributions.binomial.Binomial(probs=1 - self.p)
            mask = binomial.sample(mask_size) * (1.0 / (1 - self.p))
            mask_id = 0
            for mod in x:
                for x_mod in mod:
                    x_mod<a id="change"> *= </a>mask[mask_id]
                    mask_id += 1
            return x, mask
        return x, None</code></pre><h3>After Change</h3><pre><code class='java'>
            mask_size = torch.Size([X[0].shape[0], sum(blocks_per_mod)])
            binomial = torch.distributions.binomial.Binomial(probs=1 - self.p)
            mask = binomial.sample(mask_size) * (1.0 / (1 - self.p))
            mask_shapes<a id="change"> = </a>[list(x.shape[:2]) + [1] * (x.dim() - 2) for x in X]
            grouped_masks = torch.split(mask, blocks_per_mod, dim=1)
            grouped_masks = [m.reshape(s) for m, s in zip(grouped_masks, mask_shapes)]
            X = <a id="change">[x * m for x, m in zip(X, grouped_masks)]</a>
            return X, grouped_masks
        return X, None

</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 6</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/anita-hu/msaf/commit/a2c91bd6e186680ca2c41bbf22c9b57aff4654d2#diff-d68e3105d0084e846106ad79a39721b487918159e4343a84f4ae68b3d6eadc0cL39' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8781077</div><div id='project'> Project Name: anita-hu/msaf</div><div id='commit'> Commit Name: a2c91bd6e186680ca2c41bbf22c9b57aff4654d2</div><div id='time'> Time: 2020-12-30</div><div id='author'> Author: anitahu113@gmail.com</div><div id='file'> File Name: MSAF.py</div><div id='m_class'> M Class Name: BlockDropout</div><div id='n_method'> N Class Name: BlockDropout</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: MSAF.py</div><div id='n_file'> N File Name: MSAF.py</div><div id='m_start'> M Start Line: 40</div><div id='m_end'> M End Line: 49</div><div id='n_start'> N Start Line: 39</div><div id='n_end'> N End Line: 47</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
        return nn.Sequential(*layers)

    def forward(self, x):  &#47&#47 224x224
        features<a id="change"> = </a><a id="change">[]</a>
        x = self.conv1(x)  &#47&#47 112x112
        features.append(x)
        x = self.bn1(x)
        x = self.relu(x)</code></pre><h3>After Change</h3><pre><code class='java'>
        Normalizing the features and applying spatial resolution was taken from LPIPS and wasn&quott mentioned in the paper.
        
        images = torch.concat([x, x_rec], dim=0)  &#47&#47 batch
        features<a id="change"> = </a>self._forward(images)
        features = [f.chunk(2) for f in features]
        &#47&#47 diffs = [a * torch.abs(p[0] - p[1]).sum() for a, p in zip(self.alphas, features)]
        diffs = <a id="change">[a * torch.abs(p[0] - p[1]).mean() for a, p in zip(self.alphas, features)]</a>
        &#47&#47 diffs = [a*torch.abs(self.norm_tensor(tf) - self.norm_tensor(rf)) for a, tf, rf in zip(self.alphas, true_features, rec_features)]

        &#47&#47 diffs = [a * torch.mean(torch.abs(tf - rf)) for a, tf, rf in zip(self.alphas, features)]</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/casualganpapers/make-a-scene/commit/89ba77e885ac1c12ac2d5df5a6b3da842e30bfe0#diff-1ccb21e596d4cb9b26cee32d3e64f968bb2dc277d3d4514cc0cfe9ff65e9ef08L126' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8781075</div><div id='project'> Project Name: casualganpapers/make-a-scene</div><div id='commit'> Commit Name: 89ba77e885ac1c12ac2d5df5a6b3da842e30bfe0</div><div id='time'> Time: 2022-05-26</div><div id='author'> Author: 61938694+dome272@users.noreply.github.com</div><div id='file'> File Name: losses/face_loss.py</div><div id='m_class'> M Class Name: ResNet</div><div id='n_method'> N Class Name: ResNet</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: losses/face_loss.py</div><div id='n_file'> N File Name: losses/face_loss.py</div><div id='m_start'> M Start Line: 127</div><div id='m_end'> M End Line: 151</div><div id='n_start'> N Start Line: 163</div><div id='n_end'> N End Line: 177</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
                    pass
                labels = [torch.cat([shared_label, item], 1) for item in zs[1:]]
            else:
                labels<a id="change"> = </a><a id="change">[</a>None<a id="change"></a>]*self.chunk_size

            act = self.linear0(z)
            act = act.view(-1, self.in_dims[0], self.bottom, self.bottom)</code></pre><h3>After Change</h3><pre><code class='java'>
        with torch.cuda.amp.autocast() if self.mixed_precision and not eval else misc.dummy_context_mgr() as mp:
            if self.MODEL.info_type != "N/A":
                if self.MODEL.g_info_injection == "concat":
                    z<a id="change"> = </a>self.info_mix_linear(z)
                elif self.MODEL.g_info_injection == "cBN":
                    z, z_info = z[:, :self.z_dim], z[:, self.z_dim:]
                    affine_list.append(self.info_proj_linear(z_info))

            zs = torch.split(z, self.chunk_size, 1)
            z = zs[0]
            if self.g_cond_mtd != "W/O":
                if shared_label is None:
                    shared_label = self.shared(label)
                affine_list.append(shared_label)
            if len(affine_list) == 0:
                affines = [item for item in zs[1:]]
            else:
                affines = <a id="change">[torch.cat(affine_list + [item], 1) for item in zs[1:]]</a>

            act = self.linear0(z)
            act = act.view(-1, self.in_dims[0], self.bottom, self.bottom)
            counter = 0</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/postech-cvlab/pytorch-studiogan/commit/43b43f14632f9d0b4e18b2d081908bbc7ae2d91d#diff-57419e1a2c2ed1ee4edbe3661a53420101a7cee3cc6d9bd1c86fa02dbc9a47bbL123' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 8781081</div><div id='project'> Project Name: postech-cvlab/pytorch-studiogan</div><div id='commit'> Commit Name: 43b43f14632f9d0b4e18b2d081908bbc7ae2d91d</div><div id='time'> Time: 2022-01-25</div><div id='author'> Author: joonghyuk4727@gmail.com</div><div id='file'> File Name: src/models/big_resnet.py</div><div id='m_class'> M Class Name: Generator</div><div id='n_method'> N Class Name: Generator</div><div id='m_method'> M Method Name: forward(5)</div><div id='n_method'> N Method Name: forward(5)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: src/models/big_resnet.py</div><div id='n_file'> N File Name: src/models/big_resnet.py</div><div id='m_start'> M Start Line: 125</div><div id='m_end'> M End Line: 134</div><div id='n_start'> N Start Line: 123</div><div id='n_end'> N End Line: 143</div><BR>