<html><h3>Pattern ID :1818
</h3><img src='7007754.png'><BR><BR><BR><link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            &#47&#47 Compute head probability distribution.
            logits = logits.softmax(-1)

        <a id="change">return </a>logits
</code></pre><h3>After Change</h3><pre><code class='java'>
        head_arc = self.dropout(self.activation(self.head_arc(x)))
        dependent_arc = self.dropout(self.activation(self.dependent_arc(x)))
        head_label = self.dropout(self.activation(self.head_label(x)))
        dependent_label = <a id="change">self.dropout(self</a><a id="change">.activation(</a>self.dependent_label(x)<a id="change">))</a>

        &#47&#47 Compute biaffine attention matrix. This computes from the hidden
        &#47&#47 representations of the shape [batch_size, seq_len, hidden_size] the
        &#47&#47 attention matrices [batch_size, seq_len, seq_len].
        logits_arc = self.bilinear_arc(head_arc, dependent_arc).squeeze(-1)

        logits_label<a id="change"> = </a>self.bilinear_label(head_label, dependent_label)

        &#47&#47 Mask out head candidates that are padding time steps. The logits mask
        &#47&#47 has shape [batch_size, seq_len], we reshape it to [batch_size, 1,
        &#47&#47 seq_len] to mask out the head predictions.
        logits_arc += logits_mask
        logits_label += logits_mask.unsqueeze(-1)

        if self.training:
            &#47&#47 Compute head probability distribution.
            logits_arc = logits_arc.softmax(-1)
            logits_label = logits_label.softmax(-1)

        <a id="change">return </a>logits_arc, logits_label
</code></pre><div id='inPattern'>In pattern: SUPERPATTERN</div><BR><div id='frequency'>Frequency: 3</div><BR><div id='size'>Non-data size: 5</div><BR><h3>Instances</h3><BR><div id='link'><a href='https://github.com/explosion/spacy-experimental/commit/b683b4eb3ceef19f7437cf420d5aa133b5aa5b89#diff-510501f7cb2d459202a440b1750a360ccbcdc4c5f42a0298478a064ab610aad0L91' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 7007754</div><div id='project'> Project Name: explosion/spacy-experimental</div><div id='commit'> Commit Name: b683b4eb3ceef19f7437cf420d5aa133b5aa5b89</div><div id='time'> Time: 2021-10-22</div><div id='author'> Author: me@danieldk.eu</div><div id='file'> File Name: biaffine_parser/pytorch_biaffine_model.py</div><div id='m_class'> M Class Name: BiaffineModel</div><div id='n_method'> N Class Name: BiaffineModel</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: biaffine_parser/pytorch_biaffine_model.py</div><div id='n_file'> N File Name: biaffine_parser/pytorch_biaffine_model.py</div><div id='m_start'> M Start Line: 91</div><div id='m_end'> M End Line: 108</div><div id='n_start'> N Start Line: 95</div><div id='n_end'> N End Line: 121</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
            &#47&#47 Compute head probability distribution.
            logits = logits.softmax(-1)

        <a id="change">return </a>logits
</code></pre><h3>After Change</h3><pre><code class='java'>
        head_arc = self.dropout(self.activation(self.head_arc(x)))
        dependent_arc = self.dropout(self.activation(self.dependent_arc(x)))
        head_label = self.dropout(self.activation(self.head_label(x)))
        dependent_label<a id="change"> = </a><a id="change">self.dropout(</a><a id="change">self.activation(</a>self.dependent_label(x)<a id="change">))</a>

        &#47&#47 Compute biaffine attention matrix. This computes from the hidden
        &#47&#47 representations of the shape [batch_size, seq_len, hidden_size] the
        &#47&#47 attention matrices [batch_size, seq_len, seq_len].
        logits_arc = self.bilinear_arc(head_arc, dependent_arc).squeeze(-1)

        logits_label = self.bilinear_label(head_label, dependent_label)

        &#47&#47 Mask out head candidates that are padding time steps. The logits mask
        &#47&#47 has shape [batch_size, seq_len], we reshape it to [batch_size, 1,
        &#47&#47 seq_len] to mask out the head predictions.
        logits_arc += logits_mask
        logits_label += logits_mask.unsqueeze(-1)

        if self.training:
            &#47&#47 Compute head probability distribution.
            logits_arc = logits_arc.softmax(-1)
            logits_label = logits_label.softmax(-1)

        <a id="change">return </a>logits_arc, logits_label
</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/explosion/spacy-experimental/commit/b683b4eb3ceef19f7437cf420d5aa133b5aa5b89#diff-510501f7cb2d459202a440b1750a360ccbcdc4c5f42a0298478a064ab610aad0L84' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 7007752</div><div id='project'> Project Name: explosion/spacy-experimental</div><div id='commit'> Commit Name: b683b4eb3ceef19f7437cf420d5aa133b5aa5b89</div><div id='time'> Time: 2021-10-22</div><div id='author'> Author: me@danieldk.eu</div><div id='file'> File Name: biaffine_parser/pytorch_biaffine_model.py</div><div id='m_class'> M Class Name: BiaffineModel</div><div id='n_method'> N Class Name: BiaffineModel</div><div id='m_method'> M Method Name: forward(3)</div><div id='n_method'> N Method Name: forward(3)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: biaffine_parser/pytorch_biaffine_model.py</div><div id='n_file'> N File Name: biaffine_parser/pytorch_biaffine_model.py</div><div id='m_start'> M Start Line: 91</div><div id='m_end'> M End Line: 108</div><div id='n_start'> N Start Line: 95</div><div id='n_end'> N End Line: 121</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>

    def forward(self, x):
        output = self.net(x)
        <a id="change">return </a>output


class Postnet(nn.Module):</code></pre><h3>After Change</h3><pre><code class='java'>
    def forward(self, x):
        o = self.convolution1d(x)
        o = self.batch_normalization(o)
        o = <a id="change">self.activation(</a>o<a id="change">)</a>
        o<a id="change"> = </a><a id="change">self.dropout(</a>o<a id="change">)</a>
        <a id="change">return </a>o


class Postnet(nn.Module):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/coqui-ai/tts/commit/d282222553c97821f1028495fb7161d2f60b491d#diff-98fd28c1559c72435d1c59024b2baa25ece39483c2196f2377bfc9ee6c7f183bL26' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 7007743</div><div id='project'> Project Name: coqui-ai/tts</div><div id='commit'> Commit Name: d282222553c97821f1028495fb7161d2f60b491d</div><div id='time'> Time: 2020-05-12</div><div id='author'> Author: erogol@hotmail.com</div><div id='file'> File Name: layers/tacotron2.py</div><div id='m_class'> M Class Name: ConvBNBlock</div><div id='n_method'> N Class Name: ConvBNBlock</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: layers/tacotron2.py</div><div id='n_file'> N File Name: layers/tacotron2.py</div><div id='m_start'> M Start Line: 27</div><div id='m_end'> M End Line: 28</div><div id='n_start'> N Start Line: 27</div><div id='n_end'> N End Line: 31</div><BR>'><BR><BR><BR><h3>Before Change</h3><pre><code class='java'>
    def forward(self, x):
        out = self.stem(x)

        <a id="change">return </a>out

class NFBlock(nn.Module):
    def __init__(self, in_channels, out_channels, expansion=0.5, se_ratio=0.5, stride=1, beta=1.0, alpha=0.2, big_width=True):</code></pre><h3>After Change</h3><pre><code class='java'>
    def forward(self, x):
        out = self.stem(x)
        out = self.body(out)
        out = <a id="change">self.activation(</a>self.final_conv(out)<a id="change">)</a>

        pool = torch.mean(out, dim=(2,3))

        if self.training:
            pool<a id="change"> = </a><a id="change">self.dropout(</a>pool<a id="change">)</a>

        <a id="change">return </a>self.fc(pool)

class NFBlock(nn.Module):
    def __init__(self, in_channels, out_channels, expansion=0.5, se_ratio=0.5, stride=1, beta=1.0, alpha=0.2, big_width=True):</code></pre>'><BR><BR><BR><BR><div id='link'><a href='https://github.com/benjs/nfnets_pytorch/commit/a8603ff5081bcee8c6d027d30c01002d8864dc1c#diff-fada037ad086638e65c7ae77e3d223963e9afaa26326aab0ea718f4013176e43L95' target='_blank'>Link</a></div><div id='fragmentid'> Fragment ID: 7007746</div><div id='project'> Project Name: benjs/nfnets_pytorch</div><div id='commit'> Commit Name: a8603ff5081bcee8c6d027d30c01002d8864dc1c</div><div id='time'> Time: 2021-02-15</div><div id='author'> Author: benjs@benjs.de</div><div id='file'> File Name: model.py</div><div id='m_class'> M Class Name: NFNet</div><div id='n_method'> N Class Name: NFNet</div><div id='m_method'> M Method Name: forward(2)</div><div id='n_method'> N Method Name: forward(2)</div><div id='m_parent_class'> M Parent Class: nn.Module</div><div id='n_parent_class'> N Parent Class: nn.Module</div><div id='m_file'> M File Name: model.py</div><div id='n_file'> N File Name: model.py</div><div id='m_start'> M Start Line: 96</div><div id='m_end'> M End Line: 98</div><div id='n_start'> N Start Line: 119</div><div id='n_end'> N End Line: 128</div><BR>